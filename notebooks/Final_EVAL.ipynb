{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bac7eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure these indices do not collide with existing ones, the indices will be wiped clean before data is inserted\n",
    "doc_index = \"squad_docs\"\n",
    "label_index = \"squad_labels\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae61e32",
   "metadata": {},
   "source": [
    "# 200 split_lenght\n",
    "\n",
    "Estos eran los parametros por defecto encontrados en los tutoriales de haystack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c686034",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = ['model_1', 'model_2', 'model_3', 'model_4', 'model_5', 'model_6', 'model_7', 'model_8', 'model_9'\n",
    "             ,'model_10', 'model_1', 'base_model', 'old_base_model', 'bm25']\n",
    "\n",
    "test_200_map = []\n",
    "test_200_recall = []\n",
    "dev_200_map = []\n",
    "dev_200_recall = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c935ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.document_stores.base -  Numba not found, replacing njit() with no-op implementation. Enable it with 'pip install numba'.\n",
      "INFO - haystack.modeling.model.optimization -  apex not found, won't use it. See https://nvidia.github.io/apex/\n",
      "ERROR - root -  Failed to import 'magic' (from 'python-magic' and 'python-magic-bin' on Windows). FileTypeClassifier will not perform mimetype detection on extensionless files. Please make sure the necessary OS libraries are installed if you need this functionality.\n",
      "/home/heider/Codes/thesis_v4/env/lib/python3.8/site-packages/elasticsearch/connection/base.py:190: ElasticsearchDeprecationWarning: Elasticsearch built-in security features are not enabled. Without authentication, your cluster could be accessible to anyone. See https://www.elastic.co/guide/en/elasticsearch/reference/7.13/security-minimal-setup.html to enable security.\n",
      "  warnings.warn(message, category=ElasticsearchDeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Connect to Elasticsearch\n",
    "# docker start es01-test -a\n",
    "from haystack.document_stores import ElasticsearchDocumentStore\n",
    "\n",
    "document_store = ElasticsearchDocumentStore(\n",
    "    host=\"localhost\",\n",
    "    username=\"\",\n",
    "    password=\"\",\n",
    "    index=doc_index,\n",
    "    label_index=label_index,\n",
    "    embedding_field=\"emb\",\n",
    "    embedding_dim=768,\n",
    "    excluded_meta_data=[\"emb\"],\n",
    ")\n",
    "\n",
    "from haystack.nodes import PreProcessor\n",
    "\n",
    "document_store.delete_documents(index=doc_index)\n",
    "document_store.delete_documents(index=label_index)\n",
    "\n",
    "preprocessor = PreProcessor(\n",
    "    split_length=200,\n",
    "    split_by=\"word\",\n",
    "    split_overlap=0,\n",
    "    split_respect_sentence_boundary=False,\n",
    "    clean_empty_lines=False,\n",
    "    clean_whitespace=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effb3c53",
   "metadata": {},
   "source": [
    "## Model 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9117c379",
   "metadata": {},
   "source": [
    "### Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "168d73cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - haystack.document_stores.utils -  No title information found for documents in QA file: squad_format_thesis/test.json\n"
     ]
    }
   ],
   "source": [
    "# The add_eval_data() method converts the given dataset in json format into Haystack document and label objects. Those objects are then indexed in their respective document and label index in the document store. The method can be used with any dataset in SQuAD format.\n",
    "document_store.add_eval_data(\n",
    "    filename=\"squad_format_thesis/test.json\",\n",
    "    doc_index=doc_index,\n",
    "    label_index=label_index,\n",
    "    preprocessor=preprocessor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78e4782c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.modeling.utils -  Using devices: CUDA:0\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 1\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_1/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_1/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_1/passage_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_1/passage_encoder\n",
      "INFO - haystack.nodes.retriever.dense -  DPR model loaded from models/model_1\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import DensePassageRetriever\n",
    "\n",
    "save_dir = \"models/model_1\"\n",
    "\n",
    "retriever = DensePassageRetriever.load(load_dir=save_dir, document_store=document_store, use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23311ddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.document_stores.elasticsearch -  Updating embeddings for all 651 docs ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8468419e56044760a240a7121c5aad04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Updating embeddings:   0%|          | 0/651 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Create embeddings:   0%|          | 0/656 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "document_store.update_embeddings(retriever, index=doc_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "572b8b27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.nodes.retriever.base -  Performing eval queries...\n",
      "100%|███████████████████████████████████████████| 25/25 [00:00<00:00, 66.70it/s]\n",
      "INFO - haystack.nodes.retriever.base -  For 16 out of 25 questions (64.00%), the answer was in the top-10 candidate passages selected by the retriever.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retriever Recall: 0.64\n",
      "Retriever Mean Avg Precision: 0.4063333333333333\n"
     ]
    }
   ],
   "source": [
    "## Evaluate Retriever on its own # THIS IS THE FINE-TUNED model_1\n",
    "# Note that no_answer samples are omitted when evaluation is performed with this method\n",
    "retriever_eval_results = retriever.eval(top_k=10, label_index=label_index, doc_index=doc_index, open_domain=True)\n",
    "# Retriever Recall is the proportion of questions for which the correct document containing the answer is\n",
    "# among the correct documents\n",
    "print(\"Retriever Recall:\", retriever_eval_results[\"recall\"])\n",
    "test_200_recall.append(retriever_eval_results[\"recall\"])\n",
    "# Retriever Mean Avg Precision rewards retrievers that give relevant documents a higher rank\n",
    "print(\"Retriever Mean Avg Precision:\", retriever_eval_results[\"map\"])\n",
    "test_200_map.append(retriever_eval_results[\"map\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd29874",
   "metadata": {},
   "source": [
    "### Dev set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d04bc827",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_store.delete_documents(index=doc_index)\n",
    "document_store.delete_documents(index=label_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d32ee5a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - haystack.document_stores.utils -  No title information found for documents in QA file: squad_format_thesis/dev.json\n"
     ]
    }
   ],
   "source": [
    "# The add_eval_data() method converts the given dataset in json format into Haystack document and label objects. Those objects are then indexed in their respective document and label index in the document store. The method can be used with any dataset in SQuAD format.\n",
    "document_store.add_eval_data(\n",
    "    filename=\"squad_format_thesis/dev.json\",\n",
    "    doc_index=doc_index,\n",
    "    label_index=label_index,\n",
    "    preprocessor=preprocessor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf8f9bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.modeling.utils -  Using devices: CUDA:0\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 1\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_1/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_1/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_1/passage_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_1/passage_encoder\n",
      "INFO - haystack.nodes.retriever.dense -  DPR model loaded from models/model_1\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import DensePassageRetriever\n",
    "\n",
    "save_dir = \"models/model_1\"\n",
    "\n",
    "retriever = DensePassageRetriever.load(load_dir=save_dir, document_store=document_store, use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dac73b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.document_stores.elasticsearch -  Updating embeddings for all 608 docs ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1487c639dfd14274a80d7a407495d7b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Updating embeddings:   0%|          | 0/608 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Create embeddings:   0%|          | 0/608 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "document_store.update_embeddings(retriever, index=doc_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f6c76ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.nodes.retriever.base -  Performing eval queries...\n",
      "100%|███████████████████████████████████████████| 24/24 [00:00<00:00, 80.99it/s]\n",
      "INFO - haystack.nodes.retriever.base -  For 18 out of 24 questions (75.00%), the answer was in the top-10 candidate passages selected by the retriever.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retriever Recall: 0.75\n",
      "Retriever Mean Avg Precision: 0.3371527777777778\n"
     ]
    }
   ],
   "source": [
    "## Evaluate Retriever on its own # THIS IS THE FINE-TUNED model_1\n",
    "# Note that no_answer samples are omitted when evaluation is performed with this method\n",
    "retriever_eval_results = retriever.eval(top_k=10, label_index=label_index, doc_index=doc_index, open_domain=True)\n",
    "# Retriever Recall is the proportion of questions for which the correct document containing the answer is\n",
    "# among the correct documents\n",
    "print(\"Retriever Recall:\", retriever_eval_results[\"recall\"])\n",
    "dev_200_recall.append(retriever_eval_results[\"recall\"])\n",
    "# Retriever Mean Avg Precision rewards retrievers that give relevant documents a higher rank\n",
    "print(\"Retriever Mean Avg Precision:\", retriever_eval_results[\"map\"])\n",
    "dev_200_map.append(retriever_eval_results[\"map\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2994bf8",
   "metadata": {},
   "source": [
    "## Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6212f7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_store.delete_documents(index=doc_index)\n",
    "document_store.delete_documents(index=label_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775d416b",
   "metadata": {},
   "source": [
    "### Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4943d867",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - haystack.document_stores.utils -  No title information found for documents in QA file: squad_format_thesis/test.json\n"
     ]
    }
   ],
   "source": [
    "# The add_eval_data() method converts the given dataset in json format into Haystack document and label objects. Those objects are then indexed in their respective document and label index in the document store. The method can be used with any dataset in SQuAD format.\n",
    "document_store.add_eval_data(\n",
    "    filename=\"squad_format_thesis/test.json\",\n",
    "    doc_index=doc_index,\n",
    "    label_index=label_index,\n",
    "    preprocessor=preprocessor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f22efb5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.modeling.utils -  Using devices: CUDA:0\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 1\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_2/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_2/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_2/passage_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_2/passage_encoder\n",
      "INFO - haystack.nodes.retriever.dense -  DPR model loaded from models/model_2\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import DensePassageRetriever\n",
    "\n",
    "save_dir = \"models/model_2\"\n",
    "\n",
    "retriever = DensePassageRetriever.load(load_dir=save_dir, document_store=document_store, use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "84db62d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.document_stores.elasticsearch -  Updating embeddings for all 651 docs ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab12278bbd134aefb8b646b01aca9666",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Updating embeddings:   0%|          | 0/651 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Create embeddings:   0%|          | 0/656 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "document_store.update_embeddings(retriever, index=doc_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6004242a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.nodes.retriever.base -  Performing eval queries...\n",
      "100%|███████████████████████████████████████████| 25/25 [00:00<00:00, 73.41it/s]\n",
      "INFO - haystack.nodes.retriever.base -  For 20 out of 25 questions (80.00%), the answer was in the top-10 candidate passages selected by the retriever.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retriever Recall: 0.8\n",
      "Retriever Mean Avg Precision: 0.5023809523809525\n"
     ]
    }
   ],
   "source": [
    "## Evaluate Retriever on its own # THIS IS THE FINE-TUNED model_1\n",
    "# Note that no_answer samples are omitted when evaluation is performed with this method\n",
    "retriever_eval_results = retriever.eval(top_k=10, label_index=label_index, doc_index=doc_index, open_domain=True)\n",
    "# Retriever Recall is the proportion of questions for which the correct document containing the answer is\n",
    "# among the correct documents\n",
    "print(\"Retriever Recall:\", retriever_eval_results[\"recall\"])\n",
    "test_200_recall.append(retriever_eval_results[\"recall\"])\n",
    "# Retriever Mean Avg Precision rewards retrievers that give relevant documents a higher rank\n",
    "print(\"Retriever Mean Avg Precision:\", retriever_eval_results[\"map\"])\n",
    "test_200_map.append(retriever_eval_results[\"map\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b001c4",
   "metadata": {},
   "source": [
    "### Dev set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "68d5aace",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_store.delete_documents(index=doc_index)\n",
    "document_store.delete_documents(index=label_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e4de95f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - haystack.document_stores.utils -  No title information found for documents in QA file: squad_format_thesis/dev.json\n"
     ]
    }
   ],
   "source": [
    "# The add_eval_data() method converts the given dataset in json format into Haystack document and label objects. Those objects are then indexed in their respective document and label index in the document store. The method can be used with any dataset in SQuAD format.\n",
    "document_store.add_eval_data(\n",
    "    filename=\"squad_format_thesis/dev.json\",\n",
    "    doc_index=doc_index,\n",
    "    label_index=label_index,\n",
    "    preprocessor=preprocessor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1502c19b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.modeling.utils -  Using devices: CUDA:0\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 1\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_2/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_2/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_2/passage_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_2/passage_encoder\n",
      "INFO - haystack.nodes.retriever.dense -  DPR model loaded from models/model_2\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import DensePassageRetriever\n",
    "\n",
    "save_dir = \"models/model_2\"\n",
    "\n",
    "retriever = DensePassageRetriever.load(load_dir=save_dir, document_store=document_store, use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ad135352",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.document_stores.elasticsearch -  Updating embeddings for all 608 docs ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "009ed57f632f4ad3a12a9f964d9adcdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Updating embeddings:   0%|          | 0/608 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Create embeddings:   0%|          | 0/608 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "document_store.update_embeddings(retriever, index=doc_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ba786c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.nodes.retriever.base -  Performing eval queries...\n",
      "100%|███████████████████████████████████████████| 24/24 [00:00<00:00, 67.17it/s]\n",
      "INFO - haystack.nodes.retriever.base -  For 19 out of 24 questions (79.17%), the answer was in the top-10 candidate passages selected by the retriever.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retriever Recall: 0.7916666666666666\n",
      "Retriever Mean Avg Precision: 0.50625\n"
     ]
    }
   ],
   "source": [
    "## Evaluate Retriever on its own # THIS IS THE FINE-TUNED model_1\n",
    "# Note that no_answer samples are omitted when evaluation is performed with this method\n",
    "retriever_eval_results = retriever.eval(top_k=10, label_index=label_index, doc_index=doc_index, open_domain=True)\n",
    "# Retriever Recall is the proportion of questions for which the correct document containing the answer is\n",
    "# among the correct documents\n",
    "print(\"Retriever Recall:\", retriever_eval_results[\"recall\"])\n",
    "dev_200_recall.append(retriever_eval_results[\"recall\"])\n",
    "# Retriever Mean Avg Precision rewards retrievers that give relevant documents a higher rank\n",
    "print(\"Retriever Mean Avg Precision:\", retriever_eval_results[\"map\"])\n",
    "dev_200_map.append(retriever_eval_results[\"map\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859b3b99",
   "metadata": {},
   "source": [
    "## Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3af4fb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_store.delete_documents(index=doc_index)\n",
    "document_store.delete_documents(index=label_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75f32e3",
   "metadata": {},
   "source": [
    "### Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f99efe24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - haystack.document_stores.utils -  No title information found for documents in QA file: squad_format_thesis/test.json\n"
     ]
    }
   ],
   "source": [
    "# The add_eval_data() method converts the given dataset in json format into Haystack document and label objects. Those objects are then indexed in their respective document and label index in the document store. The method can be used with any dataset in SQuAD format.\n",
    "document_store.add_eval_data(\n",
    "    filename=\"squad_format_thesis/test.json\",\n",
    "    doc_index=doc_index,\n",
    "    label_index=label_index,\n",
    "    preprocessor=preprocessor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "381e99d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.modeling.utils -  Using devices: CUDA:0\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 1\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_3/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_3/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_3/passage_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_3/passage_encoder\n",
      "INFO - haystack.nodes.retriever.dense -  DPR model loaded from models/model_3\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import DensePassageRetriever\n",
    "\n",
    "save_dir = \"models/model_3\"\n",
    "\n",
    "retriever = DensePassageRetriever.load(load_dir=save_dir, document_store=document_store, use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "64b5b178",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.document_stores.elasticsearch -  Updating embeddings for all 651 docs ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d204bc8fd8f4a33b557391f4cf30673",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Updating embeddings:   0%|          | 0/651 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Create embeddings:   0%|          | 0/656 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "document_store.update_embeddings(retriever, index=doc_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d6d9de1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.nodes.retriever.base -  Performing eval queries...\n",
      "100%|███████████████████████████████████████████| 25/25 [00:00<00:00, 61.32it/s]\n",
      "INFO - haystack.nodes.retriever.base -  For 18 out of 25 questions (72.00%), the answer was in the top-10 candidate passages selected by the retriever.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retriever Recall: 0.72\n",
      "Retriever Mean Avg Precision: 0.4754920634920636\n"
     ]
    }
   ],
   "source": [
    "## Evaluate Retriever on its own # THIS IS THE FINE-TUNED model_1\n",
    "# Note that no_answer samples are omitted when evaluation is performed with this method\n",
    "retriever_eval_results = retriever.eval(top_k=10, label_index=label_index, doc_index=doc_index, open_domain=True)\n",
    "# Retriever Recall is the proportion of questions for which the correct document containing the answer is\n",
    "# among the correct documents\n",
    "print(\"Retriever Recall:\", retriever_eval_results[\"recall\"])\n",
    "test_200_recall.append(retriever_eval_results[\"recall\"])\n",
    "# Retriever Mean Avg Precision rewards retrievers that give relevant documents a higher rank\n",
    "print(\"Retriever Mean Avg Precision:\", retriever_eval_results[\"map\"])\n",
    "test_200_map.append(retriever_eval_results[\"map\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89ff17d",
   "metadata": {},
   "source": [
    "### Dev set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bedadc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_store.delete_documents(index=doc_index)\n",
    "document_store.delete_documents(index=label_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3e5d124b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - haystack.document_stores.utils -  No title information found for documents in QA file: squad_format_thesis/dev.json\n"
     ]
    }
   ],
   "source": [
    "# The add_eval_data() method converts the given dataset in json format into Haystack document and label objects. Those objects are then indexed in their respective document and label index in the document store. The method can be used with any dataset in SQuAD format.\n",
    "document_store.add_eval_data(\n",
    "    filename=\"squad_format_thesis/dev.json\",\n",
    "    doc_index=doc_index,\n",
    "    label_index=label_index,\n",
    "    preprocessor=preprocessor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eb613257",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.modeling.utils -  Using devices: CUDA:0\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 1\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_3/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_3/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_3/passage_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_3/passage_encoder\n",
      "INFO - haystack.nodes.retriever.dense -  DPR model loaded from models/model_3\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import DensePassageRetriever\n",
    "\n",
    "save_dir = \"models/model_3\"\n",
    "\n",
    "retriever = DensePassageRetriever.load(load_dir=save_dir, document_store=document_store, use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "292d7fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.document_stores.elasticsearch -  Updating embeddings for all 608 docs ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4632eeb92534e7391375ff2c7516698",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Updating embeddings:   0%|          | 0/608 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Create embeddings:   0%|          | 0/608 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "document_store.update_embeddings(retriever, index=doc_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4d1a4d4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.nodes.retriever.base -  Performing eval queries...\n",
      "100%|███████████████████████████████████████████| 24/24 [00:00<00:00, 81.74it/s]\n",
      "INFO - haystack.nodes.retriever.base -  For 18 out of 24 questions (75.00%), the answer was in the top-10 candidate passages selected by the retriever.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retriever Recall: 0.75\n",
      "Retriever Mean Avg Precision: 0.373015873015873\n"
     ]
    }
   ],
   "source": [
    "## Evaluate Retriever on its own # THIS IS THE FINE-TUNED model_1\n",
    "# Note that no_answer samples are omitted when evaluation is performed with this method\n",
    "retriever_eval_results = retriever.eval(top_k=10, label_index=label_index, doc_index=doc_index, open_domain=True)\n",
    "# Retriever Recall is the proportion of questions for which the correct document containing the answer is\n",
    "# among the correct documents\n",
    "print(\"Retriever Recall:\", retriever_eval_results[\"recall\"])\n",
    "dev_200_recall.append(retriever_eval_results[\"recall\"])\n",
    "# Retriever Mean Avg Precision rewards retrievers that give relevant documents a higher rank\n",
    "print(\"Retriever Mean Avg Precision:\", retriever_eval_results[\"map\"])\n",
    "dev_200_map.append(retriever_eval_results[\"map\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb0f6ab",
   "metadata": {},
   "source": [
    "## Model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "178be1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_store.delete_documents(index=doc_index)\n",
    "document_store.delete_documents(index=label_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a015b7",
   "metadata": {},
   "source": [
    "### Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a189c6d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - haystack.document_stores.utils -  No title information found for documents in QA file: squad_format_thesis/test.json\n"
     ]
    }
   ],
   "source": [
    "# The add_eval_data() method converts the given dataset in json format into Haystack document and label objects. Those objects are then indexed in their respective document and label index in the document store. The method can be used with any dataset in SQuAD format.\n",
    "document_store.add_eval_data(\n",
    "    filename=\"squad_format_thesis/test.json\",\n",
    "    doc_index=doc_index,\n",
    "    label_index=label_index,\n",
    "    preprocessor=preprocessor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "83c7720e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.modeling.utils -  Using devices: CUDA:0\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 1\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_4/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_4/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_4/passage_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_4/passage_encoder\n",
      "INFO - haystack.nodes.retriever.dense -  DPR model loaded from models/model_4\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import DensePassageRetriever\n",
    "\n",
    "save_dir = \"models/model_4\"\n",
    "\n",
    "retriever = DensePassageRetriever.load(load_dir=save_dir, document_store=document_store, use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "53b02ab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.document_stores.elasticsearch -  Updating embeddings for all 651 docs ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4faa2f6bdab4db881ea7010ee0bb5d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Updating embeddings:   0%|          | 0/651 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Create embeddings:   0%|          | 0/656 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "document_store.update_embeddings(retriever, index=doc_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "84aca774",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.nodes.retriever.base -  Performing eval queries...\n",
      "100%|███████████████████████████████████████████| 25/25 [00:00<00:00, 77.24it/s]\n",
      "INFO - haystack.nodes.retriever.base -  For 15 out of 25 questions (60.00%), the answer was in the top-10 candidate passages selected by the retriever.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retriever Recall: 0.6\n",
      "Retriever Mean Avg Precision: 0.3734920634920635\n"
     ]
    }
   ],
   "source": [
    "## Evaluate Retriever on its own # THIS IS THE FINE-TUNED model_1\n",
    "# Note that no_answer samples are omitted when evaluation is performed with this method\n",
    "retriever_eval_results = retriever.eval(top_k=10, label_index=label_index, doc_index=doc_index, open_domain=True)\n",
    "# Retriever Recall is the proportion of questions for which the correct document containing the answer is\n",
    "# among the correct documents\n",
    "print(\"Retriever Recall:\", retriever_eval_results[\"recall\"])\n",
    "test_200_recall.append(retriever_eval_results[\"recall\"])\n",
    "# Retriever Mean Avg Precision rewards retrievers that give relevant documents a higher rank\n",
    "print(\"Retriever Mean Avg Precision:\", retriever_eval_results[\"map\"])\n",
    "test_200_map.append(retriever_eval_results[\"map\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127b2dfb",
   "metadata": {},
   "source": [
    "### Dev set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0d3c23bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_store.delete_documents(index=doc_index)\n",
    "document_store.delete_documents(index=label_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "92b449cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - haystack.document_stores.utils -  No title information found for documents in QA file: squad_format_thesis/dev.json\n"
     ]
    }
   ],
   "source": [
    "# The add_eval_data() method converts the given dataset in json format into Haystack document and label objects. Those objects are then indexed in their respective document and label index in the document store. The method can be used with any dataset in SQuAD format.\n",
    "document_store.add_eval_data(\n",
    "    filename=\"squad_format_thesis/dev.json\",\n",
    "    doc_index=doc_index,\n",
    "    label_index=label_index,\n",
    "    preprocessor=preprocessor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "90164594",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.modeling.utils -  Using devices: CUDA:0\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 1\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_4/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_4/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_4/passage_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_4/passage_encoder\n",
      "INFO - haystack.nodes.retriever.dense -  DPR model loaded from models/model_4\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import DensePassageRetriever\n",
    "\n",
    "save_dir = \"models/model_4\"\n",
    "\n",
    "retriever = DensePassageRetriever.load(load_dir=save_dir, document_store=document_store, use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "aa38e9c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.document_stores.elasticsearch -  Updating embeddings for all 608 docs ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e1a6fff2a274e87b900a845a1b28a0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Updating embeddings:   0%|          | 0/608 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Create embeddings:   0%|          | 0/608 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "document_store.update_embeddings(retriever, index=doc_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a63f1312",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.nodes.retriever.base -  Performing eval queries...\n",
      "100%|███████████████████████████████████████████| 24/24 [00:00<00:00, 78.57it/s]\n",
      "INFO - haystack.nodes.retriever.base -  For 17 out of 24 questions (70.83%), the answer was in the top-10 candidate passages selected by the retriever.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retriever Recall: 0.7083333333333334\n",
      "Retriever Mean Avg Precision: 0.2785714285714286\n"
     ]
    }
   ],
   "source": [
    "## Evaluate Retriever on its own # THIS IS THE FINE-TUNED model_1\n",
    "# Note that no_answer samples are omitted when evaluation is performed with this method\n",
    "retriever_eval_results = retriever.eval(top_k=10, label_index=label_index, doc_index=doc_index, open_domain=True)\n",
    "# Retriever Recall is the proportion of questions for which the correct document containing the answer is\n",
    "# among the correct documents\n",
    "print(\"Retriever Recall:\", retriever_eval_results[\"recall\"])\n",
    "dev_200_recall.append(retriever_eval_results[\"recall\"])\n",
    "# Retriever Mean Avg Precision rewards retrievers that give relevant documents a higher rank\n",
    "print(\"Retriever Mean Avg Precision:\", retriever_eval_results[\"map\"])\n",
    "dev_200_map.append(retriever_eval_results[\"map\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7bc91a",
   "metadata": {},
   "source": [
    "## Model 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1a402ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_store.delete_documents(index=doc_index)\n",
    "document_store.delete_documents(index=label_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc248ae",
   "metadata": {},
   "source": [
    "### Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fd70a2b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - haystack.document_stores.utils -  No title information found for documents in QA file: squad_format_thesis/test.json\n"
     ]
    }
   ],
   "source": [
    "# The add_eval_data() method converts the given dataset in json format into Haystack document and label objects. Those objects are then indexed in their respective document and label index in the document store. The method can be used with any dataset in SQuAD format.\n",
    "document_store.add_eval_data(\n",
    "    filename=\"squad_format_thesis/test.json\",\n",
    "    doc_index=doc_index,\n",
    "    label_index=label_index,\n",
    "    preprocessor=preprocessor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fed28d58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.modeling.utils -  Using devices: CUDA:0\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 1\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_5/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_5/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_5/passage_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_5/passage_encoder\n",
      "INFO - haystack.nodes.retriever.dense -  DPR model loaded from models/model_5\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import DensePassageRetriever\n",
    "\n",
    "save_dir = \"models/model_5\"\n",
    "\n",
    "retriever = DensePassageRetriever.load(load_dir=save_dir, document_store=document_store, use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "980ceb7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.document_stores.elasticsearch -  Updating embeddings for all 651 docs ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7974c89c6226498ca17670e9c7b6cf1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Updating embeddings:   0%|          | 0/651 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Create embeddings:   0%|          | 0/656 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "document_store.update_embeddings(retriever, index=doc_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "57fcbe0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.nodes.retriever.base -  Performing eval queries...\n",
      "100%|███████████████████████████████████████████| 25/25 [00:00<00:00, 82.83it/s]\n",
      "INFO - haystack.nodes.retriever.base -  For 21 out of 25 questions (84.00%), the answer was in the top-10 candidate passages selected by the retriever.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retriever Recall: 0.84\n",
      "Retriever Mean Avg Precision: 0.5166666666666667\n"
     ]
    }
   ],
   "source": [
    "## Evaluate Retriever on its own # THIS IS THE FINE-TUNED model_1\n",
    "# Note that no_answer samples are omitted when evaluation is performed with this method\n",
    "retriever_eval_results = retriever.eval(top_k=10, label_index=label_index, doc_index=doc_index, open_domain=True)\n",
    "# Retriever Recall is the proportion of questions for which the correct document containing the answer is\n",
    "# among the correct documents\n",
    "print(\"Retriever Recall:\", retriever_eval_results[\"recall\"])\n",
    "test_200_recall.append(retriever_eval_results[\"recall\"])\n",
    "# Retriever Mean Avg Precision rewards retrievers that give relevant documents a higher rank\n",
    "print(\"Retriever Mean Avg Precision:\", retriever_eval_results[\"map\"])\n",
    "test_200_map.append(retriever_eval_results[\"map\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b57d10d",
   "metadata": {},
   "source": [
    "### Dev set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0484c470",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_store.delete_documents(index=doc_index)\n",
    "document_store.delete_documents(index=label_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6a7e5751",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - haystack.document_stores.utils -  No title information found for documents in QA file: squad_format_thesis/dev.json\n"
     ]
    }
   ],
   "source": [
    "# The add_eval_data() method converts the given dataset in json format into Haystack document and label objects. Those objects are then indexed in their respective document and label index in the document store. The method can be used with any dataset in SQuAD format.\n",
    "document_store.add_eval_data(\n",
    "    filename=\"squad_format_thesis/dev.json\",\n",
    "    doc_index=doc_index,\n",
    "    label_index=label_index,\n",
    "    preprocessor=preprocessor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d2e2acc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.modeling.utils -  Using devices: CUDA:0\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 1\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_5/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_5/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_5/passage_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_5/passage_encoder\n",
      "INFO - haystack.nodes.retriever.dense -  DPR model loaded from models/model_5\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import DensePassageRetriever\n",
    "\n",
    "save_dir = \"models/model_5\"\n",
    "\n",
    "retriever = DensePassageRetriever.load(load_dir=save_dir, document_store=document_store, use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f80e29be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.document_stores.elasticsearch -  Updating embeddings for all 608 docs ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a26a30e5cf1b4119a7e330a16eca6d7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Updating embeddings:   0%|          | 0/608 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Create embeddings:   0%|          | 0/608 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "document_store.update_embeddings(retriever, index=doc_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cad147a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.nodes.retriever.base -  Performing eval queries...\n",
      "100%|███████████████████████████████████████████| 24/24 [00:00<00:00, 76.00it/s]\n",
      "INFO - haystack.nodes.retriever.base -  For 20 out of 24 questions (83.33%), the answer was in the top-10 candidate passages selected by the retriever.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retriever Recall: 0.8333333333333334\n",
      "Retriever Mean Avg Precision: 0.5385912698412699\n"
     ]
    }
   ],
   "source": [
    "## Evaluate Retriever on its own # THIS IS THE FINE-TUNED model_1\n",
    "# Note that no_answer samples are omitted when evaluation is performed with this method\n",
    "retriever_eval_results = retriever.eval(top_k=10, label_index=label_index, doc_index=doc_index, open_domain=True)\n",
    "# Retriever Recall is the proportion of questions for which the correct document containing the answer is\n",
    "# among the correct documents\n",
    "print(\"Retriever Recall:\", retriever_eval_results[\"recall\"])\n",
    "dev_200_recall.append(retriever_eval_results[\"recall\"])\n",
    "# Retriever Mean Avg Precision rewards retrievers that give relevant documents a higher rank\n",
    "print(\"Retriever Mean Avg Precision:\", retriever_eval_results[\"map\"])\n",
    "dev_200_map.append(retriever_eval_results[\"map\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b55681",
   "metadata": {},
   "source": [
    "## Model 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "16f0c1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_store.delete_documents(index=doc_index)\n",
    "document_store.delete_documents(index=label_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ed786b",
   "metadata": {},
   "source": [
    "### Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "23d355e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - haystack.document_stores.utils -  No title information found for documents in QA file: squad_format_thesis/test.json\n"
     ]
    }
   ],
   "source": [
    "# The add_eval_data() method converts the given dataset in json format into Haystack document and label objects. Those objects are then indexed in their respective document and label index in the document store. The method can be used with any dataset in SQuAD format.\n",
    "document_store.add_eval_data(\n",
    "    filename=\"squad_format_thesis/test.json\",\n",
    "    doc_index=doc_index,\n",
    "    label_index=label_index,\n",
    "    preprocessor=preprocessor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d1f2ee6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.modeling.utils -  Using devices: CUDA:0\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 1\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_6/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_6/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_6/passage_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_6/passage_encoder\n",
      "INFO - haystack.nodes.retriever.dense -  DPR model loaded from models/model_6\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import DensePassageRetriever\n",
    "\n",
    "save_dir = \"models/model_6\"\n",
    "\n",
    "retriever = DensePassageRetriever.load(load_dir=save_dir, document_store=document_store, use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "79642a4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.document_stores.elasticsearch -  Updating embeddings for all 651 docs ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb600599cabc4b3aad2f997bab1b5e21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Updating embeddings:   0%|          | 0/651 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Create embeddings:   0%|          | 0/656 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "document_store.update_embeddings(retriever, index=doc_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4ed12476",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.nodes.retriever.base -  Performing eval queries...\n",
      "100%|███████████████████████████████████████████| 25/25 [00:00<00:00, 85.29it/s]\n",
      "INFO - haystack.nodes.retriever.base -  For 16 out of 25 questions (64.00%), the answer was in the top-10 candidate passages selected by the retriever.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retriever Recall: 0.64\n",
      "Retriever Mean Avg Precision: 0.40801587301587305\n"
     ]
    }
   ],
   "source": [
    "## Evaluate Retriever on its own # THIS IS THE FINE-TUNED model_1\n",
    "# Note that no_answer samples are omitted when evaluation is performed with this method\n",
    "retriever_eval_results = retriever.eval(top_k=10, label_index=label_index, doc_index=doc_index, open_domain=True)\n",
    "# Retriever Recall is the proportion of questions for which the correct document containing the answer is\n",
    "# among the correct documents\n",
    "print(\"Retriever Recall:\", retriever_eval_results[\"recall\"])\n",
    "test_200_recall.append(retriever_eval_results[\"recall\"])\n",
    "# Retriever Mean Avg Precision rewards retrievers that give relevant documents a higher rank\n",
    "print(\"Retriever Mean Avg Precision:\", retriever_eval_results[\"map\"])\n",
    "test_200_map.append(retriever_eval_results[\"map\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d378d1b",
   "metadata": {},
   "source": [
    "### Dev set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e7b12209",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_store.delete_documents(index=doc_index)\n",
    "document_store.delete_documents(index=label_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6d9acf26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - haystack.document_stores.utils -  No title information found for documents in QA file: squad_format_thesis/dev.json\n"
     ]
    }
   ],
   "source": [
    "# The add_eval_data() method converts the given dataset in json format into Haystack document and label objects. Those objects are then indexed in their respective document and label index in the document store. The method can be used with any dataset in SQuAD format.\n",
    "document_store.add_eval_data(\n",
    "    filename=\"squad_format_thesis/dev.json\",\n",
    "    doc_index=doc_index,\n",
    "    label_index=label_index,\n",
    "    preprocessor=preprocessor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "890741a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.modeling.utils -  Using devices: CUDA:0\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 1\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_6/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_6/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_6/passage_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_6/passage_encoder\n",
      "INFO - haystack.nodes.retriever.dense -  DPR model loaded from models/model_6\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import DensePassageRetriever\n",
    "\n",
    "save_dir = \"models/model_6\"\n",
    "\n",
    "retriever = DensePassageRetriever.load(load_dir=save_dir, document_store=document_store, use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3d4da308",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.document_stores.elasticsearch -  Updating embeddings for all 608 docs ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcc47af1e359449b908a70127a64558b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Updating embeddings:   0%|          | 0/608 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Create embeddings:   0%|          | 0/608 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "document_store.update_embeddings(retriever, index=doc_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "970afa65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.nodes.retriever.base -  Performing eval queries...\n",
      "100%|███████████████████████████████████████████| 24/24 [00:00<00:00, 79.42it/s]\n",
      "INFO - haystack.nodes.retriever.base -  For 16 out of 24 questions (66.67%), the answer was in the top-10 candidate passages selected by the retriever.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retriever Recall: 0.6666666666666666\n",
      "Retriever Mean Avg Precision: 0.31636904761904766\n"
     ]
    }
   ],
   "source": [
    "## Evaluate Retriever on its own # THIS IS THE FINE-TUNED model_1\n",
    "# Note that no_answer samples are omitted when evaluation is performed with this method\n",
    "retriever_eval_results = retriever.eval(top_k=10, label_index=label_index, doc_index=doc_index, open_domain=True)\n",
    "# Retriever Recall is the proportion of questions for which the correct document containing the answer is\n",
    "# among the correct documents\n",
    "print(\"Retriever Recall:\", retriever_eval_results[\"recall\"])\n",
    "dev_200_recall.append(retriever_eval_results[\"recall\"])\n",
    "# Retriever Mean Avg Precision rewards retrievers that give relevant documents a higher rank\n",
    "print(\"Retriever Mean Avg Precision:\", retriever_eval_results[\"map\"])\n",
    "dev_200_map.append(retriever_eval_results[\"map\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a6d997",
   "metadata": {},
   "source": [
    "## Model 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6394857d",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_store.delete_documents(index=doc_index)\n",
    "document_store.delete_documents(index=label_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810ab0d9",
   "metadata": {},
   "source": [
    "### Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ea727e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - haystack.document_stores.utils -  No title information found for documents in QA file: squad_format_thesis/test.json\n"
     ]
    }
   ],
   "source": [
    "# The add_eval_data() method converts the given dataset in json format into Haystack document and label objects. Those objects are then indexed in their respective document and label index in the document store. The method can be used with any dataset in SQuAD format.\n",
    "document_store.add_eval_data(\n",
    "    filename=\"squad_format_thesis/test.json\",\n",
    "    doc_index=doc_index,\n",
    "    label_index=label_index,\n",
    "    preprocessor=preprocessor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0c60e033",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.modeling.utils -  Using devices: CUDA:0\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 1\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_7/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_7/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_7/passage_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_7/passage_encoder\n",
      "INFO - haystack.nodes.retriever.dense -  DPR model loaded from models/model_7\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import DensePassageRetriever\n",
    "\n",
    "save_dir = \"models/model_7\"\n",
    "\n",
    "retriever = DensePassageRetriever.load(load_dir=save_dir, document_store=document_store, use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3c5d4988",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.document_stores.elasticsearch -  Updating embeddings for all 651 docs ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "195dabaa6c654b19945da91f24cf32ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Updating embeddings:   0%|          | 0/651 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Create embeddings:   0%|          | 0/656 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "document_store.update_embeddings(retriever, index=doc_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "37b5390b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.nodes.retriever.base -  Performing eval queries...\n",
      "100%|███████████████████████████████████████████| 25/25 [00:00<00:00, 82.81it/s]\n",
      "INFO - haystack.nodes.retriever.base -  For 21 out of 25 questions (84.00%), the answer was in the top-10 candidate passages selected by the retriever.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retriever Recall: 0.84\n",
      "Retriever Mean Avg Precision: 0.5137619047619048\n"
     ]
    }
   ],
   "source": [
    "## Evaluate Retriever on its own # THIS IS THE FINE-TUNED model_1\n",
    "# Note that no_answer samples are omitted when evaluation is performed with this method\n",
    "retriever_eval_results = retriever.eval(top_k=10, label_index=label_index, doc_index=doc_index, open_domain=True)\n",
    "# Retriever Recall is the proportion of questions for which the correct document containing the answer is\n",
    "# among the correct documents\n",
    "print(\"Retriever Recall:\", retriever_eval_results[\"recall\"])\n",
    "test_200_recall.append(retriever_eval_results[\"recall\"])\n",
    "# Retriever Mean Avg Precision rewards retrievers that give relevant documents a higher rank\n",
    "print(\"Retriever Mean Avg Precision:\", retriever_eval_results[\"map\"])\n",
    "test_200_map.append(retriever_eval_results[\"map\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9fd962",
   "metadata": {},
   "source": [
    "### Dev set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7764a230",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_store.delete_documents(index=doc_index)\n",
    "document_store.delete_documents(index=label_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e23cd374",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - haystack.document_stores.utils -  No title information found for documents in QA file: squad_format_thesis/dev.json\n"
     ]
    }
   ],
   "source": [
    "# The add_eval_data() method converts the given dataset in json format into Haystack document and label objects. Those objects are then indexed in their respective document and label index in the document store. The method can be used with any dataset in SQuAD format.\n",
    "document_store.add_eval_data(\n",
    "    filename=\"squad_format_thesis/dev.json\",\n",
    "    doc_index=doc_index,\n",
    "    label_index=label_index,\n",
    "    preprocessor=preprocessor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e6f7ee90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.modeling.utils -  Using devices: CUDA:0\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 1\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_7/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_7/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_7/passage_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_7/passage_encoder\n",
      "INFO - haystack.nodes.retriever.dense -  DPR model loaded from models/model_7\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import DensePassageRetriever\n",
    "\n",
    "save_dir = \"models/model_7\"\n",
    "\n",
    "retriever = DensePassageRetriever.load(load_dir=save_dir, document_store=document_store, use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9177bf11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.document_stores.elasticsearch -  Updating embeddings for all 608 docs ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "611924ec1a80462a80b1aa1c0ad3dd12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Updating embeddings:   0%|          | 0/608 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Create embeddings:   0%|          | 0/608 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "document_store.update_embeddings(retriever, index=doc_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "205bb8ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.nodes.retriever.base -  Performing eval queries...\n",
      "100%|███████████████████████████████████████████| 24/24 [00:00<00:00, 77.57it/s]\n",
      "INFO - haystack.nodes.retriever.base -  For 20 out of 24 questions (83.33%), the answer was in the top-10 candidate passages selected by the retriever.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retriever Recall: 0.8333333333333334\n",
      "Retriever Mean Avg Precision: 0.5143518518518518\n"
     ]
    }
   ],
   "source": [
    "## Evaluate Retriever on its own # THIS IS THE FINE-TUNED model_1\n",
    "# Note that no_answer samples are omitted when evaluation is performed with this method\n",
    "retriever_eval_results = retriever.eval(top_k=10, label_index=label_index, doc_index=doc_index, open_domain=True)\n",
    "# Retriever Recall is the proportion of questions for which the correct document containing the answer is\n",
    "# among the correct documents\n",
    "print(\"Retriever Recall:\", retriever_eval_results[\"recall\"])\n",
    "dev_200_recall.append(retriever_eval_results[\"recall\"])\n",
    "# Retriever Mean Avg Precision rewards retrievers that give relevant documents a higher rank\n",
    "print(\"Retriever Mean Avg Precision:\", retriever_eval_results[\"map\"])\n",
    "dev_200_map.append(retriever_eval_results[\"map\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735cd28f",
   "metadata": {},
   "source": [
    "## Model 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1943c1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_store.delete_documents(index=doc_index)\n",
    "document_store.delete_documents(index=label_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507486dd",
   "metadata": {},
   "source": [
    "### Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6a180bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - haystack.document_stores.utils -  No title information found for documents in QA file: squad_format_thesis/test.json\n"
     ]
    }
   ],
   "source": [
    "# The add_eval_data() method converts the given dataset in json format into Haystack document and label objects. Those objects are then indexed in their respective document and label index in the document store. The method can be used with any dataset in SQuAD format.\n",
    "document_store.add_eval_data(\n",
    "    filename=\"squad_format_thesis/test.json\",\n",
    "    doc_index=doc_index,\n",
    "    label_index=label_index,\n",
    "    preprocessor=preprocessor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d5ceb9cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.modeling.utils -  Using devices: CUDA:0\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 1\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_8/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_8/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_8/passage_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_8/passage_encoder\n",
      "INFO - haystack.nodes.retriever.dense -  DPR model loaded from models/model_8\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import DensePassageRetriever\n",
    "\n",
    "save_dir = \"models/model_8\"\n",
    "\n",
    "retriever = DensePassageRetriever.load(load_dir=save_dir, document_store=document_store, use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "eb8f5e0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.document_stores.elasticsearch -  Updating embeddings for all 651 docs ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e17bad623e1943598edda86276917faa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Updating embeddings:   0%|          | 0/651 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Create embeddings:   0%|          | 0/656 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "document_store.update_embeddings(retriever, index=doc_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f65d1a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.nodes.retriever.base -  Performing eval queries...\n",
      "100%|███████████████████████████████████████████| 25/25 [00:00<00:00, 80.02it/s]\n",
      "INFO - haystack.nodes.retriever.base -  For 20 out of 25 questions (80.00%), the answer was in the top-10 candidate passages selected by the retriever.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retriever Recall: 0.8\n",
      "Retriever Mean Avg Precision: 0.49866666666666676\n"
     ]
    }
   ],
   "source": [
    "## Evaluate Retriever on its own # THIS IS THE FINE-TUNED model_1\n",
    "# Note that no_answer samples are omitted when evaluation is performed with this method\n",
    "retriever_eval_results = retriever.eval(top_k=10, label_index=label_index, doc_index=doc_index, open_domain=True)\n",
    "# Retriever Recall is the proportion of questions for which the correct document containing the answer is\n",
    "# among the correct documents\n",
    "print(\"Retriever Recall:\", retriever_eval_results[\"recall\"])\n",
    "test_200_recall.append(retriever_eval_results[\"recall\"])\n",
    "# Retriever Mean Avg Precision rewards retrievers that give relevant documents a higher rank\n",
    "print(\"Retriever Mean Avg Precision:\", retriever_eval_results[\"map\"])\n",
    "test_200_map.append(retriever_eval_results[\"map\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52dfd24",
   "metadata": {},
   "source": [
    "### Dev set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7855bb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_store.delete_documents(index=doc_index)\n",
    "document_store.delete_documents(index=label_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "747c55fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - haystack.document_stores.utils -  No title information found for documents in QA file: squad_format_thesis/dev.json\n"
     ]
    }
   ],
   "source": [
    "# The add_eval_data() method converts the given dataset in json format into Haystack document and label objects. Those objects are then indexed in their respective document and label index in the document store. The method can be used with any dataset in SQuAD format.\n",
    "document_store.add_eval_data(\n",
    "    filename=\"squad_format_thesis/dev.json\",\n",
    "    doc_index=doc_index,\n",
    "    label_index=label_index,\n",
    "    preprocessor=preprocessor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ef101ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.modeling.utils -  Using devices: CUDA:0\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 1\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_8/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_8/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_8/passage_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_8/passage_encoder\n",
      "INFO - haystack.nodes.retriever.dense -  DPR model loaded from models/model_8\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import DensePassageRetriever\n",
    "\n",
    "save_dir = \"models/model_8\"\n",
    "\n",
    "retriever = DensePassageRetriever.load(load_dir=save_dir, document_store=document_store, use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "37308e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.document_stores.elasticsearch -  Updating embeddings for all 608 docs ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0b49a7a6c794987981cbd342d2f2a61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Updating embeddings:   0%|          | 0/608 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Create embeddings:   0%|          | 0/608 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "document_store.update_embeddings(retriever, index=doc_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "fff0830a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.nodes.retriever.base -  Performing eval queries...\n",
      "100%|███████████████████████████████████████████| 24/24 [00:00<00:00, 87.67it/s]\n",
      "INFO - haystack.nodes.retriever.base -  For 19 out of 24 questions (79.17%), the answer was in the top-10 candidate passages selected by the retriever.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retriever Recall: 0.7916666666666666\n",
      "Retriever Mean Avg Precision: 0.39523809523809533\n"
     ]
    }
   ],
   "source": [
    "## Evaluate Retriever on its own # THIS IS THE FINE-TUNED model_1\n",
    "# Note that no_answer samples are omitted when evaluation is performed with this method\n",
    "retriever_eval_results = retriever.eval(top_k=10, label_index=label_index, doc_index=doc_index, open_domain=True)\n",
    "# Retriever Recall is the proportion of questions for which the correct document containing the answer is\n",
    "# among the correct documents\n",
    "print(\"Retriever Recall:\", retriever_eval_results[\"recall\"])\n",
    "dev_200_recall.append(retriever_eval_results[\"recall\"])\n",
    "# Retriever Mean Avg Precision rewards retrievers that give relevant documents a higher rank\n",
    "print(\"Retriever Mean Avg Precision:\", retriever_eval_results[\"map\"])\n",
    "dev_200_map.append(retriever_eval_results[\"map\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07c1efa",
   "metadata": {},
   "source": [
    "## Model 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6dcb19d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_store.delete_documents(index=doc_index)\n",
    "document_store.delete_documents(index=label_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94249c7b",
   "metadata": {},
   "source": [
    "### Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9d14b958",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - haystack.document_stores.utils -  No title information found for documents in QA file: squad_format_thesis/test.json\n"
     ]
    }
   ],
   "source": [
    "# The add_eval_data() method converts the given dataset in json format into Haystack document and label objects. Those objects are then indexed in their respective document and label index in the document store. The method can be used with any dataset in SQuAD format.\n",
    "document_store.add_eval_data(\n",
    "    filename=\"squad_format_thesis/test.json\",\n",
    "    doc_index=doc_index,\n",
    "    label_index=label_index,\n",
    "    preprocessor=preprocessor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4a5a3ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.modeling.utils -  Using devices: CUDA:0\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 1\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_9/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_9/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_9/passage_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_9/passage_encoder\n",
      "INFO - haystack.nodes.retriever.dense -  DPR model loaded from models/model_9\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import DensePassageRetriever\n",
    "\n",
    "save_dir = \"models/model_9\"\n",
    "\n",
    "retriever = DensePassageRetriever.load(load_dir=save_dir, document_store=document_store, use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "799c76a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.document_stores.elasticsearch -  Updating embeddings for all 651 docs ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3b56347244c4fb09ad5b70e225295da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Updating embeddings:   0%|          | 0/651 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Create embeddings:   0%|          | 0/656 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "document_store.update_embeddings(retriever, index=doc_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "20e13750",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.nodes.retriever.base -  Performing eval queries...\n",
      "100%|███████████████████████████████████████████| 25/25 [00:00<00:00, 62.31it/s]\n",
      "INFO - haystack.nodes.retriever.base -  For 21 out of 25 questions (84.00%), the answer was in the top-10 candidate passages selected by the retriever.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retriever Recall: 0.84\n",
      "Retriever Mean Avg Precision: 0.5166666666666667\n"
     ]
    }
   ],
   "source": [
    "## Evaluate Retriever on its own # THIS IS THE FINE-TUNED model_1\n",
    "# Note that no_answer samples are omitted when evaluation is performed with this method\n",
    "retriever_eval_results = retriever.eval(top_k=10, label_index=label_index, doc_index=doc_index, open_domain=True)\n",
    "# Retriever Recall is the proportion of questions for which the correct document containing the answer is\n",
    "# among the correct documents\n",
    "print(\"Retriever Recall:\", retriever_eval_results[\"recall\"])\n",
    "test_200_recall.append(retriever_eval_results[\"recall\"])\n",
    "# Retriever Mean Avg Precision rewards retrievers that give relevant documents a higher rank\n",
    "print(\"Retriever Mean Avg Precision:\", retriever_eval_results[\"map\"])\n",
    "test_200_map.append(retriever_eval_results[\"map\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d8768d",
   "metadata": {},
   "source": [
    "### Dev set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "69da0e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_store.delete_documents(index=doc_index)\n",
    "document_store.delete_documents(index=label_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "6d506430",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - haystack.document_stores.utils -  No title information found for documents in QA file: squad_format_thesis/dev.json\n"
     ]
    }
   ],
   "source": [
    "# The add_eval_data() method converts the given dataset in json format into Haystack document and label objects. Those objects are then indexed in their respective document and label index in the document store. The method can be used with any dataset in SQuAD format.\n",
    "document_store.add_eval_data(\n",
    "    filename=\"squad_format_thesis/dev.json\",\n",
    "    doc_index=doc_index,\n",
    "    label_index=label_index,\n",
    "    preprocessor=preprocessor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f26a7df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.modeling.utils -  Using devices: CUDA:0\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 1\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_9/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_9/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_9/passage_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_9/passage_encoder\n",
      "INFO - haystack.nodes.retriever.dense -  DPR model loaded from models/model_9\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import DensePassageRetriever\n",
    "\n",
    "save_dir = \"models/model_9\"\n",
    "\n",
    "retriever = DensePassageRetriever.load(load_dir=save_dir, document_store=document_store, use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "83d3949e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.document_stores.elasticsearch -  Updating embeddings for all 608 docs ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71546814bca84430a3527eb1df28d876",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Updating embeddings:   0%|          | 0/608 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Create embeddings:   0%|          | 0/608 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "document_store.update_embeddings(retriever, index=doc_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "efd6cca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.nodes.retriever.base -  Performing eval queries...\n",
      "100%|███████████████████████████████████████████| 24/24 [00:00<00:00, 77.97it/s]\n",
      "INFO - haystack.nodes.retriever.base -  For 20 out of 24 questions (83.33%), the answer was in the top-10 candidate passages selected by the retriever.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retriever Recall: 0.8333333333333334\n",
      "Retriever Mean Avg Precision: 0.5385912698412699\n"
     ]
    }
   ],
   "source": [
    "## Evaluate Retriever on its own # THIS IS THE FINE-TUNED model_1\n",
    "# Note that no_answer samples are omitted when evaluation is performed with this method\n",
    "retriever_eval_results = retriever.eval(top_k=10, label_index=label_index, doc_index=doc_index, open_domain=True)\n",
    "# Retriever Recall is the proportion of questions for which the correct document containing the answer is\n",
    "# among the correct documents\n",
    "print(\"Retriever Recall:\", retriever_eval_results[\"recall\"])\n",
    "dev_200_recall.append(retriever_eval_results[\"recall\"])\n",
    "# Retriever Mean Avg Precision rewards retrievers that give relevant documents a higher rank\n",
    "print(\"Retriever Mean Avg Precision:\", retriever_eval_results[\"map\"])\n",
    "dev_200_map.append(retriever_eval_results[\"map\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92b8b2c",
   "metadata": {},
   "source": [
    "## Model 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e3f81d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_store.delete_documents(index=doc_index)\n",
    "document_store.delete_documents(index=label_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b03287",
   "metadata": {},
   "source": [
    "### Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d158afb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - haystack.document_stores.utils -  No title information found for documents in QA file: squad_format_thesis/test.json\n"
     ]
    }
   ],
   "source": [
    "# The add_eval_data() method converts the given dataset in json format into Haystack document and label objects. Those objects are then indexed in their respective document and label index in the document store. The method can be used with any dataset in SQuAD format.\n",
    "document_store.add_eval_data(\n",
    "    filename=\"squad_format_thesis/test.json\",\n",
    "    doc_index=doc_index,\n",
    "    label_index=label_index,\n",
    "    preprocessor=preprocessor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "2bfc9681",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.modeling.utils -  Using devices: CUDA:0\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 1\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_10/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_10/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_10/passage_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_10/passage_encoder\n",
      "INFO - haystack.nodes.retriever.dense -  DPR model loaded from models/model_10\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import DensePassageRetriever\n",
    "\n",
    "save_dir = \"models/model_10\"\n",
    "\n",
    "retriever = DensePassageRetriever.load(load_dir=save_dir, document_store=document_store, use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1cb123c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.document_stores.elasticsearch -  Updating embeddings for all 651 docs ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ec8beaebc9749f2bff47e0279e66523",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Updating embeddings:   0%|          | 0/651 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Create embeddings:   0%|          | 0/656 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "document_store.update_embeddings(retriever, index=doc_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "65be42df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.nodes.retriever.base -  Performing eval queries...\n",
      "100%|███████████████████████████████████████████| 25/25 [00:00<00:00, 81.33it/s]\n",
      "INFO - haystack.nodes.retriever.base -  For 21 out of 25 questions (84.00%), the answer was in the top-10 candidate passages selected by the retriever.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retriever Recall: 0.84\n",
      "Retriever Mean Avg Precision: 0.5166666666666667\n"
     ]
    }
   ],
   "source": [
    "## Evaluate Retriever on its own # THIS IS THE FINE-TUNED model_1\n",
    "# Note that no_answer samples are omitted when evaluation is performed with this method\n",
    "retriever_eval_results = retriever.eval(top_k=10, label_index=label_index, doc_index=doc_index, open_domain=True)\n",
    "# Retriever Recall is the proportion of questions for which the correct document containing the answer is\n",
    "# among the correct documents\n",
    "print(\"Retriever Recall:\", retriever_eval_results[\"recall\"])\n",
    "test_200_recall.append(retriever_eval_results[\"recall\"])\n",
    "# Retriever Mean Avg Precision rewards retrievers that give relevant documents a higher rank\n",
    "print(\"Retriever Mean Avg Precision:\", retriever_eval_results[\"map\"])\n",
    "test_200_map.append(retriever_eval_results[\"map\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b16fe9b",
   "metadata": {},
   "source": [
    "### Dev set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "51feb298",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_store.delete_documents(index=doc_index)\n",
    "document_store.delete_documents(index=label_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "58fba63a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - haystack.document_stores.utils -  No title information found for documents in QA file: squad_format_thesis/dev.json\n"
     ]
    }
   ],
   "source": [
    "# The add_eval_data() method converts the given dataset in json format into Haystack document and label objects. Those objects are then indexed in their respective document and label index in the document store. The method can be used with any dataset in SQuAD format.\n",
    "document_store.add_eval_data(\n",
    "    filename=\"squad_format_thesis/dev.json\",\n",
    "    doc_index=doc_index,\n",
    "    label_index=label_index,\n",
    "    preprocessor=preprocessor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "6dba5aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.modeling.utils -  Using devices: CUDA:0\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 1\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_10/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_10/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_10/passage_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_10/passage_encoder\n",
      "INFO - haystack.nodes.retriever.dense -  DPR model loaded from models/model_10\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import DensePassageRetriever\n",
    "\n",
    "save_dir = \"models/model_10\"\n",
    "\n",
    "retriever = DensePassageRetriever.load(load_dir=save_dir, document_store=document_store, use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "cf41a579",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.document_stores.elasticsearch -  Updating embeddings for all 608 docs ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48752de800344d58863bef03a0507e7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Updating embeddings:   0%|          | 0/608 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Create embeddings:   0%|          | 0/608 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "document_store.update_embeddings(retriever, index=doc_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "b166fc1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.nodes.retriever.base -  Performing eval queries...\n",
      "100%|███████████████████████████████████████████| 24/24 [00:00<00:00, 80.65it/s]\n",
      "INFO - haystack.nodes.retriever.base -  For 20 out of 24 questions (83.33%), the answer was in the top-10 candidate passages selected by the retriever.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retriever Recall: 0.8333333333333334\n",
      "Retriever Mean Avg Precision: 0.5385912698412699\n"
     ]
    }
   ],
   "source": [
    "## Evaluate Retriever on its own # THIS IS THE FINE-TUNED model_1\n",
    "# Note that no_answer samples are omitted when evaluation is performed with this method\n",
    "retriever_eval_results = retriever.eval(top_k=10, label_index=label_index, doc_index=doc_index, open_domain=True)\n",
    "# Retriever Recall is the proportion of questions for which the correct document containing the answer is\n",
    "# among the correct documents\n",
    "print(\"Retriever Recall:\", retriever_eval_results[\"recall\"])\n",
    "dev_200_recall.append(retriever_eval_results[\"recall\"])\n",
    "# Retriever Mean Avg Precision rewards retrievers that give relevant documents a higher rank\n",
    "print(\"Retriever Mean Avg Precision:\", retriever_eval_results[\"map\"])\n",
    "dev_200_map.append(retriever_eval_results[\"map\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0adc26",
   "metadata": {},
   "source": [
    "## Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "017974e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_store.delete_documents(index=doc_index)\n",
    "document_store.delete_documents(index=label_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458f295b",
   "metadata": {},
   "source": [
    "### Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "2045379f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - haystack.document_stores.utils -  No title information found for documents in QA file: squad_format_thesis/test.json\n"
     ]
    }
   ],
   "source": [
    "# The add_eval_data() method converts the given dataset in json format into Haystack document and label objects. Those objects are then indexed in their respective document and label index in the document store. The method can be used with any dataset in SQuAD format.\n",
    "document_store.add_eval_data(\n",
    "    filename=\"squad_format_thesis/test.json\",\n",
    "    doc_index=doc_index,\n",
    "    label_index=label_index,\n",
    "    preprocessor=preprocessor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "1f4b4f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.modeling.utils -  Using devices: CUDA:0\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 1\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Could not find IIC/dpr-spanish-question_encoder-allqa-base locally.\n",
      "INFO - haystack.modeling.model.language_model -  Looking on Transformers Model Hub (in local cache and online)...\n",
      "INFO - haystack.modeling.model.language_model -  Automatically detected language from language model name: spanish\n",
      "INFO - haystack.modeling.model.language_model -  Loaded IIC/dpr-spanish-question_encoder-allqa-base\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Could not find IIC/dpr-spanish-passage_encoder-allqa-base locally.\n",
      "INFO - haystack.modeling.model.language_model -  Looking on Transformers Model Hub (in local cache and online)...\n",
      "INFO - haystack.modeling.model.language_model -  Automatically detected language from language model name: spanish\n",
      "INFO - haystack.modeling.model.language_model -  Loaded IIC/dpr-spanish-passage_encoder-allqa-base\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import DensePassageRetriever\n",
    "retriever = DensePassageRetriever(\n",
    "            document_store=document_store,\n",
    "            query_embedding_model=\"IIC/dpr-spanish-question_encoder-allqa-base\",\n",
    "            passage_embedding_model=\"IIC/dpr-spanish-passage_encoder-allqa-base\",\n",
    "            use_gpu=True,\n",
    "            batch_size = 64\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "c919bdd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.document_stores.elasticsearch -  Updating embeddings for all 651 docs ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "468ab519524e4c8ca6d296a6c7b4a82d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Updating embeddings:   0%|          | 0/651 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Create embeddings:   0%|          | 0/704 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "document_store.update_embeddings(retriever, index=doc_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "1de4725b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.nodes.retriever.base -  Performing eval queries...\n",
      "100%|███████████████████████████████████████████| 25/25 [00:00<00:00, 73.38it/s]\n",
      "INFO - haystack.nodes.retriever.base -  For 21 out of 25 questions (84.00%), the answer was in the top-10 candidate passages selected by the retriever.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retriever Recall: 0.84\n",
      "Retriever Mean Avg Precision: 0.5166666666666667\n"
     ]
    }
   ],
   "source": [
    "## Evaluate Retriever on its own #THIS IS THE BARE BONES\n",
    "# Note that no_answer samples are omitted when evaluation is performed with this method\n",
    "retriever_eval_results = retriever.eval(top_k=10, label_index=label_index, doc_index=doc_index, open_domain=True)\n",
    "# Retriever Recall is the proportion of questions for which the correct document containing the answer is\n",
    "# among the correct documents\n",
    "print(\"Retriever Recall:\", retriever_eval_results[\"recall\"])\n",
    "test_200_recall.append(retriever_eval_results[\"recall\"])\n",
    "# Retriever Mean Avg Precision rewards retrievers that give relevant documents a higher rank\n",
    "print(\"Retriever Mean Avg Precision:\", retriever_eval_results[\"map\"])\n",
    "test_200_map.append(retriever_eval_results[\"map\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26397947",
   "metadata": {},
   "source": [
    "### Dev Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "7c237f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_store.delete_documents(index=doc_index)\n",
    "document_store.delete_documents(index=label_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "fec4a1f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - haystack.document_stores.utils -  No title information found for documents in QA file: squad_format_thesis/dev.json\n"
     ]
    }
   ],
   "source": [
    "# The add_eval_data() method converts the given dataset in json format into Haystack document and label objects. Those objects are then indexed in their respective document and label index in the document store. The method can be used with any dataset in SQuAD format.\n",
    "document_store.add_eval_data(\n",
    "    filename=\"squad_format_thesis/dev.json\",\n",
    "    doc_index=doc_index,\n",
    "    label_index=label_index,\n",
    "    preprocessor=preprocessor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "1791c740",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.modeling.utils -  Using devices: CUDA:0\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 1\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Could not find IIC/dpr-spanish-question_encoder-allqa-base locally.\n",
      "INFO - haystack.modeling.model.language_model -  Looking on Transformers Model Hub (in local cache and online)...\n",
      "INFO - haystack.modeling.model.language_model -  Automatically detected language from language model name: spanish\n",
      "INFO - haystack.modeling.model.language_model -  Loaded IIC/dpr-spanish-question_encoder-allqa-base\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Could not find IIC/dpr-spanish-passage_encoder-allqa-base locally.\n",
      "INFO - haystack.modeling.model.language_model -  Looking on Transformers Model Hub (in local cache and online)...\n",
      "INFO - haystack.modeling.model.language_model -  Automatically detected language from language model name: spanish\n",
      "INFO - haystack.modeling.model.language_model -  Loaded IIC/dpr-spanish-passage_encoder-allqa-base\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import DensePassageRetriever\n",
    "retriever = DensePassageRetriever(\n",
    "            document_store=document_store,\n",
    "            query_embedding_model=\"IIC/dpr-spanish-question_encoder-allqa-base\",\n",
    "            passage_embedding_model=\"IIC/dpr-spanish-passage_encoder-allqa-base\",\n",
    "            use_gpu=True,\n",
    "            batch_size = 64\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b3bdb2b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.document_stores.elasticsearch -  Updating embeddings for all 608 docs ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8180994fbab04d989c2955e90c1b0e2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Updating embeddings:   0%|          | 0/608 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Create embeddings:   0%|          | 0/640 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "document_store.update_embeddings(retriever, index=doc_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "c9f878fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.nodes.retriever.base -  Performing eval queries...\n",
      "100%|███████████████████████████████████████████| 24/24 [00:00<00:00, 80.66it/s]\n",
      "INFO - haystack.nodes.retriever.base -  For 20 out of 24 questions (83.33%), the answer was in the top-10 candidate passages selected by the retriever.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retriever Recall: 0.8333333333333334\n",
      "Retriever Mean Avg Precision: 0.5385912698412699\n"
     ]
    }
   ],
   "source": [
    "## Evaluate Retriever on its own #THIS IS THE BARE BONES\n",
    "# Note that no_answer samples are omitted when evaluation is performed with this method\n",
    "retriever_eval_results = retriever.eval(top_k=10, label_index=label_index, doc_index=doc_index, open_domain=True)\n",
    "# Retriever Recall is the proportion of questions for which the correct document containing the answer is\n",
    "# among the correct documents\n",
    "print(\"Retriever Recall:\", retriever_eval_results[\"recall\"])\n",
    "dev_200_recall.append(retriever_eval_results[\"recall\"])\n",
    "# Retriever Mean Avg Precision rewards retrievers that give relevant documents a higher rank\n",
    "print(\"Retriever Mean Avg Precision:\", retriever_eval_results[\"map\"])\n",
    "dev_200_map.append(retriever_eval_results[\"map\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986e84f6",
   "metadata": {},
   "source": [
    "## Old Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "2b9d6fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_store.delete_documents(index=doc_index)\n",
    "document_store.delete_documents(index=label_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095ae104",
   "metadata": {},
   "source": [
    "### Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "9806c88b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - haystack.document_stores.utils -  No title information found for documents in QA file: squad_format_thesis/test.json\n"
     ]
    }
   ],
   "source": [
    "# The add_eval_data() method converts the given dataset in json format into Haystack document and label objects. Those objects are then indexed in their respective document and label index in the document store. The method can be used with any dataset in SQuAD format.\n",
    "document_store.add_eval_data(\n",
    "    filename=\"squad_format_thesis/test.json\",\n",
    "    doc_index=doc_index,\n",
    "    label_index=label_index,\n",
    "    preprocessor=preprocessor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "0437887b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.modeling.utils -  Using devices: CUDA:0\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 1\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Could not find voidful/dpr-question_encoder-bert-base-multilingual locally.\n",
      "INFO - haystack.modeling.model.language_model -  Looking on Transformers Model Hub (in local cache and online)...\n",
      "INFO - haystack.modeling.model.language_model -  Automatically detected language from language model name: multilingual\n",
      "INFO - haystack.modeling.model.language_model -  Loaded voidful/dpr-question_encoder-bert-base-multilingual\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
      "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Could not find voidful/dpr-ctx_encoder-bert-base-multilingual locally.\n",
      "INFO - haystack.modeling.model.language_model -  Looking on Transformers Model Hub (in local cache and online)...\n",
      "INFO - haystack.modeling.model.language_model -  Automatically detected language from language model name: multilingual\n",
      "INFO - haystack.modeling.model.language_model -  Loaded voidful/dpr-ctx_encoder-bert-base-multilingual\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import DensePassageRetriever\n",
    "retriever = DensePassageRetriever(\n",
    "            document_store=document_store,\n",
    "            query_embedding_model=\"voidful/dpr-question_encoder-bert-base-multilingual\",\n",
    "            passage_embedding_model=\"voidful/dpr-ctx_encoder-bert-base-multilingual\",\n",
    "            use_gpu=True,\n",
    "            batch_size = 64\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "c0741250",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.document_stores.elasticsearch -  Updating embeddings for all 651 docs ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56bbd45fb57f402e88cf1a97ade087e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Updating embeddings:   0%|          | 0/651 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Create embeddings:   0%|          | 0/704 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "document_store.update_embeddings(retriever, index=doc_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "3010b860",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.nodes.retriever.base -  Performing eval queries...\n",
      "100%|███████████████████████████████████████████| 25/25 [00:00<00:00, 81.44it/s]\n",
      "INFO - haystack.nodes.retriever.base -  For 10 out of 25 questions (40.00%), the answer was in the top-10 candidate passages selected by the retriever.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retriever Recall: 0.4\n",
      "Retriever Mean Avg Precision: 0.204\n"
     ]
    }
   ],
   "source": [
    "## Evaluate Retriever on its own #THIS IS THE BARE BONES\n",
    "# Note that no_answer samples are omitted when evaluation is performed with this method\n",
    "retriever_eval_results = retriever.eval(top_k=10, label_index=label_index, doc_index=doc_index, open_domain=True)\n",
    "# Retriever Recall is the proportion of questions for which the correct document containing the answer is\n",
    "# among the correct documents\n",
    "print(\"Retriever Recall:\", retriever_eval_results[\"recall\"])\n",
    "test_200_recall.append(retriever_eval_results[\"recall\"])\n",
    "# Retriever Mean Avg Precision rewards retrievers that give relevant documents a higher rank\n",
    "print(\"Retriever Mean Avg Precision:\", retriever_eval_results[\"map\"])\n",
    "test_200_map.append(retriever_eval_results[\"map\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35fe8941",
   "metadata": {},
   "source": [
    "### Dev Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "fe6c20f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_store.delete_documents(index=doc_index)\n",
    "document_store.delete_documents(index=label_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "1663c18e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - haystack.document_stores.utils -  No title information found for documents in QA file: squad_format_thesis/dev.json\n"
     ]
    }
   ],
   "source": [
    "# The add_eval_data() method converts the given dataset in json format into Haystack document and label objects. Those objects are then indexed in their respective document and label index in the document store. The method can be used with any dataset in SQuAD format.\n",
    "document_store.add_eval_data(\n",
    "    filename=\"squad_format_thesis/dev.json\",\n",
    "    doc_index=doc_index,\n",
    "    label_index=label_index,\n",
    "    preprocessor=preprocessor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "215c8d7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.modeling.utils -  Using devices: CUDA:0\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 1\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Could not find voidful/dpr-question_encoder-bert-base-multilingual locally.\n",
      "INFO - haystack.modeling.model.language_model -  Looking on Transformers Model Hub (in local cache and online)...\n",
      "INFO - haystack.modeling.model.language_model -  Automatically detected language from language model name: multilingual\n",
      "INFO - haystack.modeling.model.language_model -  Loaded voidful/dpr-question_encoder-bert-base-multilingual\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
      "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Could not find voidful/dpr-ctx_encoder-bert-base-multilingual locally.\n",
      "INFO - haystack.modeling.model.language_model -  Looking on Transformers Model Hub (in local cache and online)...\n",
      "INFO - haystack.modeling.model.language_model -  Automatically detected language from language model name: multilingual\n",
      "INFO - haystack.modeling.model.language_model -  Loaded voidful/dpr-ctx_encoder-bert-base-multilingual\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import DensePassageRetriever\n",
    "retriever = DensePassageRetriever(\n",
    "            document_store=document_store,\n",
    "            query_embedding_model=\"voidful/dpr-question_encoder-bert-base-multilingual\",\n",
    "            passage_embedding_model=\"voidful/dpr-ctx_encoder-bert-base-multilingual\",\n",
    "            use_gpu=True,\n",
    "            batch_size = 64\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "9699b175",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.document_stores.elasticsearch -  Updating embeddings for all 608 docs ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64bab29f77d24362b0e99f68e6d6a226",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Updating embeddings:   0%|          | 0/608 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Create embeddings:   0%|          | 0/640 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "document_store.update_embeddings(retriever, index=doc_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "5d2a1bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.nodes.retriever.base -  Performing eval queries...\n",
      "100%|███████████████████████████████████████████| 24/24 [00:00<00:00, 83.79it/s]\n",
      "INFO - haystack.nodes.retriever.base -  For 11 out of 24 questions (45.83%), the answer was in the top-10 candidate passages selected by the retriever.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retriever Recall: 0.4583333333333333\n",
      "Retriever Mean Avg Precision: 0.23303571428571426\n"
     ]
    }
   ],
   "source": [
    "## Evaluate Retriever on its own #THIS IS THE BARE BONES\n",
    "# Note that no_answer samples are omitted when evaluation is performed with this method\n",
    "retriever_eval_results = retriever.eval(top_k=10, label_index=label_index, doc_index=doc_index, open_domain=True)\n",
    "# Retriever Recall is the proportion of questions for which the correct document containing the answer is\n",
    "# among the correct documents\n",
    "print(\"Retriever Recall:\", retriever_eval_results[\"recall\"])\n",
    "dev_200_recall.append(retriever_eval_results[\"recall\"])\n",
    "# Retriever Mean Avg Precision rewards retrievers that give relevant documents a higher rank\n",
    "print(\"Retriever Mean Avg Precision:\", retriever_eval_results[\"map\"])\n",
    "dev_200_map.append(retriever_eval_results[\"map\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7c3d6c",
   "metadata": {},
   "source": [
    "## BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "2f5f20d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Retriever\n",
    "from haystack.nodes import ElasticsearchRetriever, BM25Retriever\n",
    "\n",
    "retriever = BM25Retriever(document_store=document_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "818b506f",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_store.delete_documents(index=doc_index)\n",
    "document_store.delete_documents(index=label_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe69d1f",
   "metadata": {},
   "source": [
    "### Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "e6193131",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - haystack.document_stores.utils -  No title information found for documents in QA file: squad_format_thesis/test.json\n"
     ]
    }
   ],
   "source": [
    "# The add_eval_data() method converts the given dataset in json format into Haystack document and label objects. Those objects are then indexed in their respective document and label index in the document store. The method can be used with any dataset in SQuAD format.\n",
    "document_store.add_eval_data(\n",
    "    filename=\"squad_format_thesis/test.json\",\n",
    "    doc_index=doc_index,\n",
    "    label_index=label_index,\n",
    "    preprocessor=preprocessor\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "b547bc3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.nodes.retriever.base -  Performing eval queries...\n",
      "100%|███████████████████████████████████████████| 25/25 [00:00<00:00, 63.48it/s]\n",
      "INFO - haystack.nodes.retriever.base -  For 17 out of 25 questions (68.00%), the answer was in the top-10 candidate passages selected by the retriever.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retriever Recall: 0.68\n",
      "Retriever Mean Avg Precision: 0.46944444444444433\n"
     ]
    }
   ],
   "source": [
    "## Evaluate Retriever on its own #THIS IS THE ES\n",
    "# Note that no_answer samples are omitted when evaluation is performed with this method\n",
    "retriever_eval_results = retriever.eval(top_k=10, label_index=label_index, doc_index=doc_index, open_domain=True)\n",
    "# Retriever Recall is the proportion of questions for which the correct document containing the answer is\n",
    "# among the correct documents\n",
    "print(\"Retriever Recall:\", retriever_eval_results[\"recall\"])\n",
    "test_200_recall.append(retriever_eval_results[\"recall\"])\n",
    "# Retriever Mean Avg Precision rewards retrievers that give relevant documents a higher rank\n",
    "print(\"Retriever Mean Avg Precision:\", retriever_eval_results[\"map\"])\n",
    "test_200_map.append(retriever_eval_results[\"map\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a53dc6",
   "metadata": {},
   "source": [
    "### Dev Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "075e80c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_store.delete_documents(index=doc_index)\n",
    "document_store.delete_documents(index=label_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "3cf13df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - haystack.document_stores.utils -  No title information found for documents in QA file: squad_format_thesis/dev.json\n"
     ]
    }
   ],
   "source": [
    "# The add_eval_data() method converts the given dataset in json format into Haystack document and label objects. Those objects are then indexed in their respective document and label index in the document store. The method can be used with any dataset in SQuAD format.\n",
    "document_store.add_eval_data(\n",
    "    filename=\"squad_format_thesis/dev.json\",\n",
    "    doc_index=doc_index,\n",
    "    label_index=label_index,\n",
    "    preprocessor=preprocessor\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "446963a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.nodes.retriever.base -  Performing eval queries...\n",
      "100%|██████████████████████████████████████████| 24/24 [00:00<00:00, 101.15it/s]\n",
      "INFO - haystack.nodes.retriever.base -  For 18 out of 24 questions (75.00%), the answer was in the top-10 candidate passages selected by the retriever.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retriever Recall: 0.75\n",
      "Retriever Mean Avg Precision: 0.5365079365079366\n"
     ]
    }
   ],
   "source": [
    "## Evaluate Retriever on its own #THIS IS THE ES\n",
    "# Note that no_answer samples are omitted when evaluation is performed with this method\n",
    "retriever_eval_results = retriever.eval(top_k=10, label_index=label_index, doc_index=doc_index, open_domain=True)\n",
    "# Retriever Recall is the proportion of questions for which the correct document containing the answer is\n",
    "# among the correct documents\n",
    "print(\"Retriever Recall:\", retriever_eval_results[\"recall\"])\n",
    "dev_200_recall.append(retriever_eval_results[\"recall\"])\n",
    "# Retriever Mean Avg Precision rewards retrievers that give relevant documents a higher rank\n",
    "print(\"Retriever Mean Avg Precision:\", retriever_eval_results[\"map\"])\n",
    "dev_200_map.append(retriever_eval_results[\"map\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70482ab3",
   "metadata": {},
   "source": [
    "# 400 split_lenght\n",
    "\n",
    "Estos eran los parametros por defecto en el area de entrenamiento de haystack, tambien son los mismos parametros con que se subieron los documentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "a01af579",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = ['model_1', 'model_2', 'model_3', 'model_4', 'model_5', 'model_6', 'model_7', 'model_8', 'model_9'\n",
    "             ,'model_10', 'base_model', 'old_base_model', 'bm25']\n",
    "\n",
    "test_400_map = []\n",
    "test_400_recall = []\n",
    "dev_400_map = []\n",
    "dev_400_recall = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "f48f1084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to Elasticsearch\n",
    "# docker start es01-test -a\n",
    "from haystack.document_stores import ElasticsearchDocumentStore\n",
    "\n",
    "document_store = ElasticsearchDocumentStore(\n",
    "    host=\"localhost\",\n",
    "    username=\"\",\n",
    "    password=\"\",\n",
    "    index=doc_index,\n",
    "    label_index=label_index,\n",
    "    embedding_field=\"emb\",\n",
    "    embedding_dim=768,\n",
    "    excluded_meta_data=[\"emb\"],\n",
    ")\n",
    "\n",
    "from haystack.nodes import PreProcessor\n",
    "\n",
    "document_store.delete_documents(index=doc_index)\n",
    "document_store.delete_documents(index=label_index)\n",
    "\n",
    "preprocessor = PreProcessor(\n",
    "    clean_empty_lines=False, #Not supported\n",
    "    clean_whitespace=False, #Not supported\n",
    "    split_by=\"word\",\n",
    "    split_length=400,\n",
    "    split_respect_sentence_boundary=False, #Not supported\n",
    "    split_overlap=0,\n",
    "    language=\"es\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891170cb",
   "metadata": {},
   "source": [
    "## Model 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd0c009",
   "metadata": {},
   "source": [
    "### Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "e84633a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - haystack.document_stores.utils -  No title information found for documents in QA file: squad_format_thesis/test.json\n"
     ]
    }
   ],
   "source": [
    "# The add_eval_data() method converts the given dataset in json format into Haystack document and label objects. Those objects are then indexed in their respective document and label index in the document store. The method can be used with any dataset in SQuAD format.\n",
    "document_store.add_eval_data(\n",
    "    filename=\"squad_format_thesis/test.json\",\n",
    "    doc_index=doc_index,\n",
    "    label_index=label_index,\n",
    "    preprocessor=preprocessor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "200b23e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.modeling.utils -  Using devices: CUDA:0\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 1\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_1/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_1/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_1/passage_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_1/passage_encoder\n",
      "INFO - haystack.nodes.retriever.dense -  DPR model loaded from models/model_1\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import DensePassageRetriever\n",
    "\n",
    "save_dir = \"models/model_1\"\n",
    "\n",
    "retriever = DensePassageRetriever.load(load_dir=save_dir, document_store=document_store, use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "20092b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.document_stores.elasticsearch -  Updating embeddings for all 326 docs ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e20abcb843d48358ddf257e93d9db6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Updating embeddings:   0%|          | 0/326 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Create embeddings:   0%|          | 0/336 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "document_store.update_embeddings(retriever, index=doc_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "0c9f3ff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.nodes.retriever.base -  Performing eval queries...\n",
      "100%|███████████████████████████████████████████| 25/25 [00:00<00:00, 82.37it/s]\n",
      "INFO - haystack.nodes.retriever.base -  For 13 out of 25 questions (52.00%), the answer was in the top-10 candidate passages selected by the retriever.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retriever Recall: 0.52\n",
      "Retriever Mean Avg Precision: 0.30366666666666664\n"
     ]
    }
   ],
   "source": [
    "## Evaluate Retriever on its own # THIS IS THE FINE-TUNED model_1\n",
    "# Note that no_answer samples are omitted when evaluation is performed with this method\n",
    "retriever_eval_results = retriever.eval(top_k=10, label_index=label_index, doc_index=doc_index, open_domain=True)\n",
    "# Retriever Recall is the proportion of questions for which the correct document containing the answer is\n",
    "# among the correct documents\n",
    "print(\"Retriever Recall:\", retriever_eval_results[\"recall\"])\n",
    "test_400_recall.append(retriever_eval_results[\"recall\"])\n",
    "# Retriever Mean Avg Precision rewards retrievers that give relevant documents a higher rank\n",
    "print(\"Retriever Mean Avg Precision:\", retriever_eval_results[\"map\"])\n",
    "test_400_map.append(retriever_eval_results[\"map\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc04c362",
   "metadata": {},
   "source": [
    "### Dev set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "9ce70b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_store.delete_documents(index=doc_index)\n",
    "document_store.delete_documents(index=label_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "e500793e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - haystack.document_stores.utils -  No title information found for documents in QA file: squad_format_thesis/dev.json\n"
     ]
    }
   ],
   "source": [
    "# The add_eval_data() method converts the given dataset in json format into Haystack document and label objects. Those objects are then indexed in their respective document and label index in the document store. The method can be used with any dataset in SQuAD format.\n",
    "document_store.add_eval_data(\n",
    "    filename=\"squad_format_thesis/dev.json\",\n",
    "    doc_index=doc_index,\n",
    "    label_index=label_index,\n",
    "    preprocessor=preprocessor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "c6eb7b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.modeling.utils -  Using devices: CUDA:0\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 1\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_1/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_1/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_1/passage_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_1/passage_encoder\n",
      "INFO - haystack.nodes.retriever.dense -  DPR model loaded from models/model_1\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import DensePassageRetriever\n",
    "\n",
    "save_dir = \"models/model_1\"\n",
    "\n",
    "retriever = DensePassageRetriever.load(load_dir=save_dir, document_store=document_store, use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "a9af41c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.document_stores.elasticsearch -  Updating embeddings for all 305 docs ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8a5465aa8ab4f2497d9596188075703",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Updating embeddings:   0%|          | 0/305 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Create embeddings:   0%|          | 0/320 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "document_store.update_embeddings(retriever, index=doc_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "acc13edd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.nodes.retriever.base -  Performing eval queries...\n",
      "100%|███████████████████████████████████████████| 24/24 [00:00<00:00, 88.85it/s]\n",
      "INFO - haystack.nodes.retriever.base -  For 10 out of 24 questions (41.67%), the answer was in the top-10 candidate passages selected by the retriever.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retriever Recall: 0.4166666666666667\n",
      "Retriever Mean Avg Precision: 0.2108796296296296\n"
     ]
    }
   ],
   "source": [
    "## Evaluate Retriever on its own # THIS IS THE FINE-TUNED model_1\n",
    "# Note that no_answer samples are omitted when evaluation is performed with this method\n",
    "retriever_eval_results = retriever.eval(top_k=10, label_index=label_index, doc_index=doc_index, open_domain=True)\n",
    "# Retriever Recall is the proportion of questions for which the correct document containing the answer is\n",
    "# among the correct documents\n",
    "print(\"Retriever Recall:\", retriever_eval_results[\"recall\"])\n",
    "dev_400_recall.append(retriever_eval_results[\"recall\"])\n",
    "# Retriever Mean Avg Precision rewards retrievers that give relevant documents a higher rank\n",
    "print(\"Retriever Mean Avg Precision:\", retriever_eval_results[\"map\"])\n",
    "dev_400_map.append(retriever_eval_results[\"map\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6643a609",
   "metadata": {},
   "source": [
    "## Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "1f1db274",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_store.delete_documents(index=doc_index)\n",
    "document_store.delete_documents(index=label_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec91da9",
   "metadata": {},
   "source": [
    "### Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "b15d46f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - haystack.document_stores.utils -  No title information found for documents in QA file: squad_format_thesis/test.json\n"
     ]
    }
   ],
   "source": [
    "# The add_eval_data() method converts the given dataset in json format into Haystack document and label objects. Those objects are then indexed in their respective document and label index in the document store. The method can be used with any dataset in SQuAD format.\n",
    "document_store.add_eval_data(\n",
    "    filename=\"squad_format_thesis/test.json\",\n",
    "    doc_index=doc_index,\n",
    "    label_index=label_index,\n",
    "    preprocessor=preprocessor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "896aa038",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.modeling.utils -  Using devices: CUDA:0\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 1\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_2/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_2/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_2/passage_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_2/passage_encoder\n",
      "INFO - haystack.nodes.retriever.dense -  DPR model loaded from models/model_2\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import DensePassageRetriever\n",
    "\n",
    "save_dir = \"models/model_2\"\n",
    "\n",
    "retriever = DensePassageRetriever.load(load_dir=save_dir, document_store=document_store, use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "643a0dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.document_stores.elasticsearch -  Updating embeddings for all 326 docs ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9824579338fd4d1ca773a44993442d71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Updating embeddings:   0%|          | 0/326 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Create embeddings:   0%|          | 0/336 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "document_store.update_embeddings(retriever, index=doc_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "86cc8b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.nodes.retriever.base -  Performing eval queries...\n",
      "100%|███████████████████████████████████████████| 25/25 [00:00<00:00, 72.97it/s]\n",
      "INFO - haystack.nodes.retriever.base -  For 16 out of 25 questions (64.00%), the answer was in the top-10 candidate passages selected by the retriever.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retriever Recall: 0.64\n",
      "Retriever Mean Avg Precision: 0.3804285714285714\n"
     ]
    }
   ],
   "source": [
    "## Evaluate Retriever on its own # THIS IS THE FINE-TUNED model_1\n",
    "# Note that no_answer samples are omitted when evaluation is performed with this method\n",
    "retriever_eval_results = retriever.eval(top_k=10, label_index=label_index, doc_index=doc_index, open_domain=True)\n",
    "# Retriever Recall is the proportion of questions for which the correct document containing the answer is\n",
    "# among the correct documents\n",
    "print(\"Retriever Recall:\", retriever_eval_results[\"recall\"])\n",
    "test_400_recall.append(retriever_eval_results[\"recall\"])\n",
    "# Retriever Mean Avg Precision rewards retrievers that give relevant documents a higher rank\n",
    "print(\"Retriever Mean Avg Precision:\", retriever_eval_results[\"map\"])\n",
    "test_400_map.append(retriever_eval_results[\"map\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4fd675",
   "metadata": {},
   "source": [
    "### Dev set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "8978a312",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_store.delete_documents(index=doc_index)\n",
    "document_store.delete_documents(index=label_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "bd427417",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - haystack.document_stores.utils -  No title information found for documents in QA file: squad_format_thesis/dev.json\n"
     ]
    }
   ],
   "source": [
    "# The add_eval_data() method converts the given dataset in json format into Haystack document and label objects. Those objects are then indexed in their respective document and label index in the document store. The method can be used with any dataset in SQuAD format.\n",
    "document_store.add_eval_data(\n",
    "    filename=\"squad_format_thesis/dev.json\",\n",
    "    doc_index=doc_index,\n",
    "    label_index=label_index,\n",
    "    preprocessor=preprocessor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "6e05c83a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.modeling.utils -  Using devices: CUDA:0\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 1\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_2/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_2/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_2/passage_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_2/passage_encoder\n",
      "INFO - haystack.nodes.retriever.dense -  DPR model loaded from models/model_2\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import DensePassageRetriever\n",
    "\n",
    "save_dir = \"models/model_2\"\n",
    "\n",
    "retriever = DensePassageRetriever.load(load_dir=save_dir, document_store=document_store, use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "169f4d12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.document_stores.elasticsearch -  Updating embeddings for all 305 docs ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2deb73d9b04c4eafbc1f886594108fd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Updating embeddings:   0%|          | 0/305 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Create embeddings:   0%|          | 0/320 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "document_store.update_embeddings(retriever, index=doc_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "4f1f525f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.nodes.retriever.base -  Performing eval queries...\n",
      "100%|███████████████████████████████████████████| 24/24 [00:00<00:00, 85.49it/s]\n",
      "INFO - haystack.nodes.retriever.base -  For 12 out of 24 questions (50.00%), the answer was in the top-10 candidate passages selected by the retriever.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retriever Recall: 0.5\n",
      "Retriever Mean Avg Precision: 0.3483796296296296\n"
     ]
    }
   ],
   "source": [
    "## Evaluate Retriever on its own # THIS IS THE FINE-TUNED model_1\n",
    "# Note that no_answer samples are omitted when evaluation is performed with this method\n",
    "retriever_eval_results = retriever.eval(top_k=10, label_index=label_index, doc_index=doc_index, open_domain=True)\n",
    "# Retriever Recall is the proportion of questions for which the correct document containing the answer is\n",
    "# among the correct documents\n",
    "print(\"Retriever Recall:\", retriever_eval_results[\"recall\"])\n",
    "dev_400_recall.append(retriever_eval_results[\"recall\"])\n",
    "# Retriever Mean Avg Precision rewards retrievers that give relevant documents a higher rank\n",
    "print(\"Retriever Mean Avg Precision:\", retriever_eval_results[\"map\"])\n",
    "dev_400_map.append(retriever_eval_results[\"map\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3638ddf",
   "metadata": {},
   "source": [
    "## Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "b261a489",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_store.delete_documents(index=doc_index)\n",
    "document_store.delete_documents(index=label_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a214ab",
   "metadata": {},
   "source": [
    "### Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "05eb14f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - haystack.document_stores.utils -  No title information found for documents in QA file: squad_format_thesis/test.json\n"
     ]
    }
   ],
   "source": [
    "# The add_eval_data() method converts the given dataset in json format into Haystack document and label objects. Those objects are then indexed in their respective document and label index in the document store. The method can be used with any dataset in SQuAD format.\n",
    "document_store.add_eval_data(\n",
    "    filename=\"squad_format_thesis/test.json\",\n",
    "    doc_index=doc_index,\n",
    "    label_index=label_index,\n",
    "    preprocessor=preprocessor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "aa3a8487",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.modeling.utils -  Using devices: CUDA:0\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 1\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_3/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_3/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_3/passage_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_3/passage_encoder\n",
      "INFO - haystack.nodes.retriever.dense -  DPR model loaded from models/model_3\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import DensePassageRetriever\n",
    "\n",
    "save_dir = \"models/model_3\"\n",
    "\n",
    "retriever = DensePassageRetriever.load(load_dir=save_dir, document_store=document_store, use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "da26a322",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.document_stores.elasticsearch -  Updating embeddings for all 326 docs ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d87bf9162b0440449fe1bf959836df3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Updating embeddings:   0%|          | 0/326 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Create embeddings:   0%|          | 0/336 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "document_store.update_embeddings(retriever, index=doc_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "85ad40e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.nodes.retriever.base -  Performing eval queries...\n",
      "100%|███████████████████████████████████████████| 25/25 [00:00<00:00, 87.63it/s]\n",
      "INFO - haystack.nodes.retriever.base -  For 16 out of 25 questions (64.00%), the answer was in the top-10 candidate passages selected by the retriever.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retriever Recall: 0.64\n",
      "Retriever Mean Avg Precision: 0.36753968253968256\n"
     ]
    }
   ],
   "source": [
    "## Evaluate Retriever on its own # THIS IS THE FINE-TUNED model_1\n",
    "# Note that no_answer samples are omitted when evaluation is performed with this method\n",
    "retriever_eval_results = retriever.eval(top_k=10, label_index=label_index, doc_index=doc_index, open_domain=True)\n",
    "# Retriever Recall is the proportion of questions for which the correct document containing the answer is\n",
    "# among the correct documents\n",
    "print(\"Retriever Recall:\", retriever_eval_results[\"recall\"])\n",
    "test_400_recall.append(retriever_eval_results[\"recall\"])\n",
    "# Retriever Mean Avg Precision rewards retrievers that give relevant documents a higher rank\n",
    "print(\"Retriever Mean Avg Precision:\", retriever_eval_results[\"map\"])\n",
    "test_400_map.append(retriever_eval_results[\"map\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9c1caf",
   "metadata": {},
   "source": [
    "### Dev set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "0d2ef789",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_store.delete_documents(index=doc_index)\n",
    "document_store.delete_documents(index=label_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "188b3c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - haystack.document_stores.utils -  No title information found for documents in QA file: squad_format_thesis/dev.json\n"
     ]
    }
   ],
   "source": [
    "# The add_eval_data() method converts the given dataset in json format into Haystack document and label objects. Those objects are then indexed in their respective document and label index in the document store. The method can be used with any dataset in SQuAD format.\n",
    "document_store.add_eval_data(\n",
    "    filename=\"squad_format_thesis/dev.json\",\n",
    "    doc_index=doc_index,\n",
    "    label_index=label_index,\n",
    "    preprocessor=preprocessor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "1d4daf98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.modeling.utils -  Using devices: CUDA:0\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 1\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_3/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_3/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_3/passage_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_3/passage_encoder\n",
      "INFO - haystack.nodes.retriever.dense -  DPR model loaded from models/model_3\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import DensePassageRetriever\n",
    "\n",
    "save_dir = \"models/model_3\"\n",
    "\n",
    "retriever = DensePassageRetriever.load(load_dir=save_dir, document_store=document_store, use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "346194fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.document_stores.elasticsearch -  Updating embeddings for all 305 docs ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d44dc7fb91db4b24a247605c67c7d0c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Updating embeddings:   0%|          | 0/305 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Create embeddings:   0%|          | 0/320 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "document_store.update_embeddings(retriever, index=doc_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "baa0ca87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.nodes.retriever.base -  Performing eval queries...\n",
      "100%|███████████████████████████████████████████| 24/24 [00:00<00:00, 85.67it/s]\n",
      "INFO - haystack.nodes.retriever.base -  For 12 out of 24 questions (50.00%), the answer was in the top-10 candidate passages selected by the retriever.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retriever Recall: 0.5\n",
      "Retriever Mean Avg Precision: 0.25143849206349206\n"
     ]
    }
   ],
   "source": [
    "## Evaluate Retriever on its own # THIS IS THE FINE-TUNED model_1\n",
    "# Note that no_answer samples are omitted when evaluation is performed with this method\n",
    "retriever_eval_results = retriever.eval(top_k=10, label_index=label_index, doc_index=doc_index, open_domain=True)\n",
    "# Retriever Recall is the proportion of questions for which the correct document containing the answer is\n",
    "# among the correct documents\n",
    "print(\"Retriever Recall:\", retriever_eval_results[\"recall\"])\n",
    "dev_400_recall.append(retriever_eval_results[\"recall\"])\n",
    "# Retriever Mean Avg Precision rewards retrievers that give relevant documents a higher rank\n",
    "print(\"Retriever Mean Avg Precision:\", retriever_eval_results[\"map\"])\n",
    "dev_400_map.append(retriever_eval_results[\"map\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9045ba4",
   "metadata": {},
   "source": [
    "## Model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "c2969894",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_store.delete_documents(index=doc_index)\n",
    "document_store.delete_documents(index=label_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b5155c",
   "metadata": {},
   "source": [
    "### Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "8de78ef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - haystack.document_stores.utils -  No title information found for documents in QA file: squad_format_thesis/test.json\n"
     ]
    }
   ],
   "source": [
    "# The add_eval_data() method converts the given dataset in json format into Haystack document and label objects. Those objects are then indexed in their respective document and label index in the document store. The method can be used with any dataset in SQuAD format.\n",
    "document_store.add_eval_data(\n",
    "    filename=\"squad_format_thesis/test.json\",\n",
    "    doc_index=doc_index,\n",
    "    label_index=label_index,\n",
    "    preprocessor=preprocessor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "60894a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.modeling.utils -  Using devices: CUDA:0\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 1\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_4/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_4/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_4/passage_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_4/passage_encoder\n",
      "INFO - haystack.nodes.retriever.dense -  DPR model loaded from models/model_4\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import DensePassageRetriever\n",
    "\n",
    "save_dir = \"models/model_4\"\n",
    "\n",
    "retriever = DensePassageRetriever.load(load_dir=save_dir, document_store=document_store, use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "9703c996",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.document_stores.elasticsearch -  Updating embeddings for all 326 docs ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5805b5208f854880b1f8e2e5343b1672",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Updating embeddings:   0%|          | 0/326 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Create embeddings:   0%|          | 0/336 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "document_store.update_embeddings(retriever, index=doc_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "7fc4bb5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.nodes.retriever.base -  Performing eval queries...\n",
      "100%|███████████████████████████████████████████| 25/25 [00:00<00:00, 89.62it/s]\n",
      "INFO - haystack.nodes.retriever.base -  For 13 out of 25 questions (52.00%), the answer was in the top-10 candidate passages selected by the retriever.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retriever Recall: 0.52\n",
      "Retriever Mean Avg Precision: 0.3224444444444444\n"
     ]
    }
   ],
   "source": [
    "## Evaluate Retriever on its own # THIS IS THE FINE-TUNED model_1\n",
    "# Note that no_answer samples are omitted when evaluation is performed with this method\n",
    "retriever_eval_results = retriever.eval(top_k=10, label_index=label_index, doc_index=doc_index, open_domain=True)\n",
    "# Retriever Recall is the proportion of questions for which the correct document containing the answer is\n",
    "# among the correct documents\n",
    "print(\"Retriever Recall:\", retriever_eval_results[\"recall\"])\n",
    "test_400_recall.append(retriever_eval_results[\"recall\"])\n",
    "# Retriever Mean Avg Precision rewards retrievers that give relevant documents a higher rank\n",
    "print(\"Retriever Mean Avg Precision:\", retriever_eval_results[\"map\"])\n",
    "test_400_map.append(retriever_eval_results[\"map\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33ace31",
   "metadata": {},
   "source": [
    "### Dev set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "45f917ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_store.delete_documents(index=doc_index)\n",
    "document_store.delete_documents(index=label_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "ec9c811d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - haystack.document_stores.utils -  No title information found for documents in QA file: squad_format_thesis/dev.json\n"
     ]
    }
   ],
   "source": [
    "# The add_eval_data() method converts the given dataset in json format into Haystack document and label objects. Those objects are then indexed in their respective document and label index in the document store. The method can be used with any dataset in SQuAD format.\n",
    "document_store.add_eval_data(\n",
    "    filename=\"squad_format_thesis/dev.json\",\n",
    "    doc_index=doc_index,\n",
    "    label_index=label_index,\n",
    "    preprocessor=preprocessor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "9780b445",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.modeling.utils -  Using devices: CUDA:0\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 1\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_4/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_4/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_4/passage_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_4/passage_encoder\n",
      "INFO - haystack.nodes.retriever.dense -  DPR model loaded from models/model_4\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import DensePassageRetriever\n",
    "\n",
    "save_dir = \"models/model_4\"\n",
    "\n",
    "retriever = DensePassageRetriever.load(load_dir=save_dir, document_store=document_store, use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "eed93302",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.document_stores.elasticsearch -  Updating embeddings for all 305 docs ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35603b549f4640229e3a7a350f7b2064",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Updating embeddings:   0%|          | 0/305 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Create embeddings:   0%|          | 0/320 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "document_store.update_embeddings(retriever, index=doc_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "71610b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.nodes.retriever.base -  Performing eval queries...\n",
      "100%|███████████████████████████████████████████| 24/24 [00:00<00:00, 67.72it/s]\n",
      "INFO - haystack.nodes.retriever.base -  For 9 out of 24 questions (37.50%), the answer was in the top-10 candidate passages selected by the retriever.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retriever Recall: 0.375\n",
      "Retriever Mean Avg Precision: 0.20949074074074073\n"
     ]
    }
   ],
   "source": [
    "## Evaluate Retriever on its own # THIS IS THE FINE-TUNED model_1\n",
    "# Note that no_answer samples are omitted when evaluation is performed with this method\n",
    "retriever_eval_results = retriever.eval(top_k=10, label_index=label_index, doc_index=doc_index, open_domain=True)\n",
    "# Retriever Recall is the proportion of questions for which the correct document containing the answer is\n",
    "# among the correct documents\n",
    "print(\"Retriever Recall:\", retriever_eval_results[\"recall\"])\n",
    "dev_400_recall.append(retriever_eval_results[\"recall\"])\n",
    "# Retriever Mean Avg Precision rewards retrievers that give relevant documents a higher rank\n",
    "print(\"Retriever Mean Avg Precision:\", retriever_eval_results[\"map\"])\n",
    "dev_400_map.append(retriever_eval_results[\"map\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3a8c5b",
   "metadata": {},
   "source": [
    "## Model 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "65596223",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_store.delete_documents(index=doc_index)\n",
    "document_store.delete_documents(index=label_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3219e677",
   "metadata": {},
   "source": [
    "### Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "3b7aec85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - haystack.document_stores.utils -  No title information found for documents in QA file: squad_format_thesis/test.json\n"
     ]
    }
   ],
   "source": [
    "# The add_eval_data() method converts the given dataset in json format into Haystack document and label objects. Those objects are then indexed in their respective document and label index in the document store. The method can be used with any dataset in SQuAD format.\n",
    "document_store.add_eval_data(\n",
    "    filename=\"squad_format_thesis/test.json\",\n",
    "    doc_index=doc_index,\n",
    "    label_index=label_index,\n",
    "    preprocessor=preprocessor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "552a924c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.modeling.utils -  Using devices: CUDA:0\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 1\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_5/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_5/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_5/passage_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_5/passage_encoder\n",
      "INFO - haystack.nodes.retriever.dense -  DPR model loaded from models/model_5\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import DensePassageRetriever\n",
    "\n",
    "save_dir = \"models/model_5\"\n",
    "\n",
    "retriever = DensePassageRetriever.load(load_dir=save_dir, document_store=document_store, use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "bdd1d5d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.document_stores.elasticsearch -  Updating embeddings for all 326 docs ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd652f320f4a42e2bd9017d1b9d34ba0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Updating embeddings:   0%|          | 0/326 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Create embeddings:   0%|          | 0/336 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "document_store.update_embeddings(retriever, index=doc_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "96c8660d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.nodes.retriever.base -  Performing eval queries...\n",
      "100%|███████████████████████████████████████████| 25/25 [00:00<00:00, 87.40it/s]\n",
      "INFO - haystack.nodes.retriever.base -  For 16 out of 25 questions (64.00%), the answer was in the top-10 candidate passages selected by the retriever.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retriever Recall: 0.64\n",
      "Retriever Mean Avg Precision: 0.3813809523809523\n"
     ]
    }
   ],
   "source": [
    "## Evaluate Retriever on its own # THIS IS THE FINE-TUNED model_1\n",
    "# Note that no_answer samples are omitted when evaluation is performed with this method\n",
    "retriever_eval_results = retriever.eval(top_k=10, label_index=label_index, doc_index=doc_index, open_domain=True)\n",
    "# Retriever Recall is the proportion of questions for which the correct document containing the answer is\n",
    "# among the correct documents\n",
    "print(\"Retriever Recall:\", retriever_eval_results[\"recall\"])\n",
    "test_400_recall.append(retriever_eval_results[\"recall\"])\n",
    "# Retriever Mean Avg Precision rewards retrievers that give relevant documents a higher rank\n",
    "print(\"Retriever Mean Avg Precision:\", retriever_eval_results[\"map\"])\n",
    "test_400_map.append(retriever_eval_results[\"map\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2dd4555",
   "metadata": {},
   "source": [
    "### Dev set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "9fd81c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_store.delete_documents(index=doc_index)\n",
    "document_store.delete_documents(index=label_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "b101da9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - haystack.document_stores.utils -  No title information found for documents in QA file: squad_format_thesis/dev.json\n"
     ]
    }
   ],
   "source": [
    "# The add_eval_data() method converts the given dataset in json format into Haystack document and label objects. Those objects are then indexed in their respective document and label index in the document store. The method can be used with any dataset in SQuAD format.\n",
    "document_store.add_eval_data(\n",
    "    filename=\"squad_format_thesis/dev.json\",\n",
    "    doc_index=doc_index,\n",
    "    label_index=label_index,\n",
    "    preprocessor=preprocessor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "59a4bd01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.modeling.utils -  Using devices: CUDA:0\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 1\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_5/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_5/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_5/passage_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_5/passage_encoder\n",
      "INFO - haystack.nodes.retriever.dense -  DPR model loaded from models/model_5\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import DensePassageRetriever\n",
    "\n",
    "save_dir = \"models/model_5\"\n",
    "\n",
    "retriever = DensePassageRetriever.load(load_dir=save_dir, document_store=document_store, use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "05ae2b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.document_stores.elasticsearch -  Updating embeddings for all 305 docs ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da3a3cae616f4d239edfbf528008608d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Updating embeddings:   0%|          | 0/305 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Create embeddings:   0%|          | 0/320 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "document_store.update_embeddings(retriever, index=doc_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "4b49bf0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.nodes.retriever.base -  Performing eval queries...\n",
      "100%|███████████████████████████████████████████| 24/24 [00:00<00:00, 82.36it/s]\n",
      "INFO - haystack.nodes.retriever.base -  For 12 out of 24 questions (50.00%), the answer was in the top-10 candidate passages selected by the retriever.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retriever Recall: 0.5\n",
      "Retriever Mean Avg Precision: 0.38958333333333334\n"
     ]
    }
   ],
   "source": [
    "## Evaluate Retriever on its own # THIS IS THE FINE-TUNED model_1\n",
    "# Note that no_answer samples are omitted when evaluation is performed with this method\n",
    "retriever_eval_results = retriever.eval(top_k=10, label_index=label_index, doc_index=doc_index, open_domain=True)\n",
    "# Retriever Recall is the proportion of questions for which the correct document containing the answer is\n",
    "# among the correct documents\n",
    "print(\"Retriever Recall:\", retriever_eval_results[\"recall\"])\n",
    "dev_400_recall.append(retriever_eval_results[\"recall\"])\n",
    "# Retriever Mean Avg Precision rewards retrievers that give relevant documents a higher rank\n",
    "print(\"Retriever Mean Avg Precision:\", retriever_eval_results[\"map\"])\n",
    "dev_400_map.append(retriever_eval_results[\"map\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a2de63",
   "metadata": {},
   "source": [
    "## Model 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "aefc9c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_store.delete_documents(index=doc_index)\n",
    "document_store.delete_documents(index=label_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fecced2d",
   "metadata": {},
   "source": [
    "### Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "db32081c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - haystack.document_stores.utils -  No title information found for documents in QA file: squad_format_thesis/test.json\n"
     ]
    }
   ],
   "source": [
    "# The add_eval_data() method converts the given dataset in json format into Haystack document and label objects. Those objects are then indexed in their respective document and label index in the document store. The method can be used with any dataset in SQuAD format.\n",
    "document_store.add_eval_data(\n",
    "    filename=\"squad_format_thesis/test.json\",\n",
    "    doc_index=doc_index,\n",
    "    label_index=label_index,\n",
    "    preprocessor=preprocessor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "0e1c85c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.modeling.utils -  Using devices: CUDA:0\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 1\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_6/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_6/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_6/passage_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_6/passage_encoder\n",
      "INFO - haystack.nodes.retriever.dense -  DPR model loaded from models/model_6\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import DensePassageRetriever\n",
    "\n",
    "save_dir = \"models/model_6\"\n",
    "\n",
    "retriever = DensePassageRetriever.load(load_dir=save_dir, document_store=document_store, use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "f6ec7547",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.document_stores.elasticsearch -  Updating embeddings for all 326 docs ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff72e86b737f408bb8777a19cae2f8e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Updating embeddings:   0%|          | 0/326 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Create embeddings:   0%|          | 0/336 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "document_store.update_embeddings(retriever, index=doc_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "54974441",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.nodes.retriever.base -  Performing eval queries...\n",
      "100%|███████████████████████████████████████████| 25/25 [00:00<00:00, 78.71it/s]\n",
      "INFO - haystack.nodes.retriever.base -  For 13 out of 25 questions (52.00%), the answer was in the top-10 candidate passages selected by the retriever.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retriever Recall: 0.52\n",
      "Retriever Mean Avg Precision: 0.3361111111111111\n"
     ]
    }
   ],
   "source": [
    "## Evaluate Retriever on its own # THIS IS THE FINE-TUNED model_1\n",
    "# Note that no_answer samples are omitted when evaluation is performed with this method\n",
    "retriever_eval_results = retriever.eval(top_k=10, label_index=label_index, doc_index=doc_index, open_domain=True)\n",
    "# Retriever Recall is the proportion of questions for which the correct document containing the answer is\n",
    "# among the correct documents\n",
    "print(\"Retriever Recall:\", retriever_eval_results[\"recall\"])\n",
    "test_400_recall.append(retriever_eval_results[\"recall\"])\n",
    "# Retriever Mean Avg Precision rewards retrievers that give relevant documents a higher rank\n",
    "print(\"Retriever Mean Avg Precision:\", retriever_eval_results[\"map\"])\n",
    "test_400_map.append(retriever_eval_results[\"map\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6bbcb1",
   "metadata": {},
   "source": [
    "### Dev set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "064f5911",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_store.delete_documents(index=doc_index)\n",
    "document_store.delete_documents(index=label_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "58ffd9e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - haystack.document_stores.utils -  No title information found for documents in QA file: squad_format_thesis/dev.json\n"
     ]
    }
   ],
   "source": [
    "# The add_eval_data() method converts the given dataset in json format into Haystack document and label objects. Those objects are then indexed in their respective document and label index in the document store. The method can be used with any dataset in SQuAD format.\n",
    "document_store.add_eval_data(\n",
    "    filename=\"squad_format_thesis/dev.json\",\n",
    "    doc_index=doc_index,\n",
    "    label_index=label_index,\n",
    "    preprocessor=preprocessor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "2e755ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.modeling.utils -  Using devices: CUDA:0\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 1\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_6/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_6/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_6/passage_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_6/passage_encoder\n",
      "INFO - haystack.nodes.retriever.dense -  DPR model loaded from models/model_6\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import DensePassageRetriever\n",
    "\n",
    "save_dir = \"models/model_6\"\n",
    "\n",
    "retriever = DensePassageRetriever.load(load_dir=save_dir, document_store=document_store, use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "78a1aa78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.document_stores.elasticsearch -  Updating embeddings for all 305 docs ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7591b2687a1d4a57b4da7e1f38dbde24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Updating embeddings:   0%|          | 0/305 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Create embeddings:   0%|          | 0/320 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "document_store.update_embeddings(retriever, index=doc_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "db5f2ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.nodes.retriever.base -  Performing eval queries...\n",
      "100%|███████████████████████████████████████████| 24/24 [00:00<00:00, 75.94it/s]\n",
      "INFO - haystack.nodes.retriever.base -  For 9 out of 24 questions (37.50%), the answer was in the top-10 candidate passages selected by the retriever.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retriever Recall: 0.375\n",
      "Retriever Mean Avg Precision: 0.21006944444444442\n"
     ]
    }
   ],
   "source": [
    "## Evaluate Retriever on its own # THIS IS THE FINE-TUNED model_1\n",
    "# Note that no_answer samples are omitted when evaluation is performed with this method\n",
    "retriever_eval_results = retriever.eval(top_k=10, label_index=label_index, doc_index=doc_index, open_domain=True)\n",
    "# Retriever Recall is the proportion of questions for which the correct document containing the answer is\n",
    "# among the correct documents\n",
    "print(\"Retriever Recall:\", retriever_eval_results[\"recall\"])\n",
    "dev_400_recall.append(retriever_eval_results[\"recall\"])\n",
    "# Retriever Mean Avg Precision rewards retrievers that give relevant documents a higher rank\n",
    "print(\"Retriever Mean Avg Precision:\", retriever_eval_results[\"map\"])\n",
    "dev_400_map.append(retriever_eval_results[\"map\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd8bbc0",
   "metadata": {},
   "source": [
    "## Model 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "ba19c243",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_store.delete_documents(index=doc_index)\n",
    "document_store.delete_documents(index=label_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df5de16",
   "metadata": {},
   "source": [
    "### Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "7fe13829",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - haystack.document_stores.utils -  No title information found for documents in QA file: squad_format_thesis/test.json\n"
     ]
    }
   ],
   "source": [
    "# The add_eval_data() method converts the given dataset in json format into Haystack document and label objects. Those objects are then indexed in their respective document and label index in the document store. The method can be used with any dataset in SQuAD format.\n",
    "document_store.add_eval_data(\n",
    "    filename=\"squad_format_thesis/test.json\",\n",
    "    doc_index=doc_index,\n",
    "    label_index=label_index,\n",
    "    preprocessor=preprocessor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "0a87c519",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.modeling.utils -  Using devices: CUDA:0\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 1\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_7/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_7/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_7/passage_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_7/passage_encoder\n",
      "INFO - haystack.nodes.retriever.dense -  DPR model loaded from models/model_7\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import DensePassageRetriever\n",
    "\n",
    "save_dir = \"models/model_7\"\n",
    "\n",
    "retriever = DensePassageRetriever.load(load_dir=save_dir, document_store=document_store, use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "a9c8c3a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.document_stores.elasticsearch -  Updating embeddings for all 326 docs ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "895916e5cf0e48a99420708c818ec83b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Updating embeddings:   0%|          | 0/326 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Create embeddings:   0%|          | 0/336 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "document_store.update_embeddings(retriever, index=doc_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "aff3d76c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.nodes.retriever.base -  Performing eval queries...\n",
      "100%|███████████████████████████████████████████| 25/25 [00:00<00:00, 80.49it/s]\n",
      "INFO - haystack.nodes.retriever.base -  For 16 out of 25 questions (64.00%), the answer was in the top-10 candidate passages selected by the retriever.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retriever Recall: 0.64\n",
      "Retriever Mean Avg Precision: 0.3813809523809523\n"
     ]
    }
   ],
   "source": [
    "## Evaluate Retriever on its own # THIS IS THE FINE-TUNED model_1\n",
    "# Note that no_answer samples are omitted when evaluation is performed with this method\n",
    "retriever_eval_results = retriever.eval(top_k=10, label_index=label_index, doc_index=doc_index, open_domain=True)\n",
    "# Retriever Recall is the proportion of questions for which the correct document containing the answer is\n",
    "# among the correct documents\n",
    "print(\"Retriever Recall:\", retriever_eval_results[\"recall\"])\n",
    "test_400_recall.append(retriever_eval_results[\"recall\"])\n",
    "# Retriever Mean Avg Precision rewards retrievers that give relevant documents a higher rank\n",
    "print(\"Retriever Mean Avg Precision:\", retriever_eval_results[\"map\"])\n",
    "test_400_map.append(retriever_eval_results[\"map\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55249c70",
   "metadata": {},
   "source": [
    "### Dev set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "134565ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_store.delete_documents(index=doc_index)\n",
    "document_store.delete_documents(index=label_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "a0266ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - haystack.document_stores.utils -  No title information found for documents in QA file: squad_format_thesis/dev.json\n"
     ]
    }
   ],
   "source": [
    "# The add_eval_data() method converts the given dataset in json format into Haystack document and label objects. Those objects are then indexed in their respective document and label index in the document store. The method can be used with any dataset in SQuAD format.\n",
    "document_store.add_eval_data(\n",
    "    filename=\"squad_format_thesis/dev.json\",\n",
    "    doc_index=doc_index,\n",
    "    label_index=label_index,\n",
    "    preprocessor=preprocessor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "65dd3934",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.modeling.utils -  Using devices: CUDA:0\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 1\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_7/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_7/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_7/passage_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_7/passage_encoder\n",
      "INFO - haystack.nodes.retriever.dense -  DPR model loaded from models/model_7\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import DensePassageRetriever\n",
    "\n",
    "save_dir = \"models/model_7\"\n",
    "\n",
    "retriever = DensePassageRetriever.load(load_dir=save_dir, document_store=document_store, use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "df250300",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.document_stores.elasticsearch -  Updating embeddings for all 305 docs ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a3d2483312f456eb67a96ef84aa7355",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Updating embeddings:   0%|          | 0/305 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Create embeddings:   0%|          | 0/320 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "document_store.update_embeddings(retriever, index=doc_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "8447be05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.nodes.retriever.base -  Performing eval queries...\n",
      "100%|███████████████████████████████████████████| 24/24 [00:00<00:00, 85.84it/s]\n",
      "INFO - haystack.nodes.retriever.base -  For 12 out of 24 questions (50.00%), the answer was in the top-10 candidate passages selected by the retriever.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retriever Recall: 0.5\n",
      "Retriever Mean Avg Precision: 0.34791666666666665\n"
     ]
    }
   ],
   "source": [
    "## Evaluate Retriever on its own # THIS IS THE FINE-TUNED model_1\n",
    "# Note that no_answer samples are omitted when evaluation is performed with this method\n",
    "retriever_eval_results = retriever.eval(top_k=10, label_index=label_index, doc_index=doc_index, open_domain=True)\n",
    "# Retriever Recall is the proportion of questions for which the correct document containing the answer is\n",
    "# among the correct documents\n",
    "print(\"Retriever Recall:\", retriever_eval_results[\"recall\"])\n",
    "dev_400_recall.append(retriever_eval_results[\"recall\"])\n",
    "# Retriever Mean Avg Precision rewards retrievers that give relevant documents a higher rank\n",
    "print(\"Retriever Mean Avg Precision:\", retriever_eval_results[\"map\"])\n",
    "dev_400_map.append(retriever_eval_results[\"map\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce39eca",
   "metadata": {},
   "source": [
    "## Model 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "a2317c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_store.delete_documents(index=doc_index)\n",
    "document_store.delete_documents(index=label_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6065c18",
   "metadata": {},
   "source": [
    "### Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "181e7d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - haystack.document_stores.utils -  No title information found for documents in QA file: squad_format_thesis/test.json\n"
     ]
    }
   ],
   "source": [
    "# The add_eval_data() method converts the given dataset in json format into Haystack document and label objects. Those objects are then indexed in their respective document and label index in the document store. The method can be used with any dataset in SQuAD format.\n",
    "document_store.add_eval_data(\n",
    "    filename=\"squad_format_thesis/test.json\",\n",
    "    doc_index=doc_index,\n",
    "    label_index=label_index,\n",
    "    preprocessor=preprocessor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "029371a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.modeling.utils -  Using devices: CUDA:0\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 1\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_8/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_8/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_8/passage_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_8/passage_encoder\n",
      "INFO - haystack.nodes.retriever.dense -  DPR model loaded from models/model_8\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import DensePassageRetriever\n",
    "\n",
    "save_dir = \"models/model_8\"\n",
    "\n",
    "retriever = DensePassageRetriever.load(load_dir=save_dir, document_store=document_store, use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "76efb330",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.document_stores.elasticsearch -  Updating embeddings for all 326 docs ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7354d7e925f540f083a40d7ca1e3ed1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Updating embeddings:   0%|          | 0/326 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Create embeddings:   0%|          | 0/336 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "document_store.update_embeddings(retriever, index=doc_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "d4185beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.nodes.retriever.base -  Performing eval queries...\n",
      "100%|███████████████████████████████████████████| 25/25 [00:00<00:00, 72.77it/s]\n",
      "INFO - haystack.nodes.retriever.base -  For 16 out of 25 questions (64.00%), the answer was in the top-10 candidate passages selected by the retriever.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retriever Recall: 0.64\n",
      "Retriever Mean Avg Precision: 0.36825396825396817\n"
     ]
    }
   ],
   "source": [
    "## Evaluate Retriever on its own # THIS IS THE FINE-TUNED model_1\n",
    "# Note that no_answer samples are omitted when evaluation is performed with this method\n",
    "retriever_eval_results = retriever.eval(top_k=10, label_index=label_index, doc_index=doc_index, open_domain=True)\n",
    "# Retriever Recall is the proportion of questions for which the correct document containing the answer is\n",
    "# among the correct documents\n",
    "print(\"Retriever Recall:\", retriever_eval_results[\"recall\"])\n",
    "test_400_recall.append(retriever_eval_results[\"recall\"])\n",
    "# Retriever Mean Avg Precision rewards retrievers that give relevant documents a higher rank\n",
    "print(\"Retriever Mean Avg Precision:\", retriever_eval_results[\"map\"])\n",
    "test_400_map.append(retriever_eval_results[\"map\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f5af0c",
   "metadata": {},
   "source": [
    "### Dev set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "ac9b9fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_store.delete_documents(index=doc_index)\n",
    "document_store.delete_documents(index=label_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "e141b4bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - haystack.document_stores.utils -  No title information found for documents in QA file: squad_format_thesis/dev.json\n"
     ]
    }
   ],
   "source": [
    "# The add_eval_data() method converts the given dataset in json format into Haystack document and label objects. Those objects are then indexed in their respective document and label index in the document store. The method can be used with any dataset in SQuAD format.\n",
    "document_store.add_eval_data(\n",
    "    filename=\"squad_format_thesis/dev.json\",\n",
    "    doc_index=doc_index,\n",
    "    label_index=label_index,\n",
    "    preprocessor=preprocessor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "5027b793",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.modeling.utils -  Using devices: CUDA:0\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 1\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_8/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_8/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_8/passage_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_8/passage_encoder\n",
      "INFO - haystack.nodes.retriever.dense -  DPR model loaded from models/model_8\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import DensePassageRetriever\n",
    "\n",
    "save_dir = \"models/model_8\"\n",
    "\n",
    "retriever = DensePassageRetriever.load(load_dir=save_dir, document_store=document_store, use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "786526e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.document_stores.elasticsearch -  Updating embeddings for all 305 docs ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9342c9fa17774abbb3b2a8890b0fd67c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Updating embeddings:   0%|          | 0/305 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Create embeddings:   0%|          | 0/320 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "document_store.update_embeddings(retriever, index=doc_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "d554dccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.nodes.retriever.base -  Performing eval queries...\n",
      "100%|███████████████████████████████████████████| 24/24 [00:00<00:00, 63.88it/s]\n",
      "INFO - haystack.nodes.retriever.base -  For 12 out of 24 questions (50.00%), the answer was in the top-10 candidate passages selected by the retriever.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retriever Recall: 0.5\n",
      "Retriever Mean Avg Precision: 0.2659722222222222\n"
     ]
    }
   ],
   "source": [
    "## Evaluate Retriever on its own # THIS IS THE FINE-TUNED model_1\n",
    "# Note that no_answer samples are omitted when evaluation is performed with this method\n",
    "retriever_eval_results = retriever.eval(top_k=10, label_index=label_index, doc_index=doc_index, open_domain=True)\n",
    "# Retriever Recall is the proportion of questions for which the correct document containing the answer is\n",
    "# among the correct documents\n",
    "print(\"Retriever Recall:\", retriever_eval_results[\"recall\"])\n",
    "dev_400_recall.append(retriever_eval_results[\"recall\"])\n",
    "# Retriever Mean Avg Precision rewards retrievers that give relevant documents a higher rank\n",
    "print(\"Retriever Mean Avg Precision:\", retriever_eval_results[\"map\"])\n",
    "dev_400_map.append(retriever_eval_results[\"map\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16531e41",
   "metadata": {},
   "source": [
    "## Model 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "92ed6eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_store.delete_documents(index=doc_index)\n",
    "document_store.delete_documents(index=label_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a7d4f3",
   "metadata": {},
   "source": [
    "### Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "7ce2e339",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - haystack.document_stores.utils -  No title information found for documents in QA file: squad_format_thesis/test.json\n"
     ]
    }
   ],
   "source": [
    "# The add_eval_data() method converts the given dataset in json format into Haystack document and label objects. Those objects are then indexed in their respective document and label index in the document store. The method can be used with any dataset in SQuAD format.\n",
    "document_store.add_eval_data(\n",
    "    filename=\"squad_format_thesis/test.json\",\n",
    "    doc_index=doc_index,\n",
    "    label_index=label_index,\n",
    "    preprocessor=preprocessor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "7d609bea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.modeling.utils -  Using devices: CUDA:0\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 1\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_9/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_9/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_9/passage_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_9/passage_encoder\n",
      "INFO - haystack.nodes.retriever.dense -  DPR model loaded from models/model_9\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import DensePassageRetriever\n",
    "\n",
    "save_dir = \"models/model_9\"\n",
    "\n",
    "retriever = DensePassageRetriever.load(load_dir=save_dir, document_store=document_store, use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "308e94ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.document_stores.elasticsearch -  Updating embeddings for all 326 docs ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d0cab2b61104e68967bd7cf2a697860",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Updating embeddings:   0%|          | 0/326 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Create embeddings:   0%|          | 0/336 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "document_store.update_embeddings(retriever, index=doc_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "77c0ef88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.nodes.retriever.base -  Performing eval queries...\n",
      "100%|███████████████████████████████████████████| 25/25 [00:00<00:00, 67.32it/s]\n",
      "INFO - haystack.nodes.retriever.base -  For 16 out of 25 questions (64.00%), the answer was in the top-10 candidate passages selected by the retriever.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retriever Recall: 0.64\n",
      "Retriever Mean Avg Precision: 0.3813809523809523\n"
     ]
    }
   ],
   "source": [
    "## Evaluate Retriever on its own # THIS IS THE FINE-TUNED model_1\n",
    "# Note that no_answer samples are omitted when evaluation is performed with this method\n",
    "retriever_eval_results = retriever.eval(top_k=10, label_index=label_index, doc_index=doc_index, open_domain=True)\n",
    "# Retriever Recall is the proportion of questions for which the correct document containing the answer is\n",
    "# among the correct documents\n",
    "print(\"Retriever Recall:\", retriever_eval_results[\"recall\"])\n",
    "test_400_recall.append(retriever_eval_results[\"recall\"])\n",
    "# Retriever Mean Avg Precision rewards retrievers that give relevant documents a higher rank\n",
    "print(\"Retriever Mean Avg Precision:\", retriever_eval_results[\"map\"])\n",
    "test_400_map.append(retriever_eval_results[\"map\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5f1218",
   "metadata": {},
   "source": [
    "### Dev set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "8f6497a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_store.delete_documents(index=doc_index)\n",
    "document_store.delete_documents(index=label_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "e168ec94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - haystack.document_stores.utils -  No title information found for documents in QA file: squad_format_thesis/dev.json\n"
     ]
    }
   ],
   "source": [
    "# The add_eval_data() method converts the given dataset in json format into Haystack document and label objects. Those objects are then indexed in their respective document and label index in the document store. The method can be used with any dataset in SQuAD format.\n",
    "document_store.add_eval_data(\n",
    "    filename=\"squad_format_thesis/dev.json\",\n",
    "    doc_index=doc_index,\n",
    "    label_index=label_index,\n",
    "    preprocessor=preprocessor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "2c6a8736",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.modeling.utils -  Using devices: CUDA:0\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 1\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_9/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_9/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_9/passage_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_9/passage_encoder\n",
      "INFO - haystack.nodes.retriever.dense -  DPR model loaded from models/model_9\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import DensePassageRetriever\n",
    "\n",
    "save_dir = \"models/model_9\"\n",
    "\n",
    "retriever = DensePassageRetriever.load(load_dir=save_dir, document_store=document_store, use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "10081d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.document_stores.elasticsearch -  Updating embeddings for all 305 docs ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2e5d9df6a6e45cdaafee1dd6774e39d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Updating embeddings:   0%|          | 0/305 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Create embeddings:   0%|          | 0/320 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "document_store.update_embeddings(retriever, index=doc_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "093f39e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.nodes.retriever.base -  Performing eval queries...\n",
      "100%|███████████████████████████████████████████| 24/24 [00:00<00:00, 82.64it/s]\n",
      "INFO - haystack.nodes.retriever.base -  For 12 out of 24 questions (50.00%), the answer was in the top-10 candidate passages selected by the retriever.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retriever Recall: 0.5\n",
      "Retriever Mean Avg Precision: 0.38958333333333334\n"
     ]
    }
   ],
   "source": [
    "## Evaluate Retriever on its own # THIS IS THE FINE-TUNED model_1\n",
    "# Note that no_answer samples are omitted when evaluation is performed with this method\n",
    "retriever_eval_results = retriever.eval(top_k=10, label_index=label_index, doc_index=doc_index, open_domain=True)\n",
    "# Retriever Recall is the proportion of questions for which the correct document containing the answer is\n",
    "# among the correct documents\n",
    "print(\"Retriever Recall:\", retriever_eval_results[\"recall\"])\n",
    "dev_400_recall.append(retriever_eval_results[\"recall\"])\n",
    "# Retriever Mean Avg Precision rewards retrievers that give relevant documents a higher rank\n",
    "print(\"Retriever Mean Avg Precision:\", retriever_eval_results[\"map\"])\n",
    "dev_400_map.append(retriever_eval_results[\"map\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4ea61b",
   "metadata": {},
   "source": [
    "## Model 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "4d98c59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_store.delete_documents(index=doc_index)\n",
    "document_store.delete_documents(index=label_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633550f5",
   "metadata": {},
   "source": [
    "### Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "9fde9da6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - haystack.document_stores.utils -  No title information found for documents in QA file: squad_format_thesis/test.json\n"
     ]
    }
   ],
   "source": [
    "# The add_eval_data() method converts the given dataset in json format into Haystack document and label objects. Those objects are then indexed in their respective document and label index in the document store. The method can be used with any dataset in SQuAD format.\n",
    "document_store.add_eval_data(\n",
    "    filename=\"squad_format_thesis/test.json\",\n",
    "    doc_index=doc_index,\n",
    "    label_index=label_index,\n",
    "    preprocessor=preprocessor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "0a70fdfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.modeling.utils -  Using devices: CUDA:0\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 1\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_10/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_10/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_10/passage_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_10/passage_encoder\n",
      "INFO - haystack.nodes.retriever.dense -  DPR model loaded from models/model_10\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import DensePassageRetriever\n",
    "\n",
    "save_dir = \"models/model_10\"\n",
    "\n",
    "retriever = DensePassageRetriever.load(load_dir=save_dir, document_store=document_store, use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "bee7e69f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.document_stores.elasticsearch -  Updating embeddings for all 326 docs ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de92621248fc445ca98352cdf14190d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Updating embeddings:   0%|          | 0/326 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Create embeddings:   0%|          | 0/336 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "document_store.update_embeddings(retriever, index=doc_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "c387b6a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.nodes.retriever.base -  Performing eval queries...\n",
      "100%|███████████████████████████████████████████| 25/25 [00:00<00:00, 80.34it/s]\n",
      "INFO - haystack.nodes.retriever.base -  For 16 out of 25 questions (64.00%), the answer was in the top-10 candidate passages selected by the retriever.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retriever Recall: 0.64\n",
      "Retriever Mean Avg Precision: 0.3813809523809523\n"
     ]
    }
   ],
   "source": [
    "## Evaluate Retriever on its own # THIS IS THE FINE-TUNED model_1\n",
    "# Note that no_answer samples are omitted when evaluation is performed with this method\n",
    "retriever_eval_results = retriever.eval(top_k=10, label_index=label_index, doc_index=doc_index, open_domain=True)\n",
    "# Retriever Recall is the proportion of questions for which the correct document containing the answer is\n",
    "# among the correct documents\n",
    "print(\"Retriever Recall:\", retriever_eval_results[\"recall\"])\n",
    "test_400_recall.append(retriever_eval_results[\"recall\"])\n",
    "# Retriever Mean Avg Precision rewards retrievers that give relevant documents a higher rank\n",
    "print(\"Retriever Mean Avg Precision:\", retriever_eval_results[\"map\"])\n",
    "test_400_map.append(retriever_eval_results[\"map\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32904e8",
   "metadata": {},
   "source": [
    "### Dev set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "13936478",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_store.delete_documents(index=doc_index)\n",
    "document_store.delete_documents(index=label_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "6fc9734a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - haystack.document_stores.utils -  No title information found for documents in QA file: squad_format_thesis/dev.json\n"
     ]
    }
   ],
   "source": [
    "# The add_eval_data() method converts the given dataset in json format into Haystack document and label objects. Those objects are then indexed in their respective document and label index in the document store. The method can be used with any dataset in SQuAD format.\n",
    "document_store.add_eval_data(\n",
    "    filename=\"squad_format_thesis/dev.json\",\n",
    "    doc_index=doc_index,\n",
    "    label_index=label_index,\n",
    "    preprocessor=preprocessor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "eac04d1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.modeling.utils -  Using devices: CUDA:0\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 1\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_10/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_10/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_10/passage_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_10/passage_encoder\n",
      "INFO - haystack.nodes.retriever.dense -  DPR model loaded from models/model_10\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import DensePassageRetriever\n",
    "\n",
    "save_dir = \"models/model_10\"\n",
    "\n",
    "retriever = DensePassageRetriever.load(load_dir=save_dir, document_store=document_store, use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "c39a230e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.document_stores.elasticsearch -  Updating embeddings for all 305 docs ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11fea06f45a24302ae94ff42fe6905dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Updating embeddings:   0%|          | 0/305 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Create embeddings:   0%|          | 0/320 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "document_store.update_embeddings(retriever, index=doc_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "e2e3ec9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.nodes.retriever.base -  Performing eval queries...\n",
      "100%|███████████████████████████████████████████| 24/24 [00:00<00:00, 87.70it/s]\n",
      "INFO - haystack.nodes.retriever.base -  For 12 out of 24 questions (50.00%), the answer was in the top-10 candidate passages selected by the retriever.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retriever Recall: 0.5\n",
      "Retriever Mean Avg Precision: 0.38958333333333334\n"
     ]
    }
   ],
   "source": [
    "## Evaluate Retriever on its own # THIS IS THE FINE-TUNED model_1\n",
    "# Note that no_answer samples are omitted when evaluation is performed with this method\n",
    "retriever_eval_results = retriever.eval(top_k=10, label_index=label_index, doc_index=doc_index, open_domain=True)\n",
    "# Retriever Recall is the proportion of questions for which the correct document containing the answer is\n",
    "# among the correct documents\n",
    "print(\"Retriever Recall:\", retriever_eval_results[\"recall\"])\n",
    "dev_400_recall.append(retriever_eval_results[\"recall\"])\n",
    "# Retriever Mean Avg Precision rewards retrievers that give relevant documents a higher rank\n",
    "print(\"Retriever Mean Avg Precision:\", retriever_eval_results[\"map\"])\n",
    "dev_400_map.append(retriever_eval_results[\"map\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a66842",
   "metadata": {},
   "source": [
    "## Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "b7695d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_store.delete_documents(index=doc_index)\n",
    "document_store.delete_documents(index=label_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45f29c0",
   "metadata": {},
   "source": [
    "### Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "42c995f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - haystack.document_stores.utils -  No title information found for documents in QA file: squad_format_thesis/test.json\n"
     ]
    }
   ],
   "source": [
    "# The add_eval_data() method converts the given dataset in json format into Haystack document and label objects. Those objects are then indexed in their respective document and label index in the document store. The method can be used with any dataset in SQuAD format.\n",
    "document_store.add_eval_data(\n",
    "    filename=\"squad_format_thesis/test.json\",\n",
    "    doc_index=doc_index,\n",
    "    label_index=label_index,\n",
    "    preprocessor=preprocessor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "45c8cec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.modeling.utils -  Using devices: CUDA:0\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 1\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Could not find IIC/dpr-spanish-question_encoder-allqa-base locally.\n",
      "INFO - haystack.modeling.model.language_model -  Looking on Transformers Model Hub (in local cache and online)...\n",
      "INFO - haystack.modeling.model.language_model -  Automatically detected language from language model name: spanish\n",
      "INFO - haystack.modeling.model.language_model -  Loaded IIC/dpr-spanish-question_encoder-allqa-base\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Could not find IIC/dpr-spanish-passage_encoder-allqa-base locally.\n",
      "INFO - haystack.modeling.model.language_model -  Looking on Transformers Model Hub (in local cache and online)...\n",
      "INFO - haystack.modeling.model.language_model -  Automatically detected language from language model name: spanish\n",
      "INFO - haystack.modeling.model.language_model -  Loaded IIC/dpr-spanish-passage_encoder-allqa-base\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import DensePassageRetriever\n",
    "retriever = DensePassageRetriever(\n",
    "            document_store=document_store,\n",
    "            query_embedding_model=\"IIC/dpr-spanish-question_encoder-allqa-base\",\n",
    "            passage_embedding_model=\"IIC/dpr-spanish-passage_encoder-allqa-base\",\n",
    "            use_gpu=True,\n",
    "            batch_size = 64\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "f59dad8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.document_stores.elasticsearch -  Updating embeddings for all 326 docs ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c376d1729f99421c880b613c9ea3706f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Updating embeddings:   0%|          | 0/326 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Create embeddings:   0%|          | 0/384 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "document_store.update_embeddings(retriever, index=doc_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "3bcb2c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.nodes.retriever.base -  Performing eval queries...\n",
      "100%|███████████████████████████████████████████| 25/25 [00:00<00:00, 79.13it/s]\n",
      "INFO - haystack.nodes.retriever.base -  For 16 out of 25 questions (64.00%), the answer was in the top-10 candidate passages selected by the retriever.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retriever Recall: 0.64\n",
      "Retriever Mean Avg Precision: 0.3813809523809523\n"
     ]
    }
   ],
   "source": [
    "## Evaluate Retriever on its own #THIS IS THE BARE BONES\n",
    "# Note that no_answer samples are omitted when evaluation is performed with this method\n",
    "retriever_eval_results = retriever.eval(top_k=10, label_index=label_index, doc_index=doc_index, open_domain=True)\n",
    "# Retriever Recall is the proportion of questions for which the correct document containing the answer is\n",
    "# among the correct documents\n",
    "print(\"Retriever Recall:\", retriever_eval_results[\"recall\"])\n",
    "test_400_recall.append(retriever_eval_results[\"recall\"])\n",
    "# Retriever Mean Avg Precision rewards retrievers that give relevant documents a higher rank\n",
    "print(\"Retriever Mean Avg Precision:\", retriever_eval_results[\"map\"])\n",
    "test_400_map.append(retriever_eval_results[\"map\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fcae9cc",
   "metadata": {},
   "source": [
    "### Dev Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "3f41b054",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_store.delete_documents(index=doc_index)\n",
    "document_store.delete_documents(index=label_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "16cff31d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - haystack.document_stores.utils -  No title information found for documents in QA file: squad_format_thesis/dev.json\n"
     ]
    }
   ],
   "source": [
    "# The add_eval_data() method converts the given dataset in json format into Haystack document and label objects. Those objects are then indexed in their respective document and label index in the document store. The method can be used with any dataset in SQuAD format.\n",
    "document_store.add_eval_data(\n",
    "    filename=\"squad_format_thesis/dev.json\",\n",
    "    doc_index=doc_index,\n",
    "    label_index=label_index,\n",
    "    preprocessor=preprocessor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "55e210f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.modeling.utils -  Using devices: CUDA:0\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 1\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Could not find IIC/dpr-spanish-question_encoder-allqa-base locally.\n",
      "INFO - haystack.modeling.model.language_model -  Looking on Transformers Model Hub (in local cache and online)...\n",
      "INFO - haystack.modeling.model.language_model -  Automatically detected language from language model name: spanish\n",
      "INFO - haystack.modeling.model.language_model -  Loaded IIC/dpr-spanish-question_encoder-allqa-base\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Could not find IIC/dpr-spanish-passage_encoder-allqa-base locally.\n",
      "INFO - haystack.modeling.model.language_model -  Looking on Transformers Model Hub (in local cache and online)...\n",
      "INFO - haystack.modeling.model.language_model -  Automatically detected language from language model name: spanish\n",
      "INFO - haystack.modeling.model.language_model -  Loaded IIC/dpr-spanish-passage_encoder-allqa-base\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import DensePassageRetriever\n",
    "retriever = DensePassageRetriever(\n",
    "            document_store=document_store,\n",
    "            query_embedding_model=\"IIC/dpr-spanish-question_encoder-allqa-base\",\n",
    "            passage_embedding_model=\"IIC/dpr-spanish-passage_encoder-allqa-base\",\n",
    "            use_gpu=True,\n",
    "            batch_size = 64\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "32d0fedd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.document_stores.elasticsearch -  Updating embeddings for all 305 docs ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e75306306e0a47dab6f5b0da2cf8098b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Updating embeddings:   0%|          | 0/305 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Create embeddings:   0%|          | 0/320 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "document_store.update_embeddings(retriever, index=doc_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "e5df3e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.nodes.retriever.base -  Performing eval queries...\n",
      "100%|███████████████████████████████████████████| 24/24 [00:00<00:00, 65.07it/s]\n",
      "INFO - haystack.nodes.retriever.base -  For 12 out of 24 questions (50.00%), the answer was in the top-10 candidate passages selected by the retriever.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retriever Recall: 0.5\n",
      "Retriever Mean Avg Precision: 0.38958333333333334\n"
     ]
    }
   ],
   "source": [
    "## Evaluate Retriever on its own #THIS IS THE BARE BONES\n",
    "# Note that no_answer samples are omitted when evaluation is performed with this method\n",
    "retriever_eval_results = retriever.eval(top_k=10, label_index=label_index, doc_index=doc_index, open_domain=True)\n",
    "# Retriever Recall is the proportion of questions for which the correct document containing the answer is\n",
    "# among the correct documents\n",
    "print(\"Retriever Recall:\", retriever_eval_results[\"recall\"])\n",
    "dev_400_recall.append(retriever_eval_results[\"recall\"])\n",
    "# Retriever Mean Avg Precision rewards retrievers that give relevant documents a higher rank\n",
    "print(\"Retriever Mean Avg Precision:\", retriever_eval_results[\"map\"])\n",
    "dev_400_map.append(retriever_eval_results[\"map\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1690fd0",
   "metadata": {},
   "source": [
    "## Old Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "7f9d3bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_store.delete_documents(index=doc_index)\n",
    "document_store.delete_documents(index=label_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd69945",
   "metadata": {},
   "source": [
    "### Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "47bb03a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - haystack.document_stores.utils -  No title information found for documents in QA file: squad_format_thesis/test.json\n"
     ]
    }
   ],
   "source": [
    "# The add_eval_data() method converts the given dataset in json format into Haystack document and label objects. Those objects are then indexed in their respective document and label index in the document store. The method can be used with any dataset in SQuAD format.\n",
    "document_store.add_eval_data(\n",
    "    filename=\"squad_format_thesis/test.json\",\n",
    "    doc_index=doc_index,\n",
    "    label_index=label_index,\n",
    "    preprocessor=preprocessor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "eacdd8ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.modeling.utils -  Using devices: CUDA:0\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 1\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Could not find voidful/dpr-question_encoder-bert-base-multilingual locally.\n",
      "INFO - haystack.modeling.model.language_model -  Looking on Transformers Model Hub (in local cache and online)...\n",
      "INFO - haystack.modeling.model.language_model -  Automatically detected language from language model name: multilingual\n",
      "INFO - haystack.modeling.model.language_model -  Loaded voidful/dpr-question_encoder-bert-base-multilingual\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
      "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Could not find voidful/dpr-ctx_encoder-bert-base-multilingual locally.\n",
      "INFO - haystack.modeling.model.language_model -  Looking on Transformers Model Hub (in local cache and online)...\n",
      "INFO - haystack.modeling.model.language_model -  Automatically detected language from language model name: multilingual\n",
      "INFO - haystack.modeling.model.language_model -  Loaded voidful/dpr-ctx_encoder-bert-base-multilingual\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import DensePassageRetriever\n",
    "retriever = DensePassageRetriever(\n",
    "            document_store=document_store,\n",
    "            query_embedding_model=\"voidful/dpr-question_encoder-bert-base-multilingual\",\n",
    "            passage_embedding_model=\"voidful/dpr-ctx_encoder-bert-base-multilingual\",\n",
    "            use_gpu=True,\n",
    "            batch_size = 64\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "e4b0a041",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.document_stores.elasticsearch -  Updating embeddings for all 326 docs ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c282b1f26a5d4db989f7dbf8f4dabadd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Updating embeddings:   0%|          | 0/326 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Create embeddings:   0%|          | 0/384 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "document_store.update_embeddings(retriever, index=doc_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "1907447d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.nodes.retriever.base -  Performing eval queries...\n",
      "100%|███████████████████████████████████████████| 25/25 [00:00<00:00, 91.43it/s]\n",
      "INFO - haystack.nodes.retriever.base -  For 6 out of 25 questions (24.00%), the answer was in the top-10 candidate passages selected by the retriever.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retriever Recall: 0.24\n",
      "Retriever Mean Avg Precision: 0.12444444444444444\n"
     ]
    }
   ],
   "source": [
    "## Evaluate Retriever on its own #THIS IS THE BARE BONES\n",
    "# Note that no_answer samples are omitted when evaluation is performed with this method\n",
    "retriever_eval_results = retriever.eval(top_k=10, label_index=label_index, doc_index=doc_index, open_domain=True)\n",
    "# Retriever Recall is the proportion of questions for which the correct document containing the answer is\n",
    "# among the correct documents\n",
    "print(\"Retriever Recall:\", retriever_eval_results[\"recall\"])\n",
    "test_400_recall.append(retriever_eval_results[\"recall\"])\n",
    "# Retriever Mean Avg Precision rewards retrievers that give relevant documents a higher rank\n",
    "print(\"Retriever Mean Avg Precision:\", retriever_eval_results[\"map\"])\n",
    "test_400_map.append(retriever_eval_results[\"map\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068342c6",
   "metadata": {},
   "source": [
    "### Dev Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "7b2cdd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_store.delete_documents(index=doc_index)\n",
    "document_store.delete_documents(index=label_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "5448696b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - haystack.document_stores.utils -  No title information found for documents in QA file: squad_format_thesis/dev.json\n"
     ]
    }
   ],
   "source": [
    "# The add_eval_data() method converts the given dataset in json format into Haystack document and label objects. Those objects are then indexed in their respective document and label index in the document store. The method can be used with any dataset in SQuAD format.\n",
    "document_store.add_eval_data(\n",
    "    filename=\"squad_format_thesis/dev.json\",\n",
    "    doc_index=doc_index,\n",
    "    label_index=label_index,\n",
    "    preprocessor=preprocessor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "5889cd13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.modeling.utils -  Using devices: CUDA:0\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 1\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Could not find voidful/dpr-question_encoder-bert-base-multilingual locally.\n",
      "INFO - haystack.modeling.model.language_model -  Looking on Transformers Model Hub (in local cache and online)...\n",
      "INFO - haystack.modeling.model.language_model -  Automatically detected language from language model name: multilingual\n",
      "INFO - haystack.modeling.model.language_model -  Loaded voidful/dpr-question_encoder-bert-base-multilingual\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
      "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Could not find voidful/dpr-ctx_encoder-bert-base-multilingual locally.\n",
      "INFO - haystack.modeling.model.language_model -  Looking on Transformers Model Hub (in local cache and online)...\n",
      "INFO - haystack.modeling.model.language_model -  Automatically detected language from language model name: multilingual\n",
      "INFO - haystack.modeling.model.language_model -  Loaded voidful/dpr-ctx_encoder-bert-base-multilingual\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import DensePassageRetriever\n",
    "retriever = DensePassageRetriever(\n",
    "            document_store=document_store,\n",
    "            query_embedding_model=\"voidful/dpr-question_encoder-bert-base-multilingual\",\n",
    "            passage_embedding_model=\"voidful/dpr-ctx_encoder-bert-base-multilingual\",\n",
    "            use_gpu=True,\n",
    "            batch_size = 64\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "993f7163",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.document_stores.elasticsearch -  Updating embeddings for all 305 docs ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b28dbebd212e4bde847a634623e5d77c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Updating embeddings:   0%|          | 0/305 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Create embeddings:   0%|          | 0/320 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "document_store.update_embeddings(retriever, index=doc_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "2e3471e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.nodes.retriever.base -  Performing eval queries...\n",
      "100%|███████████████████████████████████████████| 24/24 [00:00<00:00, 85.77it/s]\n",
      "INFO - haystack.nodes.retriever.base -  For 7 out of 24 questions (29.17%), the answer was in the top-10 candidate passages selected by the retriever.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retriever Recall: 0.2916666666666667\n",
      "Retriever Mean Avg Precision: 0.14484126984126983\n"
     ]
    }
   ],
   "source": [
    "## Evaluate Retriever on its own #THIS IS THE BARE BONES\n",
    "# Note that no_answer samples are omitted when evaluation is performed with this method\n",
    "retriever_eval_results = retriever.eval(top_k=10, label_index=label_index, doc_index=doc_index, open_domain=True)\n",
    "# Retriever Recall is the proportion of questions for which the correct document containing the answer is\n",
    "# among the correct documents\n",
    "print(\"Retriever Recall:\", retriever_eval_results[\"recall\"])\n",
    "dev_400_recall.append(retriever_eval_results[\"recall\"])\n",
    "# Retriever Mean Avg Precision rewards retrievers that give relevant documents a higher rank\n",
    "print(\"Retriever Mean Avg Precision:\", retriever_eval_results[\"map\"])\n",
    "dev_400_map.append(retriever_eval_results[\"map\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4280c811",
   "metadata": {},
   "source": [
    "## BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "05226e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Retriever\n",
    "from haystack.nodes import ElasticsearchRetriever, BM25Retriever\n",
    "\n",
    "retriever = BM25Retriever(document_store=document_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "4f1fc152",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_store.delete_documents(index=doc_index)\n",
    "document_store.delete_documents(index=label_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7946f1fa",
   "metadata": {},
   "source": [
    "### Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "b2792aa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - haystack.document_stores.utils -  No title information found for documents in QA file: squad_format_thesis/test.json\n"
     ]
    }
   ],
   "source": [
    "# The add_eval_data() method converts the given dataset in json format into Haystack document and label objects. Those objects are then indexed in their respective document and label index in the document store. The method can be used with any dataset in SQuAD format.\n",
    "document_store.add_eval_data(\n",
    "    filename=\"squad_format_thesis/test.json\",\n",
    "    doc_index=doc_index,\n",
    "    label_index=label_index,\n",
    "    preprocessor=preprocessor\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "394e67cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.nodes.retriever.base -  Performing eval queries...\n",
      "100%|██████████████████████████████████████████| 25/25 [00:00<00:00, 100.00it/s]\n",
      "INFO - haystack.nodes.retriever.base -  For 19 out of 25 questions (76.00%), the answer was in the top-10 candidate passages selected by the retriever.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retriever Recall: 0.76\n",
      "Retriever Mean Avg Precision: 0.4868253968253968\n"
     ]
    }
   ],
   "source": [
    "## Evaluate Retriever on its own #THIS IS THE ES\n",
    "# Note that no_answer samples are omitted when evaluation is performed with this method\n",
    "retriever_eval_results = retriever.eval(top_k=10, label_index=label_index, doc_index=doc_index, open_domain=True)\n",
    "# Retriever Recall is the proportion of questions for which the correct document containing the answer is\n",
    "# among the correct documents\n",
    "print(\"Retriever Recall:\", retriever_eval_results[\"recall\"])\n",
    "test_400_recall.append(retriever_eval_results[\"recall\"])\n",
    "# Retriever Mean Avg Precision rewards retrievers that give relevant documents a higher rank\n",
    "print(\"Retriever Mean Avg Precision:\", retriever_eval_results[\"map\"])\n",
    "test_400_map.append(retriever_eval_results[\"map\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4743a6",
   "metadata": {},
   "source": [
    "### Dev Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "9e518593",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_store.delete_documents(index=doc_index)\n",
    "document_store.delete_documents(index=label_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "0adbc045",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - haystack.document_stores.utils -  No title information found for documents in QA file: squad_format_thesis/dev.json\n"
     ]
    }
   ],
   "source": [
    "# The add_eval_data() method converts the given dataset in json format into Haystack document and label objects. Those objects are then indexed in their respective document and label index in the document store. The method can be used with any dataset in SQuAD format.\n",
    "document_store.add_eval_data(\n",
    "    filename=\"squad_format_thesis/dev.json\",\n",
    "    doc_index=doc_index,\n",
    "    label_index=label_index,\n",
    "    preprocessor=preprocessor\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "dbede070",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.nodes.retriever.base -  Performing eval queries...\n",
      "100%|██████████████████████████████████████████| 24/24 [00:00<00:00, 109.77it/s]\n",
      "INFO - haystack.nodes.retriever.base -  For 19 out of 24 questions (79.17%), the answer was in the top-10 candidate passages selected by the retriever.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retriever Recall: 0.7916666666666666\n",
      "Retriever Mean Avg Precision: 0.5680555555555555\n"
     ]
    }
   ],
   "source": [
    "## Evaluate Retriever on its own #THIS IS THE ES\n",
    "# Note that no_answer samples are omitted when evaluation is performed with this method\n",
    "retriever_eval_results = retriever.eval(top_k=10, label_index=label_index, doc_index=doc_index, open_domain=True)\n",
    "# Retriever Recall is the proportion of questions for which the correct document containing the answer is\n",
    "# among the correct documents\n",
    "print(\"Retriever Recall:\", retriever_eval_results[\"recall\"])\n",
    "dev_400_recall.append(retriever_eval_results[\"recall\"])\n",
    "# Retriever Mean Avg Precision rewards retrievers that give relevant documents a higher rank\n",
    "print(\"Retriever Mean Avg Precision:\", retriever_eval_results[\"map\"])\n",
    "dev_400_map.append(retriever_eval_results[\"map\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d7450e",
   "metadata": {},
   "source": [
    "# Build the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "796640f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "200\n",
      "TEST_RECALL 13 \n",
      " [0.64, 0.8, 0.72, 0.6, 0.84, 0.64, 0.84, 0.8, 0.84, 0.84, 0.84, 0.4, 0.68]\n",
      "TEST_MAP 13 \n",
      " [0.406, 0.502, 0.475, 0.373, 0.517, 0.408, 0.514, 0.499, 0.517, 0.517, 0.517, 0.204, 0.469]\n",
      "DEV_RECALL 13 \n",
      " [0.75, 0.792, 0.75, 0.708, 0.833, 0.667, 0.833, 0.792, 0.833, 0.833, 0.833, 0.458, 0.75]\n",
      "DEV_MAP 13 \n",
      " [0.337, 0.506, 0.373, 0.279, 0.539, 0.316, 0.514, 0.395, 0.539, 0.539, 0.539, 0.233, 0.537]\n",
      "400\n",
      "TEST_RECALL\n",
      " 13 \n",
      " [0.52, 0.64, 0.64, 0.52, 0.64, 0.52, 0.64, 0.64, 0.64, 0.64, 0.64, 0.24, 0.76]\n",
      "TEST_MAP\n",
      " 13 \n",
      " [0.304, 0.38, 0.368, 0.322, 0.381, 0.336, 0.381, 0.368, 0.381, 0.381, 0.381, 0.124, 0.487]\n",
      "DEV_RECALL\n",
      " 13 \n",
      " [0.417, 0.5, 0.5, 0.375, 0.5, 0.375, 0.5, 0.5, 0.5, 0.5, 0.5, 0.292, 0.792]\n",
      "DEV_MAP 13 \n",
      " [0.211, 0.348, 0.251, 0.209, 0.39, 0.21, 0.348, 0.266, 0.39, 0.39, 0.39, 0.145, 0.568]\n"
     ]
    }
   ],
   "source": [
    "print(len(model_name))\n",
    "print(\"200\")\n",
    "print(\"TEST_RECALL\", len(test_200_recall), \"\\n\", [round(x,3) for x in test_200_recall])\n",
    "print(\"TEST_MAP\", len(test_200_map), \"\\n\", [round(x,3) for x in test_200_map])\n",
    "print(\"DEV_RECALL\", len(dev_200_recall), \"\\n\",  [round(x,3) for x in dev_200_recall])\n",
    "print(\"DEV_MAP\", len(dev_200_map),\"\\n\",  [round(x,3) for x in dev_200_map])\n",
    "print(\"400\")\n",
    "print(\"TEST_RECALL\\n\", len(test_400_recall) , \"\\n\", [round(x,3) for x in test_400_recall])\n",
    "print(\"TEST_MAP\\n\", len(test_400_map), \"\\n\", [round(x,3) for x in test_400_map])\n",
    "print(\"DEV_RECALL\\n\", len(dev_400_recall), \"\\n\", [round(x,3) for x in dev_400_recall])\n",
    "print(\"DEV_MAP\", len(dev_400_map), \"\\n\", [round(x,3) for x in dev_400_map])\n",
    "\n",
    "r_test_200_recall = [round(x,3) for x in test_200_recall]\n",
    "r_test_200_map = [round(x,3) for x in test_200_map]\n",
    "r_dev_200_recall = [round(x,3) for x in dev_200_recall]\n",
    "r_dev_200_map = [round(x,3) for x in dev_200_map]\n",
    "\n",
    "r_test_400_recall = [round(x,3) for x in test_400_recall]\n",
    "r_test_400_map = [round(x,3) for x in test_400_map]\n",
    "r_dev_400_recall = [round(x,3) for x in dev_400_recall]\n",
    "r_dev_400_map = [round(x,3) for x in dev_400_map]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "7360123e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_name': ['model_1',\n",
       "  'model_2',\n",
       "  'model_3',\n",
       "  'model_4',\n",
       "  'model_5',\n",
       "  'model_6',\n",
       "  'model_7',\n",
       "  'model_8',\n",
       "  'model_9',\n",
       "  'model_10',\n",
       "  'base_model',\n",
       "  'old_base_model',\n",
       "  'bm25'],\n",
       " 'test_200_recall': [0.64,\n",
       "  0.8,\n",
       "  0.72,\n",
       "  0.6,\n",
       "  0.84,\n",
       "  0.64,\n",
       "  0.84,\n",
       "  0.8,\n",
       "  0.84,\n",
       "  0.84,\n",
       "  0.84,\n",
       "  0.4,\n",
       "  0.68],\n",
       " 'test_200_map': [0.406,\n",
       "  0.502,\n",
       "  0.475,\n",
       "  0.373,\n",
       "  0.517,\n",
       "  0.408,\n",
       "  0.514,\n",
       "  0.499,\n",
       "  0.517,\n",
       "  0.517,\n",
       "  0.517,\n",
       "  0.204,\n",
       "  0.469],\n",
       " 'dev_200_recall': [0.75,\n",
       "  0.792,\n",
       "  0.75,\n",
       "  0.708,\n",
       "  0.833,\n",
       "  0.667,\n",
       "  0.833,\n",
       "  0.792,\n",
       "  0.833,\n",
       "  0.833,\n",
       "  0.833,\n",
       "  0.458,\n",
       "  0.75],\n",
       " 'dev_200_map': [0.337,\n",
       "  0.506,\n",
       "  0.373,\n",
       "  0.279,\n",
       "  0.539,\n",
       "  0.316,\n",
       "  0.514,\n",
       "  0.395,\n",
       "  0.539,\n",
       "  0.539,\n",
       "  0.539,\n",
       "  0.233,\n",
       "  0.537],\n",
       " 'test_400_recall': [0.52,\n",
       "  0.64,\n",
       "  0.64,\n",
       "  0.52,\n",
       "  0.64,\n",
       "  0.52,\n",
       "  0.64,\n",
       "  0.64,\n",
       "  0.64,\n",
       "  0.64,\n",
       "  0.64,\n",
       "  0.24,\n",
       "  0.76],\n",
       " 'test_400_map': [0.304,\n",
       "  0.38,\n",
       "  0.368,\n",
       "  0.322,\n",
       "  0.381,\n",
       "  0.336,\n",
       "  0.381,\n",
       "  0.368,\n",
       "  0.381,\n",
       "  0.381,\n",
       "  0.381,\n",
       "  0.124,\n",
       "  0.487],\n",
       " 'dev_400_recall': [0.417,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  0.375,\n",
       "  0.5,\n",
       "  0.375,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  0.292,\n",
       "  0.792],\n",
       " 'dev_400_map': [0.211,\n",
       "  0.348,\n",
       "  0.251,\n",
       "  0.209,\n",
       "  0.39,\n",
       "  0.21,\n",
       "  0.348,\n",
       "  0.266,\n",
       "  0.39,\n",
       "  0.39,\n",
       "  0.39,\n",
       "  0.145,\n",
       "  0.568]}"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_eval = {\"model_name\" : model_name, \"test_200_recall\": r_test_200_recall, \"test_200_map\": r_test_200_map,\n",
    "            \"dev_200_recall\": r_dev_200_recall, \"dev_200_map\": r_dev_200_map, \"test_400_recall\": r_test_400_recall,\n",
    "            \"test_400_map\": r_test_400_map, \"dev_400_recall\": r_dev_400_recall, \"dev_400_map\": r_dev_400_map}\n",
    "data_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "92a0b772",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>test_200_recall</th>\n",
       "      <th>test_200_map</th>\n",
       "      <th>dev_200_recall</th>\n",
       "      <th>dev_200_map</th>\n",
       "      <th>test_400_recall</th>\n",
       "      <th>test_400_map</th>\n",
       "      <th>dev_400_recall</th>\n",
       "      <th>dev_400_map</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>model_1</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.406</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.337</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.304</td>\n",
       "      <td>0.417</td>\n",
       "      <td>0.211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>model_2</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.502</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.506</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.380</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>model_3</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.373</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.368</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>model_4</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.373</td>\n",
       "      <td>0.708</td>\n",
       "      <td>0.279</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.322</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>model_5</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.517</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.539</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.381</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>model_6</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.408</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.316</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.336</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>model_7</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.381</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>model_8</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.499</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.395</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.368</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>model_9</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.517</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.539</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.381</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>model_10</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.517</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.539</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.381</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>base_model</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.517</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.539</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.381</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>old_base_model</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.458</td>\n",
       "      <td>0.233</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.292</td>\n",
       "      <td>0.145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>bm25</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.469</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.537</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.487</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.568</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        model_name  test_200_recall  test_200_map  dev_200_recall  \\\n",
       "0          model_1             0.64         0.406           0.750   \n",
       "1          model_2             0.80         0.502           0.792   \n",
       "2          model_3             0.72         0.475           0.750   \n",
       "3          model_4             0.60         0.373           0.708   \n",
       "4          model_5             0.84         0.517           0.833   \n",
       "5          model_6             0.64         0.408           0.667   \n",
       "6          model_7             0.84         0.514           0.833   \n",
       "7          model_8             0.80         0.499           0.792   \n",
       "8          model_9             0.84         0.517           0.833   \n",
       "9         model_10             0.84         0.517           0.833   \n",
       "10      base_model             0.84         0.517           0.833   \n",
       "11  old_base_model             0.40         0.204           0.458   \n",
       "12            bm25             0.68         0.469           0.750   \n",
       "\n",
       "    dev_200_map  test_400_recall  test_400_map  dev_400_recall  dev_400_map  \n",
       "0         0.337             0.52         0.304           0.417        0.211  \n",
       "1         0.506             0.64         0.380           0.500        0.348  \n",
       "2         0.373             0.64         0.368           0.500        0.251  \n",
       "3         0.279             0.52         0.322           0.375        0.209  \n",
       "4         0.539             0.64         0.381           0.500        0.390  \n",
       "5         0.316             0.52         0.336           0.375        0.210  \n",
       "6         0.514             0.64         0.381           0.500        0.348  \n",
       "7         0.395             0.64         0.368           0.500        0.266  \n",
       "8         0.539             0.64         0.381           0.500        0.390  \n",
       "9         0.539             0.64         0.381           0.500        0.390  \n",
       "10        0.539             0.64         0.381           0.500        0.390  \n",
       "11        0.233             0.24         0.124           0.292        0.145  \n",
       "12        0.537             0.76         0.487           0.792        0.568  "
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_data_eval = pd.DataFrame(data_eval)\n",
    "df_data_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "401a4e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_eval.to_csv(\"data/df_data_eval.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363b9932",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
