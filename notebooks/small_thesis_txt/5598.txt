Diseñar algoritmos de despliegue que permitan la visualización, libre de artefac- tos, de cortes arbitrarios sobre sólidos volumétricos. • Diseñar algoritmos de manipulación que permitan la detección y manipulación de fragmentos de hueso. • Implementar la estrategia propuesta utilizando el lenguaje de programación C++, la arquitectura CUDA y el estándar gráfico OpenGL. • Implementar una biblioteca que muestre el uso del modelo desarrollado para la simulación de cortes de hueso en tiempo real. • Implementar una aplicación para demostrar el uso de la biblioteca desarrollada. • Utilizar la metodoloǵıa de desarrollo de programación extrema y UML para la especificación de las clases. 6 Caṕıtulo 2 Marco Teórico 2.1. CUDA En Noviembre de 2006, NVIDIA introdujo una arquitectura de propósito general para cómputo paralelo denominada CUDATM. En ella se incluyó un nuevo modelo de programación y conjunto de instrucciones, que permiten utilizar las capacidades de paralelismo de los GPUs de NVIDIA para resolver problemas computacionales complejos de forma eficiente [20]. CUDA viene con un ambiente de desarrollo que permite utilizar C como lenguaje de programación de alto nivel, aunque como se muestra en la Figura 2.1, también existen otras interfaces de programación de aplicaciones. Figura 2.1: Soporte de diferentes lenguajes e interfaces de programación por CUDA. Caṕıtulo 2: Marco Teórico 7 2.1.1. Modelo de Programación Escalable La llegada de los CPUs de múltiples núcleos y los GPUs de muchos núcleos significa que la mayoŕıa de los procesadores de hoy en d́ıa son sistemas paralelos. Más aún, su paralelismo continúa creciendo según la ley de Moore. Para poder explotar dicho crecimiento al máximo, la arquitectura CUDA se ha diseñado de forma que aprovechar el aumento de núcleos sea transparente para la aplicación [20]. Esta transparencia se logró con tres simples abstracciones: una jerarqúıa de gru- pos de hilos, memoria compartida y barreras de sincronización. Estas abstracciones proveen paralelismo de granularidad fina para datos e hilos, Arquitectura SIMT Un multiprocesador está diseñado para ejecutar cientos de hilos concurrentes, para manejar tal cantidad de hilos éste utiliza una arquitectura llamada SIMT 3 (una instrucción, múltiples hilos). Para maximizar la utilización, el hardware aprovecha el paralelismo a nivel de hilos en vez del paralelismo a nivel de instrucciones dentro de un mismo hilo, es decir, las instrucciones son ejecutadas en orden, sin predicción de salto ni ejecución especulativa [20]. El multiprocesador crea, maneja, planifica y ejecuta hilos en grupos de 32 hilos paralelos llamados warps4. Los hilos que componen un warp comienzan su ejecución al mismo tiempo en la misma dirección de programa, pero tienen su propio conta- 2Streaming Multiprocesors. 3El término SIMT es un acrónimo de Single-Instruction Multiple-Thread. 4El término warp (urdimbre) recibe el nombre de la tejeduŕıa, considerada la primera tecnoloǵıa paralela de hilos. Se decidió utilizar el término en inglés por su amplia aceptación en la documentación, mientras que el término urdimbre no es muy utilizado en el área de cómputo paralelo. Caṕıtulo 2: Marco Teórico 14 dor de programa y estado de registros, por lo que son libres de divergir y ejecutar independientemente [20]. Cuando un multiprocesador recibe uno o más bloques de hilos, este los parti- ciona en warps que son planificados por un planificador de warps. La forma en la que los bloques son particionados es siempre la misma; cada warp contiene hilos con identificadores consecutivos y crecientes, donde el primer warp recibe el hilo con iden- tificador 0 [20]. Un warp ejecuta una instrucción común a la vez, por lo que la mayor eficiencia es alcanzada cuando los 32 hilos del warp tienen el mismo camino de ejecución. Si los hilos de un warp divergen por medio de ramificaciones condicionales, el warp ejecuta cada rama de forma serial, deshabilitando los hilos que no pertenecen a dicha rama. Cuando todos los caminos terminan, los hilos convergen de nuevo a la misma ruta de ejecución. La divergencia de ramas sólo ocurre dentro de un warp, ya que, los diferentes warps de un mismo bloque siempre se ejecutan de forma independiente sin importar si están ejecutando la misma ruta de ejecución o no [20]. CUDA 2.0 incluyen caché tradicional para memoria global, por lo tanto, la memoria de textura no ofrece ninguna ventaja para explotar localidad espacial en dichos dispositivos. Caṕıtulo 2: Marco Teórico 21 • Minimizar la cantidad de instrucciones lentas, lo que significa sacrificar precisión por velocidad cuando sea posible. • Minimizar la divergencia de ramas dentro de los warps, como se explicó ante- riormente. • Reducir la cantidad de instrucciones, optimizando la cantidad de puntos de sin- cronización, por ejemplo. Para mayor detalle sobre la cantidad de ciclos que cada operación requiere se refiere al lector a [20]. 2.2. Despliegue Volumétrico El término, despliegue volumétrico (volume rendering), se refiere a un conjunto de técnicas que permiten generar imágenes bidimensionales a partir de datos tridimensio- nales, llamados volúmenes. De forma teórica, un volumen es un campo escalar sobre el espacio eucĺıdeo tridimensional, es decir, una función f : E3 → R [4]. Sin embargo, el incentivo original del despliegue volumétrico fue crear métodos eficientes para visuali- zar imágenes médicas, campo que sigue siendo el más importante. Los datos generados por Tomograf́ıas Computarizadas (CT) o Imágenes por Resonancia Magnética (MRI) son los de mayor interés, este tipo de técnicas generan mallas tridimensionales basadas en muestras discretas regularmente espaciadas a lo largo de cada eje7 [26]. Los métodos de despliegue volumétrico se pueden dividir en dos categoŕıas. La primera categoŕıa, denominada despliegue volumétrico indirecto, consiste en detectar superficies en el volumen, ajustar primitivas geométricas a dichas superficies y luego desplegarlas utilizando técnicas de despliegue tradicionales. Una de las técnicas más utilizadas en esta categoŕıa se conoce como cubos marchantes, presentado por primera 7El espaciado de las muestras no tiene que ser el mismo en todos los ejes.  una vez como en una función tradicional de C. La definición de un kernel se especifica con el modificador global y la invocación de los mismos utiliza una nueva sintaxis de configuración de ejecución, en la que se especifica la cantidad de bloques de hilos y la cantidad de hilos por bloque [20]. Cada hilo que ejecuta el kernel recibe un identificador de hilo y un ı́ndice de hilo, únicos dentro del bloque; el ı́ndice de hilo es accesible dentro del kernel a través de la variable integrada threadIdx, la cual es un vector de tres dimensiones. Por lo tanto, los hilos pueden ser organizados en bloques de hilos de una, dos o tres dimensiones. Lo cual provee una forma natural de invocar cálculos para los elementos de un domino, tales como vectores, matrices o volúmenes [20]. 1Kernel en español significa núcleo, se decidió utilizar el término en inglés para evitar posibles confusiones con los núcleos de ejecución (execution core), manteniendo a su vez, la mayor consistencia posible con la documentación existente. Caṕıtulo 2: Marco Teórico 9 El ı́ndice de hilo y su identificador de hilo se relacionan de la siguiente forma: • Para un bloque de una dimensión el ı́ndice y el identificador es el mismo. • Para un bloque bidimensional de tamaño (Dx, Dy), el identificador del hilo con ı́ndice (x, y) es x+ yDx. • Para un bloque tridimensional de tamaño (Dx, Dy, Dz), el identificador del hilo con ı́ndice (x, y, z) es x+ yDx + zDxDy. La cantidad de hilos por bloque es limitada, ya que todos los hilos de un mismo bloque deben residir en el mismo núcleo de ejecución y compartir la memoria limitada de dicho núcleo. El multiprocesador crea, maneja, planifica y ejecuta hilos en grupos de 32 hilos paralelos llamados warps4. Los hilos que componen un warp comienzan su ejecución al mismo tiempo en la misma dirección de programa, pero tienen su propio conta- 2Streaming Multiprocesors. 3El término SIMT es un acrónimo de Single-Instruction Multiple-Thread. 4El término warp (urdimbre) recibe el nombre de la tejeduŕıa, considerada la primera tecnoloǵıa paralela de hilos. Se decidió utilizar el término en inglés por su amplia aceptación en la documentación, mientras que el término urdimbre no es muy utilizado en el área de cómputo paralelo. Caṕıtulo 2: Marco Teórico 14 dor de programa y estado de registros, por lo que son libres de divergir y ejecutar independientemente [20]. Cuando un multiprocesador recibe uno o más bloques de hilos, este los parti- ciona en warps que son planificados por un planificador de warps. La forma en la que los bloques son particionados es siempre la misma; cada warp contiene hilos con identificadores consecutivos y crecientes, donde el primer warp recibe el hilo con iden- tificador 0 