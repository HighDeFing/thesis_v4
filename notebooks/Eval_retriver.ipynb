{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8af0276e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## eval retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "419b842c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure these indices do not collide with existing ones, the indices will be wiped clean before data is inserted\n",
    "doc_index = \"squad_docs\"\n",
    "label_index = \"squad_labels\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ab61f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.document_stores.base -  Numba not found, replacing njit() with no-op implementation. Enable it with 'pip install numba'.\n",
      "INFO - haystack.modeling.model.optimization -  apex not found, won't use it. See https://nvidia.github.io/apex/\n",
      "ERROR - root -  Failed to import 'magic' (from 'python-magic' and 'python-magic-bin' on Windows). FileTypeClassifier will not perform mimetype detection on extensionless files. Please make sure the necessary OS libraries are installed if you need this functionality.\n",
      "/home/heider/Codes/thesis_v4/env/lib/python3.8/site-packages/elasticsearch/connection/base.py:190: ElasticsearchDeprecationWarning: Elasticsearch built-in security features are not enabled. Without authentication, your cluster could be accessible to anyone. See https://www.elastic.co/guide/en/elasticsearch/reference/7.13/security-minimal-setup.html to enable security.\n",
      "  warnings.warn(message, category=ElasticsearchDeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Connect to Elasticsearch\n",
    "# docker start es01-test -a\n",
    "from haystack.document_stores import ElasticsearchDocumentStore\n",
    "\n",
    "document_store = ElasticsearchDocumentStore(\n",
    "    host=\"localhost\",\n",
    "    username=\"\",\n",
    "    password=\"\",\n",
    "    index=doc_index,\n",
    "    label_index=label_index,\n",
    "    embedding_field=\"emb\",\n",
    "    embedding_dim=768,\n",
    "    excluded_meta_data=[\"emb\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0af249",
   "metadata": {},
   "source": [
    "## Model_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee4be583",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - haystack.document_stores.utils -  No title information found for documents in QA file: squad_format_thesis/test.json\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import PreProcessor\n",
    "\n",
    "document_store.delete_documents(index=doc_index)\n",
    "document_store.delete_documents(index=label_index)\n",
    "\n",
    "preprocessor = PreProcessor(\n",
    "    split_length=200,\n",
    "    split_overlap=0,\n",
    "    split_respect_sentence_boundary=False,\n",
    "    clean_empty_lines=False,\n",
    "    clean_whitespace=False,\n",
    ")\n",
    "\n",
    "# The add_eval_data() method converts the given dataset in json format into Haystack document and label objects. Those objects are then indexed in their respective document and label index in the document store. The method can be used with any dataset in SQuAD format.\n",
    "document_store.add_eval_data(\n",
    "    filename=\"squad_format_thesis/test.json\",\n",
    "    doc_index=doc_index,\n",
    "    label_index=label_index,\n",
    "    preprocessor=preprocessor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b12f8dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.modeling.utils -  Using devices: CUDA:0\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 1\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_1/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_1/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_1/passage_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_1/passage_encoder\n",
      "INFO - haystack.nodes.retriever.dense -  DPR model loaded from models/model_1\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import DensePassageRetriever\n",
    "\n",
    "save_dir = \"models/model_1\"\n",
    "\n",
    "retriever = DensePassageRetriever.load(load_dir=save_dir, document_store=document_store, use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d094b268",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.document_stores.elasticsearch -  Updating embeddings for all 651 docs ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba60eac68bfb48f2a46cdb4e57660bee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Updating embeddings:   0%|          | 0/651 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Create embeddings:   0%|          | 0/656 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "document_store.update_embeddings(retriever, index=doc_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48916951",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.nodes.retriever.base -  Performing eval queries...\n",
      "  4%|█▊                                          | 1/25 [00:00<00:03,  6.69it/s]/home/heider/Codes/thesis_v4/env/lib/python3.8/site-packages/elasticsearch/connection/base.py:190: ElasticsearchDeprecationWarning: Elasticsearch built-in security features are not enabled. Without authentication, your cluster could be accessible to anyone. See https://www.elastic.co/guide/en/elasticsearch/reference/7.13/security-minimal-setup.html to enable security.\n",
      "  warnings.warn(message, category=ElasticsearchDeprecationWarning)\n",
      "100%|███████████████████████████████████████████| 25/25 [00:00<00:00, 60.70it/s]\n",
      "INFO - haystack.nodes.retriever.base -  For 16 out of 25 questions (64.00%), the answer was in the top-5 candidate passages selected by the retriever.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retriever Recall: 0.64\n",
      "Retriever Mean Avg Precision: 0.456\n"
     ]
    }
   ],
   "source": [
    "## Evaluate Retriever on its own # THIS IS THE FINE-TUNED model_1\n",
    "# Note that no_answer samples are omitted when evaluation is performed with this method\n",
    "retriever_eval_results = retriever.eval(top_k=5, label_index=label_index, doc_index=doc_index, open_domain=True)\n",
    "# Retriever Recall is the proportion of questions for which the correct document containing the answer is\n",
    "# among the correct documents\n",
    "print(\"Retriever Recall:\", retriever_eval_results[\"recall\"])\n",
    "# Retriever Mean Avg Precision rewards retrievers that give relevant documents a higher rank\n",
    "print(\"Retriever Mean Avg Precision:\", retriever_eval_results[\"map\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57cd070",
   "metadata": {},
   "source": [
    "### DEV SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e86cbfb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - haystack.document_stores.utils -  No title information found for documents in QA file: squad_format_thesis/dev.json\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import PreProcessor\n",
    "\n",
    "document_store.delete_documents(index=doc_index)\n",
    "document_store.delete_documents(index=label_index)\n",
    "\n",
    "preprocessor = PreProcessor(\n",
    "    split_length=200,\n",
    "    split_overlap=0,\n",
    "    split_respect_sentence_boundary=False,\n",
    "    clean_empty_lines=False,\n",
    "    clean_whitespace=False,\n",
    ")\n",
    "\n",
    "# The add_eval_data() method converts the given dataset in json format into Haystack document and label objects. Those objects are then indexed in their respective document and label index in the document store. The method can be used with any dataset in SQuAD format.\n",
    "document_store.add_eval_data(\n",
    "    filename=\"squad_format_thesis/dev.json\",\n",
    "    doc_index=doc_index,\n",
    "    label_index=label_index,\n",
    "    preprocessor=preprocessor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5e9b5e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.modeling.utils -  Using devices: CUDA:0\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 1\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_1/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_1/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_1/passage_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_1/passage_encoder\n",
      "INFO - haystack.nodes.retriever.dense -  DPR model loaded from models/model_1\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import DensePassageRetriever\n",
    "\n",
    "save_dir = \"models/model_1\"\n",
    "\n",
    "retriever = DensePassageRetriever.load(load_dir=save_dir, document_store=document_store, use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "49fe023a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.document_stores.elasticsearch -  Updating embeddings for all 608 docs ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d43097843c84faa93e876ede4c123f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Updating embeddings:   0%|          | 0/608 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Create embeddings:   0%|          | 0/608 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "document_store.update_embeddings(retriever, index=doc_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "dcab762f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.nodes.retriever.base -  Performing eval queries...\n",
      "100%|███████████████████████████████████████████| 24/24 [00:00<00:00, 93.53it/s]\n",
      "INFO - haystack.nodes.retriever.base -  For 17 out of 24 questions (70.83%), the answer was in the top-5 candidate passages selected by the retriever.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retriever Recall: 0.7083333333333334\n",
      "Retriever Mean Avg Precision: 0.39375\n"
     ]
    }
   ],
   "source": [
    "## Evaluate Retriever on its own # THIS IS THE FINE-TUNED model_1\n",
    "# Note that no_answer samples are omitted when evaluation is performed with this method\n",
    "retriever_eval_results = retriever.eval(top_k=5, label_index=label_index, doc_index=doc_index, open_domain=True)\n",
    "# Retriever Recall is the proportion of questions for which the correct document containing the answer is\n",
    "# among the correct documents\n",
    "print(\"Retriever Recall:\", retriever_eval_results[\"recall\"])\n",
    "# Retriever Mean Avg Precision rewards retrievers that give relevant documents a higher rank\n",
    "print(\"Retriever Mean Avg Precision:\", retriever_eval_results[\"map\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d690b26a",
   "metadata": {},
   "source": [
    "## Model_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07641f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - haystack.document_stores.utils -  No title information found for documents in QA file: squad_format_thesis/test.json\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import PreProcessor\n",
    "\n",
    "document_store.delete_documents(index=doc_index)\n",
    "document_store.delete_documents(index=label_index)\n",
    "\n",
    "preprocessor = PreProcessor(\n",
    "    split_length=200,\n",
    "    split_overlap=0,\n",
    "    split_respect_sentence_boundary=False,\n",
    "    clean_empty_lines=False,\n",
    "    clean_whitespace=False,\n",
    ")\n",
    "\n",
    "# The add_eval_data() method converts the given dataset in json format into Haystack document and label objects. Those objects are then indexed in their respective document and label index in the document store. The method can be used with any dataset in SQuAD format.\n",
    "document_store.add_eval_data(\n",
    "    filename=\"squad_format_thesis/test.json\",\n",
    "    doc_index=doc_index,\n",
    "    label_index=label_index,\n",
    "    preprocessor=preprocessor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94be26ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.modeling.utils -  Using devices: CPU\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 0\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_2/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_2/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_2/passage_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_2/passage_encoder\n",
      "INFO - haystack.nodes.retriever.dense -  DPR model loaded from models/model_2\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import DensePassageRetriever\n",
    "\n",
    "save_dir = \"models/model_2\"\n",
    "\n",
    "retriever = DensePassageRetriever.load(load_dir=save_dir, document_store=document_store, use_gpu=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1cadc93e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.document_stores.elasticsearch -  Updating embeddings for all 651 docs ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04cf740d1c904e38a989110b499b8983",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Updating embeddings:   0%|          | 0/651 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Create embeddings:   0%|          | 0/656 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "document_store.update_embeddings(retriever, index=doc_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18439b27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.nodes.retriever.base -  Performing eval queries...\n",
      "  4%|██▊                                                                   | 1/25 [00:00<00:14,  1.69it/s]/home/heider/Codes/thesis_v4/env/lib/python3.8/site-packages/elasticsearch/connection/base.py:190: ElasticsearchDeprecationWarning: Elasticsearch built-in security features are not enabled. Without authentication, your cluster could be accessible to anyone. See https://www.elastic.co/guide/en/elasticsearch/reference/7.13/security-minimal-setup.html to enable security.\n",
      "  warnings.warn(message, category=ElasticsearchDeprecationWarning)\n",
      "100%|█████████████████████████████████████████████████████████████████████| 25/25 [00:01<00:00, 16.07it/s]\n",
      "INFO - haystack.nodes.retriever.base -  For 17 out of 25 questions (68.00%), the answer was in the top-5 candidate passages selected by the retriever.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retriever Recall: 0.68\n",
      "Retriever Mean Avg Precision: 0.49933333333333335\n"
     ]
    }
   ],
   "source": [
    "## Evaluate Retriever on its own # THIS IS THE FINE-TUNED model_2\n",
    "# Note that no_answer samples are omitted when evaluation is performed with this method\n",
    "retriever_eval_results = retriever.eval(top_k=5, label_index=label_index, doc_index=doc_index, open_domain=True)\n",
    "# Retriever Recall is the proportion of questions for which the correct document containing the answer is\n",
    "# among the correct documents\n",
    "print(\"Retriever Recall:\", retriever_eval_results[\"recall\"])\n",
    "# Retriever Mean Avg Precision rewards retrievers that give relevant documents a higher rank\n",
    "print(\"Retriever Mean Avg Precision:\", retriever_eval_results[\"map\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b866618",
   "metadata": {},
   "source": [
    "### DEV SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3cbb0930",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - haystack.document_stores.utils -  No title information found for documents in QA file: squad_format_thesis/dev.json\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import PreProcessor\n",
    "\n",
    "document_store.delete_documents(index=doc_index)\n",
    "document_store.delete_documents(index=label_index)\n",
    "\n",
    "preprocessor = PreProcessor(\n",
    "    split_length=200,\n",
    "    split_overlap=0,\n",
    "    split_respect_sentence_boundary=False,\n",
    "    clean_empty_lines=False,\n",
    "    clean_whitespace=False,\n",
    ")\n",
    "\n",
    "# The add_eval_data() method converts the given dataset in json format into Haystack document and label objects. Those objects are then indexed in their respective document and label index in the document store. The method can be used with any dataset in SQuAD format.\n",
    "document_store.add_eval_data(\n",
    "    filename=\"squad_format_thesis/dev.json\",\n",
    "    doc_index=doc_index,\n",
    "    label_index=label_index,\n",
    "    preprocessor=preprocessor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4ac77761",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.modeling.utils -  Using devices: CUDA:0\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 1\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_2/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_2/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_2/passage_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_2/passage_encoder\n",
      "INFO - haystack.nodes.retriever.dense -  DPR model loaded from models/model_2\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import DensePassageRetriever\n",
    "\n",
    "save_dir = \"models/model_2\"\n",
    "\n",
    "retriever = DensePassageRetriever.load(load_dir=save_dir, document_store=document_store, use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c9b73f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.document_stores.elasticsearch -  Updating embeddings for all 608 docs ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2eaed1a7eac0461bbe52ffc3819f5ec3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Updating embeddings:   0%|          | 0/608 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Create embeddings:   0%|          | 0/608 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "document_store.update_embeddings(retriever, index=doc_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "bdcd1429",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.nodes.retriever.base -  Performing eval queries...\n",
      "100%|██████████████████████████████████████████| 24/24 [00:00<00:00, 109.72it/s]\n",
      "INFO - haystack.nodes.retriever.base -  For 18 out of 24 questions (75.00%), the answer was in the top-5 candidate passages selected by the retriever.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retriever Recall: 0.75\n",
      "Retriever Mean Avg Precision: 0.4993055555555556\n"
     ]
    }
   ],
   "source": [
    "## Evaluate Retriever on its own # THIS IS THE FINE-TUNED model_2\n",
    "# Note that no_answer samples are omitted when evaluation is performed with this method\n",
    "retriever_eval_results = retriever.eval(top_k=5, label_index=label_index, doc_index=doc_index, open_domain=True)\n",
    "# Retriever Recall is the proportion of questions for which the correct document containing the answer is\n",
    "# among the correct documents\n",
    "print(\"Retriever Recall:\", retriever_eval_results[\"recall\"])\n",
    "# Retriever Mean Avg Precision rewards retrievers that give relevant documents a higher rank\n",
    "print(\"Retriever Mean Avg Precision:\", retriever_eval_results[\"map\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f12f4ef",
   "metadata": {},
   "source": [
    "## Model_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb373b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - haystack.document_stores.utils -  No title information found for documents in QA file: squad_format_thesis/test.json\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import PreProcessor\n",
    "\n",
    "document_store.delete_documents(index=doc_index)\n",
    "document_store.delete_documents(index=label_index)\n",
    "\n",
    "preprocessor = PreProcessor(\n",
    "    split_length=200,\n",
    "    split_overlap=0,\n",
    "    split_respect_sentence_boundary=False,\n",
    "    clean_empty_lines=False,\n",
    "    clean_whitespace=False,\n",
    ")\n",
    "\n",
    "# The add_eval_data() method converts the given dataset in json format into Haystack document and label objects. Those objects are then indexed in their respective document and label index in the document store. The method can be used with any dataset in SQuAD format.\n",
    "document_store.add_eval_data(\n",
    "    filename=\"squad_format_thesis/test.json\",\n",
    "    doc_index=doc_index,\n",
    "    label_index=label_index,\n",
    "    preprocessor=preprocessor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c39df24b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.modeling.utils -  Using devices: CUDA:0\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 1\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_3/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_3/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_3/passage_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_3/passage_encoder\n",
      "INFO - haystack.nodes.retriever.dense -  DPR model loaded from models/model_3\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import DensePassageRetriever\n",
    "\n",
    "save_dir = \"models/model_3\"\n",
    "\n",
    "retriever = DensePassageRetriever.load(load_dir=save_dir, document_store=document_store, use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "919dfcd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.document_stores.elasticsearch -  Updating embeddings for all 651 docs ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d7e75859c1745008ed09812385e43da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Updating embeddings:   0%|          | 0/651 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Create embeddings:   0%|          | 0/656 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "document_store.update_embeddings(retriever, index=doc_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a5e7686",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.nodes.retriever.base -  Performing eval queries...\n",
      "100%|██████████████████████████████████████████| 25/25 [00:00<00:00, 103.41it/s]\n",
      "INFO - haystack.nodes.retriever.base -  For 15 out of 25 questions (60.00%), the answer was in the top-5 candidate passages selected by the retriever.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retriever Recall: 0.6\n",
      "Retriever Mean Avg Precision: 0.456\n"
     ]
    }
   ],
   "source": [
    "## Evaluate Retriever on its own # THIS IS THE FINE-TUNED model_2\n",
    "# Note that no_answer samples are omitted when evaluation is performed with this method\n",
    "retriever_eval_results = retriever.eval(top_k=5, label_index=label_index, doc_index=doc_index, open_domain=True)\n",
    "# Retriever Recall is the proportion of questions for which the correct document containing the answer is\n",
    "# among the correct documents\n",
    "print(\"Retriever Recall:\", retriever_eval_results[\"recall\"])\n",
    "# Retriever Mean Avg Precision rewards retrievers that give relevant documents a higher rank\n",
    "print(\"Retriever Mean Avg Precision:\", retriever_eval_results[\"map\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d979e7f",
   "metadata": {},
   "source": [
    "### DEV SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "025b398c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - haystack.document_stores.utils -  No title information found for documents in QA file: squad_format_thesis/dev.json\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import PreProcessor\n",
    "\n",
    "document_store.delete_documents(index=doc_index)\n",
    "document_store.delete_documents(index=label_index)\n",
    "\n",
    "preprocessor = PreProcessor(\n",
    "    split_length=200,\n",
    "    split_overlap=0,\n",
    "    split_respect_sentence_boundary=False,\n",
    "    clean_empty_lines=False,\n",
    "    clean_whitespace=False,\n",
    ")\n",
    "\n",
    "# The add_eval_data() method converts the given dataset in json format into Haystack document and label objects. Those objects are then indexed in their respective document and label index in the document store. The method can be used with any dataset in SQuAD format.\n",
    "document_store.add_eval_data(\n",
    "    filename=\"squad_format_thesis/dev.json\",\n",
    "    doc_index=doc_index,\n",
    "    label_index=label_index,\n",
    "    preprocessor=preprocessor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "93e7e6f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.modeling.utils -  Using devices: CUDA:0\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 1\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_3/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_3/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_3/passage_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_3/passage_encoder\n",
      "INFO - haystack.nodes.retriever.dense -  DPR model loaded from models/model_3\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import DensePassageRetriever\n",
    "\n",
    "save_dir = \"models/model_3\"\n",
    "\n",
    "retriever = DensePassageRetriever.load(load_dir=save_dir, document_store=document_store, use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "70f9cc92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.document_stores.elasticsearch -  Updating embeddings for all 608 docs ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3921b85bf7a438ea220c467b56d72cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Updating embeddings:   0%|          | 0/608 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Create embeddings:   0%|          | 0/608 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "document_store.update_embeddings(retriever, index=doc_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "20c296dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.nodes.retriever.base -  Performing eval queries...\n",
      "100%|██████████████████████████████████████████| 24/24 [00:00<00:00, 101.73it/s]\n",
      "INFO - haystack.nodes.retriever.base -  For 15 out of 24 questions (62.50%), the answer was in the top-5 candidate passages selected by the retriever.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retriever Recall: 0.625\n",
      "Retriever Mean Avg Precision: 0.3541666666666667\n"
     ]
    }
   ],
   "source": [
    "## Evaluate Retriever on its own # THIS IS THE FINE-TUNED model_2\n",
    "# Note that no_answer samples are omitted when evaluation is performed with this method\n",
    "retriever_eval_results = retriever.eval(top_k=5, label_index=label_index, doc_index=doc_index, open_domain=True)\n",
    "# Retriever Recall is the proportion of questions for which the correct document containing the answer is\n",
    "# among the correct documents\n",
    "print(\"Retriever Recall:\", retriever_eval_results[\"recall\"])\n",
    "# Retriever Mean Avg Precision rewards retrievers that give relevant documents a higher rank\n",
    "print(\"Retriever Mean Avg Precision:\", retriever_eval_results[\"map\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09217fe0",
   "metadata": {},
   "source": [
    "## Model_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85dbdf2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - haystack.document_stores.utils -  No title information found for documents in QA file: squad_format_thesis/test.json\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import PreProcessor\n",
    "\n",
    "document_store.delete_documents(index=doc_index)\n",
    "document_store.delete_documents(index=label_index)\n",
    "\n",
    "preprocessor = PreProcessor(\n",
    "    split_length=200,\n",
    "    split_overlap=0,\n",
    "    split_respect_sentence_boundary=False,\n",
    "    clean_empty_lines=False,\n",
    "    clean_whitespace=False,\n",
    ")\n",
    "\n",
    "# The add_eval_data() method converts the given dataset in json format into Haystack document and label objects. Those objects are then indexed in their respective document and label index in the document store. The method can be used with any dataset in SQuAD format.\n",
    "document_store.add_eval_data(\n",
    "    filename=\"squad_format_thesis/test.json\",\n",
    "    doc_index=doc_index,\n",
    "    label_index=label_index,\n",
    "    preprocessor=preprocessor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c958893e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.modeling.utils -  Using devices: CUDA:0\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 1\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_4/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_4/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_4/passage_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_4/passage_encoder\n",
      "INFO - haystack.nodes.retriever.dense -  DPR model loaded from models/model_4\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import DensePassageRetriever\n",
    "\n",
    "save_dir = \"models/model_4\"\n",
    "\n",
    "retriever = DensePassageRetriever.load(load_dir=save_dir, document_store=document_store, use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a744ebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.document_stores.elasticsearch -  Updating embeddings for all 651 docs ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "322a4781a58f4a08a53ced1d652fa98a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Updating embeddings:   0%|          | 0/651 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Create embeddings:   0%|          | 0/656 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "document_store.update_embeddings(retriever, index=doc_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b90ccd15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.nodes.retriever.base -  Performing eval queries...\n",
      "  4%|█▊                                          | 1/25 [00:00<00:06,  3.47it/s]/home/heider/Codes/thesis_v4/env/lib/python3.8/site-packages/elasticsearch/connection/base.py:190: ElasticsearchDeprecationWarning: Elasticsearch built-in security features are not enabled. Without authentication, your cluster could be accessible to anyone. See https://www.elastic.co/guide/en/elasticsearch/reference/7.13/security-minimal-setup.html to enable security.\n",
      "  warnings.warn(message, category=ElasticsearchDeprecationWarning)\n",
      "100%|███████████████████████████████████████████| 25/25 [00:00<00:00, 48.73it/s]\n",
      "INFO - haystack.nodes.retriever.base -  For 13 out of 25 questions (52.00%), the answer was in the top-5 candidate passages selected by the retriever.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retriever Recall: 0.52\n",
      "Retriever Mean Avg Precision: 0.36333333333333334\n"
     ]
    }
   ],
   "source": [
    "## Evaluate Retriever on its own # THIS IS THE FINE-TUNED model_2\n",
    "# Note that no_answer samples are omitted when evaluation is performed with this method\n",
    "retriever_eval_results = retriever.eval(top_k=5, label_index=label_index, doc_index=doc_index, open_domain=True)\n",
    "# Retriever Recall is the proportion of questions for which the correct document containing the answer is\n",
    "# among the correct documents\n",
    "print(\"Retriever Recall:\", retriever_eval_results[\"recall\"])\n",
    "# Retriever Mean Avg Precision rewards retrievers that give relevant documents a higher rank\n",
    "print(\"Retriever Mean Avg Precision:\", retriever_eval_results[\"map\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edde4696",
   "metadata": {},
   "source": [
    "### DEV SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "31ffce8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - haystack.document_stores.utils -  No title information found for documents in QA file: squad_format_thesis/dev.json\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import PreProcessor\n",
    "\n",
    "document_store.delete_documents(index=doc_index)\n",
    "document_store.delete_documents(index=label_index)\n",
    "\n",
    "preprocessor = PreProcessor(\n",
    "    split_length=200,\n",
    "    split_overlap=0,\n",
    "    split_respect_sentence_boundary=False,\n",
    "    clean_empty_lines=False,\n",
    "    clean_whitespace=False,\n",
    ")\n",
    "\n",
    "# The add_eval_data() method converts the given dataset in json format into Haystack document and label objects. Those objects are then indexed in their respective document and label index in the document store. The method can be used with any dataset in SQuAD format.\n",
    "document_store.add_eval_data(\n",
    "    filename=\"squad_format_thesis/dev.json\",\n",
    "    doc_index=doc_index,\n",
    "    label_index=label_index,\n",
    "    preprocessor=preprocessor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0391474a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.modeling.utils -  Using devices: CUDA:0\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 1\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_4/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_4/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_4/passage_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_4/passage_encoder\n",
      "INFO - haystack.nodes.retriever.dense -  DPR model loaded from models/model_4\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import DensePassageRetriever\n",
    "\n",
    "save_dir = \"models/model_4\"\n",
    "\n",
    "retriever = DensePassageRetriever.load(load_dir=save_dir, document_store=document_store, use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "dfd2608b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.document_stores.elasticsearch -  Updating embeddings for all 608 docs ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d749e20ce7b4e5d97da32ad33de7a18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Updating embeddings:   0%|          | 0/608 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Create embeddings:   0%|          | 0/608 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "document_store.update_embeddings(retriever, index=doc_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "21593555",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.nodes.retriever.base -  Performing eval queries...\n",
      "100%|██████████████████████████████████████████| 24/24 [00:00<00:00, 105.35it/s]\n",
      "INFO - haystack.nodes.retriever.base -  For 13 out of 24 questions (54.17%), the answer was in the top-5 candidate passages selected by the retriever.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retriever Recall: 0.5416666666666666\n",
      "Retriever Mean Avg Precision: 0.25625000000000003\n"
     ]
    }
   ],
   "source": [
    "## Evaluate Retriever on its own # THIS IS THE FINE-TUNED model_2\n",
    "# Note that no_answer samples are omitted when evaluation is performed with this method\n",
    "retriever_eval_results = retriever.eval(top_k=5, label_index=label_index, doc_index=doc_index, open_domain=True)\n",
    "# Retriever Recall is the proportion of questions for which the correct document containing the answer is\n",
    "# among the correct documents\n",
    "print(\"Retriever Recall:\", retriever_eval_results[\"recall\"])\n",
    "# Retriever Mean Avg Precision rewards retrievers that give relevant documents a higher rank\n",
    "print(\"Retriever Mean Avg Precision:\", retriever_eval_results[\"map\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e680c8d7",
   "metadata": {},
   "source": [
    "## Model_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1243186",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - haystack.document_stores.utils -  No title information found for documents in QA file: squad_format_thesis/test.json\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import PreProcessor\n",
    "\n",
    "document_store.delete_documents(index=doc_index)\n",
    "document_store.delete_documents(index=label_index)\n",
    "\n",
    "preprocessor = PreProcessor(\n",
    "    split_length=200,\n",
    "    split_overlap=0,\n",
    "    split_respect_sentence_boundary=False,\n",
    "    clean_empty_lines=False,\n",
    "    clean_whitespace=False,\n",
    ")\n",
    "\n",
    "# The add_eval_data() method converts the given dataset in json format into Haystack document and label objects. Those objects are then indexed in their respective document and label index in the document store. The method can be used with any dataset in SQuAD format.\n",
    "document_store.add_eval_data(\n",
    "    filename=\"squad_format_thesis/test.json\",\n",
    "    doc_index=doc_index,\n",
    "    label_index=label_index,\n",
    "    preprocessor=preprocessor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8373561a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.modeling.utils -  Using devices: CUDA:0\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 1\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_5/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_5/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_5/passage_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_5/passage_encoder\n",
      "INFO - haystack.nodes.retriever.dense -  DPR model loaded from models/model_5\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import DensePassageRetriever\n",
    "\n",
    "save_dir = \"models/model_5\"\n",
    "\n",
    "retriever = DensePassageRetriever.load(load_dir=save_dir, document_store=document_store, use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0380d0fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.document_stores.elasticsearch -  Updating embeddings for all 651 docs ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48f8b57179a2465a93cb2abec1122468",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Updating embeddings:   0%|          | 0/651 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Create embeddings:   0%|          | 0/656 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "document_store.update_embeddings(retriever, index=doc_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a66f790",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.nodes.retriever.base -  Performing eval queries...\n",
      "  4%|█▊                                          | 1/25 [00:00<00:03,  7.31it/s]/home/heider/Codes/thesis_v4/env/lib/python3.8/site-packages/elasticsearch/connection/base.py:190: ElasticsearchDeprecationWarning: Elasticsearch built-in security features are not enabled. Without authentication, your cluster could be accessible to anyone. See https://www.elastic.co/guide/en/elasticsearch/reference/7.13/security-minimal-setup.html to enable security.\n",
      "  warnings.warn(message, category=ElasticsearchDeprecationWarning)\n",
      "100%|███████████████████████████████████████████| 25/25 [00:00<00:00, 68.85it/s]\n",
      "INFO - haystack.nodes.retriever.base -  For 17 out of 25 questions (68.00%), the answer was in the top-5 candidate passages selected by the retriever.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retriever Recall: 0.68\n",
      "Retriever Mean Avg Precision: 0.5076666666666667\n"
     ]
    }
   ],
   "source": [
    "## Evaluate Retriever on its own # THIS IS THE FINE-TUNED model_2\n",
    "# Note that no_answer samples are omitted when evaluation is performed with this method\n",
    "retriever_eval_results = retriever.eval(top_k=5, label_index=label_index, doc_index=doc_index, open_domain=True)\n",
    "# Retriever Recall is the proportion of questions for which the correct document containing the answer is\n",
    "# among the correct documents\n",
    "print(\"Retriever Recall:\", retriever_eval_results[\"recall\"])\n",
    "# Retriever Mean Avg Precision rewards retrievers that give relevant documents a higher rank\n",
    "print(\"Retriever Mean Avg Precision:\", retriever_eval_results[\"map\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943e746b",
   "metadata": {},
   "source": [
    "### DEV SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a829b9bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - haystack.document_stores.utils -  No title information found for documents in QA file: squad_format_thesis/dev.json\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import PreProcessor\n",
    "\n",
    "document_store.delete_documents(index=doc_index)\n",
    "document_store.delete_documents(index=label_index)\n",
    "\n",
    "preprocessor = PreProcessor(\n",
    "    split_length=200,\n",
    "    split_overlap=0,\n",
    "    split_respect_sentence_boundary=False,\n",
    "    clean_empty_lines=False,\n",
    "    clean_whitespace=False,\n",
    ")\n",
    "\n",
    "# The add_eval_data() method converts the given dataset in json format into Haystack document and label objects. Those objects are then indexed in their respective document and label index in the document store. The method can be used with any dataset in SQuAD format.\n",
    "document_store.add_eval_data(\n",
    "    filename=\"squad_format_thesis/dev.json\",\n",
    "    doc_index=doc_index,\n",
    "    label_index=label_index,\n",
    "    preprocessor=preprocessor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "246cd4c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.modeling.utils -  Using devices: CUDA:0\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 1\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_5/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_5/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_5/passage_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_5/passage_encoder\n",
      "INFO - haystack.nodes.retriever.dense -  DPR model loaded from models/model_5\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import DensePassageRetriever\n",
    "\n",
    "save_dir = \"models/model_5\"\n",
    "\n",
    "retriever = DensePassageRetriever.load(load_dir=save_dir, document_store=document_store, use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a12704dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.document_stores.elasticsearch -  Updating embeddings for all 608 docs ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce02c59d81434d7bb5e2013fa070c476",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Updating embeddings:   0%|          | 0/608 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Create embeddings:   0%|          | 0/608 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "document_store.update_embeddings(retriever, index=doc_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a65835c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.nodes.retriever.base -  Performing eval queries...\n",
      "100%|███████████████████████████████████████████| 24/24 [00:00<00:00, 95.77it/s]\n",
      "INFO - haystack.nodes.retriever.base -  For 18 out of 24 questions (75.00%), the answer was in the top-5 candidate passages selected by the retriever.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retriever Recall: 0.75\n",
      "Retriever Mean Avg Precision: 0.5256944444444445\n"
     ]
    }
   ],
   "source": [
    "## Evaluate Retriever on its own # THIS IS THE FINE-TUNED model_2\n",
    "# Note that no_answer samples are omitted when evaluation is performed with this method\n",
    "retriever_eval_results = retriever.eval(top_k=5, label_index=label_index, doc_index=doc_index, open_domain=True)\n",
    "# Retriever Recall is the proportion of questions for which the correct document containing the answer is\n",
    "# among the correct documents\n",
    "print(\"Retriever Recall:\", retriever_eval_results[\"recall\"])\n",
    "# Retriever Mean Avg Precision rewards retrievers that give relevant documents a higher rank\n",
    "print(\"Retriever Mean Avg Precision:\", retriever_eval_results[\"map\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f5f89c",
   "metadata": {},
   "source": [
    "## Model_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3fb1d508",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - haystack.document_stores.utils -  No title information found for documents in QA file: squad_format_thesis/test.json\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import PreProcessor\n",
    "\n",
    "document_store.delete_documents(index=doc_index)\n",
    "document_store.delete_documents(index=label_index)\n",
    "\n",
    "preprocessor = PreProcessor(\n",
    "    split_length=200,\n",
    "    split_overlap=0,\n",
    "    split_respect_sentence_boundary=False,\n",
    "    clean_empty_lines=False,\n",
    "    clean_whitespace=False,\n",
    ")\n",
    "\n",
    "# The add_eval_data() method converts the given dataset in json format into Haystack document and label objects. Those objects are then indexed in their respective document and label index in the document store. The method can be used with any dataset in SQuAD format.\n",
    "document_store.add_eval_data(\n",
    "    filename=\"squad_format_thesis/test.json\",\n",
    "    doc_index=doc_index,\n",
    "    label_index=label_index,\n",
    "    preprocessor=preprocessor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1f568a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.modeling.utils -  Using devices: CUDA:0\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 1\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_6/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_6/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_6/passage_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_6/passage_encoder\n",
      "INFO - haystack.nodes.retriever.dense -  DPR model loaded from models/model_6\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import DensePassageRetriever\n",
    "\n",
    "save_dir = \"models/model_6\"\n",
    "\n",
    "retriever = DensePassageRetriever.load(load_dir=save_dir, document_store=document_store, use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "557e0053",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.document_stores.elasticsearch -  Updating embeddings for all 651 docs ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f12599ce43da4b548617c79fa9e231bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Updating embeddings:   0%|          | 0/651 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Create embeddings:   0%|          | 0/656 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "document_store.update_embeddings(retriever, index=doc_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf9bac0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.nodes.retriever.base -  Performing eval queries...\n",
      "100%|███████████████████████████████████████████| 25/25 [00:00<00:00, 99.27it/s]\n",
      "INFO - haystack.nodes.retriever.base -  For 12 out of 25 questions (48.00%), the answer was in the top-5 candidate passages selected by the retriever.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retriever Recall: 0.48\n",
      "Retriever Mean Avg Precision: 0.38333333333333336\n"
     ]
    }
   ],
   "source": [
    "## Evaluate Retriever on its own # THIS IS THE FINE-TUNED model_2\n",
    "# Note that no_answer samples are omitted when evaluation is performed with this method\n",
    "retriever_eval_results = retriever.eval(top_k=5, label_index=label_index, doc_index=doc_index, open_domain=True)\n",
    "# Retriever Recall is the proportion of questions for which the correct document containing the answer is\n",
    "# among the correct documents\n",
    "print(\"Retriever Recall:\", retriever_eval_results[\"recall\"])\n",
    "# Retriever Mean Avg Precision rewards retrievers that give relevant documents a higher rank\n",
    "print(\"Retriever Mean Avg Precision:\", retriever_eval_results[\"map\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1775fc8",
   "metadata": {},
   "source": [
    "### DEV SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e895a89c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - haystack.document_stores.utils -  No title information found for documents in QA file: squad_format_thesis/dev.json\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import PreProcessor\n",
    "\n",
    "document_store.delete_documents(index=doc_index)\n",
    "document_store.delete_documents(index=label_index)\n",
    "\n",
    "preprocessor = PreProcessor(\n",
    "    split_length=200,\n",
    "    split_overlap=0,\n",
    "    split_respect_sentence_boundary=False,\n",
    "    clean_empty_lines=False,\n",
    "    clean_whitespace=False,\n",
    ")\n",
    "\n",
    "# The add_eval_data() method converts the given dataset in json format into Haystack document and label objects. Those objects are then indexed in their respective document and label index in the document store. The method can be used with any dataset in SQuAD format.\n",
    "document_store.add_eval_data(\n",
    "    filename=\"squad_format_thesis/dev.json\",\n",
    "    doc_index=doc_index,\n",
    "    label_index=label_index,\n",
    "    preprocessor=preprocessor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "399a23a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.modeling.utils -  Using devices: CUDA:0\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 1\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_6/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_6/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_6/passage_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_6/passage_encoder\n",
      "INFO - haystack.nodes.retriever.dense -  DPR model loaded from models/model_6\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import DensePassageRetriever\n",
    "\n",
    "save_dir = \"models/model_6\"\n",
    "\n",
    "retriever = DensePassageRetriever.load(load_dir=save_dir, document_store=document_store, use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f2518841",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.document_stores.elasticsearch -  Updating embeddings for all 608 docs ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1538e079871a455283e3542ae6e3d246",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Updating embeddings:   0%|          | 0/608 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Create embeddings:   0%|          | 0/608 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "document_store.update_embeddings(retriever, index=doc_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fcb8d29a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.nodes.retriever.base -  Performing eval queries...\n",
      "100%|██████████████████████████████████████████| 24/24 [00:00<00:00, 105.09it/s]\n",
      "INFO - haystack.nodes.retriever.base -  For 13 out of 24 questions (54.17%), the answer was in the top-5 candidate passages selected by the retriever.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retriever Recall: 0.5416666666666666\n",
      "Retriever Mean Avg Precision: 0.2965277777777778\n"
     ]
    }
   ],
   "source": [
    "## Evaluate Retriever on its own # THIS IS THE FINE-TUNED model_2\n",
    "# Note that no_answer samples are omitted when evaluation is performed with this method\n",
    "retriever_eval_results = retriever.eval(top_k=5, label_index=label_index, doc_index=doc_index, open_domain=True)\n",
    "# Retriever Recall is the proportion of questions for which the correct document containing the answer is\n",
    "# among the correct documents\n",
    "print(\"Retriever Recall:\", retriever_eval_results[\"recall\"])\n",
    "# Retriever Mean Avg Precision rewards retrievers that give relevant documents a higher rank\n",
    "print(\"Retriever Mean Avg Precision:\", retriever_eval_results[\"map\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd3016e",
   "metadata": {},
   "source": [
    "## Model_7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e827b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - haystack.document_stores.utils -  No title information found for documents in QA file: squad_format_thesis/test.json\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import PreProcessor\n",
    "\n",
    "document_store.delete_documents(index=doc_index)\n",
    "document_store.delete_documents(index=label_index)\n",
    "\n",
    "preprocessor = PreProcessor(\n",
    "    split_length=200,\n",
    "    split_overlap=0,\n",
    "    split_respect_sentence_boundary=False,\n",
    "    clean_empty_lines=False,\n",
    "    clean_whitespace=False,\n",
    ")\n",
    "\n",
    "# The add_eval_data() method converts the given dataset in json format into Haystack document and label objects. Those objects are then indexed in their respective document and label index in the document store. The method can be used with any dataset in SQuAD format.\n",
    "document_store.add_eval_data(\n",
    "    filename=\"squad_format_thesis/test.json\",\n",
    "    doc_index=doc_index,\n",
    "    label_index=label_index,\n",
    "    preprocessor=preprocessor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e531dec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.modeling.utils -  Using devices: CUDA:0\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 1\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_7/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_7/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_7/passage_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_7/passage_encoder\n",
      "INFO - haystack.nodes.retriever.dense -  DPR model loaded from models/model_7\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import DensePassageRetriever\n",
    "\n",
    "save_dir = \"models/model_7\"\n",
    "\n",
    "retriever = DensePassageRetriever.load(load_dir=save_dir, document_store=document_store, use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4dd5314",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.document_stores.elasticsearch -  Updating embeddings for all 651 docs ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb600b2615b54423a5bb5be278b79034",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Updating embeddings:   0%|          | 0/651 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Create embeddings:   0%|          | 0/656 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "document_store.update_embeddings(retriever, index=doc_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c09670f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.nodes.retriever.base -  Performing eval queries...\n",
      "  4%|█▊                                          | 1/25 [00:00<00:03,  7.11it/s]/home/heider/Codes/thesis_v4/env/lib/python3.8/site-packages/elasticsearch/connection/base.py:190: ElasticsearchDeprecationWarning: Elasticsearch built-in security features are not enabled. Without authentication, your cluster could be accessible to anyone. See https://www.elastic.co/guide/en/elasticsearch/reference/7.13/security-minimal-setup.html to enable security.\n",
      "  warnings.warn(message, category=ElasticsearchDeprecationWarning)\n",
      "100%|███████████████████████████████████████████| 25/25 [00:00<00:00, 69.00it/s]\n",
      "INFO - haystack.nodes.retriever.base -  For 17 out of 25 questions (68.00%), the answer was in the top-5 candidate passages selected by the retriever.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retriever Recall: 0.68\n",
      "Retriever Mean Avg Precision: 0.5076666666666667\n"
     ]
    }
   ],
   "source": [
    "## Evaluate Retriever on its own # THIS IS THE FINE-TUNED model_2\n",
    "# Note that no_answer samples are omitted when evaluation is performed with this method\n",
    "retriever_eval_results = retriever.eval(top_k=5, label_index=label_index, doc_index=doc_index, open_domain=True)\n",
    "# Retriever Recall is the proportion of questions for which the correct document containing the answer is\n",
    "# among the correct documents\n",
    "print(\"Retriever Recall:\", retriever_eval_results[\"recall\"])\n",
    "# Retriever Mean Avg Precision rewards retrievers that give relevant documents a higher rank\n",
    "print(\"Retriever Mean Avg Precision:\", retriever_eval_results[\"map\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9351751",
   "metadata": {},
   "source": [
    "### DEV SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "35c7bf9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - haystack.document_stores.utils -  No title information found for documents in QA file: squad_format_thesis/dev.json\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import PreProcessor\n",
    "\n",
    "document_store.delete_documents(index=doc_index)\n",
    "document_store.delete_documents(index=label_index)\n",
    "\n",
    "preprocessor = PreProcessor(\n",
    "    split_length=200,\n",
    "    split_overlap=0,\n",
    "    split_respect_sentence_boundary=False,\n",
    "    clean_empty_lines=False,\n",
    "    clean_whitespace=False,\n",
    ")\n",
    "\n",
    "# The add_eval_data() method converts the given dataset in json format into Haystack document and label objects. Those objects are then indexed in their respective document and label index in the document store. The method can be used with any dataset in SQuAD format.\n",
    "document_store.add_eval_data(\n",
    "    filename=\"squad_format_thesis/dev.json\",\n",
    "    doc_index=doc_index,\n",
    "    label_index=label_index,\n",
    "    preprocessor=preprocessor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "268008a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.modeling.utils -  Using devices: CUDA:0\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 1\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_7/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_7/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_7/passage_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_7/passage_encoder\n",
      "INFO - haystack.nodes.retriever.dense -  DPR model loaded from models/model_7\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import DensePassageRetriever\n",
    "\n",
    "save_dir = \"models/model_7\"\n",
    "\n",
    "retriever = DensePassageRetriever.load(load_dir=save_dir, document_store=document_store, use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9cafab1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.document_stores.elasticsearch -  Updating embeddings for all 608 docs ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3929762a0d724efda48622a4e1354423",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Updating embeddings:   0%|          | 0/608 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Create embeddings:   0%|          | 0/608 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "document_store.update_embeddings(retriever, index=doc_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b9c28b1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.nodes.retriever.base -  Performing eval queries...\n",
      "100%|██████████████████████████████████████████| 24/24 [00:00<00:00, 105.80it/s]\n",
      "INFO - haystack.nodes.retriever.base -  For 18 out of 24 questions (75.00%), the answer was in the top-5 candidate passages selected by the retriever.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retriever Recall: 0.75\n",
      "Retriever Mean Avg Precision: 0.5027777777777778\n"
     ]
    }
   ],
   "source": [
    "## Evaluate Retriever on its own # THIS IS THE FINE-TUNED model_2\n",
    "# Note that no_answer samples are omitted when evaluation is performed with this method\n",
    "retriever_eval_results = retriever.eval(top_k=5, label_index=label_index, doc_index=doc_index, open_domain=True)\n",
    "# Retriever Recall is the proportion of questions for which the correct document containing the answer is\n",
    "# among the correct documents\n",
    "print(\"Retriever Recall:\", retriever_eval_results[\"recall\"])\n",
    "# Retriever Mean Avg Precision rewards retrievers that give relevant documents a higher rank\n",
    "print(\"Retriever Mean Avg Precision:\", retriever_eval_results[\"map\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01c35a2",
   "metadata": {},
   "source": [
    "## Model_8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "625572eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - haystack.document_stores.utils -  No title information found for documents in QA file: squad_format_thesis/test.json\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import PreProcessor\n",
    "\n",
    "document_store.delete_documents(index=doc_index)\n",
    "document_store.delete_documents(index=label_index)\n",
    "\n",
    "preprocessor = PreProcessor(\n",
    "    split_length=200,\n",
    "    split_overlap=0,\n",
    "    split_respect_sentence_boundary=False,\n",
    "    clean_empty_lines=False,\n",
    "    clean_whitespace=False,\n",
    ")\n",
    "\n",
    "# The add_eval_data() method converts the given dataset in json format into Haystack document and label objects. Those objects are then indexed in their respective document and label index in the document store. The method can be used with any dataset in SQuAD format.\n",
    "document_store.add_eval_data(\n",
    "    filename=\"squad_format_thesis/test.json\",\n",
    "    doc_index=doc_index,\n",
    "    label_index=label_index,\n",
    "    preprocessor=preprocessor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cad95f54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.modeling.utils -  Using devices: CUDA:0\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 1\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_8/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_8/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_8/passage_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_8/passage_encoder\n",
      "INFO - haystack.nodes.retriever.dense -  DPR model loaded from models/model_8\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import DensePassageRetriever\n",
    "\n",
    "save_dir = \"models/model_8\"\n",
    "\n",
    "retriever = DensePassageRetriever.load(load_dir=save_dir, document_store=document_store, use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48b8d882",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.document_stores.elasticsearch -  Updating embeddings for all 651 docs ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6af776c172c48839736a728404c715e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Updating embeddings:   0%|          | 0/651 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Create embeddings:   0%|          | 0/656 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "document_store.update_embeddings(retriever, index=doc_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "630ece49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.nodes.retriever.base -  Performing eval queries...\n",
      "  4%|█▊                                          | 1/25 [00:00<00:06,  3.54it/s]/home/heider/Codes/thesis_v4/env/lib/python3.8/site-packages/elasticsearch/connection/base.py:190: ElasticsearchDeprecationWarning: Elasticsearch built-in security features are not enabled. Without authentication, your cluster could be accessible to anyone. See https://www.elastic.co/guide/en/elasticsearch/reference/7.13/security-minimal-setup.html to enable security.\n",
      "  warnings.warn(message, category=ElasticsearchDeprecationWarning)\n",
      "100%|███████████████████████████████████████████| 25/25 [00:00<00:00, 49.33it/s]\n",
      "INFO - haystack.nodes.retriever.base -  For 15 out of 25 questions (60.00%), the answer was in the top-5 candidate passages selected by the retriever.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retriever Recall: 0.6\n",
      "Retriever Mean Avg Precision: 0.4866666666666667\n"
     ]
    }
   ],
   "source": [
    "## Evaluate Retriever on its own # THIS IS THE FINE-TUNED model_2\n",
    "# Note that no_answer samples are omitted when evaluation is performed with this method\n",
    "retriever_eval_results = retriever.eval(top_k=5, label_index=label_index, doc_index=doc_index, open_domain=True)\n",
    "# Retriever Recall is the proportion of questions for which the correct document containing the answer is\n",
    "# among the correct documents\n",
    "print(\"Retriever Recall:\", retriever_eval_results[\"recall\"])\n",
    "# Retriever Mean Avg Precision rewards retrievers that give relevant documents a higher rank\n",
    "print(\"Retriever Mean Avg Precision:\", retriever_eval_results[\"map\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e116f3",
   "metadata": {},
   "source": [
    "### DEV SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d41c72fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - haystack.document_stores.utils -  No title information found for documents in QA file: squad_format_thesis/dev.json\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import PreProcessor\n",
    "\n",
    "document_store.delete_documents(index=doc_index)\n",
    "document_store.delete_documents(index=label_index)\n",
    "\n",
    "preprocessor = PreProcessor(\n",
    "    split_length=200,\n",
    "    split_overlap=0,\n",
    "    split_respect_sentence_boundary=False,\n",
    "    clean_empty_lines=False,\n",
    "    clean_whitespace=False,\n",
    ")\n",
    "\n",
    "# The add_eval_data() method converts the given dataset in json format into Haystack document and label objects. Those objects are then indexed in their respective document and label index in the document store. The method can be used with any dataset in SQuAD format.\n",
    "document_store.add_eval_data(\n",
    "    filename=\"squad_format_thesis/dev.json\",\n",
    "    doc_index=doc_index,\n",
    "    label_index=label_index,\n",
    "    preprocessor=preprocessor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0e53dffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.modeling.utils -  Using devices: CUDA:0\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 1\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_8/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_8/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_8/passage_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_8/passage_encoder\n",
      "INFO - haystack.nodes.retriever.dense -  DPR model loaded from models/model_8\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import DensePassageRetriever\n",
    "\n",
    "save_dir = \"models/model_8\"\n",
    "\n",
    "retriever = DensePassageRetriever.load(load_dir=save_dir, document_store=document_store, use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f30378de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.document_stores.elasticsearch -  Updating embeddings for all 608 docs ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6fad79571d24b41935b3d910176e7c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Updating embeddings:   0%|          | 0/608 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Create embeddings:   0%|          | 0/608 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "document_store.update_embeddings(retriever, index=doc_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c6b1202d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.nodes.retriever.base -  Performing eval queries...\n",
      "100%|██████████████████████████████████████████| 24/24 [00:00<00:00, 109.92it/s]\n",
      "INFO - haystack.nodes.retriever.base -  For 15 out of 24 questions (62.50%), the answer was in the top-5 candidate passages selected by the retriever.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retriever Recall: 0.625\n",
      "Retriever Mean Avg Precision: 0.36944444444444446\n"
     ]
    }
   ],
   "source": [
    "## Evaluate Retriever on its own # THIS IS THE FINE-TUNED model_2\n",
    "# Note that no_answer samples are omitted when evaluation is performed with this method\n",
    "retriever_eval_results = retriever.eval(top_k=5, label_index=label_index, doc_index=doc_index, open_domain=True)\n",
    "# Retriever Recall is the proportion of questions for which the correct document containing the answer is\n",
    "# among the correct documents\n",
    "print(\"Retriever Recall:\", retriever_eval_results[\"recall\"])\n",
    "# Retriever Mean Avg Precision rewards retrievers that give relevant documents a higher rank\n",
    "print(\"Retriever Mean Avg Precision:\", retriever_eval_results[\"map\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc9fbde",
   "metadata": {},
   "source": [
    "## Model_9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0d52c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - haystack.document_stores.utils -  No title information found for documents in QA file: squad_format_thesis/test.json\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import PreProcessor\n",
    "\n",
    "document_store.delete_documents(index=doc_index)\n",
    "document_store.delete_documents(index=label_index)\n",
    "\n",
    "preprocessor = PreProcessor(\n",
    "    split_length=200,\n",
    "    split_overlap=0,\n",
    "    split_respect_sentence_boundary=False,\n",
    "    clean_empty_lines=False,\n",
    "    clean_whitespace=False,\n",
    ")\n",
    "\n",
    "# The add_eval_data() method converts the given dataset in json format into Haystack document and label objects. Those objects are then indexed in their respective document and label index in the document store. The method can be used with any dataset in SQuAD format.\n",
    "document_store.add_eval_data(\n",
    "    filename=\"squad_format_thesis/test.json\",\n",
    "    doc_index=doc_index,\n",
    "    label_index=label_index,\n",
    "    preprocessor=preprocessor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5914d2b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.modeling.utils -  Using devices: CUDA:0\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 1\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_9/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_9/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_9/passage_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_9/passage_encoder\n",
      "INFO - haystack.nodes.retriever.dense -  DPR model loaded from models/model_9\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import DensePassageRetriever\n",
    "\n",
    "save_dir = \"models/model_9\"\n",
    "\n",
    "retriever = DensePassageRetriever.load(load_dir=save_dir, document_store=document_store, use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "858de36f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.document_stores.elasticsearch -  Updating embeddings for all 651 docs ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13b7253ccd3c42bdb4a783e853349f50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Updating embeddings:   0%|          | 0/651 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Create embeddings:   0%|          | 0/656 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "document_store.update_embeddings(retriever, index=doc_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60b74bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.nodes.retriever.base -  Performing eval queries...\n",
      "100%|██████████████████████████████████████████| 25/25 [00:00<00:00, 102.15it/s]\n",
      "INFO - haystack.nodes.retriever.base -  For 17 out of 25 questions (68.00%), the answer was in the top-5 candidate passages selected by the retriever.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retriever Recall: 0.68\n",
      "Retriever Mean Avg Precision: 0.5076666666666667\n"
     ]
    }
   ],
   "source": [
    "## Evaluate Retriever on its own # THIS IS THE FINE-TUNED model_2\n",
    "# Note that no_answer samples are omitted when evaluation is performed with this method\n",
    "retriever_eval_results = retriever.eval(top_k=5, label_index=label_index, doc_index=doc_index, open_domain=True)\n",
    "# Retriever Recall is the proportion of questions for which the correct document containing the answer is\n",
    "# among the correct documents\n",
    "print(\"Retriever Recall:\", retriever_eval_results[\"recall\"])\n",
    "# Retriever Mean Avg Precision rewards retrievers that give relevant documents a higher rank\n",
    "print(\"Retriever Mean Avg Precision:\", retriever_eval_results[\"map\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798347df",
   "metadata": {},
   "source": [
    "### DEV SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9fbc146d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - haystack.document_stores.utils -  No title information found for documents in QA file: squad_format_thesis/dev.json\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import PreProcessor\n",
    "\n",
    "document_store.delete_documents(index=doc_index)\n",
    "document_store.delete_documents(index=label_index)\n",
    "\n",
    "preprocessor = PreProcessor(\n",
    "    split_length=200,\n",
    "    split_overlap=0,\n",
    "    split_respect_sentence_boundary=False,\n",
    "    clean_empty_lines=False,\n",
    "    clean_whitespace=False,\n",
    ")\n",
    "\n",
    "# The add_eval_data() method converts the given dataset in json format into Haystack document and label objects. Those objects are then indexed in their respective document and label index in the document store. The method can be used with any dataset in SQuAD format.\n",
    "document_store.add_eval_data(\n",
    "    filename=\"squad_format_thesis/dev.json\",\n",
    "    doc_index=doc_index,\n",
    "    label_index=label_index,\n",
    "    preprocessor=preprocessor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1219e526",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.modeling.utils -  Using devices: CUDA:0\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 1\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_9/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_9/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_9/passage_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_9/passage_encoder\n",
      "INFO - haystack.nodes.retriever.dense -  DPR model loaded from models/model_9\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import DensePassageRetriever\n",
    "\n",
    "save_dir = \"models/model_9\"\n",
    "\n",
    "retriever = DensePassageRetriever.load(load_dir=save_dir, document_store=document_store, use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "154d63e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.document_stores.elasticsearch -  Updating embeddings for all 608 docs ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bd74237f5d74d1ca3b4c1d9bf25b5f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Updating embeddings:   0%|          | 0/608 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Create embeddings:   0%|          | 0/608 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "document_store.update_embeddings(retriever, index=doc_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ca737add",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.nodes.retriever.base -  Performing eval queries...\n",
      "100%|██████████████████████████████████████████| 24/24 [00:00<00:00, 110.63it/s]\n",
      "INFO - haystack.nodes.retriever.base -  For 18 out of 24 questions (75.00%), the answer was in the top-5 candidate passages selected by the retriever.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retriever Recall: 0.75\n",
      "Retriever Mean Avg Precision: 0.5256944444444445\n"
     ]
    }
   ],
   "source": [
    "## Evaluate Retriever on its own # THIS IS THE FINE-TUNED model_2\n",
    "# Note that no_answer samples are omitted when evaluation is performed with this method\n",
    "retriever_eval_results = retriever.eval(top_k=5, label_index=label_index, doc_index=doc_index, open_domain=True)\n",
    "# Retriever Recall is the proportion of questions for which the correct document containing the answer is\n",
    "# among the correct documents\n",
    "print(\"Retriever Recall:\", retriever_eval_results[\"recall\"])\n",
    "# Retriever Mean Avg Precision rewards retrievers that give relevant documents a higher rank\n",
    "print(\"Retriever Mean Avg Precision:\", retriever_eval_results[\"map\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe6ea34",
   "metadata": {},
   "source": [
    "## Model_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc32817a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - haystack.document_stores.utils -  No title information found for documents in QA file: squad_format_thesis/test.json\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import PreProcessor\n",
    "\n",
    "document_store.delete_documents(index=doc_index)\n",
    "document_store.delete_documents(index=label_index)\n",
    "\n",
    "preprocessor = PreProcessor(\n",
    "    split_length=200,\n",
    "    split_overlap=0,\n",
    "    split_respect_sentence_boundary=False,\n",
    "    clean_empty_lines=False,\n",
    "    clean_whitespace=False,\n",
    ")\n",
    "\n",
    "# The add_eval_data() method converts the given dataset in json format into Haystack document and label objects. Those objects are then indexed in their respective document and label index in the document store. The method can be used with any dataset in SQuAD format.\n",
    "document_store.add_eval_data(\n",
    "    filename=\"squad_format_thesis/test.json\",\n",
    "    doc_index=doc_index,\n",
    "    label_index=label_index,\n",
    "    preprocessor=preprocessor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "143ae9e1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.modeling.utils -  Using devices: CUDA:0\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 1\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_10/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_10/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_10/passage_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_10/passage_encoder\n",
      "INFO - haystack.nodes.retriever.dense -  DPR model loaded from models/model_10\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import DensePassageRetriever\n",
    "\n",
    "save_dir = \"models/model_10\"\n",
    "\n",
    "retriever = DensePassageRetriever.load(load_dir=save_dir, document_store=document_store, use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97b5bca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.document_stores.elasticsearch -  Updating embeddings for all 651 docs ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9031c3f35d1e4c1089716ffe67183010",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Updating embeddings:   0%|          | 0/651 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Create embeddings:   0%|          | 0/656 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "document_store.update_embeddings(retriever, index=doc_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d9bfe8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.nodes.retriever.base -  Performing eval queries...\n",
      "  4%|█▊                                          | 1/25 [00:00<00:07,  3.35it/s]/home/heider/Codes/thesis_v4/env/lib/python3.8/site-packages/elasticsearch/connection/base.py:190: ElasticsearchDeprecationWarning: Elasticsearch built-in security features are not enabled. Without authentication, your cluster could be accessible to anyone. See https://www.elastic.co/guide/en/elasticsearch/reference/7.13/security-minimal-setup.html to enable security.\n",
      "  warnings.warn(message, category=ElasticsearchDeprecationWarning)\n",
      "100%|███████████████████████████████████████████| 25/25 [00:00<00:00, 45.77it/s]\n",
      "INFO - haystack.nodes.retriever.base -  For 17 out of 25 questions (68.00%), the answer was in the top-5 candidate passages selected by the retriever.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retriever Recall: 0.68\n",
      "Retriever Mean Avg Precision: 0.5076666666666667\n"
     ]
    }
   ],
   "source": [
    "## Evaluate Retriever on its own # THIS IS THE FINE-TUNED model_2\n",
    "# Note that no_answer samples are omitted when evaluation is performed with this method\n",
    "retriever_eval_results = retriever.eval(top_k=5, label_index=label_index, doc_index=doc_index, open_domain=True)\n",
    "# Retriever Recall is the proportion of questions for which the correct document containing the answer is\n",
    "# among the correct documents\n",
    "print(\"Retriever Recall:\", retriever_eval_results[\"recall\"])\n",
    "# Retriever Mean Avg Precision rewards retrievers that give relevant documents a higher rank\n",
    "print(\"Retriever Mean Avg Precision:\", retriever_eval_results[\"map\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf41a95",
   "metadata": {},
   "source": [
    "### DEV SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ff0f1c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - haystack.document_stores.utils -  No title information found for documents in QA file: squad_format_thesis/dev.json\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import PreProcessor\n",
    "\n",
    "document_store.delete_documents(index=doc_index)\n",
    "document_store.delete_documents(index=label_index)\n",
    "\n",
    "preprocessor = PreProcessor(\n",
    "    split_length=200,\n",
    "    split_overlap=0,\n",
    "    split_respect_sentence_boundary=False,\n",
    "    clean_empty_lines=False,\n",
    "    clean_whitespace=False,\n",
    ")\n",
    "\n",
    "# The add_eval_data() method converts the given dataset in json format into Haystack document and label objects. Those objects are then indexed in their respective document and label index in the document store. The method can be used with any dataset in SQuAD format.\n",
    "document_store.add_eval_data(\n",
    "    filename=\"squad_format_thesis/dev.json\",\n",
    "    doc_index=doc_index,\n",
    "    label_index=label_index,\n",
    "    preprocessor=preprocessor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7313e84f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.modeling.utils -  Using devices: CUDA:0\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 1\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_10/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_10/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_10/passage_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_10/passage_encoder\n",
      "INFO - haystack.nodes.retriever.dense -  DPR model loaded from models/model_10\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import DensePassageRetriever\n",
    "\n",
    "save_dir = \"models/model_10\"\n",
    "\n",
    "retriever = DensePassageRetriever.load(load_dir=save_dir, document_store=document_store, use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "68b51557",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.document_stores.elasticsearch -  Updating embeddings for all 608 docs ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5bf3b801d4b427fb46d3e75724b51a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Updating embeddings:   0%|          | 0/608 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Create embeddings:   0%|          | 0/608 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "document_store.update_embeddings(retriever, index=doc_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bc2366bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.nodes.retriever.base -  Performing eval queries...\n",
      "100%|███████████████████████████████████████████| 24/24 [00:00<00:00, 82.24it/s]\n",
      "INFO - haystack.nodes.retriever.base -  For 18 out of 24 questions (75.00%), the answer was in the top-5 candidate passages selected by the retriever.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retriever Recall: 0.75\n",
      "Retriever Mean Avg Precision: 0.5256944444444445\n"
     ]
    }
   ],
   "source": [
    "## Evaluate Retriever on its own # THIS IS THE FINE-TUNED model_2\n",
    "# Note that no_answer samples are omitted when evaluation is performed with this method\n",
    "retriever_eval_results = retriever.eval(top_k=5, label_index=label_index, doc_index=doc_index, open_domain=True)\n",
    "# Retriever Recall is the proportion of questions for which the correct document containing the answer is\n",
    "# among the correct documents\n",
    "print(\"Retriever Recall:\", retriever_eval_results[\"recall\"])\n",
    "# Retriever Mean Avg Precision rewards retrievers that give relevant documents a higher rank\n",
    "print(\"Retriever Mean Avg Precision:\", retriever_eval_results[\"map\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda1a72b",
   "metadata": {},
   "source": [
    "## Base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb96eec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - haystack.document_stores.utils -  No title information found for documents in QA file: squad_format_thesis/test.json\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import PreProcessor\n",
    "\n",
    "document_store.delete_documents(index=doc_index)\n",
    "document_store.delete_documents(index=label_index)\n",
    "\n",
    "preprocessor = PreProcessor(\n",
    "    split_length=200,\n",
    "    split_overlap=0,\n",
    "    split_respect_sentence_boundary=False,\n",
    "    clean_empty_lines=False,\n",
    "    clean_whitespace=False,\n",
    ")\n",
    "\n",
    "# The add_eval_data() method converts the given dataset in json format into Haystack document and label objects. Those objects are then indexed in their respective document and label index in the document store. The method can be used with any dataset in SQuAD format.\n",
    "document_store.add_eval_data(\n",
    "    filename=\"squad_format_thesis/test.json\",\n",
    "    doc_index=doc_index,\n",
    "    label_index=label_index,\n",
    "    preprocessor=preprocessor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52648254",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.modeling.utils -  Using devices: CUDA:0\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 1\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Could not find IIC/dpr-spanish-question_encoder-allqa-base locally.\n",
      "INFO - haystack.modeling.model.language_model -  Looking on Transformers Model Hub (in local cache and online)...\n",
      "INFO - haystack.modeling.model.language_model -  Automatically detected language from language model name: spanish\n",
      "INFO - haystack.modeling.model.language_model -  Loaded IIC/dpr-spanish-question_encoder-allqa-base\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Could not find IIC/dpr-spanish-passage_encoder-allqa-base locally.\n",
      "INFO - haystack.modeling.model.language_model -  Looking on Transformers Model Hub (in local cache and online)...\n",
      "INFO - haystack.modeling.model.language_model -  Automatically detected language from language model name: spanish\n",
      "INFO - haystack.modeling.model.language_model -  Loaded IIC/dpr-spanish-passage_encoder-allqa-base\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import DensePassageRetriever\n",
    "retriever = DensePassageRetriever(\n",
    "            document_store=document_store,\n",
    "            query_embedding_model=\"IIC/dpr-spanish-question_encoder-allqa-base\",\n",
    "            passage_embedding_model=\"IIC/dpr-spanish-passage_encoder-allqa-base\",\n",
    "            use_gpu=True,\n",
    "            batch_size = 64\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20407e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.document_stores.elasticsearch -  Updating embeddings for all 651 docs ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6431c0833a71410ca998f59ff488207f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Updating embeddings:   0%|          | 0/651 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Create embeddings:   0%|          | 0/704 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "document_store.update_embeddings(retriever, index=doc_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa0e6610",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.nodes.retriever.base -  Performing eval queries...\n",
      "100%|███████████████████████████████████████████| 25/25 [00:00<00:00, 54.09it/s]\n",
      "INFO - haystack.nodes.retriever.base -  For 17 out of 25 questions (68.00%), the answer was in the top-5 candidate passages selected by the retriever.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retriever Recall: 0.68\n",
      "Retriever Mean Avg Precision: 0.5076666666666667\n"
     ]
    }
   ],
   "source": [
    "## Evaluate Retriever on its own #THIS IS THE BARE BONES\n",
    "# Note that no_answer samples are omitted when evaluation is performed with this method\n",
    "retriever_eval_results = retriever.eval(top_k=5, label_index=label_index, doc_index=doc_index, open_domain=True)\n",
    "# Retriever Recall is the proportion of questions for which the correct document containing the answer is\n",
    "# among the correct documents\n",
    "print(\"Retriever Recall:\", retriever_eval_results[\"recall\"])\n",
    "# Retriever Mean Avg Precision rewards retrievers that give relevant documents a higher rank\n",
    "print(\"Retriever Mean Avg Precision:\", retriever_eval_results[\"map\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661725af",
   "metadata": {},
   "source": [
    "### DEV SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f4819117",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - haystack.document_stores.utils -  No title information found for documents in QA file: squad_format_thesis/dev.json\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import PreProcessor\n",
    "\n",
    "document_store.delete_documents(index=doc_index)\n",
    "document_store.delete_documents(index=label_index)\n",
    "\n",
    "preprocessor = PreProcessor(\n",
    "    split_length=200,\n",
    "    split_overlap=0,\n",
    "    split_respect_sentence_boundary=False,\n",
    "    clean_empty_lines=False,\n",
    "    clean_whitespace=False,\n",
    ")\n",
    "\n",
    "# The add_eval_data() method converts the given dataset in json format into Haystack document and label objects. Those objects are then indexed in their respective document and label index in the document store. The method can be used with any dataset in SQuAD format.\n",
    "document_store.add_eval_data(\n",
    "    filename=\"squad_format_thesis/dev.json\",\n",
    "    doc_index=doc_index,\n",
    "    label_index=label_index,\n",
    "    preprocessor=preprocessor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8de54b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.modeling.utils -  Using devices: CUDA:0\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 1\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Could not find IIC/dpr-spanish-question_encoder-allqa-base locally.\n",
      "INFO - haystack.modeling.model.language_model -  Looking on Transformers Model Hub (in local cache and online)...\n",
      "INFO - haystack.modeling.model.language_model -  Automatically detected language from language model name: spanish\n",
      "INFO - haystack.modeling.model.language_model -  Loaded IIC/dpr-spanish-question_encoder-allqa-base\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Could not find IIC/dpr-spanish-passage_encoder-allqa-base locally.\n",
      "INFO - haystack.modeling.model.language_model -  Looking on Transformers Model Hub (in local cache and online)...\n",
      "INFO - haystack.modeling.model.language_model -  Automatically detected language from language model name: spanish\n",
      "INFO - haystack.modeling.model.language_model -  Loaded IIC/dpr-spanish-passage_encoder-allqa-base\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import DensePassageRetriever\n",
    "retriever = DensePassageRetriever(\n",
    "            document_store=document_store,\n",
    "            query_embedding_model=\"IIC/dpr-spanish-question_encoder-allqa-base\",\n",
    "            passage_embedding_model=\"IIC/dpr-spanish-passage_encoder-allqa-base\",\n",
    "            use_gpu=True,\n",
    "            batch_size = 64\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6f4d3570",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.document_stores.elasticsearch -  Updating embeddings for all 608 docs ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fa4aac5b5d0440e8168c75cb8982141",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Updating embeddings:   0%|          | 0/608 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Create embeddings:   0%|          | 0/640 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "document_store.update_embeddings(retriever, index=doc_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2aff70e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.nodes.retriever.base -  Performing eval queries...\n",
      "100%|██████████████████████████████████████████| 24/24 [00:00<00:00, 110.94it/s]\n",
      "INFO - haystack.nodes.retriever.base -  For 18 out of 24 questions (75.00%), the answer was in the top-5 candidate passages selected by the retriever.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retriever Recall: 0.75\n",
      "Retriever Mean Avg Precision: 0.5256944444444445\n"
     ]
    }
   ],
   "source": [
    "## Evaluate Retriever on its own #THIS IS THE BARE BONES\n",
    "# Note that no_answer samples are omitted when evaluation is performed with this method\n",
    "retriever_eval_results = retriever.eval(top_k=5, label_index=label_index, doc_index=doc_index, open_domain=True)\n",
    "# Retriever Recall is the proportion of questions for which the correct document containing the answer is\n",
    "# among the correct documents\n",
    "print(\"Retriever Recall:\", retriever_eval_results[\"recall\"])\n",
    "# Retriever Mean Avg Precision rewards retrievers that give relevant documents a higher rank\n",
    "print(\"Retriever Mean Avg Precision:\", retriever_eval_results[\"map\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac00060",
   "metadata": {},
   "source": [
    "## Old Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e699ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - haystack.document_stores.utils -  No title information found for documents in QA file: squad_format_thesis/test.json\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import PreProcessor\n",
    "\n",
    "document_store.delete_documents(index=doc_index)\n",
    "document_store.delete_documents(index=label_index)\n",
    "\n",
    "preprocessor = PreProcessor(\n",
    "    split_length=200,\n",
    "    split_overlap=0,\n",
    "    split_respect_sentence_boundary=False,\n",
    "    clean_empty_lines=False,\n",
    "    clean_whitespace=False,\n",
    ")\n",
    "\n",
    "# The add_eval_data() method converts the given dataset in json format into Haystack document and label objects. Those objects are then indexed in their respective document and label index in the document store. The method can be used with any dataset in SQuAD format.\n",
    "document_store.add_eval_data(\n",
    "    filename=\"squad_format_thesis/test.json\",\n",
    "    doc_index=doc_index,\n",
    "    label_index=label_index,\n",
    "    preprocessor=preprocessor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4e60230",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.modeling.utils -  Using devices: CUDA:0\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 1\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Could not find voidful/dpr-question_encoder-bert-base-multilingual locally.\n",
      "INFO - haystack.modeling.model.language_model -  Looking on Transformers Model Hub (in local cache and online)...\n",
      "INFO - haystack.modeling.model.language_model -  Automatically detected language from language model name: multilingual\n",
      "INFO - haystack.modeling.model.language_model -  Loaded voidful/dpr-question_encoder-bert-base-multilingual\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
      "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Could not find voidful/dpr-ctx_encoder-bert-base-multilingual locally.\n",
      "INFO - haystack.modeling.model.language_model -  Looking on Transformers Model Hub (in local cache and online)...\n",
      "INFO - haystack.modeling.model.language_model -  Automatically detected language from language model name: multilingual\n",
      "INFO - haystack.modeling.model.language_model -  Loaded voidful/dpr-ctx_encoder-bert-base-multilingual\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import DensePassageRetriever\n",
    "retriever = DensePassageRetriever(\n",
    "            document_store=document_store,\n",
    "            query_embedding_model=\"voidful/dpr-question_encoder-bert-base-multilingual\",\n",
    "            passage_embedding_model=\"voidful/dpr-ctx_encoder-bert-base-multilingual\",\n",
    "            use_gpu=True,\n",
    "            batch_size = 64\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d25396c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.document_stores.elasticsearch -  Updating embeddings for all 651 docs ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b49f2954a704daab195d4dcbab1dab2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Updating embeddings:   0%|          | 0/651 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Create embeddings:   0%|          | 0/704 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "document_store.update_embeddings(retriever, index=doc_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4dfa28fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.nodes.retriever.base -  Performing eval queries...\n",
      "100%|███████████████████████████████████████████| 25/25 [00:00<00:00, 91.97it/s]\n",
      "INFO - haystack.nodes.retriever.base -  For 7 out of 25 questions (28.00%), the answer was in the top-5 candidate passages selected by the retriever.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retriever Recall: 0.28\n",
      "Retriever Mean Avg Precision: 0.19\n"
     ]
    }
   ],
   "source": [
    "## Evaluate Retriever on its own #THIS IS THE BARE BONES\n",
    "# Note that no_answer samples are omitted when evaluation is performed with this method\n",
    "retriever_eval_results = retriever.eval(top_k=5, label_index=label_index, doc_index=doc_index, open_domain=True)\n",
    "# Retriever Recall is the proportion of questions for which the correct document containing the answer is\n",
    "# among the correct documents\n",
    "print(\"Retriever Recall:\", retriever_eval_results[\"recall\"])\n",
    "# Retriever Mean Avg Precision rewards retrievers that give relevant documents a higher rank\n",
    "print(\"Retriever Mean Avg Precision:\", retriever_eval_results[\"map\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2112339",
   "metadata": {},
   "source": [
    "### DEV SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b77e69ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - haystack.document_stores.utils -  No title information found for documents in QA file: squad_format_thesis/dev.json\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import PreProcessor\n",
    "\n",
    "document_store.delete_documents(index=doc_index)\n",
    "document_store.delete_documents(index=label_index)\n",
    "\n",
    "preprocessor = PreProcessor(\n",
    "    split_length=200,\n",
    "    split_overlap=0,\n",
    "    split_respect_sentence_boundary=False,\n",
    "    clean_empty_lines=False,\n",
    "    clean_whitespace=False,\n",
    ")\n",
    "\n",
    "# The add_eval_data() method converts the given dataset in json format into Haystack document and label objects. Those objects are then indexed in their respective document and label index in the document store. The method can be used with any dataset in SQuAD format.\n",
    "document_store.add_eval_data(\n",
    "    filename=\"squad_format_thesis/dev.json\",\n",
    "    doc_index=doc_index,\n",
    "    label_index=label_index,\n",
    "    preprocessor=preprocessor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0e1233e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.modeling.utils -  Using devices: CUDA:0\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 1\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Could not find voidful/dpr-question_encoder-bert-base-multilingual locally.\n",
      "INFO - haystack.modeling.model.language_model -  Looking on Transformers Model Hub (in local cache and online)...\n",
      "INFO - haystack.modeling.model.language_model -  Automatically detected language from language model name: multilingual\n",
      "INFO - haystack.modeling.model.language_model -  Loaded voidful/dpr-question_encoder-bert-base-multilingual\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
      "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Could not find voidful/dpr-ctx_encoder-bert-base-multilingual locally.\n",
      "INFO - haystack.modeling.model.language_model -  Looking on Transformers Model Hub (in local cache and online)...\n",
      "INFO - haystack.modeling.model.language_model -  Automatically detected language from language model name: multilingual\n",
      "INFO - haystack.modeling.model.language_model -  Loaded voidful/dpr-ctx_encoder-bert-base-multilingual\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import DensePassageRetriever\n",
    "retriever = DensePassageRetriever(\n",
    "            document_store=document_store,\n",
    "            query_embedding_model=\"voidful/dpr-question_encoder-bert-base-multilingual\",\n",
    "            passage_embedding_model=\"voidful/dpr-ctx_encoder-bert-base-multilingual\",\n",
    "            use_gpu=True,\n",
    "            batch_size = 64\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7c871afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.document_stores.elasticsearch -  Updating embeddings for all 608 docs ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "683f6f4d60b749d5961e0b5d4746378b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Updating embeddings:   0%|          | 0/608 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Create embeddings:   0%|          | 0/640 [00:00<?, ? Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "document_store.update_embeddings(retriever, index=doc_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "852668dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.nodes.retriever.base -  Performing eval queries...\n",
      "100%|███████████████████████████████████████████| 24/24 [00:00<00:00, 99.29it/s]\n",
      "INFO - haystack.nodes.retriever.base -  For 8 out of 24 questions (33.33%), the answer was in the top-5 candidate passages selected by the retriever.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retriever Recall: 0.3333333333333333\n",
      "Retriever Mean Avg Precision: 0.21319444444444444\n"
     ]
    }
   ],
   "source": [
    "## Evaluate Retriever on its own #THIS IS THE BARE BONES\n",
    "# Note that no_answer samples are omitted when evaluation is performed with this method\n",
    "retriever_eval_results = retriever.eval(top_k=5, label_index=label_index, doc_index=doc_index, open_domain=True)\n",
    "# Retriever Recall is the proportion of questions for which the correct document containing the answer is\n",
    "# among the correct documents\n",
    "print(\"Retriever Recall:\", retriever_eval_results[\"recall\"])\n",
    "# Retriever Mean Avg Precision rewards retrievers that give relevant documents a higher rank\n",
    "print(\"Retriever Mean Avg Precision:\", retriever_eval_results[\"map\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcae8341",
   "metadata": {},
   "source": [
    "## BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3a5ac170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Retriever\n",
    "from haystack.nodes import ElasticsearchRetriever, BM25Retriever\n",
    "\n",
    "retriever = BM25Retriever(document_store=document_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "adc05266",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - haystack.document_stores.utils -  No title information found for documents in QA file: squad_format_thesis/test.json\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import PreProcessor\n",
    "\n",
    "document_store.delete_documents(index=doc_index)\n",
    "document_store.delete_documents(index=label_index)\n",
    "\n",
    "preprocessor = PreProcessor(\n",
    "    split_length=200,\n",
    "    split_overlap=0,\n",
    "    split_respect_sentence_boundary=False,\n",
    "    clean_empty_lines=False,\n",
    "    clean_whitespace=False,\n",
    ")\n",
    "\n",
    "# The add_eval_data() method converts the given dataset in json format into Haystack document and label objects. Those objects are then indexed in their respective document and label index in the document store. The method can be used with any dataset in SQuAD format.\n",
    "document_store.add_eval_data(\n",
    "    filename=\"squad_format_thesis/test.json\",\n",
    "    doc_index=doc_index,\n",
    "    label_index=label_index,\n",
    "    preprocessor=preprocessor\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a23eaad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.nodes.retriever.base -  Performing eval queries...\n",
      "100%|██████████████████████████████████████████| 25/25 [00:00<00:00, 395.48it/s]\n",
      "INFO - haystack.nodes.retriever.base -  For 14 out of 25 questions (56.00%), the answer was in the top-5 candidate passages selected by the retriever.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retriever Recall: 0.56\n",
      "Retriever Mean Avg Precision: 0.4793333333333333\n"
     ]
    }
   ],
   "source": [
    "## Evaluate Retriever on its own #THIS IS THE ES\n",
    "# Note that no_answer samples are omitted when evaluation is performed with this method\n",
    "retriever_eval_results = retriever.eval(top_k=5, label_index=label_index, doc_index=doc_index, open_domain=True)\n",
    "# Retriever Recall is the proportion of questions for which the correct document containing the answer is\n",
    "# among the correct documents\n",
    "print(\"Retriever Recall:\", retriever_eval_results[\"recall\"])\n",
    "# Retriever Mean Avg Precision rewards retrievers that give relevant documents a higher rank\n",
    "print(\"Retriever Mean Avg Precision:\", retriever_eval_results[\"map\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea6f975",
   "metadata": {},
   "source": [
    "### DEV SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9729493e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - haystack.document_stores.utils -  No title information found for documents in QA file: squad_format_thesis/dev.json\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import PreProcessor\n",
    "\n",
    "document_store.delete_documents(index=doc_index)\n",
    "document_store.delete_documents(index=label_index)\n",
    "\n",
    "preprocessor = PreProcessor(\n",
    "    split_length=200,\n",
    "    split_overlap=0,\n",
    "    split_respect_sentence_boundary=False,\n",
    "    clean_empty_lines=False,\n",
    "    clean_whitespace=False,\n",
    ")\n",
    "\n",
    "# The add_eval_data() method converts the given dataset in json format into Haystack document and label objects. Those objects are then indexed in their respective document and label index in the document store. The method can be used with any dataset in SQuAD format.\n",
    "document_store.add_eval_data(\n",
    "    filename=\"squad_format_thesis/dev.json\",\n",
    "    doc_index=doc_index,\n",
    "    label_index=label_index,\n",
    "    preprocessor=preprocessor\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "359c0756",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.nodes.retriever.base -  Performing eval queries...\n",
      "100%|██████████████████████████████████████████| 24/24 [00:00<00:00, 484.57it/s]\n",
      "INFO - haystack.nodes.retriever.base -  For 17 out of 24 questions (70.83%), the answer was in the top-5 candidate passages selected by the retriever.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retriever Recall: 0.7083333333333334\n",
      "Retriever Mean Avg Precision: 0.5305555555555556\n"
     ]
    }
   ],
   "source": [
    "## Evaluate Retriever on its own #THIS IS THE ES\n",
    "# Note that no_answer samples are omitted when evaluation is performed with this method\n",
    "retriever_eval_results = retriever.eval(top_k=5, label_index=label_index, doc_index=doc_index, open_domain=True)\n",
    "# Retriever Recall is the proportion of questions for which the correct document containing the answer is\n",
    "# among the correct documents\n",
    "print(\"Retriever Recall:\", retriever_eval_results[\"recall\"])\n",
    "# Retriever Mean Avg Precision rewards retrievers that give relevant documents a higher rank\n",
    "print(\"Retriever Mean Avg Precision:\", retriever_eval_results[\"map\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83041fb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
