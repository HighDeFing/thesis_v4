{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8af0276e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## eval retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "419b842c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure these indices do not collide with existing ones, the indices will be wiped clean before data is inserted\n",
    "doc_index = \"squad_docs\"\n",
    "label_index = \"squad_labels\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ab61f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/heider/Codes/thesis_v4/env/lib/python3.8/site-packages/elasticsearch/connection/base.py:190: ElasticsearchDeprecationWarning: Elasticsearch built-in security features are not enabled. Without authentication, your cluster could be accessible to anyone. See https://www.elastic.co/guide/en/elasticsearch/reference/7.13/security-minimal-setup.html to enable security.\n",
      "  warnings.warn(message, category=ElasticsearchDeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Connect to Elasticsearch\n",
    "from haystack.document_stores import ElasticsearchDocumentStore\n",
    "\n",
    "document_store = ElasticsearchDocumentStore(\n",
    "    host=\"localhost\",\n",
    "    username=\"\",\n",
    "    password=\"\",\n",
    "    index=doc_index,\n",
    "    label_index=label_index,\n",
    "    embedding_field=\"emb\",\n",
    "    embedding_dim=768,\n",
    "    excluded_meta_data=[\"emb\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee4be583",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - haystack.document_stores.utils -  No title information found for documents in QA file: squad_format_thesis/test.json\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import PreProcessor\n",
    "\n",
    "document_store.delete_documents(index=doc_index)\n",
    "document_store.delete_documents(index=label_index)\n",
    "\n",
    "preprocessor = PreProcessor(\n",
    "    split_length=200,\n",
    "    split_overlap=0,\n",
    "    split_respect_sentence_boundary=False,\n",
    "    clean_empty_lines=False,\n",
    "    clean_whitespace=False,\n",
    ")\n",
    "\n",
    "# The add_eval_data() method converts the given dataset in json format into Haystack document and label objects. Those objects are then indexed in their respective document and label index in the document store. The method can be used with any dataset in SQuAD format.\n",
    "document_store.add_eval_data(\n",
    "    filename=\"squad_format_thesis/test.json\",\n",
    "    doc_index=doc_index,\n",
    "    label_index=label_index,\n",
    "    preprocessor=preprocessor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b12f8dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.modeling.utils -  Using devices: CPU\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 0\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_big/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_big/query_encoder\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Model found locally at models/model_big/passage_encoder\n",
      "INFO - haystack.modeling.model.language_model -  Loaded models/model_big/passage_encoder\n",
      "INFO - haystack.nodes.retriever.dense -  DPR model loaded from models/model_big\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import DensePassageRetriever\n",
    "\n",
    "save_dir = \"models/model_big\"\n",
    "\n",
    "retriever = DensePassageRetriever.load(load_dir=save_dir, document_store=document_store, use_gpu=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d094b268",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.document_stores.elasticsearch -  Updating embeddings for all 651 docs ...\n",
      "Updating embeddings: 10000 Docs [01:07, 148.95 Docs/s]         \n"
     ]
    }
   ],
   "source": [
    "document_store.update_embeddings(retriever, index=doc_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "48916951",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.nodes.retriever.base -  Performing eval queries...\n",
      "100%|██████████| 25/25 [00:01<00:00, 22.39it/s]\n",
      "INFO - haystack.nodes.retriever.base -  For 15 out of 25 questions (60.00%), the answer was in the top-5 candidate passages selected by the retriever.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retriever Recall: 0.6\n",
      "Retriever Mean Avg Precision: 0.43133333333333335\n"
     ]
    }
   ],
   "source": [
    "## Evaluate Retriever on its own # THIS IS THE FINE-TUNED\n",
    "# Note that no_answer samples are omitted when evaluation is performed with this method\n",
    "retriever_eval_results = retriever.eval(top_k=5, label_index=label_index, doc_index=doc_index)\n",
    "# Retriever Recall is the proportion of questions for which the correct document containing the answer is\n",
    "# among the correct documents\n",
    "print(\"Retriever Recall:\", retriever_eval_results[\"recall\"])\n",
    "# Retriever Mean Avg Precision rewards retrievers that give relevant documents a higher rank\n",
    "print(\"Retriever Mean Avg Precision:\", retriever_eval_results[\"map\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "52648254",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.modeling.utils -  Using devices: CPU\n",
      "INFO - haystack.modeling.utils -  Number of GPUs: 0\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Could not find IIC/dpr-spanish-question_encoder-allqa-base locally.\n",
      "INFO - haystack.modeling.model.language_model -  Looking on Transformers Model Hub (in local cache and online)...\n",
      "INFO - haystack.modeling.model.language_model -  Automatically detected language from language model name: spanish\n",
      "INFO - haystack.modeling.model.language_model -  Loaded IIC/dpr-spanish-question_encoder-allqa-base\n",
      "INFO - haystack.modeling.model.language_model -  LOADING MODEL\n",
      "INFO - haystack.modeling.model.language_model -  =============\n",
      "INFO - haystack.modeling.model.language_model -  Could not find IIC/dpr-spanish-passage_encoder-allqa-base locally.\n",
      "INFO - haystack.modeling.model.language_model -  Looking on Transformers Model Hub (in local cache and online)...\n",
      "INFO - haystack.modeling.model.language_model -  Automatically detected language from language model name: spanish\n",
      "INFO - haystack.modeling.model.language_model -  Loaded IIC/dpr-spanish-passage_encoder-allqa-base\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import DensePassageRetriever\n",
    "retriever = DensePassageRetriever(\n",
    "            document_store=document_store,\n",
    "            query_embedding_model=\"IIC/dpr-spanish-question_encoder-allqa-base\",\n",
    "            passage_embedding_model=\"IIC/dpr-spanish-passage_encoder-allqa-base\",\n",
    "            use_gpu=False,\n",
    "            batch_size = 64\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb96eec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - haystack.document_stores.utils -  No title information found for documents in QA file: squad_format_thesis/dev.json\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import PreProcessor\n",
    "\n",
    "document_store.delete_documents(index=doc_index)\n",
    "document_store.delete_documents(index=label_index)\n",
    "\n",
    "preprocessor = PreProcessor(\n",
    "    split_length=200,\n",
    "    split_overlap=0,\n",
    "    split_respect_sentence_boundary=False,\n",
    "    clean_empty_lines=False,\n",
    "    clean_whitespace=False,\n",
    ")\n",
    "\n",
    "# The add_eval_data() method converts the given dataset in json format into Haystack document and label objects. Those objects are then indexed in their respective document and label index in the document store. The method can be used with any dataset in SQuAD format.\n",
    "document_store.add_eval_data(\n",
    "    filename=\"squad_format_thesis/dev.json\",\n",
    "    doc_index=doc_index,\n",
    "    label_index=label_index,\n",
    "    preprocessor=preprocessor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20407e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.document_stores.elasticsearch -  Updating embeddings for all 608 docs ...\n",
      "Updating embeddings: 10000 Docs [00:54, 183.92 Docs/s]         \n"
     ]
    }
   ],
   "source": [
    "document_store.update_embeddings(retriever, index=doc_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa0e6610",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.nodes.retriever.base -  Performing eval queries...\n",
      "  4%|█▊                                          | 1/24 [00:00<00:13,  1.67it/s]/home/heider/Codes/thesis_v4/env/lib/python3.8/site-packages/elasticsearch/connection/base.py:190: ElasticsearchDeprecationWarning: Elasticsearch built-in security features are not enabled. Without authentication, your cluster could be accessible to anyone. See https://www.elastic.co/guide/en/elasticsearch/reference/7.13/security-minimal-setup.html to enable security.\n",
      "  warnings.warn(message, category=ElasticsearchDeprecationWarning)\n",
      "100%|███████████████████████████████████████████| 24/24 [00:01<00:00, 14.33it/s]\n",
      "INFO - haystack.nodes.retriever.base -  For 18 out of 24 questions (75.00%), the answer was in the top-5 candidate passages selected by the retriever.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retriever Recall: 0.75\n",
      "Retriever Mean Avg Precision: 0.5256944444444445\n"
     ]
    }
   ],
   "source": [
    "## Evaluate Retriever on its own #THIS IS THE BARE BONES\n",
    "# Note that no_answer samples are omitted when evaluation is performed with this method\n",
    "retriever_eval_results = retriever.eval(top_k=5, label_index=label_index, doc_index=doc_index, open_domain=True)\n",
    "# Retriever Recall is the proportion of questions for which the correct document containing the answer is\n",
    "# among the correct documents\n",
    "print(\"Retriever Recall:\", retriever_eval_results[\"recall\"])\n",
    "# Retriever Mean Avg Precision rewards retrievers that give relevant documents a higher rank\n",
    "print(\"Retriever Mean Avg Precision:\", retriever_eval_results[\"map\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a5ac170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Retriever\n",
    "from haystack.nodes import ElasticsearchRetriever, BM25Retriever\n",
    "\n",
    "retriever = BM25Retriever(document_store=document_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a23eaad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - haystack.nodes.retriever.base -  Performing eval queries...\n",
      "100%|██████████████████████████████████████████| 25/25 [00:00<00:00, 125.72it/s]\n",
      "INFO - haystack.nodes.retriever.base -  For 18 out of 25 questions (72.00%), the answer was in the top-5 candidate passages selected by the retriever.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retriever Recall: 0.72\n",
      "Retriever Mean Avg Precision: 0.516\n"
     ]
    }
   ],
   "source": [
    "## Evaluate Retriever on its own #THIS IS THE ES\n",
    "# Note that no_answer samples are omitted when evaluation is performed with this method\n",
    "retriever_eval_results = retriever.eval(top_k=5, label_index=label_index, doc_index=doc_index)\n",
    "# Retriever Recall is the proportion of questions for which the correct document containing the answer is\n",
    "# among the correct documents\n",
    "print(\"Retriever Recall:\", retriever_eval_results[\"recall\"])\n",
    "# Retriever Mean Avg Precision rewards retrievers that give relevant documents a higher rank\n",
    "print(\"Retriever Mean Avg Precision:\", retriever_eval_results[\"map\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9729493e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
