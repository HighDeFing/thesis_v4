1 UNIVERSIDAD CENTRAL DE VENEZUELA FACULTAD DE CIENCIAS ESCUELA DE COMPUTACIÓN OPCIÓN PROFESIONAL: COMPUTACIÓN GRÁFICA SEGMENTACIÓN MULTICANAL DE TUMORES CEREBRALES EN IMAGENOLOGÍA DE RESONANCIA MAGNÉTICA CON AUTÓMATAS CELULARES PARALELIZADOS EN GPU Trabajo Especial de Grado presentado ante la Ilustre Universidad Central de Venezuela Por el Bachiller Antonio Rueda Toicen para optar al título de Licenciado en Computación Tutores: Prof. Rhadamés Carmona, Prof. Miguel Martín Landrove Caracas, Octubre 2013 2 Caracas, Octubre de 2013 Universidad Central de Venezuela Facultad de Ciencias Escuela de Computación ACTA DEL VEREDICTO Quienes suscriben, Miembros del Jurado designado por el Consejo de la Escuela de Computación para examinar el Trabajo Especial de Grado, presentado por el Bachiller Antonio Ernesto Rueda Toicen C.I.: 16971216, con el título “SEGMENTACIÓN MULTICANAL DE TUMORES CEREBRALES EN IMAGENOLOGÍA DE RESONANCIA MAGNÉTICA CON AUTÓMATAS CELULARES PARALELIZADOS EN GPU”, a los fines de cumplir con el requisito legal para optar al título de Licenciado en Computación, dejan constancia de lo siguiente: Leído el trabajo por cada uno de los Miembros del Jurado, se fijó el día 29 de Octubre de 2013, a las 11 am, para que su autor lo defendiera en forma pública, en el Centro de Computación Gráfica, lo cual este realizó mediante una exposición oral de su contenido, y luego respondió satisfactoriamente a las preguntas que les fueron formuladas por el Jurado, todo ello conforme a lo dispuesto en la Ley de Universidades y demás normativas vigentes de la Universidad Central de Venezuela. Finalizada la defensa pública del Trabajo Especial de Grado, el jurado decidió aprobarlo. En fe de lo cual se levanta la presente acta, en Caracas el 29 de Octubre de 2013, dejándose también constancia de que actuó como Coordinador del Jurado el Profesor Tutor Rhadamés Carmona. ___________________________ __________________________ Prof. Rhadamés Carmona Prof. Miguel Martín (Tutor) (Tutor) ___________________________ ___________________________ Prof. Héctor Navarro Prof. Carlos Acosta (Jurado Principal) (Jurado Principal) 3 RESUMEN La segmentación de imágenes es el proceso de particionar una imagen en múltiples conjuntos de píxeles o vóxeles que compartan alguna característica visual. Existen diversos métodos de segmentación, entre los cuales encontramos algunos basados en morfología matemática, contornos activos y modelos gráficos probabilísticos. Los métodos basados en autómatas celulares pueden acoplarse a más de uno de estos métodos. Entre los métodos de segmentación basados en autómatas celulares se encuentra el algoritmo GrowCut, el cual define una regla de autómata celular determinístico que simula el crecimiento competitivo de varias colonias de bacterias cuyo territorio es el espacio de la imagen. En este trabajo se presentan nuevas reglas para este tipo de autómatas, así como una metodología para comparar su desempeño y calidad de segmentación en problemas de segmentación de tumores cerebrales para planificación de radiocirugía estereotáctica. Se presentan una comparación de resultados en términos de calidad de segmentación y tiempo de respuesta para un conjunto de reglas y distintos casos de prueba. Adicionalmente, se especifica un patrón de implementación en CUDA que aprovecha la capacidad de paralelismo inherente de los autómatas celulares y un método para la selección no supervisada de la configuración inicial del autómata. Palabras claves: Autómata Celular, Procesamiento de Imágenes, Segmentación, GPU 4 CONTENIDO CAPITULO 1 - INTRODUCCIÓN ..................................................................................................... 7 1.1 Planteamiento del Problema .................................................................................................. 8 1.2 Propuesta de Solución ........................................................................................................... 9 1.3 Objetivo General .................................................................................................................... 9 1.4 Objetivos Específicos ............................................................................................................ 9 CAPÍTULO 2 - MARCO TEÓRICO ..................................................................................................11 2.1 Radiocirugía Estereotáctica con Gamma Knife ................................................................... 13 2.1.1 Uso y Colocación de Marco Estereotáctico (ME) ........................................................ 14 2.1.2 Coregistro de Imágenes de Resonancia Magnética ...................................................... 15 2.1.3 Estándar DICOM .......................................................................................................... 16 2.2 Volume Rendering ............................................................................................................... 19 2.2.1 Ray Casting .................................................................................................................. 20 2.2.2 Visualización de Isosuperficies .................................................................................... 22 2.3 Programación de GPU con CUDA ...................................................................................... 25 2.3.1 Modelo de Ejecución de CUDA ................................................................................... 25 2.3.2 Jerarquía de Memoria en CUDA .................................................................................. 28 2.4 Métricas de Calidad de Segmentación ................................................................................. 30 2.4.1 Verdad Fundamental a Través de TumorSim ............................................................... 33 CAPÍTULO 3 - MÉTODOS DE SEGMENTACIÓN DE IMAGENOLOGÍA DE RESONANCIA MAGNÉTICA .................................................................................................................................... 35 3.1 Segmentación Automática ................................................................................................... 35 3.1.1 Clustering por K-means ............................................................................................... 35 3.1.2 Segmentación con Modelos Gráficos Probabilísticos .................................................. 37 3.2 Segmentación Asistida de IRM ........................................................................................... 42 3.2.1 Crecimiento de Región ................................................................................................. 43 3.2.2 Transformada Watershed Basada en Marcadores ......................................................... 44 3.2.3 Métodos Basados en Contornos Activos ...................................................................... 45 3.3 Cortes en Grafos .................................................................................................................. 50 3.3.1 GrabCut ........................................................................................................................ 51 3.4 Random Walker ................................................................................................................... 53 CAPÍTULO 4 - Autómatas Celulares Deterministas para Segmentación de Imágenes ..................... 58 4.1 Definición Formal y Entendimiento Intuitivo de Evolución ............................................... 59 4.2 Regla GrowCut .................................................................................................................... 60 4.3 Ventajas de Implementación y Capacidades de Paralelismo de los Autómatas Celulares Deterministas .................................................................................................................................. 63 5 4.3.1 Corrección a GrowCut ................................................................................................. 64 4.3.2 Criterio de Convergencia .............................................................................................. 65 4.3.3 Variaciones en la Fuerza de Ataque .............................................................................. 66 4.3.3 AutomaClass, Configuración No Supervisada del Estado Inicial del Autómata ......... 71 CAPÍTULO 5 - Detalles de Implementación ..................................................................................... 76 5.1 Implementación de Autómatas Celulares Deterministas en Matlab ................................ 76 5.2 Implementación de Autómatas Celulares Deterministas en CUDA ................................ 77 5.3 Interfaz Gráfica para Segmentación Asistida ................................................................... 80 CAPÍTULO 6 - PRUEBAS Y RESULTADOS .................................................................................. 82 6.1 Bounding Box de Validación ............................................................................................... 83 6.2 Comparación entre Criterios de Dispersión de Semillas ..................................................... 84 6.3 Comparación de Convergencia Completa Frente a Convergencia por Criterio de Celdas Etiquetadas ..................................................................................................................................... 88 6.4 Estudio del Efecto de Número de Semillas Correctas Suministradas por el Usuario en la Calidad de Segmentación ............................................................................................................... 93 6.5 Comparación de Fuerza de Ataque Determinada por Distancia Manhattan contra Fuerza de Ataque Determinada por Distancia Euclidiana .............................................................................. 94 6.6 Introducción de Error e Incertidumbre en la Configuración Inicial del Autómata .............. 96 6.7 Comparación entre Vecindad Moore 3D y Vecindad Von Neumann 3D .......................... 100 6.8 Comparación entre Calidad de Segmentación Obtenida con Múltiples Versiones de GrowCut ....................................................................................................................................... 102 6.8.1 GrowCut Corregido .................................................................................................... 103 6.8.2 GrowCut con Penalización a Fuerza de Ataque ......................................................... 104 6.9 Comparación de Calidad de Segmentación entre Canales Individuales ............................ 108 6.10 Comparación de Calidad de Segmentación al Realizar Combinación de Canales ......... 111 6.10.1 Combinación de 4 Canales .......................................................................................... 111 6.10.2 Combinaciones de 3 Canales .......................................................................................112 6.10.3 Combinaciones de 2 Canales .......................................................................................113 6.11 Pruebas con Algoritmo de Selección de Semillas “AutomaClass” ....................................115 CONCLUSIONES ........................................................................................................................... 120 TRABAJOS FUTUROS .................................................................................................................. 121 BIBLIOGRAFÍA .............................................................................................................................. 122 6 Dedicatoria: A mis padres, por ser Buenos Agradecimientos Agradezco a mis tutores, los profesores Rhadamés Carmona y Miguel Martín Landrove (y al tutor extraoficial de esta tesis, el profesor Wuilian Torres) por la oportunidad de abordar este tema como trabajo especial de grado, fue la experiencia de aprendizaje que más disfruté en mi paso por la UCV. A ustedes tres debo el inicio de mi carrera como investigador. Gracias. 7 CAPITULO 1 - INTRODUCCIÓN Los tumores cerebrales son una de las formas de cáncer que mayor perjuicio generan a la calidad de vida de los pacientes afectados y son la principal causa de muerte por tumor sólido en niños [Russell13]. Resultan necesarios avances que faciliten su detección temprana y tratamiento; una tarea crítica en estos procedimientos es la correcta segmentación de las estructuras patológicas en la imagenología radiológica disponible. En la visión por computador, la segmentación es el proceso de particionar una imagen en múltiples conjuntos de píxeles o vóxeles 1 que compartan alguna característica visual. La segmentación facilita el análisis cuantitativo y cualitativo de información visual, por lo que su importancia es alta en aplicaciones de diagnóstico y planificación de tratamientos. La imagenología de resonancia magnética (IRM) es una técnica de visualización de datos que provee información anatómica detallada. Ofrece varias ventajas con respecto a otras técnicas de imagenología, como la tomografía computarizada, debido a su capacidad para proveer datos con alto contraste entre tejidos blandos. Sin embargo, la cantidad de datos que produce la IRM en sus múltiples modalidades, resulta comúnmente excesiva para el análisis y la interpretación manual, lo que tradicionalmente ha constituido uno de los grandes obstáculos para su uso clínico. La segmentación automática o asistida de diferentes clases de tejidos en IRM es una tarea importante, porque permite analizar estructuras anatómicas de una forma semánticamente intuitiva. El estudio de la visión por computador ha producido variadas técnicas de segmentación de imágenes que pueden ser utilizadas para segmentar estructuras anatómicas, permitiendo realizar análisis cuantitativo y cualitativo de los componentes de interés presentes en una imagen. Estas técnicas de segmentación constituyen herramientas útiles para diagnóstico, seguimiento evolutivo de patologías y planificación quirúrgica. Un trabajo de Warfield et al, en el año 2001 [Warfield01], señala como el tiempo requerido para realizar una segmentación de tumor cerebral, utilizando un método de segmentación asistida, reduce el tiempo de trabajo del operador a un período de 5 a 10 minutos, en lugar de 3 a 5 horas necesarias para realizar la segmentación manual sobre cada uno de los cortes del volumen de resonancia magnética analizado. Este trabajo presenta métodos de segmentación automática y asistida de tumores cerebrales en IRM, basados en autómatas celulares deterministas, diseñados específicamente para asistir en la planificación de radiocirugía cerebral. Se presentan las siguientes contribuciones originales: 1 Así como un píxel se refiere a un cuadrado unitario mínimo de imagen 2D, un vóxel se refiere a un cubo unitario mínimo de volumen 3D, su unidad mínima de muestra discreta. 8 i) Nuevas reglas de evolución para autómatas celulares deterministas, dedicados a la segmentación de imágenes que exhiben mejor sensibilidad y mejor precisión que reglas de evolución previas en la literatura. ii) Segmentación validada de múltiples canales de imagenología de resonancia magnética cerebral, evaluados de forma individual y combinada. Se compara el desempeño de los algoritmos de segmentación basados en autómatas celulares en múltiples modalidades de IRM y los efectos de la combinación de canales en la calidad de la segmentación. iii) Nuevo método de segmentación multicanal automática de tumores cerebrales en IRM, basado en una selección inteligente de la configuración inicial de los autómatas celulares. iv) Un patrón de sincronización de hilos en GPU, que minimiza el número de barreras necesarias para lograr segmentaciones con autómatas celulares deterministas en un proceso iterativo. 1.1 Planteamiento del Problema La segmentación de tejidos en IRM es una herramienta poderosa para la planificación de cirugía cerebral, ya que facilita el análisis cualitativo y cuantitativo de las patologías presentes. Actualmente, los algoritmos basados en atlas para la segmentación automática de tumores en IRM poseen una alta complejidad, lentitud de ejecución, dificultad para ser paralelizados y una tasa de errores (falsos positivos) significativa, que hace necesario un post-procesamiento por parte de un operador experto. Por otra parte, los métodos de segmentación automática basados en clusterización de datos, como K-means e Isodata, no poseen la capacidad de incorporar información espacial al proceso de segmentación realizado, y toman decisiones únicamente con base en la clusterización de niveles digitales [Ball65]. Además, el número de clases a considerar en el proceso de segmentación afecta negativamente el tiempo de cómputo, factor negativo común con otros métodos de segmentación multiclase, como Random Walker [Grady04]. Se proponen en este trabajo extensiones y mejoras a GrowCut, un método de segmentación basado en autómatas celulares deterministas, que permite segmentar simultáneamente múltiples clases de tejido, sin afectar negativamente el tiempo de cómputo necesario para proporcionar una respuesta al usuario. Los autómatas celulares deterministas propuestos, ofrecen además las ventajas 9 de realizar segmentación incorporando tanto información espacial, como información de nivel digital; son inherentemente paralelizables; pueden manejar información multicanal y también pueden ser utilizados como parte de un sistema de segmentación automática, a través de una selección inteligente de su configuración inicial. Estas características convierten a los autómatas celulares deterministas propuestos, en una herramienta matemática de utilidad en la planificación de cirugías y la evaluación de patologías cerebrales. 1.2 Propuesta de Solución Se propone la implementación de un sistema de segmentación de tumores cerebrales, basado en autómatas celulares deterministas, que permita la visualización de las estructuras anatómicas segmentadas. 1.3 Objetivo General Implementar un programa de segmentación de tumores cerebrales en imágenes de resonancia magnética, que opere tanto en cortes bidimensionales como en volúmenes, validando los resultados obtenidos. 1.4 Objetivos Específicos - Implementar un sistema de segmentación de tumores cerebrales, basado en autómatas celulares deterministas, que permita al usuario establecer semillas de segmentación, tanto de forma manual como de forma automática. - Validar, a través de métricas de calidad de segmentación, reglas de evolución originales y reglas de evolución preexistentes en la literatura, en imágenes de resonancia magnética producidas por TumorSim. - Validar, a través de métricas de calidad de segmentación, los resultados obtenidos a partir de la combinación de canales de imágenes co-registradas de resonancia magnética, producidas por TumorSim. - Implementar un autómata celular para la segmentación de tumores de forma serial para ejecutarse en CPU, y de forma paralelizada para ejecutarse en GPU, realizando comparación entre tiempos de respuesta. 10 11 CAPÍTULO 2 - MARCO TEÓRICO Desde el descubrimiento de los rayos X en 1895, la radiología ha sido usada para el diagnóstico y tratamiento de una variedad de lesiones neurológicas. En la década de los 70, el surgimiento de la imagenología por tomografía computarizada (TC), que realiza múltiples muestreos con rayos X para producir cortes de áreas específicas del cuerpo, mejoró notablemente la resolución de las imágenes anatómicas capturadas. La resolución de los tejidos blandos fue posteriormente mejorada con la introducción de la imagenología por resonancia magnética (IRM), que usa la propiedad de resonancia magnética nuclear, para representar el núcleo de los átomos de hidrógeno que están en los tejidos grasos y el agua del cuerpo humano. La IRM explota la propiedad de spin nuclear de los átomos de hidrógeno para obtener imágenes de los tejidos blandos. En IRM, un pulso de radiofrecuencia es aplicado al paciente. Como resultado, los estados de spin nuclear de sus átomos de hidrógeno, pasan de un estado de equilibrio a un estado de excitación. Debido a la ley de conservación de la energía, para retornar a su estado de equilibrio, los átomos deben emitir una energía igual a la energía absorbida. La liberación de energía entre los estados de transición de spin puede ser medida y analizada. Debido que el proceso de absorción y emisión de energía es afectado por el ambiente químico local, los átomos de hidrógeno en los tejidos suaves de variadas composiciones químicas, absorberán y emitirán energía diferentemente. Esta información es usada para producir mapas de alta resolución de la estructura de los tejidos suaves. Debido a que los tumores y los tejidos sanos a menudo difieren en composición química, este principio permite una delineación distintiva de los tejidos. Debido a la complejidad de las interacciones nucleares involucradas en la IRM, hay múltiples fuentes de error, que dan como resultado la distorsión de la imagen obtenida. Una de dichas fuentes de error, es la imperfección del campo magnético de entrada. El campo magnético de entrada, en IRM, es producido por corrientes eléctricas pasando a través de bobinas mutuamente ortogonales. Idealmente, el campo magnético generado sería uniforme, de forma tal que una relación lineal entre espacio y frecuencia de resonancia pueda ser establecida. Sin embargo, dichos campos uniformes son difíciles de lograr en la práctica. Este fenómeno es llamado no-linealidad del campo gradiente y tiende a aumentar con un incremento en distancia a partir del eje central del magneto principal. La no-linealidad del campo gradiente es corregida computacionalmente. Antes de la corrección, la no-linealidad del campo gradiente puede inducir distorsiones espaciales tan grandes 12 como hasta de 4 mm. Luego de la corrección computacional, la distorsión es minimizada a <1 mm. Otro tipo de distorsión en la resonancia magnética, que es más difícil de corregir computacionalmente, es el que ocurre debido a las interacciones electromagnéticas entre en el tejido del paciente y el campo magnético entrante. Esta distorsión es a menudo referida como el offset de resonancia. El offset de resonancia ocurre debido que los átomos de hidrógeno cargan consigo un campo magnético inherente. La colocación de tejidos portadores de hidrógeno en un campo magnético, necesariamente induce una perturbación en el campo magnético de entrada. Esta perturbación altera la relación lineal entre espacio y frecuencia de resonancia, produciendo así distorsiones geométricas. La física de esta perturbación es compleja, debido a que depende de las propiedades magnéticas inherentes al tejido del paciente, así como del volumen y forma de este tejido. Las distorsiones de offset de resonancia, tienden a ser mayores en la interfaz entre materiales que difieren en sus propiedades magnéticas, como en la interfaz agua-aire. En la práctica, esto produce grandes distorsiones en las interfaces aire-hueso o aire-tejido, que pueden ser tan grandes como 2mm. Los artefactos de movimiento, son otro factor que afecta la certeza espacial de la IRM. El lapso prolongado que es requerido para la adquisición de la imagen, aumenta el potencial de movimiento del paciente. Incluso con un paciente cooperativo ocurren artefactos de movimiento, debido a la respiración y otros movimientos provocados por actividad fisiológica. Esto compromete la precisión de la resolución espacial. Además de las distorsiones de offset y de campo magnético de entrada, que restan precisión anatómica a las imágenes producidas, un inconveniente de usar IRM como herramienta única de planeación radio-quirúrgica, es que ésta no representa información de densidad de electrones, que es usada para guiar la administración de radiación. Sin la información de densidad de electrones, la dosis de radiación administrada puede desviarse de la dosis deseable hasta un 20%, como resultado de las inhomogeneidades visuales de los tejidos. Esta información de densidad de electrones sí se encuentra presente en la tomografía computarizada, dónde la intensidad de los píxeles refleja la densidad en electrones de los tejidos representados y estas intensidades pueden ser convertidas en mapas de densidad de electrones (electrones por cm 3 ). Otro punto fuerte de la tomografía computarizada, frente a la imagenología de resonancia magnética, es que en cada imagen en tomografía computarizada se tiene una síntesis de información anatómica a partir de múltiples imágenes de rayos X, ofreciendo una resolución anatómica mejorada. Aunque la tomografía computarizada proporciona una resolución anatómica mejorada en 13 comparación a la IRM, la delineación de las estructuras de tejidos suaves a través de la TC es subóptima, incluso con la ayuda de agentes de contraste intravenosos. La delineación de las estructuras de tejido suave es mejor lograda a través del uso de IRM, especialmente para los objetivos en la base craneal. En general, la combinación de IRM y tomografía computarizada, produce planes de radiocirugía superiores a los planes producidos usando sólo una de estas modalidades [Chen08]. Las diferencias entre la tomografía computarizada e IRM, ilustran la distinción conceptual entre la certeza geométrica y diagnóstica. Aunque la imagenología de TC es geométricamente precisa, debido a la ausencia de efectos de distorsión, los tejidos patológicos son, a menudo, no visualizables en esta modalidad. Por esto, la imagenología de TC no es certera para el diagnóstico. Por otra parte, debido a su resolución superior en los tejidos blandos, la IRM tiene mayor certeza diagnóstica, pero menor certeza geométrica, debido a los efectos de distorsión de la resonancia magnética. Sin embargo, es posible introducir artefactos en la imagen resultante de la combinación de cortes de CT con MRI, a través del proceso de co-registro, que busca el máximo solapamiento entre los cortes provistos entre ambas modalidades de imagenología. Estos posibles artefactos debidos al proceso de co-registro, tienen el potencial para alterar el diagnostico de patologías. En el caso particular de la radiocirugía cerebral, se ha estudiado la certeza operatoria de planes que sólo utilicen la IRM y éstos se consideran clínicamente aceptables [Prabhakar07]. 2.1 Radiocirugía Estereotáctica con Gamma Knife La radiocirugía consiste en la administración precisa de una fuerte dosis de radiación, guiada con un marco de referencia estereotáctico a un objetivo focal, permitiendo una ganancia terapéutica. Fue introducida por Borje Larsson y Lars Leksell en 1951, usando originalmente un ciclotrón destinado a experimentos académicos de la Universidad de Uppsala, Suecia. Hoy día, la radiocirugía estereotáctica generalmente utiliza rayos gamma o rayos X. El Gamma Knife es un sistema de radiocirugía estereotáctica, desarrollado por Lars Leksell en 1968, para el tratamiento de afecciones dentro de la bóveda craneal [Prabhakar07]. Entre las patologías tratables por Gamma Knife se encuentran los tumores cerebrales, malignos y benignos: metástasis cerebral, gliomas, meningiomas, tumores pituitarios, neurinomas vestibulares, craneofaringiomas y otros. También es posible realizar tratamientos a una amplia variedad de afecciones vasculares en el cerebro. La radiocirugía con Gamma Knife es un tratamiento libre de incisiones a la bóveda craneal, que es no invasivo, indoloro y ambulatorio. En el sistema, rayos gamma son emitidos por 201 fuentes de cobalto-60 (radioactivo) a una baja intensidad. Sólo en el punto de concentración definido como objetivo, los rayos alcanzan 14 capacidad para destruir tejidos. Para fijar la posición del objetivo, el Gamma Knife requiere un marco estereotáctico (marco de Leskell, que usa coordenadas polares) que debe ser ajustado al cráneo del paciente y que no permite que éste se mueva durante la aplicación del tratamiento. Debido a la opacidad de la bóveda craneal, la definición del volumen objetivo depende enteramente de la precisión anatómica de la imagenología disponible, por lo que hay necesidad de una visualización anatómica fidedigna durante la planificación de la radiocirugía [Chen08]. Figura 2.1 - Radiocirugía con Gamma Knife Múltiples fuentes de radiación convergen en un objetivo, administran una alta dosis de radiación a la zona, evitando la radiación destructiva de los tejidos cercanos, con una precisión de corte de hasta 0.3 mm. Para asegurar el posicionamiento apropiado del paciente y su inmovilidad, se coloca un marco de posicionamiento estereotáctico al cráneo del paciente. El tratamiento dura de 45 a 60 minutos y puede tratar lesiones de hasta 3,5 cm. 2.1.1 Uso y Colocación de Marco Estereotáctico (ME) El marco estereotáctico inmoviliza al paciente durante el proceso de muestreo de imagenología de resonancia magnética y la administración del tratamiento de radiocirugía. El hecho que el paciente esté inmovilizado durante el proceso de toma de imágenes es significativo, porque facilita el co–registro entre múltiples modalidades de IRM. El procedimiento que comúnmente se sigue para la colocación del marco estereotáctico (ME) sobre el cráneo y su excentricidad con respecto a la patología, se basa en el nivel de experticia que tenga el médico que lo realiza. Un mal posicionamiento del ME trae como consecuencia inmediata que el tratamiento no se pueda realizar y deba ser postergado. Adicionalmente, la colocación incorrecta del marco puede ocasionar colisiones del mismo con los colimadores o piezas de la 15 máquina radioquirúrgica utilizada, situación problemática que puede ser identificada únicamente después de fijar el ME en el cráneo. Por esto, el Centro de Computación Gráfica de la Universidad Central de Venezuela ha desarrollado un sistema tipo CAD que provee al neurocirujano de una guía virtual y cuantitativa para la colocación óptima del ME en el cráneo, haciendo uso de las imágenes de diagnóstico del paciente, obtenidas antes del tratamiento [Mena12]. Figura 2.2 - Marco de Leskell El marco de Leskell inmoviliza al paciente cuando es colocado bajo los colimadores de rayos gamma y permite la calibración espacial del tratamiento. 2.1.2 Coregistro de Imágenes de Resonancia Magnética El registro de imágenes es el proceso de ajustar distintos conjuntos de datos visuales a un mismo sistema de coordenadas. Los datos pueden constituir imágenes captadas a través de diferentes sensores, datos tomados en diferentes intervalos de tiempo, o datos tomados en diferentes profundidades o puntos de vista [Gottesfeld92].El proceso de registro involucra la designación de una imagen como referencia (también llamada imagen fija o base) y la aplicación de transformadas espaciales a las otras imágenes, de forma que se alineen con la referencia. Las imágenes pueden estar desalineadas por una gran variedad de razones. Comúnmente, las imágenes son capturadas bajo condiciones variables. Una transformada espacial reasigna las locaciones en una imagen a nuevas locaciones en otra. El paso para determinar los parámetros correctos de transformación espacial, es clave para el 16 proceso de registro de imágenes. El registro de imágenes es a menudo usado como un paso preliminar en otras aplicaciones de procesamiento de imágenes. Por ejemplo, se puede usar para alinear imágenes de satélite capturadas por distintos sensores o para alinear imágenes de resonancia magnética capturadas en distintas modalidades (T1, T1Gad, T2, FLAIR, etc.). El registro de imágenes permite comparar características comunes en distintas imágenes, por ejemplo, puede indicar como un río ha migrado, como un área se ha inundado o el canal en que con mayor facilidad puede visualizarse un tumor [Mathworks13]. 2.1.3 Estándar DICOM DICOM es un acrónimo para Digital Image Communication in Medicine, es el estándar internacional para el almacenamiento y manejo de imágenes médicas digitales [Mildenberger02]. Actualmente, DICOM es el formato universal de PACS (picture archiving and communication systems), acrónimo que se refiere a los sistemas de archivamiento y comunicación de imágenes médicas, sin el uso de archivos de film. En 1982, el American College of Radiology (ACR) y la National Electrical Manufacturers Association (NEMA), formaron un comité para desarrollar un estándar de interconexión de equipos digitales de imagenología. La versión 1.0 del estándar (originalmente llamada estándar ARC-NEMA) fue publicada en 1985 y especifica una interfaz para la transmisión de imágenes punto-a-punto (no a través de una red), un conjunto de reglas para codificar la información de imagenología, expresado como reglas para la generación de un diccionario de datos y un conjunto de comandos para iniciar transacciones. La versión 2.0 del estándar ARC-NEMA, fue publicada en 1988 añadiendo reglas semánticas en las cuales los mensajes (conjuntos de bits representando información en tránsito de un dispositivo a otro) son organizados. La versión 3.0 del estándar ARC-NEMA fue la primera en ser llamada oficialmente DICOM, e integró la funcionalidad previa con el protocolo TCP/IP basándose en el modelo de protocolo de red ISO/OSI, para lograr transmisión de las imágenes a través de redes convencionales. El estándar DICOM incorpora el concepto de diseño orientado a objetos, con identificadores únicos para servicios y objetos. Estos objetos incluyen imágenes, datos de paciente y reportes [Mildenberger02]. En el estándar DICOM, la información de un estudio pertinente a tipo de exploración, el equipo utilizado y datos del paciente, se almacena como atributos de un archivo header (cabecera), cuyo tamaño varía dependiendo de cuánta información se registra en un estudio. Estos atributos DICOM se conocen como IODs, Information on Object Definition. DICOM agrupa información en 17 datasets inseparables, siguiendo un esquema entidad-relación, de forma que la imagen correspondiente a un caso nunca pueda ser separada por error de los demás campos del estudio, como por ejemplo, identificador de paciente, fecha y condiciones de toma de la imagen. También se especifica en IODs información pertinente al sistema de captura de imágenes, como la empresa desarrolladora y el serial del equipo. Los IODs son nombrados mediante identificadores únicos, UIDs (Unique Identifiers), para la variedad de dispositivos y clases, evitando coincidencias con equipos de diferentes países, instituciones, etc. Cada UID es creado de forma talque es único en todo el mundo [Mildenberger02]. Un objeto de datos DICOM, consiste de un número de atributos IOD, incluyendo información tal como nombre, ID y también un atributo especial conteniendo los datos de pixel de imagen, como se ilustra en la Figura 2.3. Un objeto DICOM puede tener solo un atributo conteniendo datos de pixel, sin información adicional en el encabezado. Los datos de los pixeles pueden ser comprimidos usando una variedad de estándares como JPEG, JPEG Lossless y RLE (Run-length encoding). Los elementos de datos o mensajes de DICOM (usados para ordenar operaciones de registro, envío o copia), están compuestos por cuatro campos acompañando a un nombre, como se ilustra en la Figura 2.3, y aparecen en el encabezado de un archivo de imagen. El primero de éstos, es una etiqueta compuesta por un par ordenado de dos enteros sin signo de 16 bits, que representan un número de grupo y número de elemento, respectivamente. El tercer campo, se conoce como VR (Valor de Representación) e indica en una cadena de caracteres de dos bytes, el valor de representación (binario, entero, hexadecimal, etc., además de tipos extensibles, definidos en el diccionario) del elemento de datos. El cuarto componente, representa el valor del elemento y puede corresponder a un UID, fecha, especificador de tipo de imagen, modalidad de imagenología, etc. El último campo es el nombre del IOD. El VR del Elemento de Datos puede ser determinado con el diccionario de datos. 18 Figura 2.3 - Ejemplo de un header DICOM En el header se muestran diferentes grupos y elementos denotando datos relacionados al paciente, fecha del estudio y modalidad. El diccionario de datos que está definido en el estándar, contiene un registro de todos los elementos de datos y todos los identificadores únicos incluidos en DICOM. Cada atributo en un IOD, tiene un significado bien definido. Cada elemento se define con un nombre, id de grupo y elemento, valor de representación, multiplicidad, valores permitidos y valor por defecto, como se ilustra en la Figura 2.4. Los datos son divididos en varios grupos. Por ejemplo, el grupo 8 incluye la descripción de la modalidad de imagenología y las características del examen o información acerca del médico que refiere al paciente (0008/0090), el grupo 10 está reservado para datos del paciente, etc. Como sumario de esta breve descripción del estándar, se puede decir que DICOM es una serie de reglas que permiten la interoperabilidad entre equipos médicos de imagenología y reporte, definiendo protocolos de red, además de una sintaxis única para la comunicación [Mildenberger02]. Su relevancia y utilidad es alta; DICOM es el estándar de transmisión digital de información médica más usado en la actualidad. 19 Figura 2.4 - Entrada Ejemplar en un Diccionario DICOM Cada entrada en el diccionario de datos especifica un número único de grupo y elemento, nombre de valor, representación de valor, multiplicidad, tipo de elemento, valor por defecto y una definición para cada entrada. Aquí, BI = binario en 16 bits, HX = cualquier valor hexadecimal, S = valor único, 1D = elemento requerido con un valor por defecto definido. 2.2 Volume Rendering Un volumen es un conjunto de muestras (x, y, z, w) donde w es un escalar o vector que denota alguna propiedad de los datos en su ubicación espacial 3D, como densidad, color, calor, presión, etc. Los datos del volumen pueden ser variantes con el tiempo, en cuyo caso V se convierte en un conjunto de muestras en 4D (x, y, z, t, w). El volume rendering (VR) es una técnica para visualizar volúmenes mediante la proyección de sus atributos en una imagen 2D. Para el estudio médico, el VR facilita la comprensión de la anatomía y los procesos patológicos, tanto por parte de los radiólogos como de los médicos tratantes y cirujanos. Desde el advenimiento de las modalidades de imagenología computarizada, como el TC, el IRM y la tomografía de emisión de positrones (PET) en las décadas de 1970 y 1980, la visualización de imágenes médicas ha evolucionado a partir de la proyección bidimensional de imágenes de cortes separados, a la proyección de imágenes en tres (ancho, longitud y profundidad) o cuatro dimensiones (ancho, longitud, profundidad y tiempo). La evolución en la tecnología de imagenología, ha traído con ella un incremento en el tamaño de los datasets que constituyen la típica imagen 3D. Los cortes en las primeras tomografías computarizadas eran típicamente de 320 2 píxeles. Hoy día, una imagen típica de tomografía computarizada tiene 512 3 píxeles, haciéndola aproximadamente 1000 veces más densa. Este incremento de información en la imagen, hace importante el uso de métodos eficientes para manipular y visualizar los datasets. Esta es una necesidad del radiólogo, que debe navegar los datos para hacer un diagnóstico, así como también del cirujano, que necesita una representación fidedigna 20 del paciente y su patología asociada, para planear un procedimiento terapéutico. Para apreciar los atributos tridimensionales completos de los datos, los vóxeles individuales en el dataset deben ser proyectados en la pantalla de visualización, de forma tal que sus relaciones 3D sean mantenidas, mientras simultáneamente se hace que su apariencia en la pantalla sea significativa para el observador. El cambio, por parte de los radiólogos y cirujanos, de las vistas de cortes axiales tradicionales a la visualización 3D de volúmenes, les proporciona una visualización mejorada de las estructuras anatómicas y mejora el desempeño de los usuarios, al evaluar grandes datasets médicos de forma eficiente y exhaustiva. Así, se incrementa la confianza de los radiólogos al diagnosticar patologías y de los cirujanos al planear procedimientos [Zhang10].El incremento de los tamaños de los datasets usados en el VR, trae consigo el problema de aumentar el tiempo de cómputo necesario para desplegarlos, por lo que el VR se mantiene como un área de investigación activa, en la cual se busca mejorar la calidad de la imagen producida y la rapidez de los algoritmos utilizados. 2.2.1 Ray Casting La visualización en el volumen ray casting, está guiada por un modelo físico simplificado del proceso de propagación de la luz sobre materiales con índices variables de color y opacidad. En este modelo simplificado de transporte de luz, se representa como la luz es absorbida y emitida por los elementos del volumen [Ikits04]. Estas muestras son tomadas a lo largo de cada rayo de visión, acumulando las propiedades ópticas de opacidad y color resultantes, para producir el rendering (despliegue) final. La Figura 2.5 ilustra volúmenes visualizados a través de raycasting [Levoy90]. 21 Figura 2.5 - Imágenes médicas renderizadas por ray casting a) Un cráneo de un dataset de tomografía computarizada (TC). b) Un cerebro de un dataset de resonancia magnética (RM). c) Mandíbula de TC. d) Vaso sanguíneo cerebral en RM. El ray casting usa un modelo óptico para asignar valores en el dataset original a propiedades ópticas, como color y opacidad. Durante el rendering, las propiedades ópticas son acumuladas a través de cada rayo de visión para formar una imagen de los datos. El papel que cumple el modelo óptico es describir como las partículas en el volumen interactúan con la luz. El modelo óptico más comúnmente usado asume que el volumen consiste de partículas que simultáneamente emiten y absorben luz [Ikits04]. Modelos ópticos de mayor complejidad, incorporan los efectos de la dispersión de la luz. Para el modelo de emisión-absorción, el color C y la opacidad A, acumulados por cada rayo de muestreo, son computados de acuerdo a las siguientes ecuaciones: 𝐶 = ∑𝐶𝑖 𝑛 𝑖=1 ∏(1 − 𝐴𝑗) 𝑖−1 𝑗=1 𝐴 = 1 −∏(1 − 𝐴𝑗) 𝑖−1 𝑗=1 22 La opacidad Ai aproxima la absorción de luz, y el color Ci, que es ponderado en base a la opacidad, aproxima la emisión y absorción de luz en el segmento de rayo entre las muestras i e i+1. Para el componente de color, el producto en la suma representa la cantidad de atenuación que afecta a la luz emitida por la muestra i antes de alcanzar el ojo [Ikits04]. Las propiedades ópticas de color y opacidad, con las que se visualiza finalmente el volumen, pueden ser manipuladas aplicando una o más Funciones de Transferencia (FT) a los valores escalares del volumen. La meta de la función de transferencia, en las aplicaciones de visualización, es enfatizar características de interés en los datos. Una Función de Transferencia es una función capaz de manipular los valores de opacidad y color asignados a los datos originales, afectando las características del volumen que son desplegadas [Ikits04]. El proceso de aplicar las FT a los valores escalares de cada vóxel, se llama clasificación. Aunque el dataset de volumen se interpreta como una función continua en el espacio, en la práctica se trata como una pila de cortes 2D de textura, o un objeto único de textura 3D. Cada vóxeldel objeto corresponde a una ubicación en el espacio de datos, y tiene uno o más valores asociados a él. Los valores en las locaciones intermedias, son obtenidos interpolando datos con los elementos vecinos del volumen. Este proceso se conoce como reconstrucción y juega un rol importante en el VR [Ikits04]. El orden en que se lleva a cabo la aplicación de la Función de Transferencia y la interpolación de muestras en el volumen, produce resultados visuales distintos cuando la interpolación no es conmutativa con la función de transferencia. En el proceso llamado pre- clasificación, primero se aplica la función de transferencia al volumen y luego se realiza la reconstrucción. En la post-clasificación, primero se realiza la reconstrucción y luego se aplica la función de transferencia al volumen. Al aplicar pre-clasificación, las imágenes tienden a ser más difusas que utilizando post-clasificación. 2.2.2 Visualización de Isosuperficies Una isosuperficie es una superficie cuyos puntos representan un valor constante en un volumen, la superficie es el conjunto de valores representativos de un nivel de una función continua en el espacio 3D. En IRM, las isosuperficies se usan para representar regiones de una densidad particular de un tejido de órganos, huesos u otras estructuras [Hansen04]. El problema de extracción de una superficie, a partir de los datos volumétricos originales, 23 consiste en la representación poligonal del valor implícito f (x, y, z) = 𝜆; donde 𝜆 𝜖 𝑅 es el valor de interés en la función escalar 𝑓: 𝑅3 → 𝑅. Los dos métodos más comúnmente usados para generar isosuperficies de volúmenes, son marching cubes [Lorensen87] y marching tetrahedra [Carneiro96]. Ambas técnicas asumen que un contorno puede pasar a través de un vóxel en un número finito de formas y generan un mallado de triángulos, construido en base al nivel que se desee visualizar en la isosuperficie. Ambas construyen tablas de casos, que enumeran los posibles estados topológicos del vóxel, dadas todas las posibles combinaciones de valores escalares en la superficie, relativos a los puntos vértices del vóxel. El número de estados topológicos depende del número de relaciones dentro/fuera, que los vértices del vóxel pueden tener con respecto al valor de contorno. Los vértices con valores escalares inferiores al valor de contorno, se consideran fuera del contorno. Un vóxel tiene ocho vértices y cada vértice puede estar dentro o fuera del contorno, existiendo 2 8 = 256 formas posibles en que un contorno dado puede pasar a través de un vóxel. Aprovechando las propiedades de simetría entre múltiples casos, las tablas de intersección de vóxel con superficie, son reducidas a 15 configuraciones distintas de vóxel-isosuperficie en el caso de marching cubes, como se muestra en la Figura 2.6. Figura 2.6 - Casos de intersección de vóxel con isosuperficie en Marching Cubes Se crea un índice correspondiente a cada uno de los casos, basado en el estado (dentro-fuera) del vértice con respecto a la isosuperficie. Cada vértice es representado por una posición binaria en este índice, describiendo el caso tratado. Se usa el índice para encontrar cuál es la arista del cubo que la superficie intercepta y se usa interpolación lineal para posiciones el punto de intersección superficie-cubo en la arista. Finalmente, una vez que la interpolación es realizada, el triángulo contenido en la superficie es creado conectando todos los puntos de intersección dentro del vóxel. 24 Esta tarea es repetida, vóxel por vóxel, para generar la isosuperficie completa. Un problema con marching cubes es la aparición de casos de interpretación ambigua para la intersección vóxel-superficie, como se muestra en la Figura (2.7a). Para estos casos debe generarse un criterio contingente de interpretación uniforme en todo el volumen. Este problema de ambigüedad es eliminado al reemplazar la estructura básica de intersección, usando un tetraedro en lugar de un cubo, como se muestra en la Figura (2.7b). a) b) Figura 2.7 - Casos de intersección de vóxel con isosuperficie en Marching Cubes Para marching tetrahedra, el número de casos de intersección se reduce a 3 (igualmente, aprovechando simetrías), como se ilustra en la Figura 2.8. Cada vóxel es dividido en 5 tetraedros, como se ilustra en la Figura 2.9. Los tetraedros se colocan en posiciones alternas “negro-blanco”, siendo una posición la rotación en 90 grados de la otra, para evitar confusión de polígonos al colocar cubos con la misma configuración de tetraedros adyacentes. Figura 2.8 - Casos Posibles de Intersección Tetraedro-Isosuperficie 25 Figura 2.9 - Configuración Negro-Blanco para Tetraedros en Vóxeles Adyacentes Un factor a considerar en la implementación de marching tetrahedra, es que tiende a generar una cantidad de polígonos superior a la de marching cubes, incrementando el costo del tiempo de cómputo y memoria al realizar el despliegue de la isosuperficie. 2.3 Programación de GPU con CUDA Las arquitecturas modernas de procesadores han incorporado múltiples núcleos de cómputo, capaces de realizar ejecución paralela de instrucciones. Las unidades de procesamiento gráfico (GPU), que tradicionalmente han incorporado múltiples núcleos, han evolucionado, a partir de ser dispositivos dedicados exclusivamente a rendering, para convertirse en procesadores paralelos de propósito general [Khronos11]. Una GPU moderna típicamente contiene cientos de núcleos de procesamiento, en los cuales se pueden ejecutar varios millones de hilos de cómputo simultáneamente. CUDA, que es un acrónimo para Compute Unified Device Architecture, es una plataforma de cómputo paralelo y modelo de programación, creada por Nvidia, e implementada en los GPUs que produce, que permite explotar estas capacidades. 2.3.1 Modelo de Ejecución de CUDA Las unidades de cómputo en CUDA permiten que muchas operaciones sean ejecutadas en paralelo, en un amplio conjunto de datos de forma SIMT (Single Instruction Multiple Thread 2 ). Un 2 Un thread (hilo) de ejecución es la secuencia más pequeña de instrucciones programadas que pueden ser manejadas independientemente en un sistema de cómputo. Múltiples threads pueden existir en un grupo (llamado bloque) y compartir recursos de memoria. 26 mismo programa, llamado kernel, es ejecutado de forma paralela por un conjunto de threads, cada thread ejecutando el programa sobre distintos datos. Cada vez que un kernel es ejecutado, un número de threads especificado por el programador es creado. Cada thread tiene un identificador, que es accesible a partir del kernel y es usado para distinguir los datos que deben ser procesados por el hilo de ejecución. Los kernels son enviados a su unidad de cómputo destino por las aplicaciones host, como se ilustra en Figura 2.10. Una aplicación host es una aplicación escrita en algún lenguaje de programación de propósito general (C/C++, Matlab, Python, Java, Haskell, etc.) que se encarga de ordenar la creación en memoria de los kernels en los dispositivos compatibles. CUDA divide el espacio de ejecución global de threads en conjuntos, llamados bloques, que pueden tener una, dos o tres dimensiones. La especificación de CUDA define que un bloque entero puede ejecutarse concurrentemente en un mismo Streaming Multiprocessor 3 . Los bloques permiten que exista sincronización entre los threads que los componen y prohíben la sincronización entre threads pertenecientes a otros bloques, para facilitar la escalabilidad de cómputo en distintos GPUs. La organización en bloques simplifica la planificación de ejecución de un mismo programa en varios GPUs con distinto número de SMs, reduciendo el trabajo del programador, como se ilustra en la Figura 2.11. 3 Streaming Multiprocesors (SMs), es el nombre dado a los procesadores multinúcleo de propósito general, presentes en la arquitectura CUDA. Cada SM contiene miles de registros, varios niveles de memoria caché y hardware dedicado a la planificación de ejecución de warps (un warp es un conjunto de 32 threads) de threads. Cada bloque de threads es ejecutado en un único SM, aunque un mismo SM comúnmente ejecuta varios bloques en sucesión. 27 Figura 2.10 - Distribución de Bloques y Escalabilidad en CUDA Un kernel es un programa multihilo particionado en bloques, de tal forma que una GPU con más SMs automáticamente ejecuta el mismo programa en menos tiempo que una GPU con menos SMs. Los bloques están organizados en un grid con un posible rango de 1, 2 ó 3 dimensiones. En la Figura 2.11 se muestra un grid de 2 dimensiones, con un identificador x, y para cada thread. Un aspecto esencial del modelo de ejecución de CUDA, es la definición de un conjunto de identificadores para cada thread en el espacio multidimensional definido en el grid. A través de estos identificadores únicos el modelo de ejecución de CUDA permite al desarrollador identificar de manera exacta donde reside cada instancia paralela de un kernel en el espacio de índices, para que puedan planificarse las operaciones necesarias para implementar correctamente una aplicación. El tamaño de bloque utilizado es importante porque los threads dentro de un bloque pueden compartir memoria a una tasa de transferencia mucho más rápida que la que existe entre hilos de diferentes 28 bloques, lo que hace a la escala de bloque la forma natural de fijar barreras y definir sincronización entre threads. Figura 2.11 - Grid Bidimensional Para identificar a un thread unívocamente, se considera la información respectiva a sus coordenadas x, y dentro del bloque al que pertenece, el número de bloque y sus dimensiones, así como las dimensiones del grid contenedor. 2.3.2 Jerarquía de Memoria en CUDA CUDA define una jerarquía de memoria como la que se ilustra en la Figura 2.12, su aprovechamiento apropiado es importante para los desarrolladores de aplicaciones. A continuación se describe la organización de esta jerarquía. 29 Figura 2.12 - Jerarquía de Memoria en CUDA El espacio de memoria en CUDA está dividido en una jerarquía basada en rapidez de acceso y tamaño. Ambas métricas para cada nivel de la jerarquía dependen de la GPU particular. a) Global Memory (Memoria Global): la memoria global es el subsistema de memoria de mayor capacidad en el GPU. Para la mayor parte de los dispositivos actuales, la capacidad de la memoria global será de uno o más gigabytes. Aunque la memoria global es grande y visible para todos los threads en un dispositivo, también debe ser considerada como el subsistema de memoria más lento y tiene algunas restricciones de uso. La memoria global es mejor aprovechada cuando se referencia en locaciones contiguas o se usan patrones de acceso a memoria que aprovechen su ancho de banda. Se 30 dice que dichas operaciones en memoria son coalesced, que se traduce como “fusionadas” o “unidas”. Para especificar a la memoria global se usa el modificador __global__. b) Local Memory (Memoria Local): es la memoria dentro de un thread que corresponde a los registros en alguna unidad aritmética-lógica de un GPU. La memoria privada es la más rápida y pequeña en la jerarquía de memoria y puede ser usada sin necesidad de primitivas de sincronización. c) Shared Memory (Memoria Compartida): La memoria compartida es memoria on-chip, que es mucho más rápida que la memoria global en un dispositivo. A diferencia de la memoria global, que puede tener varios gigabytes de tamaño, la memoria local está en el orden de los cientos de kilobytes. Es usada para compartir datos rápidamente entre los threads de un mismo bloque y para reducir los accesos a la memoria global, de menor ancho de banda. 2.4 Métricas de Calidad de Segmentación En el ámbito médico, es tradicional medir la eficacia de un test según las métricas estadísticas binarias de sensibilidad y especificidad. Sensibilidad = VP VP + FN = VP # 𝑑𝑒 𝑃𝑜𝑠𝑖𝑡𝑖𝑣𝑜𝑠 Especificidad = VN VN + FP = 𝑉𝑁 # 𝑑𝑒 𝑁𝑒𝑔𝑎𝑡𝑖𝑣𝑜𝑠 VP = número de verdaderos positivos VN = número de verdaderos negativos FP = número de falsos positivos FN = número de falsos negativos En el problema general de clasificación binaria, la denominación “positivo” corresponde a “identificado” y “negativo” a “rechazado”, así se da la siguiente correspondencia:  Verdadero Positivo: elemento correctamente identificado  Falso Positivo: elemento incorrectamente identificado  Verdadero Negativo: elemento correctamente rechazado 31  Falso Negativo: elemento incorrectamente rechazado En el problema particular de clasificación de vóxeles como tumorales o no se definen verdadero positivo, verdadero negativo, falso positivo y falso negativo de la siguiente manera:  Verdadero Positivo: vóxel tumoral identificado correctamente como tumoral  Falso Positivo: vóxel no tumoral identificado incorrectamente como tumoral  Verdadero Negativo: vóxel no tumoral identificado como no tumoral  Falso Negativo: vóxel tumoral identificado incorrectamente como no tumoral En general, un clasificador binario perfecto sería uno con sensibilidad = 1 y especificidad = 1. La puntuación mínima, para ambas métricas, es 0 [Koller09]. En el caso de la segmentación de tumores, un clasificador perfecto sería aquel que identifique a todo el tejido tumoral presente en un volumen de IRM y no identifique como tumoral al tejido sano. La sensibilidad mide la proporción de verdaderos positivos que son identificados. Es el número de verdaderos positivos entre el número total de elementos que auténticamente pertenecen a la clase positiva, corresponde a la probabilidad con que un vóxel sea identificado como tumoral, dado que auténticamente represente a un vóxel de tumor. La especificidad mide la proporción de verdaderos negativos, que correspondería a la probabilidad que un vóxel sea identificado como no tumoral, siendo auténticamente no tumoral. La sensibilidad y la especificidad no deben ser evaluadas de manera separada. Un algoritmo clasificador que considere a los vóxeles de tumor como clase positiva, puede tener sensibilidad de 1 marcando todos los pixeles de una imagen de resonancia como tumorales, debido a que la sensibilidad no considera falsos positivos, en dicho caso, una sensibilidad "perfecta" correspondería a una especificidad nula. Si en una segmentación se buscan vóxeles tumorales y de 100 vóxeles auténticamente tumorales se identifican 78, la sensibilidad es 0.78. Si en una segmentación se buscan vóxeles tumorales y de 100 vóxeles auténticamente no tumorales se marcan 49 de estos como no tumorales, la especificidad es 0.49. En el problema de la segmentación tumoral, una métrica que tiende a ser más representativa de la calidad de la segmentación alcanzada que las métricas de sensibilidad o especificidad, evaluadas individualmente, es el coeficiente Dice, [Popovic07] que representa la unión de 2 32 conjuntos dividida por su tamaño: Coeficiente Dice = 2 ∗ |A ⋂B| |A| + |B| En el caso de la segmentación de tumor, un coeficiente Dice igual a 1 significa que hay perfecto solapamiento entre el tumor expresado en la verdad fundamental y el tumor identificado por el algoritmo segmentador. En términos de verdaderos positivos, verdaderos negativos, falsos positivos y falsos negativos, la cardinalidad de los conjuntos A y B y su intersección, puede expresarse de la siguiente manera [Loni13]: Coeficiente Dice = 2 ∗ VP (FP + VP) + (VP + FN) Cuando se desea considerar cuantitativamente la proporción de vóxeles o píxeles que fueron correctamente identificados como pertenecientes a la clase positiva (vóxeles tumor, cuando se busca en el caso de la radiocirugía), se utiliza la métrica de precisión [Prince12], definida como Precisión = VP VP + FP = VP #𝑝í𝑥𝑒𝑙𝑒𝑠 𝑜 𝑣ó𝑥𝑒𝑙𝑒𝑠 𝑒𝑣𝑎𝑙𝑢𝑎𝑑𝑜𝑠 Una métrica que es comúnmente evaluada contra la precisión, al usarla para evaluar segmentaciones binarias (por ejemplo, tumor contra background o edema contra background) es la sensibilidad, que en estadísticas es también llamada recall o exhaustividad [Koller09]. En la clasificación binaria de vóxeles como tumorales o no tumorales, una precisión perfecta de 1.0 significa que cada vóxel identificado como tumoral es auténticamente tumoral (aunque esto no representa que todos los vóxeles tumorales presentes en el volumen hayan sido identificados como tal) y una sensibilidad de 1.0 significa que todas los vóxeles tumorales presentes en el volumen fueron identificados como tal (aunque esto no representa cuantos vóxeles no tumorales fueron identificados como tumorales, métrica representada por la especificidad). La precisión y la sensibilidad tienen una relación frecuentemente inversa, ya que es posible incrementar una métrica al costo de reducir la otra. La radiocirugía cerebral provee un ejemplo de esta relación inversa entre la precisión y la sensibilidad y la importancia del balance de estas métricas para representar resultados deseables. Considérese el resultado deseado en una cirugía planeada para remover células tumorales del cerebro de un paciente. Se desea que la cirugía remueva todas las células tumorales, debido a que cada célula tumoral remanente después de la cirugía permite al tumor volver a desarrollarse. Al mismo tiempo, la cirugía debe evitar la 33 destrucción de células cerebrales sanas, debido al perjuicio que esto ocasiona al paciente. El equipo médico dedicado a la planificación radioquirúrgica puede decidir irradiar un área de extensión máxima, para asegurar la destrucción de todas las células cancerosas, esta irradiación extensa incrementa la sensibilidad, pero reduce la precisión del tratamiento. Por otra parte, el equipo médico podría decidir irradiar un área de extensión mínima, tal vez con la intención de prevenir algún daño a las facultades cognitivas del paciente. Esta decisión incrementa la precisión pero reduce la sensibilidad. Esto significa que una mayor sensibilidad incrementa la probabilidad de remover células sanas (un resultado no deseable) e incrementa la probabilidad de remover todas las células cancerosas (un resultado deseable). Una alta precisión reduce las posibilidades de remover células saludables (resultado deseable) pero también reduce la posibilidad de remover las células cancerosas (resultado no deseable). Debido a que comúnmente se desea valorar conjuntamente a la precisión y a la sensibilidad, con igual ponderación a ambas medidas, se utiliza la puntuación F1, definida de la siguiente manera 𝐶𝑜𝑒𝑓𝑖𝑐𝑖𝑒𝑛𝑡𝑒 𝐷𝑖𝑐𝑒 𝑜 𝑚é𝑡𝑟𝑖𝑐𝑎 𝐹1 = 2 ∗ 𝑝𝑟𝑒𝑐𝑖𝑠𝑖ó𝑛 ∗ 𝑠𝑒𝑛𝑠𝑖𝑏𝑖𝑙𝑖𝑑𝑎𝑑 𝑝𝑟𝑒𝑐𝑖𝑠𝑖ó𝑛 + 𝑠𝑒𝑛𝑠𝑖𝑏𝑙𝑖𝑑𝑎𝑑 La puntuación F1 es la media harmónica de la precisión y la sensibilidad; es equivalente al Coeficiente Dice [O’Connor12]. 2.4.1 Verdad Fundamental a Través de TumorSim En imágenes de resonancia magnética reales, la obtención de datos de validación y métricas de comparación para la segmentación es una tarea difícil, debido a la ausencia de una verdad fundamental. Este problema es evidente en las imágenes que presentan patologías, que alteran la apariencia del tejido a través de infiltración y causan distorsiones geométricas. El estándar usual para la validación de segmentaciones algorítmicas, es la comparación contra los resultados de segmentación manual hechos por expertos humanos, pero esto es inconveniente y propenso a introducir errores debido a la común intervariabilidad e intravariabilidad de la percepción y el criterio humano. Por esto, para validar el desempeño de los distintos segmentadores (humanos o algorítmicos), existe la necesidad de generar imágenes sintéticas partiendo de una verdad fundamental que indique el tipo de tejido que aparece en cada vóxel de las imágenes sintéticas producidas. Evidentemente, las imágenes sintéticas deben ser altamente similares a imágenes reales para que el proceso de segmentación validado con ellas pueda resultar útil. 34 El software TumorSim combina el modelado físico y estadístico para generar imagenología sintética de resonancia magnética 3D multimodal con tumor y edema, junto con una verdad fundamental anatómica subyacente. Se simula la apariencia de tejido sano y tumoral en IRM, sintetizando las imágenes de textura en resonancias magnéticas reales. TumorSim enfatiza la simulación de efectos conocidos de la presencia tumoral, como la distorsión local del tejido sano, la infiltración de edema adyacente al tumor, destrucción y formación de tractos de fibras y contraste multimodal de tejido sano y tejido patológico [Prastawa09]. a) b) Figura 2.13 - TumorSim a) Corte de resonancia magnética sintético en el canal T2, producido por TumorSim, incluyendo tumor y edema. b) Verdad fundamental producida por TumorSim para el mismo corte, indicando la verdadera presencia de 4 clases de tejido sano, además de edema y tejido tumoral. Imagen mostrada con el mapa de color jet de Matlab. 35 CAPÍTULO 3 - MÉTODOS DE SEGMENTACIÓN DE IMAGENOLOGÍA DE RESONANCIA MAGNÉTICA La segmentación es el proceso de dividir una imagen en regiones con propiedades similares, tales como nivel de gris, color o textura. En el caso de la segmentación de imágenes médicas, las metas son:  Estudiar cualitativamente estructuras anatómicas.  Identificar regiones de interés.  Medir volumen de tejido, por ejemplo para medir crecimiento de tumor, o reducción del mismo por tratamiento.  Ayuda en cálculo de dosis de radiación en el planeamiento del tratamiento de radioterapia. Dependiendo del grado de interacción requerido por el usuario, las técnicas de segmentación de imágenes médicas se dividen en las categorías: "automática" y "asistida''. En la práctica, todos los sistemas actuales son asistentes al usuario experto en la evaluación de imágenes, los sistemas actuales de inteligencia artificial son incapaces de generar autónomamente modelos de reducción y abstracción de características visuales salientes, aún no se ha eliminado la necesidad de operadores humanos expertos para validar la calidad de las segmentaciones y la segmentación permanece como uno de los problemas más desafiantes de la visión por computador. 3.1 Segmentación Automática La segmentación automática de imágenes médicas de resonancia magnética es una tarea difícil debido a que estas rara vez poseen características lineales simples. Los sistemas actuales de segmentación automática típicamente dependen de algún parámetro suministrado por el usuario indicando morfología o nivel digital de interés en la imagen. La generación de segmentaciones de estructuras anatómicas fiables, con mínima interacción humana es un tema abierto de investigación, a continuación se presentan algunas de las técnicas relevantes en la literatura actual. 3.1.1 Clustering por K-means Los métodos de clustering agrupan muestras de vectores de n dimensiones de forma tal que las 36 características de las muestras pertenecientes a un mismo grupo tengan la máxima similitud posible entre sí. K-means es un método de clustering que agrupa datos multidimensionales utilizando medidas de semejanza mutua basadas en distancia. Comúnmente, está basado en la suma del cuadrado de la distancia euclidiana entre las muestras en un cluster (grupo) y el centro del cluster. K-means busca minimizar la suma de estas distancias para obtener clusters compactos. Un k-means para segmentar imágenes se basa en el siguiente algoritmo: 1. Se crean aleatoriamente k prototipos de centroide 𝜇𝑖. 2. Se asigna una etiqueta a los elementos en la muestra correspondiente a su centroide más cercano, utilizando la siguiente relación: 𝑥 ∈ 𝐶𝑗(𝑘) 𝑠𝑖 |𝑥 − 𝑧𝑗| < |𝑥 − 𝑧𝑖|, ∀𝑖 = 1,2,… . , 𝐾; 𝑖 ≠ 𝑗; donde 𝐶𝑗(𝑘) representa al grupo de muestras del cluster 𝑧𝑗 3. Luego de haber asignado todos los píxeles, se recalculan los centroides usando la siguiente ecuación: 𝑍𝑖 = 1 𝑁𝑗 ∑ 𝑥, 𝑗 = 1,2, … ,𝐾 𝑥∈𝐶𝑗(𝑘) 𝑁𝑗es el número de muestras en 𝐶𝑗(𝑘). 4. Los pasos 2 y 3 son repetidos hasta que los centroides convergen. 37 Figura 3.1 - K-means aplicado en cortes de PET-CT, usando K=15 Una limitación del método es que el resultado de segmentación obtenido es dependiente del número de centroides establecidos antes de iniciar el algoritmo (ver Figura 3.1). El número de centroides adecuado para lograr una segmentación útil, debe establecerse a través de ensayo y error. Otro inconveniente del método, es que incrementar el número de centroides incrementa linealmente el tiempo necesario para obtener la clasificación. 3.1.2 Segmentación con Modelos Gráficos Probabilísticos En IRM cerebral se puede aprovechar que hay características constantes entre los elementos de la imagen y que estos elementos corresponden a un número limitado de clases. Además, se presenta un contraste relativamente alto entre tejidos. Alterando la frecuencia de radio y los pulsos de gradiente en que son registradas las imágenes, y ajustando cuidadosamente los tiempos de relajación, es posible destacar distintos componentes en el objeto siendo examinado y producir imágenes de alto contraste entre distintos tejidos. Sin embargo, las condiciones ideales de imagenología difícilmente se presentan en la práctica. La propiedad de características constantes para cada elemento en la imagen, se ve degradada considerablemente por el ruido electrónico, el campo de sesgo (que es producto de inhomogeneidades en el campo de frecuencia de radio) y el efecto de volumen parcial (que ocurre cuando múltiples clases de tejido pueden ocupar un mismo vóxel). Estos problemas de medición causan que las clases se solapen en un histograma de 38 intensidades de gris en la imagen. Además, las imágenes de resonancia magnética no siempre proporcionan alto contraste, y distintas modalidades de IRM tienden a resaltar mejor los contornos de determinados tipos de tejido o edema en el cuerpo. [Zhang01]. Esta incertidumbre, propia de la imagenología, es manejada a través del marco matemático de la teoría de la probabilidad. La segmentación automática de tumores cerebrales con modelos gráficos probabilísticos, se realiza en base a análisis estadísticos relacionados a atlas anatómicos [Warfield01], [Prastawa04], donde los tumores son considerados outliers 4 , estructuras cuya probabilidad de presencia en una anatomía normal es considerada baja. Los métodos de segmentación derivados de atlas 5 identifican las estructuras anómalas y arrojan resultados positivos de tumor, cuando un tejido se presenta de forma atípica en la anatomía cerebral. Estos métodos basados en atlas, pueden ser tanto generativos como discriminativos y requieren ser entrenados a partir de los datos de pacientes con diversas patologías. Los métodos discriminativos de segmentación automática de tumores, están limitados a funcionar en la modalidad de datos del conjunto de entrenamiento y son sensibles a los datos faltantes. Los modelos generativos pueden generalizar directamente a observaciones multi-canal 6 , pero no permiten modelar las diferencias entre los procesos biológicos observados en varias modalidades. Asumiendo la misma forma y extensión de patología en todas las modalidades, la segmentación estándar multi-canal puede ignorar mucha de la información potencialmente disponible en las imágenes. Ejemplos de esto, incluyen las diferencias de agua en tejidos (T2, FLAIR), uso de agentes de contraste (gadolinio), difusión (DTI, DCE) o concentraciones relativas de metabolitos selectos (MRSI). Delinear independientemente el área de tumor en cada una de estas modalidades, es comúnmente preferido para el subsiguiente análisis cuantitativo de la forma del tumor y su evolución [Menze10]. 3.1.2.1 Aprendizaje e Inferencia La segmentación y posterior clasificación de imágenes son parte esencial de la visión por 4 En estadìstica, un outlier es una observación a una o más desviaciones estándar de la media de la data. 5 En la segmentación de imágenes médicas, un atlas es un mapa probabilístico de regiones encontradas en una anatomía normal. 6 Aunque una especificación detallada de las variadas modalidades de IRM se escapa del alcance de este trabajo, es importante señalar que cada una de las modalidades ofrece variaciones de contraste entre los tejidos: algunas son más apropiadas para identificar edema, otras para identificar materia blanca, materia gris, etc. Para propósitos de segmentación de imágenes, cada modalidad ofrece vectores de características distintasenla imagen, y es referida como canal. 39 computador. En general, la meta de la visión por computador es usar datos observados en una imagen para inferir algo acerca del estado del mundo al que corresponden. Por ejemplo, se podría observar la imagen de una persona y usar los datos en ella para inferir el contorno de su rostro y luego su identidad. Esta labor de inferencia es modelable a través del marco matemático de la teoría de la probabilidad [Prince12]. La meta de este marco teórico, es describir la metodología probabilística usada para tratar problemas de segmentación de imágenes cerebrales en resonancia magnética. Una amplia variedad de métodos estadísticos paramétricos han sido formulados. Este tipo de métodos etiqueta píxeles de acuerdo a valores de probabilidad, los cuales son determinados con base en la distribución de intensidad de la imagen. Asumiendo información apropiada para la distribución de intensidad de la imagen, los métodos estadísticos intentan resolver el problema de estimar la etiqueta de clase asociada a ellos, conociendo sólo la intensidad de cada píxel. Este problema de estimación es necesariamente formulado en base a un criterio establecido. Por ejemplo, los principios de maximum a posteriori (MAP) y máxima verosimilitud, son dos de estos criterios establecidos para formular la estimación de etiquetas de clase de tejido correspondientes a los píxeles de la imagen [Zhang01]. En los problemas de visión por computador modelados a través de la teoría de la probabilidad, se toman datos visuales x y estos se utilizan para inferir el estado del mundo w. Este estado del mundo w puede ser continuo o discreto. Cuando el estado del mundo es continuo, se llama al proceso de inferencia regresión y cuando el estado del mundo es discreto, se llama al proceso de inferencia clasificación [Prince12]. En los problemas de clasificación de tejidos cerebrales en RM, los datos visuales x corresponden a la intensidad y posición de los píxeles o vóxeles en una imagen, y el estado del mundo w a la etiqueta anatómica (materia blanca, materia gris, líquido cerebroespinal, tumor, edema, etc.) correspondiente a un píxel, vóxel o superpíxel dado. Existe incertidumbre inherente a los datos del mundo x; una interpretación dada puede ser compatible con más de un estado del mundo debido a la ambigüedad inherente en la percepción de los datos visuales; por ejemplo: un pedazo de carbón visto bajo una luz brillante puede producir las mismas medidas de luminancia que un papel blanco en luz tenue; similarmente, un objeto pequeño visto de cerca puede producir la misma imagen que un objeto grande que se encuentre a una distancia mucho mayor [Prince12]. Para tratar dicha la ambigüedad perceptual, propia del proceso de observación, se considera la distribución de probabilidad a posteriori P(w|x) sobre los estados posibles w. La probabilidad a posteriori de un evento aleatorio es la probabilidad condicional que es asignada luego de que la evidencia es tomada en cuenta [Koller09]. En los problemas de visión de 40 computador, el evento aleatorio corresponde al estado del mundo, w, y la evidencia a los datos visuales, x, así que se deben considerar todos los posibles estados del mundo generables con un conjunto de datos visuales y asignar una ponderación probabilística a cada uno de estos posibles estados [Prince12]. 3.1.2.2 Tipos de Modelos Probabilísticos Existen variadas familias de modelos probabilísticos (las redes bayesianas, los campos aleatorios de Markov y los campos aleatorios condicionales, entre otros) y a cada una corresponden algoritmos de aprendizaje e inferencia propios. Los modelos que relacionan los datos x al estado del mundo w, caen en una de dos categorías:  Discriminativos: aquellos que modelan la contingencia del estado del mundo, dados los datos, P(w|x).  Generativos: aquellos que modelan la contingencia de los datos, dado el estado del mundo, P(x|w). El aprendizaje y la inferencia son profundamente distintos entre el grupo de los modelos generativos y los modelos discriminativos. Cada grupo constituye una familia propia de métodos y algoritmos [Prince12]. Para el problema de la segmentación automática de tumores, ambos tipos de modelos enfrentan dificultades de implementación. Los modelos generativos ofrecen la facilidad de incorporar información espacial y generalizarse directamente a observaciones multi-canal, pero son incapaces de representar directamente las diferencias biológicas observadas en los varios canales. Para lograr esto Menze et al. [Menze10], utiliza información adicional incorporada a un atlas oculto, obtenido a través del algoritmo de Esperanza-Maximización. En cambio, los modelos discriminativos a pesar de ser más sensibles a las diferencias biológicas presentes en cada canal de visualización MRI, están limitados a ejecutarse en el canal que fue usado para el entrenamiento y tienden a ser sensibles a los datos faltantes [Menze10]. a) Modelos Discriminativos Para modelar la contingencia del mundo a los datos, P(w|x), se elige una forma apropiada para la distribución, P(w), sobre los estados del mundo, w, y se hace que los parámetros de la distribución 41 se comporten como una función de los datos, x. Por ejemplo, si el estado del mundo es continuo, se puede modelar P(w) con una distribución normal y hacer que la media μ de la distribución sea una función de los datos x. El valor que esta función retorna también depende de un conjunto de parámetros de ajuste, θ. Debido que la distribución posterior sobre el estado del mundo depende tanto de los datos como de estos parámetros de ajuste, la escribimos como P(w|x,θ). La meta del algoritmo de aprendizaje es ajustar los parámetros, θ usando data de entrenamiento {xi, wi} I . Esto puede hacerse través de los métodos de máxima verosimilitud, maximum a posteriori o por métodos bayesianos [Prince12]. La meta del algoritmo de inferencia es encontrar una distribución sobre los posibles estados del mundo w para una nueva observación x. La inferencia probabilística tiende a ser un problema NP-completo en la mayor parte de los modelos y se maneja con métodos variados de aproximación, como el muestreo aleatorio [Koller09]. b) Modelos Generativos Para modelar la contingencia de los datos, dado el mundo, P(x|w), se elige la forma para la distribución P(x) sobre los datos y los parámetros de la distribución, θ, son una función del estado del mundo w. Por ejemplo, si los datos fueran discretos y multi-valuados se podría usar una distribución multinomial y hacer que el vector de parámetros (correspondiente al número discreto de categorías) λ sea una función del estado del mundo w [Prince12]. El valor que esta función retorne, también depende de un conjunto de parámetros θ. Debido a que la distribución P(x) depende, tanto del estado del mundo como de estos parámetros, se le expresa como P(x|w,θ) y se le llama verosimilitud. La meta del aprendizaje es ajustar los parámetros θ usando ejemplos de aprendizaje, dados en pares {xi,wi} I . Durante el proceso de inferencia, la meta es calcular la distribución posterior P(w|x). Para esto, se especifica una distribución a priori P(w) sobre los estados del mundo y se usa luego la regla de Bayes [Prince12]:   ))()|( )()|( )|( dwwPwxP wPwxP xwP Aquí se ha modelado de forma conjunta la verosimilitud P(x|w) y la distribución a priori 42 P(w) y se multiplican en el numerador de la regla de Bayes. Hay que destacar que también se pudo haber modelado, de forma equivalente, la distribución conjunta P(x,w) = P(x|w)*P(w),ya que los modelos generativos también pueden ser expresados usando la distribución conjunta. En la aplicación de segmentación automática presentada por Menze et al. [Menze10], se modela la relación entre los datos visuales y el estado del mundo (ausencia o presencia de tumor en cada vóxel) con un Campo Aleatorio de Markov. Luego se entrena al modelo en base a un conjunto de datos que permiten ajustar parámetros para estimar la verdadera segmentación de tumor entre varios canales de imagen y finalmente, se realiza inferencia a través de los nuevos datos, para lograr identificar como tumores a los outliers anatómicos en datos nuevos. Figura 3.2 - Segmentaciones específicas al canal para cuatro modalidades en dos pacientes Los contornos de las regiones con probabilidad de tumor > 0.5 para los parámetros estimados son mostrados en rojo. Se puede apreciar como las fronteras de tumor varían entre las distintas modalidades. Una desventaja del método es que produce falsos positivos que deben ser eliminados en un paso de post-procesamiento. 3.2 Segmentación Asistida de IRM Aunque las técnicas de segmentación automática están siendo constantemente mejoradas, ninguna técnica automatizada de análisis de imágenes puede ser aplicada de forma completamente autónoma con resultados garantizados (refiriéndose esto a alta sensibilidad y especificidad) en todo caso. Por esto es que las técnicas de segmentación asistida, que permiten resolver tareas de segmentación de dificultad alta y moderada con un esfuerzo modesto por parte del usuario, han mantenido popularidad [Vezhnevets05]. Varias técnicas poderosas de segmentación asistida han sido propuestas, basadas en 43 transformadas watershed, contornos activos [Blake98], graphcuts [Boykov01], [Rother04], y Random Walker [Grady04]. Estas técnicas realizan segmentaciones de alta calidad requiriendo poco esfuerzo por parte del usuario. Las imágenes médicas tienen propiedades únicas. En muchos casos, como en la imagenología de resonancia magnética, están en escala de grises y los objetos que deben ser segmentados son muy diferentes en su estructura y apariencia a los objetos que son comunes en la edición de fotos, probablemente por esto es que tanto esfuerzo de investigación ha sido dedicado a desarrollar métodos de segmentación específicos para el dominio de las imágenes médicas. Aun así, varias técnicas de segmentación genéricas, como GraphCut, pueden ser exitosamente aplicadas a las imágenes médicas [Vezhnevets05]. Algunas técnicas de segmentación asistida “médica” son mencionadas a continuación. 3.2.1 Crecimiento de Región En esta técnica, inicialmente se considera el píxel semilla dentro del objeto de interés marcado por el usuario. Luego los píxeles vecinos son iterativamente añadidos a la región de crecimiento, en caso de que se cumpla algún criterio de homogeneidad de la región. Los criterios pueden ser definidos según intensidad de vóxel o píxel, varianza, color, forma, etc. El principal problema con este método, es el desbordamiento de la región de crecimiento a través de fronteras “débiles” [Heinmann04]; estas son regiones donde el criterio de separación falla. Otra limitación de este método, es que sólo funciona con sólo dos etiquetas (K=2), correspondientes a objeto de interés y fondo. Además, el método es altamente sensible a las posiciones de las semillas originales y no es robusto frente al ruido, causando con frecuencia que las regiones extraídas tengan desconexiones innaturales, por ejemplo, en la Figura 3.3c, se puede apreciar como parte del globo ocular derecho del corte axial de IRM, es incluido en la segmentación final como objeto de interés, pero el izquierdo no. 44 Figura 3.3 - Etapas del algoritmo de crecimiento de regiones en el corte axial de una IRM. 3.2.2 Transformada Watershed Basada en Marcadores La transformada watershed es una técnica morfológica de segmentación de imágenes 2D y 3D basada en regiones. La idea es originaria del campo de la topografía, donde en un relieve de región existen fronteras de separación entre las cuencas de deyección de ríos y lagos. La transformada watershed trata la imagen como una superficie con un relieve especificado por la luminancia de los píxeles o por el valor absoluto del gradiente de la imagen (a mayor luminancia o mayor gradiente mayor elevación para el terreno simulado, generando mayor separación entre regiones contiguas). En el algoritmo de watershed original, se usan fuentes simuladas de agua en cada uno de los mínimos locales de luminancia o gradiente en la imagen, que representan cuencas. Cada cuenca es llenada con agua hasta que ésta alcanza el punto más alto del relieve, formando represas (watersheds) en los puntos donde el agua de diversas cuencas se encuentra. Cuando la transformación se aplica a una imagen gradiente, se espera que las zonas segmentadas producidas por la imagen se ajusten a regiones homogéneas en nivel de gris en la imagen. Sin embargo, en una imagen con una alta cantidad de mínimos locales o ruido (situación que frecuentemente ocurre en la IRM), es común que se produzca sobre-segmentación de la imagen. Una solución a este problema, es utilizar marcadores especificados por el usuario para inundar el mapa de gradiente o luminancia de la imagen, empezando por estos marcadores en lugar de los mínimos regionales [Moga96]. Los marcadores colocados en la imagen especifican las etiquetas iniciales y deben ser segmentados entre sí. La Figura 3.4 muestra estos marcadores (a) b) c) 45 originales como segmentos de línea negra. Los marcadores pueden ser vistos como agujeros en el relieve de la imagen por donde el agua es vaciada mientras el relieve se inunda; cada marcador corresponde a una etiqueta distinta y hace que la imagen sea separada en una región propia para él. A medida que el relieve de la imagen es llenado con agua, las cuencas de diferentes marcadores pueden encontrarse, pero no mezclarse. Esto representa una solución parcial al problema de alta presencia de mínimos, que aún con marcadores, puede generar sobre-segmentación en la imagen que debe ser atacada con procesamiento adicional, como filtrado anisotrópico, uso de contornos activos o unión de regiones adyacentes [Szeliski10]. Figura 3.4 - Transformada Watershed a) Imagen original con marcadores semilla (segmentos de línea) añadidos. b) Imagen segmentada. Nótese como las regiones con puntos fueron separadas 3.2.3 Métodos Basados en Contornos Activos En estos métodos hay una curva frontera que se mueve iterativamente para segmentar una región de interés, el movimiento de esta curva frontera es determinado usando la combinación de fuerzas (también llamados potenciales) en la imagen, como presencia de energía de luminancia, y guías de segmentación provistas por el usuario. Se llama a estos modelos “activos” debido a su naturaleza iterativa, basada en la minimización de funciones de energía, lo que les permite exhibir comportamientos dinámicos. El primero de estos métodos, originalmente llamado snakes por sus inventores [Blake88], es a) b) 46 una curva spline (curva diferenciable, definida a trozos mediante polinomios) bidimensional, que evoluciona (se mueve) hacia características de la imagen como bordes fuertes. El segundo, tijeras inteligentes permite al usuario bosquejar en tiempo real una curva que busca adherirse a las fronteras del objeto [Mortensen95]. Finalmente, las técnicas levelset [Levelsets96], hacen que la curva evolucione como un conjunto derivado a partir de una función característica, lo que les permite cambiar topología e incorporar estadísticas basadas en cada región. 3.2.3.1 Snakes El método snakes es una spline 7 deformable, minimizadora de energía, influenciada por restricciones impuestas por el usuario y fuerzas en la imagen, que mueven la curva hacia los contornos del objeto. Como se muestra en la Figura 3.3, evoluciona hacia contornos cerrados. Un snake está definido por:  Un conjunto de n puntos  Un término de energía elástica interna  Un término de energía basado en bordes externos Se puede visualizar el snake como una banda de goma que se deforma en el tiempo, tratando de adaptarse al contorno del objeto. Las snakes no resuelven por sí mismas el problema de encontrar contornos en imágenes. Dependen de información suministrada por el usuario y son sensibles a una “mala” inicialización por parte del mismo durante toda su evolución. El contorno de la snake está definido por un conjunto de n puntos vi = (xi,yi), donde i = 0…n-1. Se busca minimizar la función de energía total de una snake que se define como 𝐸𝑠𝑛𝑎𝑘𝑒𝑣(𝑠)𝑑𝑠 = ∫ (𝐸𝑖𝑛𝑡𝑒𝑟𝑛𝑎(𝑣(𝑠)) + 𝐸𝑖𝑚𝑎𝑔𝑒𝑛(𝑣(𝑠)) + 𝐸𝑟𝑒𝑠𝑡𝑟𝑖𝑐𝑐𝑖𝑜𝑛𝑒𝑠𝑣(𝑠))𝑑𝑠 1 0 , donde s representa el espacio que el snake ocupa. 𝐸𝑟𝑒𝑠𝑡𝑟𝑖𝑐𝑐𝑖𝑜𝑛𝑒𝑠 representa las fuerzas de energía introducidas por el usuario al bosquejar la curva. La suma de los términos de imagen y restricciones denota la energía externa actuando en el spline. Einterna representa la energía interna del spline (snake) debida a su doblamiento, es la suma de la energía del contorno de la snake y la energía de la 7 Un spline es una curva derivable definida a trozos mediante polinomios. 47 curvatura del spline, 𝐸𝑐𝑢𝑟𝑣 = 𝐸𝑐𝑜𝑛𝑡 + 𝐸𝑐𝑢𝑟𝑣. 𝐸𝑖𝑚𝑎𝑔𝑒𝑛, denota las fuerzas de la imagen actuando en el spline; tiene tres componentes: líneas, bordes y terminaciones, que pueden ser representados como 𝐸𝑖𝑚𝑎𝑔𝑒𝑛 = 𝑤𝑙𝑖𝑛𝑒𝑎𝐸𝑙𝑖𝑛𝑒𝑎 +𝑤𝑏𝑜𝑟𝑑𝑒𝐸𝑏𝑜𝑟𝑑𝑒+𝑤𝑡𝑒𝑟𝑚𝐸𝑡𝑒𝑟𝑚. Los coeficientes w ajustan los pesos que se le darán a cada una de las características salientes en la imagen. 𝐸𝑙𝑖𝑛𝑒𝑎 es la intensidad de la imagen, que puede ser representada por 𝐸𝑙𝑖𝑛𝑒𝑎 = 𝐼(𝑥, 𝑦). Dependiendo del signo del coeficiente 𝑤𝑙𝑖𝑛𝑒𝑎, la línea se verá atraída por líneas oscuras o claras. 𝐸𝑏𝑜𝑟𝑑𝑒, con un alto coeficiente de peso, hará que el snake se vea atraído por contornos con grandes gradientes de imagen. 𝐸𝑡𝑒𝑟𝑚 considera las esquinas y terminaciones en una imagen. Las Figura 3.5 muestra un ejemplo de snakes segmentando efectivamente labios en distintas posiciones para hacer lip tracking. Las limitaciones de snakes son:  Dificultad para ajustar la curva sobre mínimos locales de energía.  A menudo obvian características de pequeño tamaño en la figura original, debido a que la minimización ocurre sobre todo el recorrido del contorno.  Su precisión está gobernada por los criterios de convergencia usados en la técnica de minimización de energía; mayor precisión requiere criterios de convergencia ajustados a la figura particular. Figura 3.5 - Contornos activos de snakes 3.2.3.2 Tijeras Inteligentes Los contornos activos permiten al usuario bosquejar de forma tosca una frontera de interés y 48 hacer que el sistema evolucione el contorno hacia una locación más certera. Sin embargo, los resultados de esta evolución pueden ser impredecibles y requerir guías adicionales por parte del usuario para lograr el resultado deseado. Un enfoque alternativo, es hacer que el sistema optimice el contorno en tiempo real a medida que el usuario dibuja, como el sistema de tijeras inteligentes [Mortensen95]. A medida que el usuario dibuja un bosquejo tosco (que corresponde a la curva blanca en la Figura 3.6) el sistema computa y dibuja una mejor curva que se adhiere a los bordes de alto contraste (la curva amarilla en la Figura 3.6). Figura 3.6 - Tijeras Inteligentes El usuario traza el contorno blanco. El sistema de tijeras inteligentes dibuja el contorno amarillo alrededor del objeto. Las curvas verdes muestran posiciones intermedias de evolución del live-wire. Para computar el camino óptimo de la curva (llamado live-wire), la imagen es primero pre- procesada para asociar bajos costos con bordes que tengan probabilidad de ser elementos de frontera. El sistema propuesto por Mortensen y Barrett, computa estos costos evaluando magnitudes y orientaciones de gradientes, así como puntos donde éste se cruza con cero. Luego, a medida que el usuario traza una curva tosca, el sistema continuamente recomputa el camino de costo mínimo entre el punto de semilla inicial y la ubicación actual del cursor que traza la curva, utilizando el algoritmo de Dijkstra [Dijkstra59]. Para prevenir que la curva salte de forma impredecible, el sistema “congelará” la curva, reiniciando el punto de semilla, luego de un período de inactividad. Para prevenir que el live-wire salte a regiones adyacentes de alto contraste, el sistema también “aprende” la intensidad de la curva actual y la usa para mantener al live-wire moviéndose a lo largo de una frontera similar. 49 3.2.3.3 Level-Sets Una limitación de las técnicas de tijeras inteligentes y snakes, es que es difícil cambiar la topología de la curva a medida que evoluciona a través de un contorno cerrado. Para enfrentar este problema, los métodos level-set consideran el(los) cruzamiento(s) de una función característica que define a la curva. Los level sets evolucionan para ajustar y registrar objetos de interés modificando una función de incrustación (que es otro nombre dado a la función característica) en lugar de la curva f(s) que considera snakes. Un ejemplo de función de incrustación, es la de contorno activo geodésico propuesto por Caselles et al. [Casselles97]: 𝑑Φ 𝑑𝑡 = |∇Φ|𝑑𝑖𝑣 (𝑔(𝐼) ∇Φ |∇Φ| ) = 𝑔(𝐼)|∇Φ|𝑑𝑖𝑣 ( ∇Φ |∇Φ| ) + ∇g(I) ∙ ∇Φ, Ec. 3.1 donde 𝑔(𝐼) es una versión generalizada del potencial de bordes de snakes. Un entendimiento intuitivo acerca del comportamiento de esta curva, es que la función de incrustación es una función de distancia con signo, que cuando se encuentra alejada de la curva, | Φ |=1, como se ilustra en la Figura 3.7. El primer término en la Ecuación 3.1 mueve la curva en la dirección de su curvatura, lo que la “endereza”, bajo la influencia de la función de modulación 𝑔(𝐼). El segundo término mueve la curva a lo largo del gradiente de 𝑔(𝐼), influenciando a la curva para que se mueva hacia los mínimos de 𝑔(𝐼). El primer término de la ecuación evita que la curva se quede atascada en mínimos locales, como comúnmente ocurre en snakes, y el segundo término hace que éstos no sean ignorados. Aun así, esto no solventa el problema de atascamiento en mínimos, debido a que depende de los gradientes de imagen, que son medidas locales, por lo que el método level-set es comúnmente parte de frameworks de segmentación en donde primero se usan métodos de medición de energía en la imagen, como el graph-cut. 50 Figura 3.7 - Evolución level-set para un contorno activo geodésico La función de incrustación Φ es actualizada en base a la superficie subyacente modulada por la función de bordes g(I) y su gradiente, haciendo que la curva sea atraída a bordes fuertes. 3.3 Cortes en Grafos Es una técnica de optimización combinatoria (flujo en redes), aplicada a la segmentación de imágenes [Boykov04]. La imagen es tratada como un grafo, donde cada píxel representa un nodo y las aristas entre ellos tienen un peso relativo a una función de energía. Para el caso de dos etiquetas (por ejemplo, objeto de interés y fondo), el etiquetado óptimo global (con respecto a la función de costo definida) puede ser eficientemente computado por algoritmos de max-flow/min-cut. Esta técnica puede ser aplicada a imágenes de N dimensiones. Dados algunos píxeles identificados por el usuario como objeto de interés y fondo, el resto de los píxeles pueden ser etiquetados automáticamente. Este grafo, que representa a la imagen, es modelado como una red de flujo. Todas sus aristas tienen un valor positivo (referenciando una capacidad de flujo) y existe una fuente S y un destino T. Un corte mínimo (min-cut) en una red de flujo, es una partición del grafo original en sub-conjuntos disjuntos, uno con el origen y otro con la fuente donde la capacidad de flujo (suma de valores de diferencia entre entrada y salida de flujo entre los nodos) sea la menor sobre todos los cortes posibles en la red. Como se ilustra en la Figura 3.8, cada vértice del grafo es conectado con sus 8-vecinos (para el caso de imágenes en 2D) a través de aristas no dirigidas llamadas N-links. Así, el peso de cada 51 arista corresponde a un costo por discontinuidad entre los píxeles. Adicionalmente, se agregan dos vértices especiales llamados la fuente s y el destino t. La fuente representa el objeto de interés a segmentar en la imagen, y el destino representa el fondo. Todos los vértices del grafo están conectados por una arista con la fuente y otra al destino, estas aristas son llamadas T-links y su valor corresponde al costo para etiquetar al vértice como parte de la fuente o el destino. A partir del grafo de flujo se calcula el corte mínimo que divide al grafo original en dos grafos disconexos, uno conectado al vértice fuente (objeto de interés) y otro al destino (fondo). Los otros vértices del grafo original se encuentran conectados a uno de estos dos grafos. Una limitación de este método es que sólo puede segmentar una imagen en dos conjuntos (K=2), objeto de interés y fondo. Además debe considerarse el costo considerable de almacenar en memoria el grafo y su información de conectividad, lo que limita el tamaño de las imágenes o volúmenes que pueden ser segmentados. Figura 3.8 - Graph-Cut (A) Píxeles modelados con flujo a fuente y destino en el grafo original. (B) Grafo separado por el corte mínimo. 3.3.1 GrabCut GrabCut es un método que extiende la usabilidad y poder de segmentación del algoritmo GraphCut, mediante el uso de modelos de mezclas gaussianas. Como se ilustra en la Figura 3.9, el usuario dibuja un rectángulo alrededor del objeto de interés, dando la primera aproximación del etiquetado final [Rother04]. Luego, cada paso de iteración colecta estadísticas de color, de acuerdo a 52 la segmentación actual, usando modelos de mezclas gaussianas (GMM, gaussian mixture model) para darle valor a los T-links que conectan los píxeles (o vóxeles, en el caso de volúmenes [Temoche11]), re-ponderando el grafo de la imagen, y aplica GraphCut para computar una nueva segmentación refinada. Figura 3.9 – Comparación entre GraphCut (izquierda) y GrabCut (derecha) En GraphCut, el usuario dibuja semillas denotando objeto de interés y fondo sobre la imagen. En GrabCut, se dibuja un rectángulo alrededor del objeto de interés para especificar la clase foreground en la segmentación. En GrabCut se tiene un valor de intensidad, llamado matte, que indica si el píxel/vóxel pertenece al objeto de interés o al fondo. Este valor varía a lo largo de la ejecución del algoritmo e indica si el píxel/vóxel pertenece al modelo de mezcla gaussiana del objeto de interés (foreground) o del fondo (background). Para cada píxel/vóxel,se almacena un número de componente gaussiano al que pertenece; este número, en conjunto con el matte, permite conocer a cual componente de los 10 creados ( 5 para el GMM foreground y 5 para el GMM background) pertenece el vóxel. Finalmente, se usan 3 marcas temporales para los píxeles/vóxeles llamadas trimaps. Dichas marcas pueden ser de un píxel/vóxel perteneciente al conjunto de fondo (background), objeto de interés (foreground) o desconocido (unknown) y son colocadas por el usuario. Los trimaps no varían a través de la ejecución del algoritmo, al menos que el usuario modifique su posición para corregir la segmentación. El algoritmo, paso a paso, puede describirse así [Temoche11]: a) El usuario sitúa un rectángulo (en el caso 2D) o un cubo (bounding box, para el caso 3D) que contenga el objeto a segmentar. Los píxeles/vóxeles fuera del área son marcados como trimap background y los vóxeles dentro del cubo son marcados como trimap unknown. 53 b) Los píxeles/vóxeles con trimap background son inicializados al valor de matte background, los píxeles/vóxeles con valor trimap unknown se inicializan al valor de matte foreground. c) Se crean dos GMMs, uno para foreground y otro para el background, cada uno con 5 componentes gaussianos. El GMM foreground se inicializa con píxeles/vóxeles de valor matte foreground, mientras que el GMM background se inicializa con los vóxeles de valor matte background. d) Cada píxel/vóxel en el GMM foreground, es asignado al componente gaussiano al que tenga mayor probabilidad de pertenencia. De igual manera, cada píxel/vóxel del GMM background es asignado al componente gaussiano al que tenga mayor probabilidad de pertenencia. e) Los GMMs son eliminados, y se crean unos nuevos a partir de la información obtenida anteriormente. Cada píxel/vóxel es asignado a su GMM respectivo (GMM foreground o GMM background) y al componente de ese GMM que fue asignado en el paso 4. f) Se construye el grafo y se consigue el min-cut. En base al resultado obtenido, se modifica el valor matte de algunos píxeles/vóxeles. Aquellos resulten conectados a la fuente quedan como matte foreground y los que resulten conectados al destino, como matte background. Al igual que GraphCut, GrabCut solo puede segmentar la imagen en dos conjuntos (K=2), objeto de interés y fondo. El almacenamiento en memoria del grafo con T-links es incluso más costoso que en el caso de GraphCut, debido al uso de los modelos de mezclas gaussianas. 3.4 Random Walker Este método de segmentación es aplicable para K ≥ 2 etiquetas en 2 ó 3 dimensiones, y determina la probabilidad de que un recorrido aleatorio, empezando en cada uno de los píxeles no etiquetados por el usuario, termine en uno de los píxeles etiquetados, asignando a cada píxel la etiqueta a la cual se le calcula mayor probabilidad de llegar al terminar el recorrido aleatorio. Un random walk es un proceso estocástico, en donde una partícula posicionada inicialmente en un nodo de un grafo se mueve hacia alguno de sus nodos adyacentes al paso de un intervalo de tiempo con igual probabilidad. Random Walker explota los paralelos entre la teoría de circuitos eléctricos y los recorridos aleatorios en grafos [Doyle84], modelando los recorridos aleatorios como el flujo de 54 electricidad a través de un circuito con resistencias pasivas lineales entre nodos correspondientes a pixeles, con la conectividad entre los nodos del grafo dada por la vecindad entre ellos, como se muestra en la Figura 3.10. Random Walker ofrece la ventaja de proporcionar segmentaciones que respetan las fronteras débiles (moteadas) entre objetos (ver Fig. 3.11). Otra de sus ventajas es, que a diferencia de GrabCut, permite más de 2 clases de segmentación (K=2) [Grady04]. Se representa la imagen como un grafo G = (V, E) con vértices 𝑣 ∈ 𝑉, correspondientes a pixeles/vóxeles y aristas 𝑒 ∈ 𝐸 ⊆ 𝑉𝑥𝑉, correspondientes a sus adyacencias. Una arista, 𝑒, que une dos vértices vi y vj es denotada por eij. La ponderación de una arista se denota por w(eij) o wij. El grado de un vértice es 𝑑𝑖 = ∑𝑤(𝑒𝑖𝑗) para todas las aristas eij incidentes en vi. Para interpretar wij como el sesgo/resistencia que afecta la elección de un camino aleatorio, se requiere que wij> 0. Para poder representar la estructura de la imagen con sesgos de camino aleatorio, es necesario definir una función que mapee los cambios en las intensidades de la imagen a pesos de sesgo/resistencia. El sesgo/resistencia entre nodos se deriva a partir de características de gradiente, color o textura. Por ejemplo, usando la intensidad de imagen gi en el nodo vi, es posible usar la siguiente función de ponderación de aristas [Grady04]: 𝑤𝑖𝑗 = exp (−𝛽(𝑔𝑖 − 𝑔𝑗) 2) donde gi indica la intensidad de la imagen en el pixel i. El valor de 𝛽 representa el único parámetro libre del algoritmo e indica el peso que se le dará a la diferencia de intensidades entre dos pixeles adyacentes. El sistema de ecuaciones se plantea en base a una matriz laplaciana 8 como 𝐿𝑣𝑖𝑣𝑗 { 𝑑𝑣𝑖 𝑠𝑖 𝑖 = 𝑗 −𝑤𝑖𝑗 𝑠𝑖 𝑣𝑖 𝑦 𝑣𝑗 𝑠𝑜𝑛 𝑛𝑜𝑑𝑜𝑠 𝑎𝑑𝑦𝑎𝑐𝑒𝑛𝑡𝑒𝑠 0 𝑒𝑛 𝑐𝑎𝑠𝑜 𝑐𝑜𝑛𝑡𝑟𝑎𝑟𝑖𝑜 Donde 𝐿𝑣𝑖𝑣𝑗 es usado para indicar que a matriz L es indexada por los vértices vi y vj. Los vértices son particionados en dos conjuntos, VM (nodos semilla/marcados) y VU (nodos no marcados) LM contiene todos los puntos semilla, sin importar su etiqueta. Luego la matriz L es reordenada para reflejar los subconjuntos 8 También llamada matriz de Kirchoff y matriz de admitancia, es una representación matricial de la conectividad y ponderación de un grafo. Se define como la diferencia entre la matriz de grados y la matriz de adyacencia L = D – A, siendo la matriz de grados la matriz diagonal que contiene el grado de cada vértice y la matriz de adyacencia la matriz que indica la conectividad mutua en los vértices del grafo. 55 𝐿 = [ 𝐿𝑀 𝐵 𝐵𝑇 𝐿𝑈 ] Se denota como 𝑥𝑖 𝑠 la probabilidad (potencial) asumido por cada nodo, vi para cada etiqueta s. Se define el conjunto de etiquetas para los nodos semilla como una función Q(vj)=s,∀𝑣𝑗 ∈ 𝑉𝑀 donde s ∈ 𝑍, 0 < 𝑠 ≤ 𝐾. Se define el vector de marcado |VM| x 1 (donde VM corresponde a la cardinalidad) para cada etiqueta, s, en el nodo vj∈ 𝑉𝑀 como 𝑚𝑗 𝑠 { 1 𝑠𝑖 𝑄(𝑣𝑗) = 𝑠 0 𝑠𝑖 𝑄(𝑣𝑗) ≠ 𝑠 El sistema se considera un problema de Dirichlet combinatorio, cuya solución puede encontrarse resolviendo 𝐿𝑈𝑥 𝑠 = −𝐵𝑚𝑠 que es un sistema de ecuaciones lineales simétrico, definido positivamente con numero |VU| de ecuaciones y un número de términos distintos a cero igual a 2|E|. Debido que LU está garantizada a ser no singular para un grafo no conectado, la solución x s está garantizada a existir y ser única, así que los potenciales eléctricos para todas las etiquetas en el sistema pueden ser encontrados resolviendo el sistema 𝐿𝑈𝑋 = −𝐵𝑀 donde X tiene columnas tomadas por cada x s y M tiene columnas dadas por cada m s , así que hay K- 1sistemas de ecuaciones lineales a resolver, donde K es el número total de etiquetas definidas por el usuario. 56 (a) b) c) d) Figura 3.10 - Random Walker a) Pixeles originales en una imagen, representados como nodos en un grafo con secciones de segmentación deseada indicada por fronteras curvas y etiquetas semilla L1, L2 y L3 suministradas por el usuario. Las resistencias entre nodos corresponden al módulo de gradiente entre ellos. La fuente de poder está en el nodo semilla siendo evaluado. b) Probabilidad de que un recorrido aleatorio empezando desde cada nodo alcance primero la semilla L1. c) Probabilidad de que un recorrido aleatorio empezando desde cada nodo alcance primero la semilla L2 d) Probabilidad de que un recorrido aleatorio empezando desde cada nodo alcance primero la semilla L3. 57 Figura 3.11 - Random Walker respeta las fronteras débiles (punteadas) Considérese esta imagen de 16x7 consistiendo de una frontera dura, representada por la línea negra gruesa, con un agujero y los dos puntos semilla en los círculos blanco y negro en los extremos de la imagen. Un recorrido aleatorio que inicie en un pixel cercano a la debilidad en la frontera (el centro de las cuatro flechas), tiene 3 de 4 posibilidades en su paso inicial de entrar a la región que será etiquetada como perteneciente al círculo negro. Debido a que lo mismo se mantiene válido para el otro lado de la frontera débil, la segmentación respetará la frontera, a pesar de que es débil. Un estudio comparativo por Rother et al. [Rother04], muestra que el método que se desempeña mejor en IRM es random walker, dejando atrás a la segmentación watershed y crecimiento de región por amplio margen, al evaluar métricas de calidad y robustez de la segmentación. La calidad de la segmentación obtenida con random walker es similar a la de graphcuts, pero el random walker es capaz de encontrar la solución de segmentación para un número de etiquetas >2. Sin embargo, el random walker se hace más lento en ejecución a medida que se aumenta el número de etiquetas por incluir, para cada nueva etiqueta, un nuevo sistema de ecuaciones a resolver para toda la imagen. 58 CAPÍTULO 4 - AUTÓMATAS CELULARES DETERMINISTAS PARA SEGMENTACIÓN DE IMÁGENES Un autómata celular es un modelo dinámico discreto, representado en un arreglo regular de celdas. Cada una de estas celdas se encuentra en uno de un número finito de estados posibles en un paso de evolución t. El arreglo de celdas puede tener cualquier número de dimensiones. Por cada celda del autómata, se define un conjunto de celdas adyacentes llamado vecindad. Un estado inicial para el autómata, es seleccionado asignando un valor escalar o una tupla de valores para cada celda. Se actualiza el estado del autómata generando una nueva generación de celdas en cada paso de evolución t, de acuerdo a alguna regla fija de evolución. Esta regla de evolución es una función matemática, que es evaluada en cada celda y determina su nuevo estado en términos de su estado actual y los estados de sus celdas vecinas. Típicamente, la regla de evolución se aplica simultáneamente en todo el arreglo de celdas y es invariable a lo largo del tiempo, aunque también pueden considerarse variaciones probabilísticas a las reglas y existen además los autómatas celulares asíncronos, con secciones de independencia temporal [Wolfram04]. Los autómatas celulares fueron primero estudiados por John von Neumann en 1947, cuando desarrollaba modelos de máquinas capaces de duplicarse a sí mismas, a través de una sucesión de pasos discretos. Los primeros autómatas de Von Neumann fueron modelados en dos dimensiones, con reglas complejas derivadas de la interpretación finita de ecuaciones diferenciales; poseían 29 estados posibles para cada celda. En la década de 1960, Stanislaw Ulam, antiguo colaborador de von Neumann, que había hecho numerosas sugerencias a sus estudios originales, implementó simulaciones basadas en autómatas celulares y observó que el uso de reglas simples de evolución era capaz de producir comportamientos complejos. Este fenómeno es conocido en las ciencias físicas como emergencia: la aparición de comportamientos complejos a partir de la interacción de agentes con comportamiento individual simple. Ulam argumentó la relevancia de este comportamiento en los autómatas celulares para el estudio de las ciencias naturales, particularmente la biología, señalando la variedad de procesos que operan en base a unidades elementales con estados dependientes del estado de otros elementos que se encuentren en su vecindad [vonNeumann66]. A partir de la década de 1980, Stephen Wolfram popularizó el estudio de los autómatas celulares como elementos para el modelado de sistemas complejos, a través del journal Complex Systems, y son famosos sus estudios postulando que “cualquier sistema que satisfaga ecuaciones diferenciales puede ser aproximado como un autómata celular introduciendo diferencias finitas y variables discretas” [Wolfram83]. 59 En el 2004, Matthew Cooke, investigador de Wolfram Research, publicó una demostración de la conjetura original de Wolfram acerca de la capacidad de una regla de autómata celular 1D para funcionar como máquina de cómputo universal, haciendo al autómata programable y capaz de calcular cualquier función computable [Cook04]. Un compendio de las investigaciones de Wolfram y otros autores, acerca de los autómatas celulares llamado “A New Kind of Science” fue publicado en el año 2002. Los autómatas han sido utilizados para modelar una amplia gama de sistemas dinámicos en variados dominios de aplicaciones. En tareas de procesamiento de imágenes, han sido usados para realzar bordes y eliminar ruido [Hernández96], [Popovici00] y segmentar y etiquetar imágenes [Vezhnevets05], [Kauffmann09], [Kim10]. El presente trabajo continúa la línea de investigación en autómatas celulares deterministas para segmentación de imágenes, iniciada por Vezhnevets et al [Vezhnevets05] y continuada por Kim et al [Kim10]. 4.1 Definición Formal y Entendimiento Intuitivo de Evolución Formalmente, un autómata celular determinista es una tripleta A = (S, N, δ), dónde S es un conjunto de estados no vacío que puede ser asignado a cada celda, N es el sistema de vecindad que afecta a todas las celdas y δ: S n → S es la regla de transición usada para generar una nueva generación de celdas en cada paso t. La función δ es usada para calcular la transición de estado de una celda p en un paso de evolución t hacia el paso de evolución t+ 1 en base a los estados de las celdas en la vecindad de p. Los sistemas de vecindad N usados para la segmentación de imágenes son la Vecindad Von Neumann (Figura 4.1a) y la Vecindad Moore (Figura 4.1b). En ambos casos, las figuras muestran la celda p a actualizar en rojo, y las celdas azules corresponden a la vecindad. Para tareas de segmentación de imágenes en 2D, el autómata tiene el mismo tamaño en dimensiones x, y que la imagen, y en 3D, la misma dimensión x, y, z que el volumen. La única variación formal en las reglas de evolución para los autómatas entre el caso 2D y el caso 3D, son los sistemas de vecindad considerados. La Figuras 4.2 y 4.3 muestran los sistemas de vecindad Von Neumann y Moore utilizados en volúmenes. 60 (a) b) Figura 4.1 – Vecindad de Celdas a) Vecindad Von-Neumann 2D (“Vecindad 4”). b) Vecindad Moore 2D ("Vecindad 8") Figura 4.2 - Vecindad Von Neumann 3D “doble cruz” La figura a la derecha muestra en verde a la celda actual p. Figura 4.3 - Vecindad Moore 3D, “cubo” La figura a la derecha muestra en verde a la celda actual p. 4.2 Regla GrowCut El trabajo de Vezhnevets [Vezhnevets05], propuso la siguiente regla de evolución para un autómata celular determinista diseñado para la segmentación de imágenes: 61 // para cada celda for ∀𝑝 ∈ 𝑃 // Copiar estado previo ; 1 t p t p EE   ; 1 t p t p    // los vecinos atacan a la celda actual for ∀𝑞 ∈ 𝑁(𝑝) if t p t qqp IIg   )||(|| 2 t q t p EE  1  1t p  t qqp IIg  )||(|| 2 end if end for end for Algoritmo 4.1 - “GrowCut” Aquí, q es el índice que representa al vecino de la celda p que está siendo evaluado. En esta regla, g es una función monótona decreciente acotada a [0,1] y representada por 2 ||||max 1)( I x xg  El estado de cada celda p del autómata, es una tupla (Ep, θp, 𝐼p), donde Ep representa la etiqueta de la celda, θp representa la fuerza que posee esta etiqueta en la celda e 𝐼p representa un vector de características propias de cada píxel, como su intensidad en nivel de gris, su vector RGB, o una combinación de niveles digitales [Vezhnevets05], [Kim11]. Se puede utilizar una metáfora biológica como explicación intuitiva al comportamiento de la regla de evolución del autómata. Es válido interpretar el proceso de evolución de celdas como el crecimiento competitivo, en busca de dominación espacial, de K tipos de bacterias. Las bacterias intentan reproducirse a partir de su posición original en las celdas semilla y ocupar el resto del espacio de la imagen. En cada intervalo discreto de tiempo, cada celda es atacada por sus vecinas. 62 La fuerza de los ataques realizados está definida por el parámetro θq en la celda atacante q y la distancia entre los vectores de niveles digitales de la imagen 𝐼p e 𝐼q. A mayor cercanía de características en la imagen entre celdas vecinas, mayor es la fuerza de ataque de una celda qa su vecina defensora p. Si la fuerza de ataque es mayor que la fuerza de la celda defensora, la celda defensora p es conquistada y su estado para el paso de evolución t + 1 se actualiza con la etiqueta de la celda atacante q. La nueva fortaleza de p es la fuerza del ataque con que fue conquistada. Para lograr segmentar la imagen, deben haber al menos 2 celdas con etiquetas E distintas, y fuerzas θ asignadas antes que el autómata empiece su evolución. Estas celdas iniciales con etiqueta y fuerza asignadas, reciben el nombre de semillas y la calidad de la segmentación obtenida depende del criterio usado para seleccionarlas. Las semillas pueden ser seleccionadas tanto de forma manual [Vezhnevets05], [Kim10], como automática [Torres13]. La Figura 4.4 muestra una segmentación obtenida usando un autómata celular determinista lograda utilizando semillas seleccionadas manualmente (Figura 4.4b) sobre una foto de canales RGB con la intención de dividirla en foreground (puntos de interés, en azul) y background (fondo, en rojo). La Figura 4.4c muestra el estado de las etiquetas del autómata al terminar su evolución, y la Figura 4.4d muestra la aplicación de la máscara de la Figura 4.4c para segmentar la foto original, marcando el background en gris. a) b) c) d) Figura 4.4: Segmentación Asistida con GrowCut a) Imagen Original. b) Semillas para foreground / background. c) Máscara de Segmentación. d) Resultado La Figura 4.5 muestra el proceso de evolución de las celdas en el autómata a través de t = 90 pasos para el mismo caso de segmentación. Se usan distintas semillas a las presentadas en la Figura 4.4b, demostrando la robustez del método al arrojar un resultado de segmentación consistente y una alta sensibilidad y precisión en la clasificación. 63 a) t = 0 b) t = 30 c) t = 50 d) t = 90 e) Resultado Figura 4.5: Evolución del Autómata GrowCut 4.3 Ventajas de Implementación y Capacidades de Paralelismo de los Autómatas Celulares Deterministas A diferencia de otros métodos de segmentación de imágenes multietiqueta, como random walker [Grady04], en los autómatas celulares deterministas, el uso de más de 2 clases de segmentación no incrementa el tiempo el tiempo de cómputo necesario para obtener un resultado. Una ventaja importante del paralelismo inherente a los autómatas, es que en ellos la evolución de cada celda puede ser modelada como un hilo de cómputo independiente. Esta característica de paralelismo inherente es ampliamente explotable en las arquitecturas de GPUs programables modernas. La evolución determinista de los autómatas, garantiza que los resultados obtenidos en una implementación serial en un programa convencional de CPU serán iguales a los obtenidos en un GPU, característica que no se cumple en métodos como GrabCut implementado en GPU [Temoche11]. Otra fortaleza del método basado en autómatas celulares deterministas, es que al generar las clasificaciones a nivel de píxel para K clases, se generan simultáneamente K mapas de fuerza. Estos mapas de fuerza indican el nivel calculado de pertenencia de cada celda de la imagen a su etiqueta asignada l. Resulta de particular interés en los mapas fuerza, resaltar aquellas regiones con menor nivel de fuerza al terminar la evolución del autómata, ya que estas naturalmente corresponden a las fronteras entre elementos de distintas clases, como se muestra en la imagen satelital en la Figura 4.6. 64 Figura 4.6 – Fronteras En este caso el autómata evolucionó para generar clasificaciones a nivel de píxel para 45 clases de terreno. Aquí, las celdas con menor probabilidad de ser los terrenos clasificados, se convierten en fronteras. Las celdas marcadas en rojo son aquellas con fuerza final inferior a 0.9 para la etiqueta de terreno asignado. 4.3 Contribuciones En este trabajo se proponen modificaciones al algoritmo GrowCut que afectan cualitativamente y cuantitativamente a las segmentaciones obtenidas. Estas son presentadas a continuación. 4.3.1 Corrección a GrowCut Con una apropiada selección de las semillas, la regla GrowCut produce buenas segmentaciones, a pesar de que posee un error en la condición t p t qqp IIg   )||(|| 2 , que afecta numerosos casos de borde. Esta condición hace que la celda p tome la etiqueta de la última celda vecina q que logre vencerla. Esto debe cambiarse a 1 2 )||(||   t p t qqp IIg  para que la celda p tome la etiqueta de la celda más fuerte que logre vencerla, sin importar el orden en que fue evaluada como vencedora. Además, la función g(x) puede considerar una distancia entre niveles digitales distinta a la euclidiana. Una regla de evolución de autómata celular, que corrige el error de evaluación e incluye un criterio de parada se presenta como el Algoritmo 2. 65 A = true while(A) A = false // para cada celda for Pp // Copiar estado previo t p t p EE  1 t p t p   1 // los vecinos atacan a la celda actual for )( pNq if 1 2 )||(||   t p t qqp IIg  t q t p EE  1  1t p  t qqp IIg  )||(|| 2 A = true end if end for end for end while Algoritmo 2 – Regla 2 “GrowCut Corregido” Autómata celular que determina evolución a partir de mejores vencedores y garantiza convergencia. La distancia entre niveles digitales x, definida aquí en forma euclidiana como 2 |||| qp II  , puede interpretarse de forma generalizada como cualquier medida de distancia entre vectores. 4.3.2 Criterio de Convergencia El criterio de parada en la Regla 2 está representado por la variable A, que se inicializa a falso en cada paso t de la evolución del autómata, antes de empezar la evaluación de celdas. Esto se cambia a verdadero, si al menos una celda cambia de estado durante el paso t. Un criterio de parada distinto, consiste en detener la evolución del autómata cuando todas las celdas han recibido una etiqueta. Este criterio puede producir segmentaciones iguales a las descritas en el Algoritmo 2, pero esto no está garantizado y depende del posicionamiento de las semillas. Este segundo criterio resulta útil para detener el algoritmo rápidamente y su diferencia con la evolución completa, descrita en el Algoritmo 2, tiende a ser marginal. Este criterio se presenta en el Algoritmo 3. 66 celdas_sin_etiqueta = celdas_del_volumen – celdas_semilla while(celdas_sin_etiqueta>0) // para cada celda for Pp // Copiar estado previo // los vecinos atacan a la celda actual for if 1)(  t p t q xg  if nullE t p  1 celdas_sin_etiqueta = celdas_sin_etiqueta -1; end if t q t p EE  1 t q xg )( end for end for end while Algoritmo 3 - “GrowCut Corregido” con convergencia por criterio de todas las celdas etiquetadas Un tercer criterio de parada, es detener la evolución del autómata una vez que todas las celdas han recibido una etiqueta y el número de celdas que permanecen sin cambio entre los pasos de evolución está por encima de un umbral deseado (por ejemplo, si 95% ó 99% de las celdas permanecen sin cambio en dos t consecutivos). Estas condiciones de parada, distintas a la que aparecen en el Algoritmo 2, son heurísticas útiles para reducir el tiempo de cómputo. 4.3.3 Variaciones en la Fuerza de Ataque Debido a que el término de fortaleza en las celdas del autómata es actualizado con base en la fuerza de los ataques de las celdas vecinas, resulta de interés la operación numérica que es realizada para determinar cómo se calcula la fuerza de los ataques. A continuación se presentan opciones a los ; 1 t p t p EE   ; 1 t p t p    )( pNq  1t p  67 criterios para determinar fuerzas de ataque entre celdas. 4.3.3.1 Distancias entre Niveles Digitales En la regla de evolución GrowCut, propuesta en el trabajo de Vezhnevets et al. [Vezhnevets05], se utiliza la distancia euclidiana de la intensidad de celdas vecinas para calcular la fortaleza de los ataques entre celdas vecinas. Otras medidas de distancia pueden ser utilizadas para calcular fortaleza de ataques. Figura 4.7 - Medidas de Distancia Aplicables a los Niveles Digitales en la Imagen La distancia entre los niveles de intensidad de celdas vecinas es un factor invariante durante la evolución del autómata, por lo que las distancias pueden ser pre - calculadas antes del primer paso de evolución. Esto resulta útil para reducir el tiempo de cómputo de evolución, especialmente al utilizar medidas de distancias que involucren mayor número de operaciones aritméticas. 4.3.2.2 Consideración de Nivel Digital en la Celda de la Imagen Multicanal como Escalar o Vector En los datos multicanal, se puede elegir reducir la dimensionalidad del vector representativo de los niveles digitales a un escalar, usando una operación de norma o combinando los canales a 68 través de análisis de componentes principales. 4.3.2.3 Penalización de Fuerza de Ataque en Base a Distancia a la Media de Nivel Digital para una Etiqueta El trabajo de Kim et al [Kim10], presenta una regla de evolución con penalización de fuerza de ataque, basada en estadísticas de nivel digital medio y desviación estándar de las celdas semilla. La penalización exponencial al ataque, ocurre cuando la celda invasora tiene un nivel digital que se aleja (según distancia euclidiana) en más de una desviación estándar a la media de nivel digital de las semillas correspondientes a su etiqueta. Esto se expresa en los siguientes modificadores condicionales a la función de fuerza de ataque g(x), que aquí tiene como parámetros adicionales a la distancia euclidiana entre los niveles digitales de p y q, (expresado por x), μEq y σEq denotan la media y la desviación estándar de la etiqueta E en el vóxel q, respectivamente. 𝑔(𝑥, 𝜇𝐸𝑞 , 𝜎𝐸𝑞) = { 1 − ( 𝑥 𝑤1 ∗ max|𝐼| ) 𝑠𝑖 |𝐼𝑞 − 𝜇𝐸𝑞| < 𝜎𝐸𝑞 1 − ( 𝑥 𝑤1 ∗ max|𝐼| ) (𝑒(−𝑤2∗ (|𝐼𝑞−𝜇𝐸𝑞|)−𝜎𝐸𝑞)) 𝑠𝑖 |𝐼𝑞 − 𝜇𝐸𝑞| ≥ 𝜎𝐸𝑞 Ec. 4.1 - Criterio de penalización exponencial de fuerza de ataque Si se cumple la desigualdad |Iq – μEq| < σEq, la celda vecina que ataca a la celda actual tiene un valor de nivel digital que está dentro de una desviación estándar del nivel digital de la etiqueta, asignándose entonces una fortaleza de ataque a q sin penalización. Si ocurre el caso contrario, que |Iq – μEq| ≥ σEq, la distancia euclidiana entre los niveles digitales de p y q es superiora σEq, haciendo que la fortaleza de un ataque vecino baje exponencialmente con penalización (𝑤2 ∗ (|𝐼𝑞 − 𝜇𝐸𝑞|) − 𝜎𝐸𝑞). Esta penalización de ataque puede resultar extremadamente violenta, por ser exponencial y tener un efecto acumulativo entre celdas espacialmente próximas, que se alejen de la desviación estándar (estas celdas representan una proporción del 31.8% de la población total de celdas, como se muestra en la Figura 4.9 ) y con datos no escalados es capaz de introducir errores numéricos por underflow, ya que los valores producidos tienen alta probabilidad de estar por debajo del rango de valores soportados en el estándar IEEE 754, como se ilustra en la segmentación obtenida en la Figura 4.8b. 69 a) b) Figura 4.8 – Problema de Evolución en la Penalización Exponencial a) Imagen de resonancia magnética producida por TumorSim en modalidad FLAIR. b) Segmentación obtenida utilizando la regla de evolución propuesta por Kim et al. para 2 clases: tumor y background; las secciones en negro indican celdas sin etiqueta, en donde los ataques se anularon, impidiendo la convergencia del autómata. Los pesos w1 y w2, usados en la función 𝑔 ∗(𝑥, 𝜇𝐸𝑞, 𝜎𝐸𝑞) son definidos por el usuario. En el trabajo de Kim et al. [Kim10], se menciona que fijar w1 > 1hace disminuir el efecto de las diferencias de intensidad, mientras que colocar w2 > 1 incrementa exponencialmente el efecto de las diferencias de intensidad. Estos efectos no están relacionados de forma proporcional, debido a que w2 afecta sólo los casos de ataque en donde ocurre penalización de forma exponencial y w1 afecta a todos los casos de ataque de forma lineal. En las pruebas realizadas durante este trabajo, se encontró que controlar los efectos de manipulación de w1 y w2 en las segmentaciones obtenidas es difícil, poco significativo y poco práctico. El trabajo de Kim et al., no presenta un estudio comparativo de los efectos en la calidad de segmentación al variar los valores de w1 y w2 y solo presenta resultados de segmentación cuando ambos valores han sido fijados en 2.0. 70 Figura 4.9 - Distribución de la población de etiquetas según el teorema central del límite. Al menos 31.8% de los datos auténticamente correspondientes a una misma etiqueta se encuentran a más de una desviación estándar de la media de intensidad presente en las semillas y este porcentaje aumenta en una clase de segmentación “background”, que es típicamente heterogénea. Debido a que las intensidades entre vóxeles vecinos tienden a ser numéricamente cercanas, la penalización exponencial propuesta por Kim et al. para determinar la fortaleza de las celdas debe considerarse excesiva. Este trabajo propone una regla alterna de evolución que elimina los errores numéricos durante la evolución del autómata celular y que incrementa la sensibilidad y especificidad en las segmentaciones obtenidas, manteniendo el elemento de información estadística en las semillas. Esta regla de evolución se basa en la penalización lineal de fuerza de ataque y se presenta en la Ecuación 4.2: 𝑔∗(𝑥, 𝜇𝐸𝑞 , 𝜎𝐸𝑞) = { 1 − ( 𝑥 max|𝐼| ) 𝑠𝑖 |𝐼𝑞 − 𝜇𝐸𝑞| < 𝑛 ∗ 𝜎𝐸𝑞 1 − ( 𝑥 max|𝐼| ) ∗ ( 𝜎𝐸𝑞 |𝐼𝑞 − 𝜇𝐸𝑞| ) 𝑠𝑖 |𝐼𝑞 − 𝜇𝐸𝑞| ≥ 𝑛 ∗ 𝜎𝐸𝑞 Ecuación 4.2 -Penalización lineal a la fuerza de ataque de la celda enemiga cuya intensidad está a más de n desviaciones estándar de la media de intensidad en las semillas de su etiqueta correspondiente 71 𝑔∗(𝑥, 𝜇𝐸𝑞 , 𝜎𝐸𝑞) = { 1 − ( 𝑥 max|𝐼| ) 𝑠𝑖 |𝐼𝑞 − 𝜇𝐸𝑞| < 𝑛 ∗ 𝜎𝐸𝑞 1 − ( 𝑥 max|𝐼| ) ∗ 𝑐1 𝑠𝑖 (|𝐼𝑞 − 𝜇𝐸𝑞 | ≥ 𝑛 ∗ 𝜎𝐸𝑞) 𝑦 (|𝐼𝑞 − 𝜇𝐸𝑞| < (𝑛 + 1) ∗ 𝜎𝐸𝑞) 1 − ( 𝑥 max|𝐼| ) ∗ 𝑐2 𝑠𝑖 |𝐼𝑞 − 𝜇𝐸𝑞| ≥ (𝑛 + 1) ∗ 𝜎𝐸𝑞 Ecuación 4.3 -Penalizaciones constantes a la fuerza de ataque de la celda enemiga cuya intensidad está a más de n desviaciones estándar y a más n + 1 desviaciones estándar de la media de intensidad en las semillas de su etiqueta correspondiente. Ck está en el intervalo (0,1) y C2 > C1. Esta regla resulta de utilidad para segmentar conjuntos con elementos que comparten una etiqueta a pesar de poseer niveles digitales heterogéneos que estén sobrerepresentados en el espacio de la imagen. Kim et al. [Kim10] propuso que el análisis estadístico de la media y desviación de los niveles digitales correspondientes a una etiqueta fuera realizado únicamente a partir de las celdas semilla, esto resulta inconveniente con una distribución sesgada de las celdas semilla. Las reglas de evolución basadas en información estadística presentes en este trabajo actualizan la media y desviación estándar de los niveles digitales correspondientes a una etiqueta en cada paso de evolución del autómata para atacar este problema. 4.3.3 AutomaClass, Configuración No Supervisada del Estado Inicial del Autómata Una importante fortaleza de los autómatas celulares deterministas, es su capacidad para segmentar una imagen 2D o volumen en K >= 2 clases (pudiendo ser K >> 2) sin que esto afecte negativamente el tiempo de cómputo requerido para obtener una segmentación. Además, por análisis espectral, puede fijarse automáticamente la posición espacial de las semillas de segmentación [Torres13]. En general, al seleccionar las semillas para un autómata celular determinista, de forma automática o supervisada, se busca satisfacer 2 criterios: 1) Que las semillas seleccionadas sean representativas de la distribución espacial de los elementos salientes de la imagen 2) Que las semillas seleccionadas sean representativas de la diversidad de niveles digitales presentes en la imagen La Figuras 4.11 muestran semillas seleccionadas de forma automática, obtenidas mediante el algoritmo de selección no supervisada de semillas, descrito a continuación, en una tarea de clasificación de uso del suelo, con semillas correspondientes a 45 clases en una imagen satelital multiespectral capturada por el satélite Miranda y el resultado final de segmentación. 72 a) b) Figura 4.10- Imágenes Satelitales a) Imagen de entrada, terrenos en Acarigua, Estado Portuguesa. Imagen multiespectral, capturada por el satélite Miranda en color verdadero (R, G, B). b) Muestra la imagen multiespectral en falso color infrarrojo, canales G, B, Infrarrojo Cercano. Figura 4.11 – Semillas correspondientes a 45 clases de terreno, generadas automáticamente por AutomaClass [Torres13] 73 a) b) Figura 4.12 – Modificación de Granularidad de Segmentación a) Segmentación de grano fino correspondiente a 45 clases de firmas espectrales, clasificación realizada con las cuatro bandas disponibles en imagen multiespectral, incluyendo infrarrojo cercano. b) Segmentación de grano grueso, correspondiente a las mismas 45 clases, obtenida reiniciando la evolución del autómata celular en aquellos segmentos con menos de 150 píxeles. El método AutomaClass propuesto originalmente en Segmentación No Supervisada de Imágenes Multiespectrales Utilizando Autómatas Celulares [Torres13], subdivide el espacio de niveles digitales correspondiente a N canales de imagen, de acuerdo al siguiente procedimiento: 1) Para cada píxel/vóxel multicanal se determina la suma de los niveles digitales en sus canales y se establece un número de rangos representativos de las características de la imagen, como se muestra en la Figura 4.13, que presenta un histograma de la suma de canales. La Figura 4.14 muestra un ejemplo que considera 2 canales, B1 y B2. La recta azul representa la localización en B1 y B2 de los píxeles cuyos valores suman P1 y la recta roja representa la localización de los píxeles cuyos valores suman P2. En dimensiones superiores (usando 3 o más canales) estas rectas serían reemplazadas por planos o hiperplanos. 2) Los píxeles / vóxeles multicanal que poseen la misma suma de niveles digitales en sus canales componentes, son discriminados de acuerdo al nivel digital predominante en cada canal de la imagen. En el caso bidimensional mostrado en la Figura 4.14, la región R2 corresponde a píxeles/vóxeles con valores semejantes en los dos canales considerados. Las regiones R3 y R1 agrupan píxeles donde predomina el canal 1 ó 2, respectivamente. 74 Figura 4.13 – Selección de Semillas a Través de Firma Espectral Histograma umbralizado con los rangos de selección de las semillas (barras negras, correspondientes a los percentiles de valores en este caso). El eje X representa el valor de la suma de los 4 canales considerados en el ejemplo, el eje Y representa el número de píxeles en la imagen que comparten un valor X de suma. Los píxeles que comparten un mismo valor de suma de canales son divididos en distintas regiones de acuerdo al criterio expresado en la Figura 4.14 Figura 4.14 - Regiones de semillas (R1, R2, R3) seleccionadas al utilizar 2 canales (B1, B2) en 2 secciones de píxeles con niveles digitales que comparten suma (P1, P2) 75 La Figura 4.15 ilustra el procedimiento para un corte de IRM co-registrado. (a) b) c) Figura 4.15 - AutomaClass para IRM a) Visualización de la suma de los canales FLAIR, T1, T1Gad y T2 en un corte producido por TumorSim. b) Semillas obtenidas a partir de la división umbralizada de niveles digitales. c) Segmentación obtenida. 76 CAPÍTULO 5 – DETALLES DE IMPLEMENTACIÓN Para el desarrollo de este trabajo especial de grado se utilizaron las siguientes herramientas: Matlab 2013a: Matlab es un ambiente de cómputo numérico y un lenguaje de programación desarrollado por Mathworks. Las prestaciones de cómputo de matrices que posee son de alta utilidad para el análisis de imágenes. Matlab incluye una amplia variedad de toolboxes y permite la interfaz directa con C, C++ y CUDA. CUDA 5: Plataforma de cómputo heterogéneo, desarrollada por Nvidia, la cual permite programar funciones (kernels) que se ejecuten de forma paralela en GPU. TumorSim: Simulador de tumores que produce una verdad fundamental acerca de la extensión y posición de un tumor simulado en IRM, con materia blanca, materia gris, fluido cerebroespinal, tumor y edema. TumorSim genera imágenes sintéticas en los canales T1, T1Gad, T2 y FLAIR. TumorSim genera sus simulaciones en archivos .mha que pueden ser convertidos a formato DICOM. La aplicación fue desarrollada para Windows 7, en arquitectura Intel y tarjetas gráficas Nvidia con Compute Capability superior a 1.3. 5.1 Implementación de Autómatas Celulares Deterministas en Matlab Se aprovecharon las siguientes capacidades de Matlab 2013a:  Carga y escritura de archivos en formato DICOM.  Múltiples funcionalidades del Image Processing Toolbox fueron aprovechadas durante las fases de implementación y pruebas: aplicación y edición de mapas de color, filtros de realce de bordes, métricas de área de segmentos, estadísticas de píxeles en la imagen y visualización detallada de regiones ampliadas.  Uso de las librerías de análisis de componentes principales.  Volúmenes desplegados usando las librerías de isosuperficies integradas.  Creación de interfaz de usuario a través del módulo GUIDE. 77  Llamada a kernels de cómputo CUDA, a través de la interfaz CUDAKernel. 5.2 Implementación de Autómatas Celulares Deterministas en CUDA Para eliminar condiciones de carrera que generen indeterminismo en la evolución del autómata, se hace que el kernel CUDA, encargado de la evolución de las celdas, compute un solo de paso de evolución a la vez. Además, cada thread de ejecución representa a una celda defensora, encargada de evaluar los ataques realizados contra ella en su vecindad. En memoria global, se almacenan los estados de las celdas en los pasos de evolución t y t+1. En las implementaciones de reglas de evolución realizadas, se aprovechó la capacidad de Matlab 2013a para llamar a los kernels CUDA desde un programa host, usando la interfaz CUDAKernel. En el código de kernel CUDA que se presenta a continuación, se implementa la Regla “Growcut Corregido” de la sección 4.5.1, utilizando el sistema de vecindad Von Neumann 3D. Cada thread (celda defensora p) evalúa el estado de celdas en su vecindad en el paso t, leyendo los estados de su vecindad en los arreglos d_strength y d_label. La celda defensora calcula la fuerza del ataque generado por sus vecinas y actualiza su propio estado en d_new_strength y d_new_label(correspondientes al estado de la celda para t+1). Con este patrón de acceso a memoria, sólo un thread a la vez escribe en una misma posición de los arreglos d_new_strength y d_new_label. Las lecturas para calcular ataques son realizadas en los arreglos del paso anterior, eliminando cualquier posibilidad de indeterminismo en la ejecución. __global__ void evol_cells(const float *d_imdata, const float *d_strength, const unsigned char *d_label, float *d_new_strength, unsigned char *d_new_label, unsigned char *still_updating, const int xDim, const int yDim, const int zDim, const float max_I) { unsigned int x = blockDim.x * blockIdx.x + threadIdx.x; unsigned int y = blockDim.y * blockIdx.y + threadIdx.y; unsigned int z = blockDim.z * blockIdx.z + threadIdx.z; 78 if ( (x >= xDim) || (y >= yDim) || (z >= zDim) ) return; unsigned int offset = x + xDim*y + (xDim*yDim*z); /* cálculo de coordenadas offset de la vecindad Von Neumann 3D */ int left = (x-1) + xDim*y + (xDim*yDim*z); int right = (x+1) + xDim*y + (xDim*yDim*z); int top = x + xDim* (y-1) + (xDim*yDim*z); int bottom = x + xDim*(y+1) + (xDim*yDim*z); int front = x + xDim*y + (xDim*yDim*(z-1)); int back = x + xDim*y + (xDim*yDim*(z+1)); /*Inicialización de valores locales*/ int neigh = -1; float gfunc = -1.0f; float eval_product = -1.0f; /*inicializa marcador de convergencia local*/ still_updating[offset]=0; /*chequear vecino izquierdo, las operaciones marcadas como región eval se repiten en los otros vecinos*/ if (x!=0){ neigh = left; /*empieza región de evaluación de ataque*/ gfunc = 1.0f - (abs(d_imdata[offset] - d_imdata[neigh]) / max_I); eval_product = gfunc * d_strength[neigh]; /*evaluar si la celda p es vencida por la mayor fuerza de ataque evaluada hasta el momento*/ if( ( eval_product > d_strength[offset]) && ( eval_product > d_new_strength[offset] ) ){ d_new_strength[offset] = eval_product; d_new_label[offset] = d_label[neigh]; /*actualizar marcador de convergencia*/ still_updating[offset]=1; } /*fin región eval*/ } /*termina evaluación de ataque de celda vecina*/ /*repetir evaluación de ataque en las celdas vecinas restantes*/ } } Código 5.1 – Kernel de Evolución de Celdas Para continuar la evolución del autómata garantizando ejecución determinista, se aprovecha 79 la característica de barrera implícita entre kernels del modelo de ejecución CUDA. Todos los threads del kernel anterior deben haber terminado su ejecución, antes de que se empiece la ejecución de este kernel de transición, que se encarga de asignar el estado t + 1 calculado en el paso anterior a los arreglos del estado t, como aparece en el Código 5.1 __global__ void transition_step(const float *d_new_strength, const unsigned char *d_new_label, float *d_strength, unsigned char *d_label, const int xDim, const int yDim, const int zDim ) { unsigned int x = blockDim.x * blockIdx.x + threadIdx.x; unsigned int y = blockDim.y * blockIdx.y + threadIdx.y; unsigned int z = blockDim.z * blockIdx.z + threadIdx.z; if ( (x >= xDim) || (y >=yDim) || (z >= zDim) ) return; unsigned int offset = x + xDim*y + (xDim*yDim*z); /*actualizar paso anterior*/ d_strength[offset] = d_new_strength[offset]; d_label[offset] = d_new_label[offset]; } Código 5.2 – Kernel de Transición Estos dos kernels son llamados en sucesión alternada por el programa host, hasta que el autómata converge y los cambios evolutivos desaparecen. La convergencia del autómata celular se determina a través del arreglo still_updating. Cada thread en evol_cells() fija su posición en still_updating a 0 antes de evaluar los ataques de las celdas en su vecindad y sólo cambia el valor de esta posición a 1 si alguna de las celdas atacantes logra vencer a la celda defensora. En el programa host de Matlab, se aprovecha la función nnz() integrada a las capacidades de gpuArray, para detener condicionalmente la llamada a los kernels evol_cells() y transition_step(); nnz(still_updating) retorna 0 en caso de que ninguna celda del autómata haya cambiado su estado entre pasos de evolución. 80 5.3 Interfaz Gráfica para Segmentación Asistida Se implementó una interface gráfica en Matlab para visualizar cortes de resonancia magnética y definir semillas de segmentación manualmente. Se usó el programa ReadData3D, obtenido a través del FileExchange de Mathworks, para realizar la carga de datos. Este programa permite cargar y guardar archivos en formato DICOM e Insight Meta-Image (.mha, producido por TumorSim), además permite re - escalar los datos, para llevarlos a unidades Hounsfield, como aparece en la Figura 5.1. Figura 5.1 - Interface gráfica de ReadData3D para la carga de volúmenes 81 Figura 5.2 - Interfaz gráfica para definir semillas de segmentación Se permite al usuario definir niveles de certidumbre en las semillas como un parámetro de fuerza inicial acotado entre 0.1 y 1. 82 CAPÍTULO 6 - PRUEBAS Y RESULTADOS En este capítulo se presentan pruebas de calidad de segmentación, con un dataset de prueba real, etiquetado por un operador humano experto, y dos datasets sintéticos obtenidos mediante TumorSim. Los computadores utilizados en las pruebas fueron los siguientes: a) C1: Procesador Intel Core I7 con 8 Gb de RAM y 3.40 GHz, GPU Nvidia GTX 650. b) C2: Procesador Intel Core 2 Duo con Gb de RAM, GPU Nvidia GT 520. Se utiliza una metodología de comparación enfrentando la calidad de las segmentaciones obtenidas en base a la comparación de parámetros que afectan la evolución del autómata. La calidad de las segmentaciones obtenidas se evalúa en base a las métricas presentadas en la Sección 2.5. Formalmente, cada variación de parámetros corresponde a una regla distinta de evolución de autómata celular. Se realizan las siguientes comparaciones:  Segmentaciones obtenidas mediante 3 criterios distintos de dispersión de semillas en el volumen: posicionamiento contiguo en un mismo corte, posicionamiento aleatorio en un mismo corte, posicionamiento aleatorio en todo el volumen.  Segmentación obtenida mediante convergencia completa del autómata frente a convergencia por criterio de celdas etiquetadas.  Calidad de las segmentaciones obtenidas al suministrar distintos porcentajes de semillas correctas.  Segmentación obtenida mediante vecindad Von Neumann frente a segmentación obtenida mediante vecindad Moore.  Segmentaciones obtenidas mediante las reglas de evolución GrowCut, “GrowCut corregido”, la regla de evolución propuesta por Kim et al. [Kim10] y las reglas de evolución con penalización lineal de fuerza de ataque y penalización constante de fuerza de ataque.  Segmentaciones obtenidas mediante distintas combinaciones de canales de IRM.  Segmentación obtenida mediante distintos rangos de selección de semillas utilizando el 83 algoritmo AutomaClass, detallado en la Sección 4.5.3. 6.1 Bounding Box de Validación En todos los casos de comparación de calidad de segmentación, se han calculado las métricas en base a un bounding box generado a partir de los límites de presencia de celdas de tumor y edema en la verdad fundamental de los cortes evaluados y la segmentación que da el algoritmo, se utiliza una “caja de validación” que contiene a ambas. El bounding box es determinado a partir de los menores límites inferiores y los mayores límites superiores en cada uno de los ejes x, y, z. Se utiliza este bounding box debido que las celdas background (espacio vacío y tejido sano) típicamente sesgan las métricas de calidad de segmentación, por constituir un porcentaje ampliamente dominante del volumen total. Por ejemplo, para el dataset HG0022, del BRATS 2012, el número total de celdas identificadas como tumorales en la verdad fundamental es 34973 (0.40% de las celdas totales) y el número de celdas identificadas como edema es 496333 (0.57 % de las celdas totales), mientras que las celdas identificadas como background son 8643864 (99.03% de las celdas totales). Esta metodología basada en el uso de un bounding box con límites definidos por la presencia de celdas de edema y tumor en la verdad fundamental, se propone como una validación de calidad de segmentación más justa a la que aparece en el trabajo de Kim et al. [Kim10], en el cual se presentan métricas de calidad de segmentación calculadas en base a cortes únicos de volúmenes de resonancia magnética, sin tomar en cuenta como la alta cantidad de celdas background afecta engañosamente las métricas de especificidad y precisión total en el problema de segmentación tumoral. La deficiencia de esa metodología de evaluación es que un método de segmentación que falle en la identificación de las celdas tumorales y de edema puede obtener altas puntuaciones de especificidad identificando correctamente a las celdas background como no tumorales. Las imágenes de resonancia magnética de tumores cerebrales son conjuntos de datos desbalanceados, las celdas background están representadas de forma abrumadoramente mayoritaria en todos los cortes de la IRM; si no se considera a los cortes de resonancia magnética como un conjunto de datos desbalanceado, se perjudica la evaluación justa del algoritmo segmentador. La segmentación de celdas background constituye típicamente una tarea de segmentación de dificultad menor a la segmentación de celdas de tumor y celdas de edema, que puede incrementar las puntuaciones de precisión y especificidad de forma engañosa. En la metodología de validación propuesta, se realiza la evolución del autómata en el volumen 84 completo, y el bounding box es solo empleado para obtener métricas de calidad; no constituye una simplificación del problema de segmentación o una reducción del espacio de evolución del autómata. Los límites del bounding box utilizados para validar la calidad de la segmentación son determinados a partir de los límites del bounding box de la verdad fundamental para los vóxeles de tumor y edema y los límites del bounding box de la segmentación, también para los vóxeles de tumor y edema. Se toman los límites inferiores y superiores en cada dimensión de los volúmenes de verdad fundamental y segmentación para generar los límites inferiores y superiores de este bounding box de validación. En la primera comparación en esta sección se presentan, además de las métricas de calidad de segmentación obtenidas utilizando el bounding box de validación, las métricas de calidad de segmentación obtenidas con el volumen completo. Se hace esto para ejemplificar como amplias variaciones cuantitativas y cualitativas en la calidad de las segmentaciones obtenidas son ocultadas en las métricas cuando se omite el bounding box. 6.2 Comparación entre Criterios de Dispersión de Semillas Se compara la calidad de las segmentaciones obtenidas usando 3 criterios correctos de dispersión de semillas de segmentación. En el primer criterio se definen semillas contiguas en un único corte del volumen; en el segundo criterio se definen en posición aleatoria en el mismo corte y en el tercer criterio se definen de forma aleatoria a través del volumen. En los 3 casos se definen las semillas a partir de la verdad fundamental del volumen. El número de semillas utilizado en los 3 casos corresponde a:  la mitad de celdas tumorales en el corte número 55 del volumen HG0022, 666 celdas  la mitad de celdas de edema en el corte número 55 del volumen HG0022, 279 celdas  las tres cuartas partes de las celdas background (tejido sano y espacio vacío) en el corte número 55 del volumen HG0022, 38256 celdas Se eligió este dataset debido a su alta dificultad de segmentación. La dimensión del volumen es 230x230x165 y se encuentra coregistrado en los canales T1, T1Gad, T2 y FLAIR. Su verdad fundamental fue provista por un operador humano experto, que clasificó al volumen en vóxeles de tumor, edema y background. [BRATS12] El propósito de la prueba es determinar el efecto de diversos criterios de posicionamiento correcto de semillas en la calidad de las segmentaciones obtenidas y el tiempo de convergencia necesario para el algoritmo. Se eligió al corte 55 del volumen 85 como aquel en donde se fijarían las semillas de forma contigua, debido que es el corte con mayor número de celdas de tumor, de acuerdo a la verdad fundamental. Se presenta el contraste entre las métricas de calidad de segmentación obtenidas utilizando un bounding box de validación contra las métricas de calidad de segmentación obtenidas sin utilizarlo para ilustrar el sesgo que genera esta omisión. En esta prueba se utilizaron los siguientes parámetros:  Canal de RM evaluado: T2  Regla de evolución del autómata: “Growcut Corregido”  Medida de distancia utilizada para calcular fuerzas de ataque: euclidiana  Sistema de Vecindad Usado: Von Neumann 3D  Ejecutado en: GPU a) b) Figura 6.1 - Dataset BRATS HG0022, Glioma Activo de Alto Grado a) Corte 55, vista coronal, canal T2. b) Volumen de verdad fundamental, clases tumor y edema visualizadas con isosuperficies y transparencia sobre tejido cerebral sano. b.box Clase Posicionamiento Contiguo de Semilla Posiciones aleatorias, mismo corte Posiciones aleatorias, todo el volumen Dice Sens. Prec. Esp. Dice Sens. Prec. Esp. Dice Sens. Prec. Esp. Con Tumor 0.2425 0.7382 0.1451 0.8771 0.2754 0.8390 0.1647 0.8797 0.8708 0.9441 0.8081 0.9739 Edema 0.4608 0.4206 0.5096 0.9836 0.5295 0.5893 0.4807 0.9741 0.7886 0.7698 0.8042 0.9674 Sin Tumor 0.2425 0.7382 0.1451 0.9825 0.2754 0.8390 0.1647 0.9829 0.8708 0.9441 0.8081 0.9991 Edema 0.4608 0.4206 0.5096 0.9977 0.5295 0.5893 0.4807 0.9964 0.7866 0.7698 0.8042 0.9989 Tabla 6.1: Métricas de calidad de segmentación para distintos criterios de posicionamiento de semillas 86 Figura 6.2 - Coeficiente Dice, Sensibilidad y Precisión de la clase tumor para 3 criterios de posicionamiento de semillas correctas Figura 6.3 - Efecto del bounding box de validación en la métrica de especificidad 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Contiguo, mismo corte Aleatorio, mismo corte Aleatorio, todo el volumen Dice - Tumor Sensiblidad - Tumor Precisión - Tumor 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Contiguo, mismo corte Aleatorio, mismo corte Aleatorio, todo el volumen Especificidad, con bounding box Especificidad, sin bounding box 87 Posicionamiento contiguo Posiciones aleatorias, mismo corte Posiciones aleatorias, todo el volumen Tiempo GeForce GT 520 68.1 segundos 68 segundos 18.93 segundos Tiempo GeForce GTX 650 7.99 segundos 7.23 segundos 1.7 segundos Pasos de Evolución 201 199 42 Tabla 6.2: Rendimiento para distintos criterios de posicionamiento de semillas Figura 6.4 - Pasos de evolución para lograr convergencia con distintos criterios de posicionamiento de semillas correctas El criterio de selección de semillas de forma aleatoria en todos los cortes del volumen genera una segmentación de calidad notablemente superior en precisión, sensibilidad y coeficiente Dice (un factor de 3) para las clases de tumor y edema que la selección de semillas de forma aleatoria en un mismo corte o la selección de semillas de forma contigua en un mismo corte (ver Tabla 6.1). Esto puede deberse a una mejor representatividad de los niveles de digitales que auténticamente corresponden a una etiqueta en el caso de la dispersión aleatoria en todos los cortes del volumen. El corte 55, que fue utilizado para asignar semillas en 2 de los 3 casos, presenta una segmentación de baja calidad cualitativa (en su mismo corte) en el caso de asignación contigua de semillas, como se puede observar en la Figura 6.5. La calidad de segmentación en el corte 55 en los dos casos de asignación aleatoria es cualitativamente comparable y cercana a la verdad fundamental en el mismo corte, pero la segmentación obtenida con asignación de semillas de forma aleatoria el mismo corte, 0 50 100 150 200 250 Contiguo, mismo corte Aleatorio, mismo corte Aleatorio, todo el volumen Pasos de evolución 88 tiene un bajo coeficiente Dice para la clase tumor, que corresponde a una baja calidad de segmentación de tumor en el volumen total. El número de pasos necesarios para alcanzar la convergencia completa en la segmentación se reduce significativamente (un factor de 5), como se puede observar en la Tabla 6.2 y la Figura 6.4, al asignar las semillas en todos los cortes del volumen. Las diferencias en las métricas de calidad de segmentación, en precisión de tres clases y especificidad al omitir el bounding box de validación quedan evidenciadas en la Tabla 6.2 de esta prueba. También existen diferencias de una décima o más en las especificidades registradas con y sin bounding box en la Tabla 6.1 y la Figura 6.3. La omisión del bounding box hace que la especificidad sea más alta al considerar una región de volumen (background), que está sobrerepresentada en la población de vóxeles y no resulta de relevancia semántica en la planificación de radiocirugía. Como se mencionó en la sección 6.1 y queda evidenciado en la Tabla 6.2 las métricas de coeficiente Dice, sensibilidad y precisión son invariantes al bounding box. En las siguientes pruebas, se mostrarán solo resultados utilizando el bounding box de validación para calcular métricas de calidad. a) b) c) d) Figura 6.5 - Comparación Cualitativa de Segmentaciones a) Verdad Fundamental, HG0022, corte 55 b) Segmentación en el corte 55 por semillas contiguas (en este mismo corte) c) Segmentación en el corte 55 por semillas aleatorias (colocadas únicamente en el mismo corte) d) Segmentación en el corte 55 por semillas aleatorias colocadas aleatoriamente en todo el volumen. 6.3 Comparación de Convergencia Completa Frente a Convergencia por Criterio de Celdas Etiquetadas Se define convergencia completa como el estado en el cual todas las celdas del autómata permanecen con la misma etiqueta luego de evaluar los ataques de sus celdas vecinas. Al existir 89 convergencia completa no existe variabilidad entre las etiquetas de las celdas del autómata entre los pasos t y t + 1. El criterio de convergencia completa aparece en el pseudocódigo de “Growcut Corregido” en el algoritmo de la Sección 4.5.1 y en el kernel modelo especificado en la Sección 5.1.2. El criterio de convergencia por celdas etiquetadas detiene la evolución del autómata cuando todas las celdas que lo constituyen han recibido una etiqueta de clase, aunque el autómata podría continuar evolucionando a partir de ese estado. Este criterio aparece en el pseudocódigo del algoritmo de convergencia temprana en la Sección 4.5.1.1. El criterio de convergencia por celdas etiquetadas resulta de interés práctico porque ofrece un tiempo de respuesta significativamente inferior al necesario para obtener una segmentación utilizando el criterio de convergencia completa. Los parámetros para esta prueba son los siguientes:  Regla de evolución del autómata: “Growcut Corregido”  Canal Evaluado: T2  Medida de distancia utilizada para calcular fuerzas de ataque: euclidiana  Posicionamiento de las semillas: Las semillas fueron fijadas de forma aleatoria en todo el volumen. Se usaron 666 semillas de tumor, 279 semillas de edema y 38256 semillas de background, igual que en el 3er caso de posicionamiento de Semillas en la Sección 6.2. Clase Convergencia por Criterio de Celdas Etiquetadas Convergencia Completa Dice Sensibilidad Precisión Especificidad Dice Sensibilidad Precisión Especificidad Tumor 0.8767 0.9442 0.8071 0.9737 0.8708 0.9441 0.8081 0.9739 Edema 0.7864 0.7684 0.8052 0.9677 0.7886 0.7698 0.8042 0.9674 Tabla 6.3: Métricas de calidad de segmentación para distintos criterios de convergencia Convergencia por Criterio de Celdas Etiquetadas Convergencia Completa Tiempo, GeForce GT 520 (segundos) 7.42 18.93 Tiempo, GeForce GTX 650 (segundos) 0.3 0.95 Número de pasos en los que se completa la evolución 16 42 Tabla 6.4: Tiempos de respuesta para distintos criterios de convergencia 90 Figura 6.6 - Métricas de calidad de segmentación de la clase tumor por convergencia completa y convergencia por celdas etiquetadas Figura 6.7 - Pasos de evolución para 2 criterios de convergencia La Tabla 6.3 y la Figura 6.6 evidencian en este caso que la convergencia por criterio de celdas con etiquetas asignadas tiene un coeficiente Dice, sensibilidad y precisión cercano, en el 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Convergencia completa Convergencia por celdas etiquetadas Dice - Tumor Sensiblidad - Tumor Precisión - Tumor Especificidad - Tumor 0 5 10 15 20 25 30 35 40 45 Completa Celdas etiquetadas Pasos de evolución 91 orden de las centésimas, a la convergencia completa, a pesar que termina en un número significativamente inferior de pasos de evolución, como indican la Tabla 6.4 y la Figura 6.7. Un factor a tomar en cuenta para el resultado de esta prueba es el posicionamiento aleatorio de semillas correctas en todo el volumen. Para el caso de la convergencia con todas las celdas etiquetadas, el autómata termina su evolución en 16 pasos. En el caso de la convergencia completa, el autómata termina su evolución en 42 pasos. El uso de la función isequal()de Matlab, visualizado en un corte de la segmentación en la Figura 6.8, muestra que las segmentaciones tienen posicionamiento distinto de las etiquetas y son cualitativamente distintas; las diferencias son difíciles de percibir en isosuperficies como las que aparecen en la Figura 6.9. A pesar que las segmentaciones son cualitativamente distintas, la diferencia no resulta significativa visualmente. 92 a) b) c) d) Figura 6.8 - Diferencias Cualitativas por Criterio de Convergencia en Cortes a) Verdad fundamental determinada por operador humano corte 59 del dataset HG002. Se resalta que la locación x = 138, y = 152 tiene etiqueta 2 (edema). El corte fue rotado 90 grados a la izquierda para centrar y facilitar la visualización de la etiqueta de clase correspondiente a la celda con locación (138, 152). b) Resultado de comparación de diferencias entre las segmentaciones; el punto blanco indica la única diferencia de etiquetado encontrada entre ambas segmentaciones. c) Segmentación obtenida por criterio de convergencia de celdas etiquetadas. d) Segmentación obtenida por criterio de convergencia completa. 93 (a) b) Figura 6.9 - Isosuperficies de Segmentaciones a) Segmentación obtenida por Criterio de Convergencia Completa. b) Segmentación obtenida por Criterio de Celdas Etiquetadas 6.4 Estudio del Efecto de Número de Semillas Correctas Suministradas por el Usuario en la Calidad de Segmentación En GrowCut, existe una correlación positiva entre número de semillas auténticamente correspondientes a una clase de segmentación y calidad de segmentación obtenida. El propósito de un método de segmentación asistida para IRM de radiocirugía es reducir el tiempo de trabajo de un operador humano al segmentar estructuras anatómicas. Debido que un menor número de semillas suministradas por el operador corresponde con un menor tiempo de trabajo, resulta de interés estudiar el efecto cuantitativo que tiene el número de semillas suministradas por el usuario en la segmentación. En la Tabla 6.5 y la Figura 6.10 se presentan únicamente el coeficiente Dice de cada segmentación por resultar la métrica más representativa de la calidad de la segmentación para la aplicación.  Regla de evolución del autómata: “Growcut Corregido”  Canal Evaluado: T1Gad  Medida de distancia utilizada para calcular fuerzas de ataque: euclidiana  Sistema de vecindad: von Neumann Clase 5% de las Semilas de Clase 10% de las Semillas de Clase 15% de las Semillas de Clase 20% de las Semillas de Clase 25% de las Semillas de Clase 30% de las Semillas de Clase Dice Dice Dice Dice Dice Dice Tumor 0.9403 0.9519 0.9593 0.9634 0.9681 0.9713 Edema 0.8675 0.8942 0.9100 0.9208 0.9290 0.9361 Tabla 6.5: Coeficientes Dice de Tumor y Edema para distintas cantidades de semillas correctas. 94 Figura 6.10 - Visualizaciones de coeficientes Dice de Tumor y Edema para distintas cantidades de semillas correctas. 5% de las semillas de cada clase (para tumor, edema y background) corresponde al número de etiquetas que un operador humano experto puede asignar al volumen de IRM tras pocos minutos de inspección visual. La Tabla 6.5 muestra una diferencia ínfima (3 centésimas) en la calidad de segmentación de tumor obtenida suministrando el 5% de las celdas correspondientes a la clase tumor como semilla y la obtenida suministrando el 30%; la diferencia en coeficiente Dice para la clase edema, entre los dos casos, es de apenas 8 centésimas. 5% de las celdas tumorales, 5% de las celdas de edema y 5% de las celdas de background es el número de semillas de clase usado en las siguientes pruebas, por resultar representativo del uso expedito del algoritmo segmentador por parte de un usuario experto. 6.5 Comparación de Fuerza de Ataque Determinada por Distancia Manhattan contra Fuerza de Ataque Determinada por Distancia Euclidiana La distancia Manhattan representa una medida de distancia más numéricamente estable que la distancia euclidiana, debido a que no involucra el uso de potencias o raíces cuadradas. Resulta de interés comprobar si existe diferencia en la calidad de segmentación obtenida utilizando la distancia 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 5% 10% 15% 20% 25% 30% Dice - Tumor Dice - Edema 95 Manhattan, en lugar de la distancia euclidiana, para determinar fuerzas de ataque entre celdas vecinas.  Regla de evolución del autómata: “Growcut Corregido”  Canales Evaluados : T1, T1Gad, T2 y FLAIR  Dataset: HG0022, evaluado de forma conjunta en los canales T1, T1Gad, T2 y FLAIR. Cada celda del autómata tiene un vector con 4 niveles digitales de la imagen.  Fijadas aleatoriamente en todo el volumen, corresponden al 5% de las celdas de la clase tumor, 5% de las celdas de la clase edema y 5% de las celdas de la clase background  Criterio de Convergencia: Convergencia Completa Clase Distancia Manhattan Distancia Euclidiana Dice Sensibilidad Precisión Especificidad Dice Sensibilidad Precisión Especificidad Tumor 0.9390 0.9310 0.9470 0.9927 0.9396 0.9326 0.9647 0.9928 Edema 0.8943 0.8933 0.8953 0.9778 0.8926 0.8921 0.8931 0.9776 Tabla 6.6: Métricas de calidad de segmentación para fuerza de ataque determinada por distancia Manhattan, frente a fuerza de ataque determinada por distancia euclidiana Figura 6.11 - Visualizaciones de métricas de calidad de segmentación para fuerza de ataque determinada por distancia Manhattan, frente a fuerza de ataque determinada por distancia euclidiana. 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Distancia Manhattan Distancia Euclidiana Dice - Tumor Sensiblidad - Tumor Precisión - Tumor Especificidad - Tumor 96 Tiempo de Ejecución Distancia Manhattan Distancia Euclidiana GeForce GT 520 18.91 seg. 18.93 seg. GeForce GTX 650 0.6584 seg. 0.6586 seg. Número de pasos en los que se completa la evolución 42 42 Tabla 6.7: Métricas de Tiempo de respuesta Figura 6.12 - Número de pasos de evolución invariante, distancia Manhattan frente a distancia euclidiana En este caso, existe una ínfima variabilidad en la calidad de segmentación, evidenciada en las métricas de la Tabla 6.6 y en la Figura.11, al cambiar la distancia Euclidiana por la distancia Manhattan como medida para determinar la fuerza de los ataques entre celdas vecinas. La variabilidad está en el orden de las milésimas, en cuanto a Coeficiente Dice, para las clases tumor y edema. La mayor estabilidad numérica de la distancia Manhattan puede hacer que resulte atractiva al implementar un autómata celular segmentador de datasets grandes o en aquellas reglas de evolución para el autómata celular que consideran penalizaciones a la fuerza de ataque. El número de pasos de evolución, que se muestra en la Figura 6.12 y la Tabla 6.7, resulta invariante. 6.6 Introducción de Error e Incertidumbre en la Configuración Inicial del Autómata La intervariabilidad (variabilidad en las segmentaciones producidas por distintos expertos) y 0 5 10 15 20 25 30 35 40 45 Distancia Manhattan Distancia Euclidiana Pasos de evolución 97 la intravariabilidad (variabilidad en las segmentaciones producidas por un mismo experto) están ampliamente documentadas en la literatura de métodos de segmentación de imágenes médicas [Warfield02], [Prastawa04], [Warfield04], [Warfield08]. En un proceso de segmentación asistida deben esperarse errores por parte de un operador humano en la definición de las etiquetas de clase. En esta prueba, las celdas asignadas erróneamente durante la etapa de selección de semillas simulan el uso real, por parte de un operador experto, del método propuesto en un proceso de segmentación asistida. Se cuantifica el efecto del error en la calidad de la segmentación obtenida. Además se evalúa si existe un efecto correctivo del error de asignación de semillas al agregar incertidumbre a las semillas erradas.  Se compara la calidad de segmentación obtenida con semillas correctas contra las calidades de las segmentaciones obtenidas introduciendo error sin incertidumbre e introduciendo error con incertidumbre. A continuación se especifican los parámetros de la prueba.Dataset: HG0022 del MICCAI BRATS 2012, evaluado en el canal T2.  Posicionamiento y Número de las Semillas: Las semillas fueron colocadas aleatoriamente en todo el volumen representando el 5% de las celdas totales de la clase tumor, 5% de las celdas totales de la clase edema y 5% de las celdas totales de la clase background.  Error introducido: Utilizando la verdad fundamental, se fijaron erróneamente 174 semillas, representando el 10% de las celdas semilla asignadas a la clase tumor. 87 celdas tumorales fueron asignadas a la clase background y 87 celdas tumorales fueron asignadas a la clase edema.  Incertidumbre introducida: las semillas erróneamente definidas recibieron una fuerza inicial de 0.5. Al resto de las semillas se le asignó fuerza inicial de 1.0.  Criterio de convergencia utilizado: Convergencia completa. 98 a) b) c) Figura 6.13 - Introducción de Error e Incertidumbre a) Segmentación obtenida sin introducción de error. b) Segmentación obtenida al asignar erróneamente el 10% de las semillas de segmentación para la clase tumor, la mitad de estas semillas fue asignada a la clase edema y la otra mitad a background con una certidumbre de pertenencia (fuerza) de 1.0. c) Segmentación obtenida al asignar erróneamente el 10% de las semillas de segmentación para la clase tumor, la mitad de estas semillas fue asignada a la clase edema y la otra mitad a background con una certidumbre de pertenencia (fuerza) de 0.5. Clase Caso Libre de Error Error sin Incertidumbre Error con Incertidumbre Dice Sens. Prec. Esp. Dice Sens. Prec. Esp. Dice Sens. Prec. Esp. Tumor 0.9270 0.9197 0.9345 0.9915 0.8796 0.8328 0.9321 0.9920 0.9250 0.9139 0.9363 0.9918 Edema 0.8723 0.8665 0.8782 0.9763 0.8601 0.8676 0.8527 0.9704 0.8718 0.8675 0.8762 0.9758 Tabla 6.8: Métricas de calidad de segmentación para semillas libre de error, semillas con error del 10%, semillas con error del 10% e incertidumbre Figura 6.14 - Visualizaciones de métricas de calidad de segmentación para semillas libre de error, semillas con error del 10% y semillas con error del 10% e incertidumbre 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Caso Libre de Error Error sin Incertidumbre Error con incertidumbre Dice - Tumor Sensiblidad - Tumor Precisión - Tumor Especificidad - Tumor 99 Tiempo de Ejecución Caso Libre de Error Error sin Incertidumbre Error con Incertidumbre GeForce GT 520 (segundos) 18.1 18.6 19 GeForce GTX 650 (segundos) 0.6585 0.6587 0.7103 Número de pasos en los que se completa la evolución 42 43 45 Tabla 6.9: Métricas de tiempo de respuesta para segmentaciones con semillas libres de error, semillas con error sin incertidumbre y semillas con error e incertidumbre. Figura 6.15 - Pasos de evolución de segmentación con semillas libre de error, segmentación con semillas con error del 10% y semillas con error del 10% e incertidumbre Las semillas de segmentación asignadas erróneamente, con incertidumbre de pertenencia a clase (𝜎 < 1), pueden recuperar su auténtica etiqueta de clase durante la evolución del autómata, como se puede apreciar en la Figura 6.13c; esto no ocurre si las semillas asignadas erróneamente tienen 𝜎 = 1, asumiendo que 𝜎 = 1 corresponde a la fuerza máxima de celda en el autómata, como en la Figura 6.13b. La introducción de error e incertidumbre aumentan el tiempo de respuesta, como se puede apreciar en la Figura 6.15 y la Tabla 6.9. Es importante aclarar que, debido a la naturaleza monotónica decreciente de las funciones utilizadas para calcular la fuerza de ataque entre celdas vecinas, la mayor fuerza relativa en la configuración inicial del autómata corresponderá a celdas que no tendrán capacidad de cambiar de etiqueta. Las celdas con etiqueta erróneamente asignada, con fortaleza igual a 1, no pueden corregir su etiqueta durante a la evolución del autómata, debido que 1 corresponde a la fortaleza máxima 40 41 42 43 44 45 Libre de error Error sin incertidumbre Error con incertidumbre Pasos de evolución 100 utilizada en la configuración inicial del autómata. 6.7 Comparación entre Vecindad Moore 3D y Vecindad Von Neumann 3D Las vecindades Moore 3D y Von Neumann 3D forman parte de la literatura clásica de autómatas celulares [Wolfram02]; sin embargo, los efectos de cada una en la calidad de segmentación a través de reglas derivadas de GrowCut no está presente en la literatura del método [Vezhnevets05], [Kim10]. Durante el procesamiento de imágenes utilizadas en los prototipos y demostraciones (como los presentes en las Figuras 4.4 y 4.12) se observó la aparición de artefactos de segmentación notables al utilizar la vecindad Moore, ausentes de las segmentaciones (utilizando las mismas configuraciones iniciales) obtenidas al utilizar la vecindad Von Neumann. Se realizó esta prueba en búsqueda de la aparición de este comportamiento en las métricas de calidad de segmentación. En este caso, como se aprecia en la Tabla 6.10 y la Figura 6.16, la diferencia entre la calidad de las segmentaciones, tanto para la clase tumor como para la clase edema no resultó significativa y está en centésimas. La Tabla 6.11 y la Figura 6.17 evidencian una ligera reducción (3 pasos de evolución) en tiempo de respuesta en la Vecindad Von Neumann. Clase Vecindad Moore Vecindad Von Neumann Dice Sensibilidad Precisión Especificidad Dice Sensibilidad Precisión Especifidad Tumor 0.9213 0.9172 0.9255 0.9883 0.9253 0.9203 0.9303 0.9891 Edema 0.8615 0.8662 0.8568 0.9651 0.8715 0.8704 0.8726 0.9693 Tabla 6.10: Métricas de calidad de segmentación comparando sistemas de vecindad 101 Figura 6.16 - Visualizaciones de métricas de calidad de segmentación comparando sistemas de vecindad Tiempo de Ejecución Vecindad Moore Vecindad Von Neumann GeForce GT 520 7.74 segundos 6.52 segundos GeForce GTX 650 1.10 segundos 1.07 segundos Número de pasos en los que se completa la evolución 25 22 Tabla 6.11: Métricas de tiempo de respuesta para vecindad Moore y Von Neumann 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Vecindad Moore Vecindad Von Neumann Dice - Tumor Sensiblidad - Tumor Precisión - Tumor Especificidad - Tumor 102 Figura 6.17 - Histograma de pasos de evolución para vecindades Moore y Von Neumann Durante el desarrollo de este trabajo y otros afines [Rueda13], [Torres13], se observó que el uso de la vecindad Moore, en lugar de la vecindad Von Neumann, ocasionó reducciones cualitativas notables en la calidad de las segmentaciones obtenidas. El propósito de esta prueba es dar un ejemplo de este comportamiento, que supone un cambio mínimo en la implementación del algoritmo, pero provee posible una mejora en la calidad de segmentación y reduce el número de pasos de evolución requeridos para alcanzar convergencia. Se sugiere extender esta prueba, comparando vecindades, a otros datasets. Otras pruebas en este documento son realizadas con la vecindad Von Neumann 3D. 6.8 Comparación entre Calidad de Segmentación Obtenida con Múltiples Versiones de GrowCut En esta sección se compara la calidad de la segmentaciones obtenidas con variantes a la regla GrowCut original. 1 6 11 16 21 26 Moore Von Neumann Pasos de evolución 103 6.8.1 GrowCut Corregido Clase “Growcut Original” “Growcut Corregido” Dice Sensibilidad Precisión Especificidad Dice Sensibilidad Precisión Especifidad Tumor 0.9240 0.9209 0.9271 0.9905 0.9244 0.9203 0.9284 0.9908 Edema 0.8706 0.8694 0.8719 0.9749 0.8704 0.8704 0.8718 0.9752 Tabla 6.12: Métricas de calidad de segmentación para "Growcut Original" y "GrowCut Corregido" Figura 6.18 - Visualizaciones de métricas de calidad de segmentación para "GrowCut Original" y "GrowCut Corregido" Tiempo de Ejecución “Growcut Original” “Growcut Corregido” GeForce GT 520 5.36 segundos 3.5 segundos GeForce GTX 650 0.67 segundos 0.48 segundos Número de pasos en los que se completa la evolución 32 22 Tabla 6.13: Métricas de tiempo de respuesta para "GrowCut Original" y "GrowCut Corregido" 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 GrowCut Original GrowCut Corregido Dice - Tumor Sensiblidad - Tumor Precisión - Tumor Especificidad - Tumor 104 Figura 6.19 - Visualizaciones de pasos de evolución para "GrowCut Original" y "GrowCut Corregido" A pesar que la regla GrowCut original [Vezhnevets05] tiene un error en el criterio para determinar cuál es la celda vecina que debe ser evaluada como vencedora, este error frecuentemente afecta solo a un reducido número de casos de borde y su efecto en la calidad de la segmentación puede resultar despreciable, como se aprecia en la Tabla 6.12 y la Figura 6.18. Una diferencia notable entre ambas reglas es el número de pasos requeridos para alcanzar convergencia en este caso de prueba, como se evidencia en la Figura 6.19 y la Tabla 6.13 en este caso de prueba, completa su convergencia en 60% de los pasos que requiere GrowCut original para alcanzar un resultado cuantitativamente comparable. Esto sugiere que una heurística de convergencia como la que se indica en la Sección 4.5.1.1 es inapropiada para la regla GrowCut original. 6.8.2 GrowCut con Penalización a Fuerza de Ataque La penalización de ataque tiene el propósito de hacer que las celdas cuyo nivel digital sea poco representativo de su etiqueta tengan menor probabilidad de colonizar el espacio de la imagen. En esta prueba la penalización lineal fue aplicada cuando la celda tiene nivel digital con más de 2 desviaciones estándar con respecto a la media. Para la regla de evolución que emplea penalizaciones constantes a las fuerzas de ataque entre 0 5 10 15 20 25 30 35 GrowCut Original GrowCut Corregido Pasos de evolución 105 celdas vecinas, se utilizó c1 = 0.99 (penalización de 1%) y c2 = 0.95 (penalización de 5%). En el trabajo de Kim et al. [Kim10], se mostraron ejemplos de segmentación de cortes únicos de IRM (no volúmenes), con semillas foreground / background provistas manualmente. En estos casos, se reportó que la penalización exponencial superaba a la regla GrowCut original en calidad de segmentación, evaluada según coeficiente Dice. En el caso aquí mostrado, segmentando el volumen HG0022 con semillas fijadas de forma aleatoria, a través de una distribución probabilística uniforme, la calidad de segmentación, evaluada según coeficiente Dice, resulta abrumadoramente inferior a la obtenida utilizando la regla GrowCut original para el mismo caso, esto se puede verificar en las tablas 6.12 y 6.14, el bajo coeficiente Dice se debe a la sensibilidad prácticamente nula de esta segmentación. Cualitativamente, la segmentación producida en este caso por la regla de evolución con penalización exponencial es deficiente, es una nube de puntos, no identificable como una masa tumor o edema, como se aprecia en la Figura 6.23a. Las reglas de evolución que emplean penalización lineal y penalización constante a las fuerza de ataque exhiben puntuaciones de coeficiente Dice cercanas a las de las reglas regulares (GrowCut original y corregido), como se puede verificar en la tabla 6.12. La penalización constante presenta el menor tiempo de respuesta, como se puede ver en la Tabla 6.15 y la Figura 6.21. Clase Penalización Exponencial Penalización Lineal Penalización Constante Dice Sens. Prec. Esp. Dice Sens. Prec. Esp. Dice Sens. Prec. Esp. Tumor 0.0952 0.05 1 1 0.9021 0.8594 0.9492 0.9958 0.9242 0.9223 0.9262 0.9905 Edema 0.0952 0.0500 1 1 0.7018 0.8745 0.5484 0.8912 0.8714 0.8837 0.8595 0.9720 Tabla 6.14: Métricas de calidad de segmentación para reglas de evolución con fuerzas de ataque afectadas por penalización exponencial, penalización lineal y penalización constante 106 Figura 6.20 - Visualizaciones de calidad de segmentación para reglas de evolución con fuerzas de ataque afectadas por penalización exponencial, penalización lineal y penalización constante Tiempo de Ejecución Penalización Exponencial Penalización Lineal Penalización Constante GeForce GT 520 38.17 segundos 15.16 segundos 7.56 segundos GeForce GTX 650 3.51 segundos 1.26 segundos 0.81 segundos Número de pasos en los que se completa la evolución 79 43 22 Tabla 6.15: Métricas de tiempo de respuesta para reglas de evolución con fuerzas de ataque afectadas por penalización exponencial, penalización lineal y penalización constante 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Penalización Exponencial Penalización Lineal Penalización Constante Dice - Tumor Sensiblidad - Tumor Precisión - Tumor Especificidad - Tumor 107 Figura 6.21 - Visualizaciones de pasos de evolución para reglas de evolución con fuerzas de ataque afectadas por penalización exponencial, penalización lineal y penalización constante a) b) c) d) Figura 6.22 - Comparación cualitativa de segmentaciones afectadas por penalización, corte 55, dataset HG0022 a) Penalización Exponencial b) Penalización Lineal c) Penalización Constante d) Verdad Fundamental. 0 10 20 30 40 50 60 70 80 Exponencial Lineal Constante Pasos de evolución 108 a) b) c) d) Figura 6.23 - Comparación cualitativa de segmentaciones afectadas por penalización a) Penalización Exponencial. b) Penalización Lineal. c) Penalización Constante. d) Verdad Fundamental 6.9 Comparación de Calidad de Segmentación entre Canales Individuales Frecuentemente se realizan estudios multicanal a un mismo paciente debido a que las intensidades de señal en cada canal de resonancia magnética corresponden a distinta materia. En el canal T1 las intensidades altas de señal, típicamente asociadas con el espectro "blanco", corresponden a grasa, proteínas, hemorragia, melanina y gadolinio. Las intensidades altas de señal en el canal T2 corresponden a materia acuosa. Las intensidades altas del canal FLAIR corresponden a materia acuosa y gliosis, un cambio reactivo en las células gliales que indica daño al sistema nervioso. En estas pruebas se desea evaluar el efecto de la elección de un canal particular en la calidad 109 de la segmentación obtenida, así como el efecto de la combinación de canales en un dataset sintético generado por TumorSim, TS05, con igual sesgo y ruido en los 4 canales simulados. El dataset tiene dimensiones 256 x 256 x 181.  Regla de evolución: GrowCut corregido  Sistema de vecindad: Von Neumann 3D  Medida de distancia vectorial: euclidiana  Criterio de convergencia: completa  Semillas: fijadas aleatoriamente, a partir de una distribución uniforme, corresponden al 5% de las celdas auténticamente correspondientes a cada clase. Clase Canal T1 Canal T1Gad Canal T2 Canal FLAIR Dice Sens Prec Esp Dice Sens Prec Esp Dice Sens Prec Esp Dice Sens Prec Esp Tumor 0.7856 0.7887 0.7825 0.9976 0.8586 0.8513 0.8661 0.9985 0.7958 0.7747 0.8181 0.9981 0.7915 0.7841 0.7990 0.9975 Edema 0.9334 0.9355 0.9355 0.9738 0.9273 0.9290 0.9256 0.9697 0.9364 0.9436 0.9294 0.9734 0.9463 0.9490 0.9436 0.9742 Tabla 6.16: Métricas de calidad de segmentación para canales individuales T1, T1Gad, T2 y FLAIR Figura 6.24 - Métricas de calidad de segmentación para canales individuales T1, T1Gad, T2 y FLAIR 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 T1 T1Gad T2 FLAIR Dice - Tumor Sensiblidad - Tumor Precisión - Tumor Especificidad - Tumor 110 Tiempo de Ejecución Canal T1 Canal T1Gad Canal T2 Canal FLAIR GeForce GT 520 7.14 segundos 6.61 segundos 7.01 segundos 9.5 segundos GeForce GTX 650 0.8403 segundos 0.78 segundos 0.86 segundos 1.06 segundos Pasos de Evolución 30 27 28 35 Tabla 6.17: Tiempos de respuesta para segmentaciones realizadas empleando las mismas semillas, en distintos individuales canales de IRM (T1, T1Gad, T2, FLAIR) Figura 6.25 - Tiempos de respuesta para segmentaciones realizadas empleando las mismas semillas, en distintos canales individuales de IRM (T1, T1Gad, T2, FLAIR) Esta prueba expresó un resultado de diferencia de calidad de segmentación favoreciendo al canal T1Gad en el orden de unas 7 u 8 centésimas de coeficiente Dice para clase tumor, como se muestra en la Tabla 6.16 y en la Figura 6.24. El canal T2 ofrece la calidad de segmentación más cercana al T1Gad en esta prueba. En la prueba realizada, el canal T1Gad converge más rápidamente que los otros, como se aprecia en la Figura 6.25 y la Tabla 6.17. 0 5 10 15 20 25 30 35 T1 T1Gad T2 FLAIR Pasos de evolución 111 6.10 Comparación de Calidad de Segmentación al Realizar Combinación de Canales A continuación se presentan las combinaciones de canales posibles para el dataset TS05. 6.10.1 Combinación de 4 Canales Clase Canales T1 + T1Gad + T2 + FLAIR Dice Sens Prec Esp Tumor 0.8663 0.8539 0.8790 0.9985 Edema 0.9481 0.9492 0.9470 0.9764 Tabla 6.18: Métricas de calidad de segmentación para combinación de los canales T1, T1Gad, T2 y FLAIR Figura 6.26 - Métricas de calidad de segmentación para combinación de los canales T1, T1Gad, T2 y FLAIR La calidad de segmentación de tumor y edema, según coeficiente Dice al combinar los 4 canales de segmentación (Tabla 6.18) es superior en tan sólo unas centésimas a la calidad de segmentación al utilizar únicamente el canal T1Gad (Tabla 6.14). Esto puede deberse al aumento de información al combinar los canales. El número de pasos para alcanzar la convergencia también se reduce con respecto al mejor caso unicanal, T1Gad (Tabla 6.17 y Figura 6.25). 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 T1 + T1Gad + T2+ FLAIR Dice - Tumor Sensiblidad - Tumor Precisión - Tumor Especificidad - Tumor 112 GeForce GT 520 (segundos) 10.5 GeForce GTX 650 (segundos) 1.16 Número de Pasos de Evolución 16 Tabla 6.19: Métricas de tiempo de respuesta para combinación de los canales T1, T1Gad, T2 y FLAIR 6.10.2 Combinaciones de 3 Canales En la Tabla 6.20 y la Figura 6.27 se muestran las métricas de calidad de segmentación para las combinaciones de 3 canales. Se evidencia que las combinaciones de canales que incluyen al canal T1Gad ofrecen una calidad de segmentación cercana a nivel de milésimas la que se obtiene combinando los 4 canales. En todos estos casos de combinación tricanal, se observa una reducción de los pasos requeridos para alcanzar convergencia con respecto a las segmentaciones unicanal en la Tabla 6.24, esto se aprecia en la Tabla 6.21 y la Figura 6.27. Clase Canales FLAIR+T1+T1Gad Canales T1+T1Gad+T2 Canales FLAIR + T1+ T2 Canales FLAIR + T1Gad +T2 Dice Sens Prec Esp Dice Sens Prec Esp Dice Sens Prec Esp Dice Sens Prec Esp Tumor 0.8651 0.8539 0.8766 0.9985 0.8651 0.8452 0.8859 0.9987 0.7990 0.7910 0.8072 0.9977 0.8649 0.8498 0.8805 0.9985 Edema 0.9488 0.9489 0.9486 0.9771 0.9414 0.9421 0.9407 0.9749 0.9484 0.9492 0.9477 0.9767 0.9470 0.9508 0.9433 0.9740 Tabla 6.20: Métricas de calidad de segmentación con combinaciones tricanal Tiempo de Ejecución Canales FLAIR + T1 + T1Gad Canales T1+T1Gad+T2 Canales FLAIR + T1+ T2 Canales FLAIR + T1Gad + T2 GeForce GT 520 (segundos) 7.57 7.74 8.27 8.16 GeForce GTX 650 (segundos) 0.87 0.91 0.97 0.96 Pasos de Evolución 17 18 19 19 Tabla 6.21: Métricas de tiempo de respuesta para combinaciones tricanal 113 Figura 6.27 - Métricas de calidad de segmentación con combinaciones tricanal Figura 6.28 - Métricas de tiempo de respuesta para combinaciones tricanal 6.10.3 Combinaciones de 2 Canales A continuación se presentan las combinaciones de dos canales posibles con el dataset 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 FLAIR + T1 + T1Gad T1 + T1Gad + T2 FLAIR + T1 + T2 FLAIR + T1Gad + T2 Dice - Tumor Sensiblidad - Tumor Precisión - Tumor Especificidad - Tumor 1 3 5 7 9 11 13 15 17 19 FLAIR + T1 + T1Gad T1 + T1Gad + T2 FLAIR + T1 + T2 FLAIR + T1Gad + T2 Pasos de evolución 114 sintético TS05. Clase Canales FLAIR + T1 Canales FLAIR + T1Gad Canales FLAIR + T2 Dice Sens Prec Esp Dice Sens Prec Esp Dice Sens Prec Esp Tumor 0.7973 0.7936 0.8009 0.9976 0.8619 0.8486 0.8755 0.9985 0.7992 0.7868 0.8121 0.9977 Edema 0.9489 0.9484 0.9494 0.9775 0.9479 0.9503 0.9455 0.9756 0.9459 0.9499 0.9420 0.9734 Tabla 6.22: Métricas de calidad de segmentación para combinaciones de dos canales. Clase Canales T1 + T1 Gad Canales T1 + T2 Canales T1Gad + T2 Dice Sens Prec Esp Dice Sens Prec Esp Dice Sens Prec Esp Tumor 0.8537 0.8354 0.8728 0.9986 0.7958 0.7838 0.8083 0.9978 0.8689 0.8562 0.8820 0.9986 Edema 0.9354 0.9380 0.9329 0.9738 0.9420 0.9416 0.9423 0.9756 0.9401 0.9422 0.9380 0.9736 Tabla 6.23: Métricas de calidad de segmentación para combinaciones de dos canales. Figura 6.29 - Métricas de calidad de segmentación para combinaciones de dos canales. Tiempo de Ejecución FLAIR + T1 FLAIR + T1Gad FLAIR + T2 T1 + T1 Gad T1 + T2 T1Gad + T2 GeForce GT 520 (segundos) 9.1 6.52 19.1 7.07 9.2 6.61 GeForce GTX 650 (segundos) 1.04 0.75 2.21 0.81 1.04 0.79 Pasos de Evolución 27 19 54 21 27 20 Tabla 6.24: Métricas de tiempo de respuesta, combinación de dos canales 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 flair + t1 flair + t1Gad flair + t2 t1 + t1Gad t1 + t2 t1Gad + t2 Dice - Tumor Sensiblidad - Tumor Precisión - Tumor Especificidad - Tumor 115 Figura 6.30 - Métricas de tiempo de respuesta, combinaciones de dos canales Las tablas 6.22- 6.23 y la Figura 6.29 evidencian que las mejoras en las métricas de calidad de segmentación están en el orden de las centésimas, con respecto al uso de canales individuales (ver Tabla 6.16). En este dataset, la combinación FLAIR + T2 ofrece el menor beneficio y requiere el mayor número de pasos de evolución para alcanzar convergencia, posiblemente debido a la cercanía espectral entre ambos canales. El uso de la combinación FLAIR + T2 aumenta también el tiempo de respuesta con respecto al uso de estos canales indivualmente, como se puede apreciar al comparar la Figura 6.30 con la Figura 6.25. En este caso de prueba se muestra que la combinación de canales al menos no perjudica la calidad de las segmentaciones obtenidas. Como trabajo futuro, se requiere un estudio exhaustivo en un número considerable de datasets, incluyendo los efectos de deformación por coregistro y ruido variable, del efecto de combinación de canales en la calidad de las segmentaciones obtenidas. 6.11 Pruebas con Algoritmo de Selección de Semillas “AutomaClass” En las siguientes pruebas se utilizó un dataset sintético, con niveles distintos y conocidos de ruido en cada canal de IRM. Se considera a los 4 canales de la imagen (T1, T1Gad, T2 y FLAIR) al momento de seleccionar las semillas, que corresponden a particiones de máximos locales en la imagen. El número de rangos (nrang) es significativo porque corresponde al único parámetro que 1 11 21 31 41 51 61 FLAIR + T1 FLAIR + T1Gad FLAIR + T2 T1 + T1Gad T1 + T2 T1Gad + T2 Pasos de evolución 116 debe suministrar el usuario para guiar la segmentación. Nrang determina el número de clases presentes en la segmentación. Un mayor nrang corresponde a un mayor número de particiones, como las que aparecen en el histograma de la Figura 4.13 y la Figura 4.14 como P1, P2 (para 2 particiones). La Figura 6.32 muestra las segmentaciones obtenidas con distinto valor de nrang. Dataset: TSO2, producido por TumorSim, dimensión: 256 x 256 x 181. . Sistema de Vecindad Usado: Von Neumann 3D Regla de Evolución: "GrowCut Corregido" Criterio de Convergencia: completa a) b) Figura 6.31 - Semillas de AutomaClass a) Dataset TSO2, corte 90, canal T1. b) Semillas seleccionada para el corte por AutomaClass, nrang=7 117 a) b) c) d) Figura 6.32 - Segmentaciones Producidas con Semillas de AutomaClass a) Segmentación producida al utilizar nrang = 7, generando 28 clases. b) Segmentación producida al utilizar nrang = 8, generando 37 clases. c) Segmentación producida al utilizar nrang = 9, generando 41 clases. d) Verdad Fundamental producida por TumorSim, para 7 clases. Clase Nrang = 7 Nrang = 8 Nrang = 9 Dice Sens. Prec. Esp. Dice Sens. Prec. Esp. Dice Sens. Prec. Esp. Tumor 0.8249 0.7024 0.9993 0.9999 0.8226 0.6988 0.9996 1 0.8211 0.6968 0.995 1 Edema 0.7546 0.6974 0.8221 0.9664 0.7373 0.6676 0.8234 0.9681 0.7256 0.6496 0.8217 0.9686 Tabla 6.25: Métricas de calidad de segmentación para 3 números distintos de rangos de selección de semillas a partir de máximos locales en la imagen 118 Tiempo de Ejecución Nrang = 7 Nrang = 8 Nrang = 9 GeForce GT 520 (segundos) 140.9 143.8 133.6 GeForce GTX 650 (segundos) 16.5195 16.54 16.72 Número de pasos en los que se completa la evolución 297 298 300 Tabla 6.26 Métricas de tiempo de respuesta para 3 números de rangos de selección de semillas a partir de máximos locales en la imagen Figura 6.33 - Métricas de Calidad de Segmentación para 3 números de rangos distintos de selección de semillas a partir de máximos locales en la imagen 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 nrang = 7 nrang = 8 nrang = 9 Dice - Tumor Sensiblidad - Tumor Precisión - Tumor Especificidad - Tumor 119 Figura 6.34 - Pasos de evolución para 3 números de rangos distintos de selección de semillas a partir de máximos locales en la imagen Las segmentaciones producidas por el algoritmo AutomaClass exhiben una muy alta precisión en todos los casos considerados, como aparece en la Tabla 6.25 y la Figura 6.33. El número de pasos de evolución necesario para alcanzar la convergencia resultan cercanos, a pesar de ser realizadas con amplia variabilidad del número de clases. La firma espectral de tumor tiende a ser captada como un máximo local en la imagen en un número de rangos de 7, 8 y 9 particiones de máximos locales. El número máximo de clases identificadas en el caso de 7 particiones es 35, en el caso de 8 particiones es 40 y el número máximo de clases en el caso de 9 particiones es 45. A pesar que se generan más clases basadas en firma espectral que las que provee la verdad fundamental del TumorSim (7 clases, representadas en la Figura 6.32d) el AutomaClass tiende a detectar el tumor como un elemento correspondiente a un máximo local de la imagen. 1 51 101 151 201 251 301 nrang = 7 nrang = 8 nrang = 9 Pasos de evolución 120 CONCLUSIONES Los autómatas celulares deterministas son presentados como una herramienta de alta relevancia para realizar segmentaciones y clasificaciones, para N clases, en volúmenes de resonancia magnética cerebral, tanto de manera supervisada como no supervisada. El uso de GrowCut como método efectivo de segmentación automática o asistida depende de la selección espacial correcta de semillas. Entre los resultados a destacar en las pruebas presentadas está la alta influencia de la dispersión espacial de las semillas en la calidad de las segmentaciones obtenidas y la poca influencia en la calidad de segmentación que tiene el número de semillas suministrado. Con un posicionamiento altamente disperso de las semillas, el método ha exhibido robustez y capacidad de manejar incertidumbre de pertenencia de un vóxel a determinada clase. Estos resultados constituyen criterios de usabilidad relevantes para la planificación de radiocirugía cuando se utiliza a GrowCut como método de segmentación asistido. En los casos probados, la regla "GrowCut Corregido" provee una reducción significativa del tiempo de cómputo necesario para alcanzar la convergencia completa del autómata, junto con una mejora marginal de la calidad de la segmentación obtenida, por lo que debe considerarse una mejora al método original. Se ha mostrado un caso de uso en que el criterio de penalización exponencial a la fuerza de ataque propuesto por Kim et al. [Kim10] para la segmentación de imágenes tumorales en resonancia magnética cerebral provee segmentaciones anatómicas de sensibilidad prácticamente nula. Se propone el uso de criterios de penalización lineal o penalización constante para mejorar la calidad de segmentación y evitar errores numéricos. El uso de un bounding box de validación para reducir el número de vóxeles background contados aumenta la representatividad de la métrica de especificidad y se propone aquí como parte de una nueva metodología de validación de segmentación de tumores cerebrales que incluya a las métricas de sensibilidad y precisión. Esta metodología es amena a la validación de segmentaciones para la planificación de radiocirugía y difiere de la presentada en el BRATS 2012. El algoritmo de selección de semillas, AutomaClass, es presentado como una herramienta poderosa para identificar masas tumorales de forma inmediata con una mínima interacción por parte del usuario. 121 TRABAJOS FUTUROS Debido a la alta variabilidad morfológica de la IRM cerebral, es necesario un estudio exhaustivo de la calidad de las segmentaciones obtenidas con datos clínicos obtenidos de varias fuentes, con variados niveles de ruido y más de 3 etiquetas en la verdad fundamental, para validar la metodología de selección de semillas con el AutomaClass y los parámetros de combinación de canales de GrowCut. 3DSlicer es una herramienta de código abierto utilizada para el análisis de IRM que provee un módulo GrowCut no paralelizado [Egger13]. Implementaciones CUDA de las variaciones del algoritmo propuestas en este documento resultarían de utilidad para sus usuarios. Para aumentar en el mayor número de casos de estudio posible la precisión, sensibilidad y autonomía del procedimiento de segmentación de tumores cerebrales para la aplicación de radiocirugía, un estudio de la compatibilidad de GrowCut y AutomaClass con otros métodos de segmentación de imágenes, como los contornos activos [Hamamci12] y los campos aleatorios de Markov [Behera12] puede resultar de relevancia. 122 BIBLIOGRAFÍA [Aponte12] Aponte, J. Clasificación de Tejidos en Imágenes Oncológicas de PET/CT Mediante el Algoritmo K-means. Trabajo Especial de Grado, Facultad de Ciencias, Escuela de Física, UCV, Biblioteca Alonso Gamero, 2012. [Blake98] Blake, A; M, Isard. Active Contours: The Application of Techniques from Graphics, Vision, Control Theory and Statistics to Visual Tracking of Shapes in Motion. Springer Verlag, 1998 [Boykov04] Boykov, Y.; Jolly, M. Interactive Graph Cuts for Optimal Boundary and Region Segmentation of Objects in N-D Images. Proceedings of the International Conference on Computer Vision, vol. 1, pp. 105-112, 2004 [BRATS12] Resultados de competencia de segmentación de tumores cerebrales, BRATS, Multimodal Brain Tumor Segmentation Challenge, en la International Conference on Medical Image Computing and Computer Assisted Intervention. http://www2.imm.dtu.dk/projects/BRATS2012/FinalResults_RevisedPostMiccaiAllMetrics.xlsx [Carneiro96] Carneiro, B.; Silva, C.; Kaufman, A. Tetra-Cubes: An Algorithm to Generate Isosurfaces based upon Tetrahedra. Anais do IX SIBGRAPI, pp. 205 -210, 1996 [Chen08] Chen, C; Chapman; Kooy, H.; Loeffer, J. Neuroimaging in Radiosurgery Treatment Planning and Follow-up Evaluation. Principles and Practice of Stereotactic Radiosurgery, Springer- Verlag, pp. 9-23, 2008 [Cook04] Cook, Mathew. Universality in Elementary Cellular Automata. Complex Systems, vol 15(1), pp. 1-40 [Dijkstra59] Dijkstra; E.W. A Note on Two Problems in Connexion with Graphs. Numerische Mathematik 1, pp. 269-271, 1959 http://www2.imm.dtu.dk/projects/BRATS2012/FinalResults_RevisedPostMiccaiAllMetrics.xlsx 123 [Doyle84] Doyle, P.; Snell, L.: Random walks and electric networks. Carus Mathematical Monographs. Mathematical Association of America, no. 22, 1984 [Egger13] Egger, J.; Kappur, T; Fedorov A.; Pieper S.; Miller J.; et al. GBM Volumetry Using the 3D Slicer Medical Image Computing Platform. Scientific Reports, vol 3, 2013 [Gaster11] Gaster, Benedict; Howes, Lee; Kaeli, David; Mistry, Perhad; Schaa, Dana: Heterogenous Computing with OpenCL. Morgan Kaufmann, ISBN-13: 978-0123877666, 2011 [Gindi93] Gindi, Gene; Rangarajan Anand; Zubal George: Atlas Guided Segmentation of Brain Images via Optimizing Neural Networks, Proceedings SPIE Biomedical Image Processing IV- Biomedical Image Processing and Biomedical Visualization, vol. 1905, pp 566-575, 1993 [Gottesfeld92] Gottesfeld, Lisa. A Survey of Image Registration Techniques, ACM Computing Surveys (CSUR), vol. 24, Issue 4. Pp 325 – 376, 1992 [Grady04] Grady, L; Funka-Lea G. Multi-label Image Segmentation for Medical Applications Based on Graph-Theoretic Electrical Potentials. ECCV Workshops CVAMIA and MMBIA, pp. 230-245, 2004 [Hansen04] Hansen, Charles; Johnson, Chris.Visualization Handbook. Academic Press, pp 7-11. [Ikits04] Ikits, Milan; Kniss, Joe; Lefohn, Aaron; Hansen, Charles. Volume Rendering Techniques. GPUGems, Addison Wesley, 2004 [Ball65] Ball, Geoffrey H.; Hall, David J.Isodata,A Novel Method of Data Analysis and Pattern Classification. Stanford Research Institute Technical Report, 1965 [Kaster11] Kaster, Frederik O.; Menze, Bjoern; Weber Marc-André; Hamprecht Fred A. Comparative Validation of Graphical Models for Learning Tumor Segmentations from Noisy Manual Annotation, International MICCAI Workshop, Revised Selected Papers, Springer, 2011 124 [Ken99] Kent, Beck: Extreme Programming Explained. Addison Wesley Professional, ISBN- 13:978-0201616415, 1999 [Khronos11] OpenCL 1.2 Specification.Khronos Group, 2011 [Lorensen87] Lorensen, W.; Cline, H. Marching Cubes: A high resolution 3D surface construction algorithm. In: Computer Graphics, Vol. 21, Nr. 4, 1987 [Zhao98] Zhao, Hong-Kai; Osher, Stanley; Merriman, Barry; Kang Myungjoo. Implicit, Nonparametric Shape Reconstruction from Unorganized Points Using a Variational Level Set Method. Computer Vision and Image Understanding, vol. 80, pp. 295-319, 1998 [Kauffmann09] Kauffmann, C; Piche, N. Seeded ND Medical Image Segmentation by Cellular Automaton on GPU. International Journal of Computer Assisted Radiology and Surgery, vol. 5, Issue 3, pp. 251-262, 2009 [Kass88] Kass, M; Witkin, A; Terzopoulos, D. Snakes: Active Contour Models. International Journal of Computer Vision, vol. 1, No. 4, pp. 321-331, 1988 [Kim10] Kim, Edward; Shen, Tian; Huang, Xiaolei. A Parallel Cellular Automata with Label Priors for Interactive Brain Tumor Segmentation. IEEE 23rd International Symposium on Computer-Based Medical Systems Conference Publications, pp. 232-237, 2010 [Koller09] Koller, Daphne; Friedman, Nir. Probabilistic Graphical Models, Principles and Techniques.MIT Press, ISBN-13: 978-0262013192, 2009 [Levoy90] Levoy, Marc. Efficient Ray Tracing of Volume Data. ACM Transactions on Graphics, vol. 9, No. 3, pp. 245-261, 1990 [Mathworks13] Image Registration Techniques, documentación oficial de Matlab 2013a, Mathworks, 2013 http://www.mathworks.com/help/images/registering-an-image.html http://www.mathworks.com/help/images/registering-an-image.html 125 [Mena12] Mena, Christiam. Colocación de Marco Estereotáctico para Radiocirugía. Tesis de Pregrado, Escuela de Computacion, Universidad Central de Venezuela, Biblioteca Alonso Gamero, 2012 [Menze10] Menze, Bjoern; Leemput Va, Koen; Lashkari, Danial; Weber, Marc-André; Ayache, Nicholas; Golland, Polina.A Generative Model for Brain Tumor Segmentation in Multi-Modal Images.15th International Conference Medical Image Computing and Computer-Assisted Intervention. MICCAI 2010, vol. 13, pp. 151-159, 2010 [Mildenberger02] Mildenberger, Peter; Eichelberg, Marco; Martin, Eric.Introduction to the DICOM Standard. European Radiology, vol. 12, Issue 4, pp. 920-927, 2002 [Moga96] Moga, A; Gabbouj, M. A Parallel Marker Based Watershed Transformation. International Conference on Image Processing ICIP96, No. II, pp. 137-140, 1996 [Nvidia12] OpenCL Programming Guide for the CUDA Architecture, version 4.2, Nvidia, 2012 [O’Connor12] O’ Connor, B. F-scores, Dice, and Jaccard set similarity. http://brenocon.com/blog/2012/04/f-scores-dice-and-jaccard-set-similarity/ [Pearl09] Pearl, Judea. Causality: Models, Reasoning and Inference. Cambridge University Press, ISBN-13: 978-0521895606, 2009 [Popovici02] Popovici, A; Popovici, D. Cellular Automata in Image Processing. Department of Computer Science and Mathematics, University of West Timisoara, 2002 [Prastawa04] Prastawa, Marcel; Bullit, Elizabeth; Ho, Sean; Gerig, Guido. A Brain Tumor Segmentation Framework Based on Outlier Detection. Medical Image Analysis, vol. 8, pp. 275-283, 2004 [Prince12] Prince, Simon. Computer Vision: Models Learning and Inference. Cambridge University Press, ISBN-13: 978-1107011793, 2012 http://brenocon.com/blog/2012/04/f-scores-dice-and-jaccard-set-similarity/ 126 [Prabhakar07] Prabhakar, R.; Julka, P.K.; Ganesh, T.; Munshi,A.; Joshi, R.C.; Rath, G.K. Feasibility of Using MRI Alone for 3D Radiation Treatment Planning in Brain Tumors. Japanese Journal of Clinical Oncology, vol. 37, No. 6, pp. 405-411, 2007 [Prastawa09] Prastawa, M.; Bullitt, E.; Gerig, G. Simulation of Brain Tumors in MR Images for Evaluation of Segmentation Efficacy.Medical Image Analysis vol. 13, No. 2, pp. 297–311, 2009 [Popovic07] Popovic, A.; de la Fuente, M; Engelhardt, M.; Radermacher, K. Statistical Validation Metric for Accuracy Assessment in Medical Image Segmentation.International Journal of Computer Assisted Radiology and Surgery, pp. 169 - 181, 2007 [Reese99] Reese, L. Intelligent Paint: Region-Based Interactive Image Segmentation. Master's Thesis. Department of Computer Science, Brigham Young University, 1999 [Rother04] Rother, C; Kolmogorov, V; Blake, A. Grabcut – Interactive Foreground Extraction Using Iterated Graph Cuts. ACM SIGGRAPH 2004 Conference Proceedings, pp. 309-314, 2004 [Russell13] Russell, Mark; Young, Adam; Karri, Surya. Biomarkers of Pediatric Brain Tumors. Frontiers in Pediatrics, Frontiers in Pediatrics, 2013 [Mortensen95] Mortensen, E. N.; Barrett, W. A. Intelligent scissors for image composition. ACM SIGGRAPH 1995 Conference Proceedings, pp. 191–198, 1995 [Mortensen99] Mortensen, E. N.; Barrett, W. A. Toboggan-Based Intelligent Scissors with a Four- Parameter Edge Model. IEEE Conference on Computer Vision and Pattern Recognition 1999, vol. 2, pp. 2452-2458, 1999 [Loni13] Laboratory of Neuro Imaging, UCLA, Segmentation Validation Engine, 2013 http://sve.bmap.ucla.edu/instructions/metrics/dice/ [Shlens03] Shlens, Jon. A Tutorial on Principal Component Analysis, 2003 http://sve.bmap.ucla.edu/instructions/metrics/dice/ 127 http://www.cs.princeton.edu/picasso/mats/PCA-Tutorial-Intuition_jp.pdf [Smith02] Smith, Lindsay. A Tutorial on Principal Component Analysis, 2002 http://www.cs.otago.ac.nz/cosc453/student_tutorials/principal_components.pdf [Kass88]Kass, M.; Witkin, A.;Terzopoulos, D. Snakes: Active contour models. International Journal of Computer Vision, vol. 1, No. 4, pp. 321–331, 1988 [Sylvain11] Sylvain, Henry. Functional Programming for High-Performance Computing on Heterogeneous Architectures.University of Bordeaux, preprint paper. [Szeliski10] Szeliski, Richard. Computer Vision: Algorithms and Applications. Springer, ISBN-13: 978-1848829343, 2010 [Temoche11] Temoche, Pablo. 3D-GRABCUT: GrabCut en Volúmenes empleando programación paralela en el GPU con CUDA. Tesis de Pregrado, Escuela de Computación, Universidad Central de Venezuela, Biblioteca Alonso Gamero 2011 [Torres13] Torres, Wuilian; Rueda Toicen, Antonio. Segmentación No Supervisada de Imágenes Multiespectrales Utilizando Autómatas Celulares. Memorias de las V Jornadas Nacionales de Geomática, Fundación Instituto Ingeniería, 2013 [Vezhnevets05] Vezhnevets, Vladimir; Konouchine, Vadim. GrowCut – Interactive Multi-Label N-D Image Segmentation by Cellular Automata. Proceedings of Graphicon, pp. 150–156, 2005 [vonNeumann66] von Neumann, John.Theory of Self-Reproducing Automata. University of Illinois Press, 1966 [Warfield01] Warfield, S; Kauss, M, Nabavi, A. Automated Segmentation of MRI of Brain Tumors, Radiology 2001; vol. 218, No. 2, pp. 586-591, 2001 [Warfield02] Warfield, S.; K., Zou, K. H. ; Wells, W. M. Validation of Image Segmentation and http://www.cs.princeton.edu/picasso/mats/PCA-Tutorial-Intuition_jp.pdf http://www.cs.otago.ac.nz/cosc453/student_tutorials/principal_components.pdf 128 Expert Quality with an Expectation-Maximization Algorithm. Medical Image Computing and Computer-Assisted Intervention MICCAI 2002, pp. 298-206, 2002 [Warfield04] Warfield, S.; K., Zou, K. H.; Wells, W. M. Simultaneous truth and performance level estimation (STAPLE): an algorithm for the validation of image segmentation. IEEE Transactions on Medical Imaging, vol. 23, no. 7, pp. 903–921, 2004 [Warfield08] Warfield, Simon; Zou, Kelly; Wells, William. Validation of Image Segmentation by Estimating Rater Bias and Variance. Philosophical Transactions of the Royal Society, vol. 366, no. 1874, pp-2361-2375, 2008 [Williams92] Williams, Peter; Nelson, Max. A Volume Density Optical Model. Proceedings of the 1992 Workshop on Volume visualization, pp. 61-68, 1992 [Wolfram83] Wolfram, Stephen. Statistical Mechanics of Cellular Automata. Reviews of Modern Physics, The Institute for Advanced Study, Princeton, vol. 55, issue 3, 1983 [Wright10] Wright, Richard; Haemel, Nicholas; Sellers, Graham; Lipchak, Benjamin. OpenGL Superbible: Comprehensive Tutorial and Reference, 5th Edition, Addison Wesley, ISBN-13: 978- 0321712615, 2010 [Zhang01] Zhang, Yongyue; Brady, Michael; Smith, Stephen: Segmentation of Brain MR Images Through a Hidden Markov Random Field Model and the Expectation-Maximization Algorithm. IEEE Transactions on Medical Imaging, vol. 20, no. 1, 2001 [Zhang10] Zhang, Qi; Eagleson, Roy; Peters, Terry. Volume Visualization: A Technical Overview with a Focus on Medical Applications. Journal of Digital Imaging, issue 24, pp. 640-664, 2010 129 130