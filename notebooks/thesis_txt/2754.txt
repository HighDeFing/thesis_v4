Universidad Central de Venezuela Facultad de Ciencias Escuela de Computación Laboratorio de Sistemas Paralelos y Distribuidos Diseño e implementación de un datawarehouse para la consolidación y consulta de eventos sismológicos y desastres naturales Trabajo Especial de Grado presentado ante la ilustre Universidad Central de Venezuela por el Bachiller: Enrique Buono C.I.: 19.223.511 Email: buono862@gmail.com Para optar al título de Licenciado en Computación Tutor: Prof. Andrés Sanoja Caracas, Mayo 2011 mailto:buono862@gmail.com II Universidad Central de Venezuela Facultad de Ciencias Escuela de Computación Laboratorio de Sistemas Paralelos y Distribuidos ACTA DEL VEREDICTO Quienes suscriben, Miembros del Jurado designado por el Consejo de la Escuela de Computación para examinar el Trabajo Especial de Grado, presentado por el Bachiller Enrique Buono C.I.: 19.223.511, con el título “Diseño e implementación de un datawarehouse para la consolidación y consulta de eventos sismológicos y desastres naturales”, a los fines de cumplir con el requisito legal para optar al título de Licenciado en Computación, dejan constancia de lo siguiente: Leído el trabajo por cada uno de los Miembros del Jurado, se fijó el día 27 de mayo de 2011, a las 02:00pm, para que su autor lo defendiera en forma pública, en la Escuela de Computación, Facultad de Ciencias de la Universidad Central de Venezuela, lo cual este realizó mediante una exposición oral de su contenido, y luego respondió satisfactoriamente a las preguntas que les fueron formuladas por el Jurado, todo ello conforme a lo dispuesto en la Ley de Universidades y demás normativas vigentes de la Universidad Central de Venezuela. Finalizada la defensa pública del Trabajo Especial de Grado, el jurado decidió aprobarlo. En fe de lo cual se levanta la presente acta, en Caracas el 27 de mayo de 2011, dejándose también constancia de que actuó como Coordinador del Jurado el Profesor Tutor Andrés Sanoja. ______________________ Prof. Andrés Sanoja (Tutor) ______________________ ______________________ Prof. Adriana Liendo Prof. Joali Moreno (Jurado Principal) (Jurado Principal) III Agradecimientos En primer lugar a Dios por haberme guiado por el camino del bien hasta ahora; en segundo lugar a cada uno de los que son parte de mi familia, a mi MADRE Niurka Rodriguez, la cual siempre creyó en mí, mi PADRE, MIS ABUELOS, MI TÍA Yolanda, y a mi hermano; por siempre haberme dado su fuerza y apoyo incondicional, ellos quienes me han ayudado a ser la persona que soy hoy por hoy y me han llevado hasta donde estoy. En especial agradezco a mi novia María G. De Freitas, quien fue mi apoyo, mi base, ese ser que estuvo tanto en mis momentos de felicidad al lograr un avance, así como en esos malos momentos donde pensaba que no podía más, le agradezco por siempre darme esas palabras de aliento y la fuerza necesaria para salir adelante y Por último pero no menos importante, a mis compañeros de estudio, porque en todo momento que los necesite para una duda o un consejo siempre estuvieron ahí, en especial a Marco Gómez y a Carlos Villasana; al personal de la Fundación Venezolana de Investigaciones Sismológicas (FUNVISIS) por siempre brindarme su apoyo en todo momento, en especial a la Jefa del departamento de informática Ing. Adriana Liendo y a la Ing. Mirna Freitez y claro está, a mi tutor de tesis, persona a la que admiro por todos sus logros y dedicación, quién me guió y ayudó en todo momento, Msc. Andrés Sanoja. IV Resumen La Fundación Venezolana de Investigaciones Sismológicas (FUNVISIS), maneja varios departamentos donde los datos son cargados de diversas formas mediante el uso de aplicaciones: desde archivos de texto, Microsoft Excel e incluso sistemas, lo cual conlleva a que la fundación no posea los datos integrados en un solo repositorio. El presente Trabajo Especial de Grado se realizó con la finalidad de desarrollar un repositorio de datos para FUNVISIS, además de realizar un middleware que permita comunicar las aplicaciones ya existentes con dicho repositorio para unificar de esta manera la información; para luego proponer una aplicación web orientada hacia un administrador de base de datos, en la cual los usuarios puedan visualizar las consultas que se deseen hacer sobre la base de datos. El desarrollo del sistema fue guiado por el método ágil “Programación Extrema” (XP), el cual se enfoca en reforzar la simplicidad, comunicación, retroalimentación y refactorización de código. Entre las tecnologías usadas se destaca el lenguaje de programación Ruby 1.9.2, su framework de desarrollo web Rails 3.0.6 y el sistema manejador de base de datos columnares Monet DB. El resultado es el desarrollo del repositorio de datos para FUNVISIS, donde se encuentra unificada la información generada por la aplicación SEISAN (Seismic Analysis System), así como también de los datos correspondientes con la aplicación estudios y desastres. De igual forma se obtuvo un módulo de carga de datos, el cual permite llevar los archivos en formato SEISAN y los datos de la aplicación de estudios y desastres al repositorio de datos, representando dicho modulo el proceso de extracción, transformación y carga de los datos (ETL). Finalmente el último producto obtenido es una aplicación web, mediante la cual los usuarios de FUNVISIS pueden realizar consultas sobre el repositorio desarrollado. La creación de este repositorio y demás aplicaciones aporta un agregado significativo al manejo de la información, tanto técnica como social dentro de FUNVISIS al unificar los datos y permitir la consulta sobre la misma. El presente trabajo está enmarcado dentro del proyecto de investigación “programa integral de capacitación y adiestramiento de talento humano de Funvisis y actualización tecnología”. Palabras claves: datawarehouse, FUNVISIS, SEISAN, Eventos sismológicos, Estudios y Desastre. ÍNDICE V ÍNDICE ÍNDICE DE FIGURAS ................................................................................... VIII ÍNDICE DE CUADROS ....................................................................................... X INTRODUCCIÓN ............................................................................................. 11 CAPÍTULO I ................................................................................................... 13 PLANTEAMIENTO DEL PROBLEMA ............................................................................. 13 Titulo ....................................................................................................... 13 Planteamiento del Problema .................................................................... 13 Objetivo general ...................................................................................... 13 Objetivos Específicos ............................................................................... 13 Importancia y justificación ...................................................................... 13 Propuesta de la solución .......................................................................... 14 Alcances .................................................................................................. 15 CAPÍTULO II .................................................................................................. 16 MARCO REFERENCIAL ......................................................................................... 16 1. Fundación Venezolana de Investigaciones Sismológicas .................... 16 1.1 Misión ................................................................................................................................................ 17 1.2 Visión ................................................................................................................................................. 17 1.3 Organigrama ................................................................................................................................... 17 2. Almacén de Datos ................................................................................ 17 2.1 Conceptos asociados a un datawarehouse .......................................................................... 18 2.2 Características de un datawarehouse ................................................................................... 19 2.3 Ventajas y desventajas de un datawarehouse ................................................................... 20 2.4 Arquitectura de un datawarehouse ....................................................................................... 21 3. Sistemas manejadores de bases de datos orientados a columnas ....... 23 3.1 Descripción ...................................................................................................................................... 23 3.2 Beneficios ......................................................................................................................................... 24 3.3 Implementaciones ........................................................................................................................ 25 3.4 Descripción de MonetDB ........................................................................................................... 27 3.4.1 Características de MonetDB .................................................................................................. 27 ÍNDICE VI 3.4.2 Arquitectura de MonetDB ...................................................................................................... 28 3.4.3 Funcionalidades de MonetDB .............................................................................................. 29 4. Ruby on Rails ....................................................................................... 30 4.1 Funcionamiento ............................................................................................................................. 31 4.2 Arquitectura .................................................................................................................................... 32 4.3 Gemas ................................................................................................................................................. 33 4.4 Soporte de servidores Web ....................................................................................................... 34 4.5 Soporte de Bases de Datos ........................................................................................................ 34 4.6 Requisitos ......................................................................................................................................... 34 4.7 Entorno de Trabajo ...................................................................................................................... 35 4.8 Nociones básicas de instalación y estructura de aplicación ........................................ 35 4.9 Ruby 1.9.2 ......................................................................................................................................... 36 4.10 Rails 3.0 .......................................................................................................................................... 37 CAPÍTULO III ................................................................................................ 40 MARCO METODOLÓGICO ...................................................................................... 40 Programación Extrema ............................................................................ 40 Adaptación del Proceso de Desarrollo XP ................................................ 40 CAPÍTULO 4 ................................................................................................... 59 MARCO APLICATIVO ........................................................................................... 59 Plan de Iteración ..................................................................................... 59 Iteración 0............................................................................................... 60 Iteración 1............................................................................................... 61 Iteración 2............................................................................................... 62 Iteración 3............................................................................................... 66 Iteración 4............................................................................................... 74 Iteración 5............................................................................................... 83 Iteración 6............................................................................................... 91 Iteración 7............................................................................................... 97 Iteración 8............................................................................................. 100 CONCLUSIONES ........................................................................................... 104 RECOMENDACIONES .................................................................................... 106 REFERENCIAS BIBLIOGRÁFICAS .................................................................. 107 ÍNDICE VII APÉNDICE .................................................................................................... 109 Índice de Figuras VIII Índice de Figuras Figura 1 Organigrama FUNVISIS (www.funvisis.gob.ve) ................................................................... 17 Figura 2 Arquitectura de un Datawarehouse (Bouman & Dongen, 2009) .................................. 22 Figura 3 Estructura por defecto de una Aplicación en Rails (Ruby on Rails org. Web development that doesn’t hurt. ) .................................................................................................................. 36 Figura 4 Metáfora del Sistema ....................................................................................................................... 58 Figura 5 Aplicación SEISAN (Seismic Analysis System) ..................................................................... 63 Figura 6 Fragmento del Archivo "select.out" generado por la aplicación SEISAN .................. 64 Figura 7 Descripción del formato de las líneas tipo 1 de los archivos en formato SEISAN.. 65 Figura 8 Instrucciones para la Instalación del Sistema manejador de bases de datos columnar MonetDB ............................................................................................................................................ 67 Figura 9 Interfaz del Cliente Gráfico Squirrel ......................................................................................... 68 Figura 10 Configuración del driver para realizar la conexión entre el Cliente Gráfico Squirrel y MonetDB ............................................................................................................................................ 69 Figura 11 Creación del Alias MonetDB - Test .......................................................................................... 69 Figura 12 Visualización del Esquema "funvisis" del manejador de bases de datos MonetDB .................................................................................................................................................................................... 70 Figura 13 Levantamiento del Servidor de MonetDB ............................................................................ 71 Figura 14 Verificación del Status de MonetDB ....................................................................................... 71 Figura 15 Estructura de Archivos de la aplicación estudios y desastres ..................................... 72 Figura 16 Modelo de la Base de datos de la Aplicación estudios y desastres ............................ 73 Figura 17 Diseño de las dimensiones con base al formato de Archivos SEISAN ...................... 75 Figura 18 Diseño de la tabla de hechos correspondiente con la aplicación SEISAN ............... 76 Figura 19 Diseño de las dimensiones correspondientes con la aplicación estudios y desastres ................................................................................................................................................................. 77 Figura 20 Diseño de la tabla de hechos correspondiente con la aplicación estudios y desastres ................................................................................................................................................................. 78 Figura 21 Implementación de las dimensiones asociadas a la aplicación SEISAN mediante lenguaje SQL .......................................................................................................................................................... 79 Figura 22 Implementación de la tabla de hechos correspondiente con la aplicación SEISAN “fact_evento” mediante lenguaje SQL ......................................................................................................... 80 Figura 23 Implementación de las dimensiones asociadas a la aplicación estudios y desastres mediante lenguaje SQL ................................................................................................................ 81 Índice de Figuras IX Figura 24 Implementación de la tabla de hechos correspondiente con la aplicación estudios y desastres “fact_estudios_desastres” mediante lenguaje SQL ...................................... 81 Figura 25 Modificación a la tabla de hechos "fact_evento"................................................................ 84 Figura 26 Modificación realizada a la dimensión "dim_estacion" y creación de la tabla de hehos "fact_estacion"......................................................................................................................................... 84 Figura 27 Adición de la dimension degenerada "id_evento" a las tablas de hechos existentes ............................................................................................................................................................... 85 Figura 28 Modificaciones realizadas a las dimensiones del datawarehouse y a la tabla de hechos "fact_estudios_desastres" ................................................................................................................. 86 Figura 29 Modificación de la tabla de hecho “fact_evento” mediante lenguaje SQL .............. 87 Figura 30 Modificación mediante lenguaje SQL, de la dimensión “dim_estacion” y Creación de la tabla de hechos “fact_estacion” .......................................................................................................... 88 Figura 31 Modificación de los atributos de las dimensiones y adicion de la dimension degenerada "id_evento" a las tablas de hechos existentes ................................................................ 89 Figura 32 Modelo de datos del datawarehouse ...................................................................................... 92 Figura 33 Consulta 1 Validación de las inserciones en el datawarehouse .................................. 93 Figura 34 Consulta 2 Validación de las inserciones en el datawarehouse .................................. 94 Figura 35 Consulta 3 Validación de las inserciones en el datawarehouse .................................. 94 Figura 36 Consulta 4 Validación de las inserciones en el datawarehouse .................................. 95 Figura 37 Fragmento del Código SQL, correspondiente con la inserción de los datos de prueba en el datawarehouse .......................................................................................................................... 96 Figura 38 Fragmento de código en formato Ruby perteneciente al Middleware ..................... 98 Figura 39 Ejecución del Middleware .......................................................................................................... 99 Figura 40 Vista del Prototipo de Consulta Web Sobre el datawarehouse ................................ 101 Figura 41 Fragmento del Código Perteneciente a la Vista desarrollada para el Prototipo de Consulta Web ..................................................................................................................................................... 102 Índice de Cuadros X Índice de Cuadros Cuadro 1 Información General MonetDB .................................................................................................. 29 Cuadro 2 Sistemas Operativos Soportados por MonetDB ................................................................. 30 Cuadro 3 Características Fundamentales MonetDB ............................................................................. 30 Cuadro 4 Índices en MonetDB ....................................................................................................................... 30 Cuadro 5 Formato de registro para una Historia de Usuario ........................................................... 41 Cuadro 6 Esquema de actores y roles que desempeñan .................................................................... 42 Cuadro 7 Esquema de planificación de cada iteración ........................................................................ 43 Cuadro 8 Formato de registro de Prueba de Aceptación ................................................................... 45 Introducción 11 Introducción La explosión de nuevas tecnologías y con ella los desarrollos tecnológicos, actualmente se han extendido y son de vital importancia para la sociedad, donde las bases de datos, ocupan un lugar determinante en cualquier área del quehacer humano, comercial, tecnológico, entre otros; En particular los datawarehouse los cuales dan lugar a una serie de importantes beneficios para una organización, como lo es el apoyo en la toma de decisiones. En cualquier caso, su utilización permite que la información de gestión sea: accesible, correcta, uniforme y actualizada. De igual forma se cuenta con desarrollos en cuanto a la web se refiere, la cual ha crecido muy rápidamente por las distintas utilidades inherentes que posee. Así como también, por su amplio alcance dentro del campo de la información y las comunicaciones, por lo cual, se ha tomado en cuenta como una herramienta muy poderosa para el desarrollo de aplicaciones que ayuden a aligerar la carga de actividades cotidianas. FUNVISIS, actualmente maneja varios departamentos donde los datos son cargados de diversas formas mediante el uso de aplicaciones: desde archivos de texto, Microsoft Excel e incluso sistemas; Lo cual conlleva a que la Fundación no posea todos los datos integrados en un solo repositorio. En este sentido el presente trabajo plantea desarrollar un repositorio de datos (datawarehouse) para FUNVISIS, además de realizar un middleware que permita comunicar los archivos y aplicaciones ya existentes con dicho repositorio para unificar de esta manera la información; Para luego proponer una aplicación web orientada hacia un administrador de base de datos, en la cual los usuarios puedan visualizar las consultas que se deseen hacer sobre la misma. Todo esto con la finalidad de que las nuevas aplicaciones que sean desarrolladas puedan contar con este repositorio unificado. Para llevar a cabo el objetivo anteriormente mencionado se presenta el siguiente Trabajo Especial de Grado el cual está estructurado en cuatro capítulos: Capítulo I: Planteamiento del Problema, en el cual se expone el problema, los objetivos a desarrollar, importancia y justificación, propuesta de la solución y alcances de la investigación. Capítulo II: Marco Referencial, comprende la descripción de FUNVISIS y su estructura organizativa, las características, arquitectura, ventajas y demás funcionalidades Introducción 12 de un datawarehouse, la descripción del manejador de bases de datos Monet DB, y por último la tecnología Ruby on Rails. Capítulo III: Marco Metodológico, donde se describe el proceso de desarrollo del sistema, el cual se basa en el método ágil programación extrema. Capítulo IV: Marco Aplicativo, en el que se especifican las actividades realizadas en cada una de las iteraciones que conforman el desarrollo del sistema. Finalmente se presentan las conclusiones y recomendaciones de la investigación. Capítulo I – Planteamiento del Problema 13 Capítulo I Planteamiento del problema Titulo Desarrollo de un Repositorio de Datos para la Fundación Venezolana de Investigaciones Sismológicas. Planteamiento del Problema Hoy en día, la Fundación Venezolana de Investigaciones Sismológicas, maneja varios departamentos donde los datos son cargados de diversas formas mediante el uso de aplicaciones: desde archivos de texto, Microsoft Excel e incluso sistemas; Lo cual conlleva a que la fundación no posea todos los datos integrados en un solo repositorio. Es por ello que se quiere integrar en una aplicación todos esos datos y guardarlos en un único repositorio. Incluso realizar una aplicación orientada hacia un administrador de bases de datos en la cual le permita visualizar las consultas (querys) que los usuarios deseen hacer sobre la base de datos. Objetivo general Diseñar e implementar un datawarehouse para la consolidación y consulta de eventos sismológicos y desastres naturales para la Fundación Venezolana de Investigaciones Sismológicas. Objetivos Específicos 1. Identificar el estado actual de los datos en la fundación según las necesidades en general y por departamento. 2. Identificar las necesidades y disponibilidad de información en la fundación. 3. Diseñar el modelo lógico de la base de datos. 4. Implementar la base de datos. 5. Diseñar e implementar mecanismos para la incorporación de los datos al repositorio. 6. Diseñar e implementar una aplicación web para consultas básicas generales. 7. Preparar la transferencia tecnológica y manuales de usuario. Importancia y justificación La Fundación podrá contar con un repositorio para todas sus aplicaciones o datos que se requieran registrar. Al contar con un repositorio de estas características es posible agilizar el intercambio de información, así como también darle cierta estructura y Capítulo I – Planteamiento del Problema 14 organización. De igual manera, para futuros desarrollos de sistemas en la fundación podría contarse con este repositorio como fuente de datos. Propuesta de la solución Con la finalidad de integrar en un datawarehouse toda la información, tanto técnica como social, almacenada en aplicaciones; desde archivos de texto, Microsoft Excel e incluso sistemas de FUNVISIS, se propone diseñar e implementar un datawarehouse para dicha fundación, además de realizar un middleware que permita comunicar los archivos y aplicaciones ya existentes con dicho repositorio, para unificar de esta manera la información. Para luego proponer una aplicación web orientada hacia un administrador de base de datos, en la cual los usuarios puedan visualizar las consultas que se deseen hacer sobre la misma. Para ello es necesario primeramente el análisis y revisión de los distintos archivos en los cuales es almacenada la información, así como de las distintas aplicaciones y sistemas existentes, siendo estas las fuentes de datos las cuales proveerán información indispensable para el desarrollo de dicho datawarehouse. En este orden de ideas, en primer lugar se realizará el análisis y la revisión de los archivos en formato SEISAN, pertenecientes a la aplicación SEISAN (Seismic Analysis System). Así como las entrevistas que necesarias con las cuales se obtendrán las preguntas, que se quiere sean respondidas con la implementación del datawarehouse; cabe destacar que en dicha aplicación el manejo de la información es de tipo técnica. De esta manera se obtendrán los datos requeridos para el diseño e implementación de las dimensiones y las tablas de hechos correspondientes con dicha aplicación en el datawarehouse. De igual forma se verificará la aplicación estudios y desastres, aplicación en la cual el manejo de la información es de carácter social. Esto con el fin de obtener los datos necesarios para el diseño e implementación de las dimensiones y las tablas de hechos, correspondientes con dicha aplicación en el datawarehouse. De ser necesario se realizarán modificaciones al diseño del datawarehouse en busca de unificar los datos de las dos aplicaciones descritas anteriormente. Finalmente, se realizará un middleware que permita comunicar los archivos en formato SEISAN y la aplicación estudios y desastres con el datawarehouse, para de esta manera unificar la información. Adicionalmente se propondrá una aplicación web orientada hacia un administrador de base de datos, en la cual los usuarios puedan Capítulo I – Planteamiento del Problema 15 visualizar los resultados obtenidos de las consultas que estos realicen sobre dicho repositorio. Alcances  El sistema debe estar en producción al final del proyecto. Se requerirá como mínimo la base de datos implementada, la aplicación web de consulta general y al menos dos (2) mecanismos de incorporación de datos.  El sistema debe estar corriendo en el ambiente de producción.  En el datawarehouse se unificarán los datos del tipo técnico, provenientes de la aplicación SEISAN y los datos del tipo social, provenientes de la aplicación estudios y desastres.  El prototipo de consulta permitirá la visualización de los datos inmersos en el datawarehouse en base a un formulario preestablecido. Capítulo II – Marco Referencial 16 Capítulo II Marco Referencial En el presente capítulo se exponen los fundamentos conceptuales que fueron utilizados durante el proceso de investigación y desarrollo. Éste, comprende 4 secciones las cuales serán descritas a continuación. La primera sección corresponde con una descripción general de la Fundación Venezolana de Investigaciones Sismológicas (FUNVISIS), donde se implementará el sistema, se explica su estructura organizacional, misión, visión entre otros. En la segunda sección se encuentra la descripción de las características, arquitectura, ventajas y demás funcionalidades de un datawarehouse. La tercera sección del capítulo abarca el manejador de bases de datos Monet DB, donde se destacan las características de los sistemas manejadores de bases de datos orientados a columnas. Así como también las características y funcionalidades provistas por el manejador. La cuarta y última sección, se refiere a la tecnología Ruby on Rails, de donde se destacan las funcionalidades, características y arquitectura de la misma, de igual forma se realizan comparaciones entre las diversas versiones manejadas, haciendo énfasis en la versión más actual. 1. Fundación Venezolana de Investigaciones Sismológicas La Fundación Venezolana de Investigaciones Sismológicas, adscrita al Ministerio del Poder Popular para Ciencia, Tecnología e Industrias Intermedias (MPPCTII), es una institución que promueve de forma permanente investigaciones y estudios especializados en sismología, ciencias geológicas e ingeniería sísmica, con el propósito de contribuir a la reducción de la vulnerabilidad en el país. Asimismo, FUNVISIS, se encarga de divulgar el conocimiento relacionado con las técnicas de prevención a través del programa Aula Sísmica, promueve la formación de personal especializado en el área sismológica y es el ente encargado de instalar, operar y mantener la Red Sismológica y la Red Acelerográfica Nacional (www.funvisis.gob.ve). Capítulo II – Marco Referencial 17 1.1 Misión Ejecutar y promover, permanentemente, investigaciones y estudios sismológicos destinados a atender la demanda de seguridad en la población ante la amenaza sísmica en el territorio nacional, la formación de personal especializado y divulgar los nuevos conocimientos de las ciencias. 1.2 Visión Ser una organización de excelencia en el área de protección a la colectividad frente a la amenaza sísmica, de referencia nacional e internacional, distinguida por su capacidad de servicio, la calidad de su investigación y su desarrollo técnico y científico. 1.3 Organigrama A continuación en la Figura 1 se muestra el organigrama representativo de FUNVISIS. Figura 1 Organigrama FUNVISIS (www.funvisis.gob.ve) 2. Almacén de Datos Según, Bill Inmon en el año de 1995 en su libro titulado “¿What is a Datawarehouse?”, define un almacén de datos (DW, datawarehouse por sus siglas en ingles), como una colección de datos orientados a un tema, integrados, no volátiles e Capítulo II – Marco Referencial 18 historiados, y organizados para el apoyo de un proceso de ayuda a la decisión. De igual manera un DW se caracteriza por ser:  Integrado: los datos almacenados en el DW deben integrarse en una estructura consistente, por lo que las inconsistencias existentes entre los diversos sistemas operacionales deben ser eliminadas.  Temático: sólo los datos necesarios para el proceso de generación del conocimiento del negocio se integran desde el entorno operacional. Los datos se organizan por temas para facilitar su acceso y entendimiento por parte de los usuarios finales. Por ejemplo, todos los datos sobre clientes pueden ser consolidados en una única tabla del DW. De esta forma, las peticiones de información sobre clientes serán más fáciles de responder dado que toda la información reside en el mismo lugar.  Histórico: el tiempo es parte implícita de la información contenida en un datawarehouse. En los sistemas operacionales, los datos siempre reflejan el estado de la actividad del negocio en el momento presente. Por el contrario, la información almacenada en el DW sirve, entre otras cosas, para realizar análisis de tendencias. Por lo tanto, el DW se carga con los distintos valores que toma una variable en el tiempo para permitir comparaciones.  No volátil: el almacén de información de un DW existe para ser leído, pero no modificado. La información es por tanto permanente, significando la actualización del DW la incorporación de los últimos valores que tomaron las distintas variables contenidas en él sin ningún tipo de acción sobre lo que ya existía. 2.1 Conceptos asociados a un datawarehouse Es importante destacar los conceptos descritos a continuación, ya que los mismos son la base para la construcción de un DW, en base a lo siguiente: (Ibarra, 2006).  Multidimensionalidad: se refiere a convertir los datos de varias fuentes, tablas relacionales o archivos planos en una estructura donde los datos estén agrupados en dimensiones separadas y heterogéneas, que generalmente son llamadas cubos.  Data Mart: es una versión especial de un almacén de datos. Son subconjuntos de datos con el propósito de ayudar a que un área específica dentro del negocio pueda tomar mejores decisiones. Los datos existentes en este contexto pueden ser agrupados, explorados y propagados de múltiples formas para que diversos grupos de usuarios realicen la explotación de los mismos de la forma más conveniente según sus necesidades. Capítulo II – Marco Referencial 19  Esquema en estrella: es un modo de representar datos multidimensionales en una base de datos relacional, donde las tablas de dimensión guardan información descriptiva acerca de sus miembros y sus relaciones, mientras que las tablas de hechos almacenan datos del negocio.  Medidas: es un tipo de dato cuya información es usada por los analistas en sus consultas (querys), para medir el rendimiento del comportamiento de un proceso o un objeto del negocio. Las medidas candidatas son los datos numéricos, pero no todo dato numérico es una medida candidata, de igual forma las medidas se encuentran involucradas con los cálculos de los resúmenes.  Dimensiones: es una entidad o una colección de entidades relacionadas, usadas por los analistas para identificar el contexto de las medidas con las que trabajan, estas determinan el contexto para las medidas. Es debido señalar que las dimensiones son referenciadas por las llamadas llaves de dimensión y que estas poseen entidades, atributos, jerarquías e incluso niveles de agregación.  Hechos: es una colección de medidas relacionadas con sus dimensiones asociadas, representadas por las llaves de dimensión. De igual forma un hecho puede representar un objeto de negocio, una transacción o un evento que es utilizado por el analista de información.  Granularidad: se refiere al nivel de detalle en el cual los datos se almacenan en los datawarehouse. La regla de oro es almacenar los datos en el nivel más bajo de detalle posible. 2.2 Características de un datawarehouse Con base a la definición de Bill Inmon descrita en líneas anteriores serán descritas a continuación las características provistas por un almacén de datos.  Orientado a temas: una primera característica de un DW es que la información se clasifica en base a los aspectos que son de interés para la empresa. Siendo así, los datos tomados están en contraste con los clásicos procesos orientados a las aplicaciones. Los datos en la base de datos están organizados de manera que todos los elementos de datos relativos al mismo evento u objeto del mundo real queden unidos entre sí. Las diferencias entre la orientación de procesos y funciones de las aplicaciones y la orientación a temas, radican en el contenido de los datos a nivel detallado. En el DW se excluye la información que no será usada por el proceso de sistemas de soporte de decisiones, mientras que la información de las orientadas a las aplicaciones, contiene datos para satisfacer de inmediato los requerimientos Capítulo II – Marco Referencial 20 funcionales y de proceso, que pueden ser usados o no por el analista de soporte de decisiones.  Variante en el tiempo: los cambios producidos en los datos a lo largo del tiempo quedan registrados para que los informes que se puedan generar reflejen esas variaciones. Los datos son relativos a un periodo de tiempo (semestre, año, entre otros) y deben ser incrementados periódicamente. Toda la información del DW es requerida en algún momento. Esta característica básica de los datawarehouse, es muy diferente de la información encontrada en el ambiente operacional. En éstos, la información se requiere al momento de ser accedida.  No volátil: la información no se modifica ni se elimina, una vez almacenado un dato, éste se convierte en información de sólo lectura, y se mantiene para futuras consultas. Los datos almacenados no son actualizados, sólo son incrementados. Cabe destacar que posee dos únicos tipos de operaciones: la carga inicial de datos y el acceso a los mismos.  Integrado: la base de datos contiene los datos de todos los sistemas operacionales de la organización, y dichos datos deben ser consistentes. Integra datos recogidos de diferentes sistemas operacionales de la organización (y/o fuentes externas). Se construye mediante de fuentes de datos múltiples y heterogéneas. Cualquiera que sea la forma del diseño, el resultado es el mismo, la información necesita ser almacenada en el DW en un modelo globalmente aceptable y singular, aun cuando los sistemas operacionales subyacentes almacenen los datos de manera diferente. Es importante señalar que en un DW se aplican técnicas de limpieza e integración como lo son el asegurar la consistencia en el nombrado en las estructuras codificadas, tipos de datos de los atributos, y demás aspectos entre las múltiples bases de datos. Asimismo cuando los datos se mueven al DW, éstos deben ser transformados según sean los requerimientos operacionales. 2.3 Ventajas y desventajas de un datawarehouse Un DW puede dar lugar a una serie de importantes beneficios para una organización. En cualquier caso, su utilización permitirá que la información de gestión sea: accesible, correcta, uniforme y actualizada. A continuación se describen algunas de estas ventajas:  Menor coste en la toma de decisiones: se suprime el despilfarro de tiempo que se podía producir al intentar ejecutar consultas de datos largas y complejas con Capítulo II – Marco Referencial 21 bases de datos, que estaban diseñadas específicamente para transacciones más cortas y sencillas.  Mayor flexibilidad ante el entorno: un DW convierte los datos operacionales en información relacionada y estructurada, que genera el "conocimiento" necesario para la toma de decisiones. Esto permite establecer una base única del modelo de información de la organización, que puede dar lugar a una visión global de la información en base a los conceptos de negocio que tratan los usuarios.  Mejor servicio al cliente: el hecho de que un DW implique una mayor flexibilidad ante el entorno, tiene una consecuencia directa en una mayor capacidad para responder a las necesidades de los clientes.  Rediseño de procesos: un DW ofrece a los usuarios una capacidad de análisis de la información de su negocio, que tiende a ser ilimitada y que permite con frecuencia obtener una visión más profunda y clara de los procesos de negocio propiamente dichos, lo que a su vez permite obtener ideas renovadoras para la rediseño de los mismos. Por otra parte es importante señalar que utilizar almacenes de datos también plantea algunos inconvenientes, entre los cuales se encuentran:  Altos Costos: a lo largo de su vida los almacenes de datos pueden suponer altos costos. El almacén de datos no suele ser estático. Los costos de mantenimiento son elevados.  Tiempo de vida útil: los almacenes de datos se pueden quedar obsoletos relativamente pronto.  Consultas: a veces, ante una petición de información estos devuelven una información sub óptima, que también supone una pérdida para la organización. 2.4 Arquitectura de un datawarehouse Según (Bouman & Dongen, 2009), la arquitectura de un DW viene determinada por su situación central como fuente de información para las herramientas de análisis, con base a ello a continuación se describen los componentes mostrados en la Figura 2. Capítulo II – Marco Referencial 22 Figura 2 Arquitectura de un Datawarehouse (Bouman & Dongen, 2009)  Fuente de Datos: uno o más sistemas de fuente, como lo son archivos, sistemas manejadores de bases de datos (DBMS, por sus siglas en ingles), entre otros.  Un proceso de Extracción, Transformación y Carga de los datos: realiza las funciones de extracción de las fuentes de datos (transaccionales o externas), transformación (limpieza, consolidación, entre otros) y la carga del almacén de datos (ordenación, agregación, entre otros), e incluso refrescamiento del almacén, es decir, la operación periódica que propaga los cambios de las fuentes externas al almacén de datos. A menudo este proceso contiene un área de ensayo utilizada como área intermedia en donde se extraen los datos y se realiza la transformación de los datos iniciales y su limpieza. Los datos de ensayo pueden ser usados tanto una base de datos como en ficheros planos. En muchos casos mediante archivos planos se permite un procesamiento más rápido.  El almacén de datos: que consiste en la base de datos del almacén central y cero o más Data Marts. Posee información relevante, metadatos. Los metadatos son básicamente datos acerca de los datos contenidos en el DW, es la manera de describir propiedades de las bases de datos y sus atributos, incluyendo tablas y nombres de las columnas, atributos de columnas (tamaño y tipo de dato) de las tablas de las bases de datos, así como claves primarias y relaciones con claves foráneas. En sí el almacén de datos es la base fundamental para establecer la completa integración de los datos de la empresa.  La capa de usuario final identificada como (EUL): se refiere a las diversas herramientas para trabajar con los datos, como lo son informes, cuadros de mando, hojas de cálculo y los documentos publicados. Generalmente, la combinación del almacén central y los data marts es considerada como el almacén de datos, y el término de datawarehouse es utilizado para denotar el proceso completo de construcción, carga y la gestión de los datos del almacén. Capítulo II – Marco Referencial 23 3. Sistemas manejadores de bases de datos orientados a columnas Un sistema manejador de bases de datos orientado a columnas, es un sistema de gestión de base de datos, que almacena el contenido de la columna en lugar de la fila. Esto tiene ventajas para los almacenes de datos y catálogos de la biblioteca, donde los agregados se calculan sobre un gran número de elementos de datos similares. Es posible obtener algunos beneficios de la organización orientada a columnas y por hilera con cualquier base de datos. Cuando se trata de, orientada a columnas nos referimos tanto a la facilidad de expresión de una estructura orientada a la columna como al foco en la optimización de las cargas de trabajo orientadas a columnas. Este enfoque contrasta con el orientado a fila y con bases de datos de correlación, que utilizan una base de almacenamiento de la estructura de valor. (Abadi, Boncz, & Harizopoulos, 2009) 3.1 Descripción Un programa de base de datos debe mostrar sus datos como tablas de dos dimensiones, de columnas y filas, pero lo almacenan como cadenas de una sola dimensión. Por ejemplo, una base de datos podría tener los siguientes datos. EmpId Apellido Nombre Salario 1 Smith Joe 40000 2 Jones María 50000 3 Johnson Cathy 44000 De esta información es posible apreciar un simple empleado de identificador (EmpId), campos de nombre (nombre y apellido) y un salario (sueldo). Aunque las unidades de memoria (RAM) y almacenamiento (disco duro) difieren mecánicamente, el sistema operativo del equipo se resume en ellos. Sin embargo, la base de datos debe convertir a su tabla de dos dimensiones en una serie unidimensional de bytes. Para así el sistema operativo pueda escribir en cualquiera de la memoria RAM o disco duro, o ambos. Una base de datos orientada a filas serializa todos los valores de una fila juntos, entonces los valores de la fila siguiente, y así sucesivamente, como por ejemplo: 1, Smith, Joe, 40000; 2, Jones, Mary, 50000; 3, Johnson, Cathy, 44.000; Capítulo II – Marco Referencial 24 Por otro lado una base de datos orientada a columnas serializa todos los valores de una columna en conjunto, los valores de la columna siguiente, y así sucesivamente, como por ejemplo. 1,2,3; Smith, Jones, Johnson; Joe, María, Catalina; 40000, 50000, 44000; Las particiones, la indexación, el almacenamiento en caché, los cubos de procesamiento analítico en línea (OLAP, por sus siglas en ingles) y los sistemas de procesamiento transaccionales en línea (OLTP, por sus siglas en ingles), tales como escribir por delante de registro o control de concurrencia multiversión; todos afectan dramáticamente la organización física. Dicho esto, el procesamiento de transacciones en línea centrada en los sistemas manejadores de bases de datos relacionales (RDBMS) más orientada a la fila, mientras que en el procesamiento analítico en línea, son un balance de los orientados a filas y de los orientados a columnas. 3.2 Beneficios Las comparaciones entre sistemas manejadores de bases de datos orientados a filas y los orientados a columnas, son típicamente relacionadas con la eficiencia de acceso al disco duro para una determinada carga de trabajo, como el tiempo de búsqueda es muy largo comparado con los retrasos en otras computadoras. A veces, la lectura de un megabyte de datos almacenado de forma secuencial, no tiene en el tiempo más de un acceso al azar. Además, debido a que el tiempo de búsqueda está mejorando a un ritmo lento en relación a la potencia de la CPU, este enfoque probablemente continuará en los sistemas que dependen de discos duros para su almacenamiento. A continuación se presenta un conjunto de observaciones con base a las compensaciones entre las organizaciones de los orientados a columnas y los orientados a filas.  Sistemas orientados a columnas, son más eficientes cuando un agregado debe ser calculado a lo largo de filas, pero sólo para un subconjunto notablemente más pequeño de todas las columnas de datos, ya que la lectura que los pequeños subconjunto de datos puede ser más rápido que leer todos los datos.  Sistemas orientados a columnas, son más eficientes cuando los nuevos valores de una columna se suministran para todas las filas a la vez, debido a que los datos de la columna se puede escribir de manera eficiente y reemplazar los datos de la columna vieja sin tocar las otras columnas de las filas. Capítulo II – Marco Referencial 25  Sistemas orientados a filas, son más eficientes cuando varías columnas de una sola fila se requiere al mismo tiempo, y cuando la fila de tamaño es relativamente pequeño, ya que toda la fila se pueden recuperar con una sola búsqueda en disco.  Sistemas orientados a filas, son más eficientes cuando se escribe una nueva fila si todos los datos de la columna se suministra al mismo tiempo, como toda la fila se puede escribir con una sola búsqueda en disco. En la práctica, las arquitecturas orientadas a filas, están bien adaptadas para OLTP como las cargas de trabajo, que están mucho más cargadas de transacciones interactivas. Almacenes orientados a columnas son muy adecuados para OLAP, como las cargas de trabajo (por ejemplo, almacenes de datos), que suelen implicar un menor número de consultas muy complejo en todos los datos (posiblemente terabytes). Sin embargo, hay un número de pruebas realizadas, basada en filas RDBMS OLAP que se encarga de terabytes, o incluso petabytes de datos, como Teradata. (Abadi, Boncz, & Harizopoulos, 2009) 3.3 Implementaciones Almacenes de columnas o archivos de transposición se han aplicado desde los primeros días del desarrollo de los DBMS, a partir de la década de 1970. Por ejemplo, la empresa Estadísticas Canadá implementó en 1976 y un sistema, el cual se utilizó para el procesamiento y la recuperación del censo canadiense de población y vivienda, así como varias aplicaciones de estadística. Los resultados de este sistema eran compartidos con otras organizaciones estadísticas en todo el mundo y utilizados ampliamente en la década de 1980. Durante muchos años, sólo el DMMS Sybase IQ, era el único producto comercialmente disponible en los DBMS orientado a la clase de la columna. Sin embargo, eso ha cambiado rápidamente en los últimos años, tanto con las implementaciones en código abierto, como con las implementaciones comerciales. Ejemplos actuales de DBMS en columnas incluyen:  Comercial o Oracle Application predicativo Servir al por menor (RPA) o ARENA CDBMS o SenSage o HassoDB o Sybase IQ o SADAS http://translate.googleusercontent.com/translate_c?hl=es&sl=en&tl=es&u=http://en.wikipedia.org/wiki/Petabyte&rurl=translate.google.com&twu=1&usg=ALkJrhibAXwJLL34txPH7nDlGGfqEFki9A http://translate.googleusercontent.com/translate_c?hl=es&sl=en&tl=es&u=http://en.wikipedia.org/wiki/Teradata&rurl=translate.google.com&twu=1&usg=ALkJrhjB1S3WR4guBX5G_W4149ZC33DKjA http://translate.googleusercontent.com/translate_c?hl=es&sl=en&tl=es&u=http://en.wikipedia.org/wiki/Sybase_IQ&rurl=translate.google.com&twu=1&usg=ALkJrhiX8MdwqPaWJUU4xof_cwwk9D4Bqw Capítulo II – Marco Referencial 26 o Vertica y sus académicos de código abierto primo de la tienda C- o Valentina base de datos o KDB o Addamark, ahora el SenSage registro del servidor escalable o 1010data 's de base de datos Tenbase o Dataprobe o EXASolution o Skytide servidor XOLAP o SuperStar desde el Espacio-Tiempo de Investigación o ParAccel analítico de base de datos o Datos Aster Sistemas o FluidDB o Ingres y Vectorwise iniciativa  De código abierto ( software propietario ) o Calpont de InfiniDB Enterprise Edition-front-end de MySQL o Infobright Enterprise Edition, se integra con MySQL (antes Brighthouse) o RC21 proyecto de código abierto comercial o Xplain semántica de base de datos (llamados archivos incorporado). El software ya no está disponible.  De código abierto ( software libre ) o Calpont de InfiniDB Community Edition, MySQL-Front End, GPLv2 o C-Store nueva versión desde octubre 2006 o GenoByte column, sistema de almacenamiento basada en la API para el manejo de datos genotipo o Lemur Bitmap Index C++ Library (GPL) o FastBIT o Infobright Community Edition o LucidDB y Eigenbase o MonetDB o Metakit o El lenguaje de programación S y R de GNU incorporado en estructuras de datos orientadas a columnas para análisis estadísticos De todos los sistemas manejadores de bases datos orientados a columnas expuestos en líneas anteriores, será descrito en profundidad a MonetDB perteneciente al grupo de los sistemas manejadores de bases de datos de código abierto de software libre; http://translate.googleusercontent.com/translate_c?hl=es&sl=en&tl=es&u=http://en.wikipedia.org/wiki/Vertica&rurl=translate.google.com&twu=1&usg=ALkJrhjUVPkllpvasDXZHVoj4sDQkn6KPA http://translate.googleusercontent.com/translate_c?hl=es&sl=en&tl=es&u=http://www.sensage.com/&rurl=translate.google.com&twu=1&usg=ALkJrhhNmUC99S9xJfd7f6CR35Gmy5TO2Q http://translate.googleusercontent.com/translate_c?hl=es&sl=en&tl=es&u=http://en.wikipedia.org/wiki/Infobright&rurl=translate.google.com&twu=1&usg=ALkJrhjWktPea_CtpVSiFAAZKYU1sGbB6Q http://translate.googleusercontent.com/translate_c?hl=es&sl=en&tl=es&u=http://en.wikipedia.org/wiki/MySQL&rurl=translate.google.com&twu=1&usg=ALkJrhjN8uhY3M18G3NTdXIm1zmaprk01g http://translate.googleusercontent.com/translate_c?hl=es&sl=en&tl=es&u=http://www.jhterbekke.net/XplainDBMS.html&rurl=translate.google.com&twu=1&usg=ALkJrhj_NcZ0QhBlFTCAQfyef7Gqakditw http://translate.googleusercontent.com/translate_c?hl=es&sl=en&tl=es&u=http://www.obiba.org/%3Fq%3Dnode/75&rurl=translate.google.com&twu=1&usg=ALkJrhi014RSXat3g_0oO_NmwsyaD0FNGw http://translate.googleusercontent.com/translate_c?hl=es&sl=en&tl=es&u=http://en.wikipedia.org/wiki/LucidDB&rurl=translate.google.com&twu=1&usg=ALkJrhjt953ape9vn11Z5ZB9kv-LG3ZxtQ Capítulo II – Marco Referencial 27 por ser este uno de los más eficientes para la creación y manipulación de un almacén de datos (Datawarehouse). 3.4 Descripción de MonetDB Según Vermeij, Quak, Kersten, & Nes, el sistema manejador de bases de datos MonetDB es un sistema de gestión de alto rendimiento y de código abierto, desarrollado en el instituto de investigación nacional para las matemáticas y de informática (CWI; En Informática de Wiskunde del voor) en los Países Bajos. Fue diseñado para proporcionar alto rendimiento en preguntas complejas contra bases de datos grandes. MonetDB se ha aplicado con éxito en actividades de alto rendimiento para Explotación minera de datos, OLAP, pregunta XML, recuperación del texto y de las multimedias, entre otras. La representación de datos internos de MonetDB es almacenada en la memoria, confiando en las gamas enormes del registro de dirección de la memoria de CPU contemporáneas, y así saliendo del DBMS tradicional diseña la participación de la gerencia compleja de los almacenes grandes de los datos en memoria limitada. MonetDB introdujo innovaciones en todas las capas de un DBMS, un modelo de almacenamiento basado en la Fragmentación vertical, una CPU moderna, una arquitectura vectorizada en la ejecución de la consulta, eso a menudo da a MonetDB más que diez veces una ventaja neta, en cuanto a la velocidad en el mismo algoritmo ejecutado sobre un típico intérprete para un RDBMS. La familia de MonetDB consiste en:  MonetDB/SQL: la solución de la base de datos relacional  MonetDB/XQuery: la solución de la base de datos de XML  Servidor de MonetDB: el servidor de base de datos del multi-modelo 3.4.1 Características de MonetDB Las tres (3) principales características de MonetDB son:  La fragmentación vertical, utilizada por MonetDB para almacenar sus datos es muy beneficioso para el procesamiento de consultas espaciales. La razón principal es que con las técnicas espaciales de filtro, sólo una fracción de las geometrías de una tabla son realmente necesarios en la mayoría de los casos. En un modelo tradicional de tupla de almacenamiento basado en los datos de geometría se encuentra todavía en el camino. Debido al tamaño de la geometría sólo pocas tuplas son las que pueden ser almacenadas en un bloque de disco. La http://enciclopediaespana.com/Base_de_datis_relacional.html Capítulo II – Marco Referencial 28 fragmentación vertical asegura que los atributos que no se necesitan no se encuentren en el camino.  Consultas espaciales son a menudo muy difíciles de manejar. A menudo, el optimizador de consultas tiene que ser ayudado por las pistas dadas por el optimizador de SQL. Durante años, se han hecho varios intentos para crear un optimizador de consultas redestinable o modular. Los más prometedores se basan en la reescritura de plazo, lo que proporciona un ajuste a la razón de su corrección (Becker & Guting, 1992). Sin embargo, se sabe también que muchas dependen tanto de la semántica inherente al lenguaje de consulta e información circunstancial, como la disponibilidad de los índices, los algoritmos y el nivel de protección de la transacción. En estos casos, la regla de re escritura de forma rápida se hace difícil de seguir y mantener la coherencia. El software MonetDB ofrece un esquema fácil de depurar, desplegar y optimizadores de seguimiento orientado a tareas bien definidas.  En el código XML dominio espacial (y específicamente GML) es cada vez más utilizado. Sin embargo, hacer consultas a un gran documento XML sigue siendo complicado. MonetDB tiene un historial de rentabilidad demostrado, encontrado en su motor XQuery. La combinación de la funcionalidad de XQuery eficiente de MonetDB con el módulo espacial, conlleva a una poderosa solución de procesamiento de GML. Cabe destacar que en la actualidad la relación entre SQL / XML de integración está en desarrollo. 3.4.2 Arquitectura de MonetDB En esta sección se presentan brevemente el servidor MonetDB y el compilador de SQL. Una creciente clase de los motores de bases de datos están orientados a la explotación de un almacén de datos orientado a columnas (Stonebraker, 2005). En este campo, tablas relacionales se dividen verticalmente en cada columna que representa un atributo relacional único. Casi como si cada columna se almacena en una tabla separada o incluso una matriz común, pero con una implementación que se orienta a explotar de manera óptima esta estructura. Este enfoque conduce a una arquitectura de sistema muy simplificado y abre muchos caminos para aumentar el rendimiento. Los beneficios provienen de una mejor racionalización del flujo de datos desde el disco a través de la memoria en la caché de la CPU. Almacenes de datos orientados a columnas son especialmente beneficiosos en datawarehouse y aplicaciones de minería de datos, que a menudo se utilizan en bases de datos científicas. La razón principal es que la mayoría de las aplicaciones no necesitan los cientos de columnas de una tabla relacional con los datos Capítulo II – Marco Referencial 29 de medición científica, sino que simplemente requieren una labor de sólo unas pocas a la vez, para el análisis estadístico. El beneficio inmediato del enfoque de la columna del almacén de datos, es que sólo los datos que son relevantes para el proceso son los que se traen desde el disco. MonetDB es una pilar completamente funcional del almacén de datos desarrollado a lo largo de una década en el CWI (Centrum Wiskunde & Informática). Se trata de una arquitectura de dos capas de un servidor de base de datos y una serie de interfaces. En la actualidad dispone de interfaces que proporcionan una para SQL y una para la interfaz XQuery con el servidor de base de datos. El servidor se aborda en un lenguaje propio, llamado lenguaje para MonetDB ensamblador (LMA). LMA es un lenguaje de álgebra relacional que soporta una gran colección de primitivas relacionales, funciones y fácil vinculación con las funciones definidas por el usuario. Este enfoque simplifica considerablemente los compiladores de interfaces, la interfaz analiza las consultas SQL y los compila en los planes de LMA semi-optimizado que explotan el lenguaje SQL y la semántica del esquema. Sólo se centran en la reducción de volumen posible. El compilador de aplicaciones para usuario también selecciona los componentes LMA optimizador para ser activado, por ejemplo, eliminación de la expresión común, la eliminación de código muerto, paralelismo, entre otros. De esta manera, un optimizador de la arquitectura de tres niveles se logra con una clara división de tareas. La capa inferior se centra en la optimización operacional con el estado actual de la máquina. La capa superior está orientada a la explotación de la semántica del esquema, y la capa media está orientada a las decisiones tácticas. 3.4.3 Funcionalidades de MonetDB A continuación se presentan una serie de cuadros, con un resumen de las funcionalidades provistas por el sistema manejador de bases de datos MonetDB. (Comparison_of_relational_database_management_systems). Información General Mantenedor Primera Fecha de Lanzamiento Ultima versión Última Fecha de Lanzamiento Licencia de Software MonetDB El equipo de desarrolladores MonetDB 2004 5.6 06 2008 MonetDB Licencia Pública v1.1 Cuadro 1 Información General MonetDB http://translate.googleusercontent.com/translate_c?hl=es&sl=en&u=http://monetdb.cwi.nl/Legal/MonetDBLicense-1.1.html&prev=/search%3Fq%3DMonetDB%2B%252B%2Bwikipedia%26hl%3Des%26biw%3D1280%26bih%3D608%26prmd%3Div&rurl=translate.google.co.ve&twu=1&usg=ALkJrhhvR9FJU5onpW7HmSlBtVu5OGhwxA http://translate.googleusercontent.com/translate_c?hl=es&sl=en&u=http://monetdb.cwi.nl/Legal/MonetDBLicense-1.1.html&prev=/search%3Fq%3DMonetDB%2B%252B%2Bwikipedia%26hl%3Des%26biw%3D1280%26bih%3D608%26prmd%3Div&rurl=translate.google.co.ve&twu=1&usg=ALkJrhhvR9FJU5onpW7HmSlBtVu5OGhwxA http://translate.googleusercontent.com/translate_c?hl=es&sl=en&u=http://monetdb.cwi.nl/Legal/MonetDBLicense-1.1.html&prev=/search%3Fq%3DMonetDB%2B%252B%2Bwikipedia%26hl%3Des%26biw%3D1280%26bih%3D608%26prmd%3Div&rurl=translate.google.co.ve&twu=1&usg=ALkJrhhvR9FJU5onpW7HmSlBtVu5OGhwxA Capítulo II – Marco Referencial 30 Sistemas Operativos Windows Mac OS X Linux BSD UNIX AmigaOS Symbian z/OS 1 MonetDB SI SI SI NO SI NO NO NO Cuadro 2 Sistemas Operativos Soportados por MonetDB Características Fundamentales MonetDB ACID SI Integridad Referencial SI Transacciones SI Unicode SI Tabla Temporal SI Materializado Vista NO Cuadro 3 Características Fundamentales MonetDB Índices MonetDB -R / + R árbol NO Hash SI Expresión NO Parcial NO Inversa NO Mapa de bits NO GiST NO GIN NO Cuadro 4 Índices en MonetDB 4. Ruby on Rails Según Ruby on Rails org. Web development that doesn’t hurt. Ruby on Rails es un entorno de desarrollo web de código abierto que está optimizado para satisfacción de los programadores y de la productividad. Permite escribir un buen código favoreciendo la convención antes que la configuración. http://translate.googleusercontent.com/translate_c?hl=es&sl=en&u=http://en.wikipedia.org/wiki/AmigaOS&prev=/search%3Fq%3DMonetDB%2B%252B%2Bwikipedia%26hl%3Des%26biw%3D1280%26bih%3D608%26prmd%3Div&rurl=translate.google.co.ve&twu=1&usg=ALkJrhiWhbaVE64wY14OeLS8BCIkW7vyKw http://translate.googleusercontent.com/translate_c?hl=es&sl=en&u=http://en.wikipedia.org/wiki/Symbian&prev=/search%3Fq%3DMonetDB%2B%252B%2Bwikipedia%26hl%3Des%26biw%3D1280%26bih%3D608%26prmd%3Div&rurl=translate.google.co.ve&twu=1&usg=ALkJrhjAzcEvCq6DoWjzn_CKRDcvNcZwmQ http://translate.googleusercontent.com/translate_c?hl=es&sl=en&u=http://en.wikipedia.org/wiki/Z/OS&prev=/search%3Fq%3DMonetDB%2B%252B%2Bwikipedia%26hl%3Des%26biw%3D1280%26bih%3D608%26prmd%3Div&rurl=translate.google.co.ve&twu=1&usg=ALkJrhhxlCPOccA8uOIrWKf4gK4clQRTHg http://translate.googleusercontent.com/translate_c?hl=es&sl=en&u=http://en.wikipedia.org/wiki/Comparison_of_relational_database_management_systems&prev=/search%3Fq%3DMonetDB%2B%252B%2Bwikipedia%26hl%3Des%26biw%3D1280%26bih%3D608%26prmd%3Div&rurl=translate.google.co.ve&twu=1&usg=ALkJrhizYJLnNJYWKd9l02FP4Kz_5KZBSg#os_1 http://translate.googleusercontent.com/translate_c?hl=es&sl=en&u=http://en.wikipedia.org/wiki/R-tree&prev=/search%3Fq%3DMonetDB%2B%252B%2Bwikipedia%26hl%3Des%26biw%3D1280%26bih%3D608%26prmd%3Div&rurl=translate.google.co.ve&twu=1&usg=ALkJrhhxWf8OhbGTjMcQdwgclpg9W3Zo1w http://translate.googleusercontent.com/translate_c?hl=es&sl=en&u=http://en.wikipedia.org/wiki/R%252B_tree&prev=/search%3Fq%3DMonetDB%2B%252B%2Bwikipedia%26hl%3Des%26biw%3D1280%26bih%3D608%26prmd%3Div&rurl=translate.google.co.ve&twu=1&usg=ALkJrhgJt9dEQPVdhG-EO1kF0D7NKawiaw http://translate.googleusercontent.com/translate_c?hl=es&sl=en&u=http://en.wikipedia.org/wiki/GiST&prev=/search%3Fq%3DMonetDB%2B%252B%2Bwikipedia%26hl%3Des%26biw%3D1280%26bih%3D608%26prmd%3Div&rurl=translate.google.co.ve&twu=1&usg=ALkJrhjgFqPLTC1Uk9HMVuI6ZrgbuyST8A Capítulo II – Marco Referencial 31 En este concepto es importante definir la separación entre los dos entes importantes que conforman este entorno, como lo son Ruby y Rails. Por su parte, según Informit (Informit. Ruby Language), Ruby es un lenguaje de programación interpretado, reflexivo y orientado a objetos, creado por el programador japonés Yukihiro "Matz" Matsumoto, es un lenguaje de programación interpretado en una sola pasada y su implementación oficial es distribuida bajo una licencia de software libre. Según su creador, Ruby está diseñado para la productividad y la diversión del desarrollador, siguiendo los principios de una buena interfaz de usuario. Sostiene que el diseño de sistemas necesita enfatizar las necesidades humanas más que las de la máquina. Por otro lado, Rails, según Ruby on Rails Org, es un completo entorno para desarrollar aplicaciones web con base de datos de acuerdo con la estructura Modelo Vista Controlador (MVC). Desde el Ajax en la vista, a la petición y respuesta en el controlador, hasta el modelo, Rails proporciona un entorno de desarrollo de Ruby. Para probarlo, solo se necesita una base de datos y un servidor web. El desarrollo sobre este entorno está basado en dos filosofías, no te repitas (del inglés Don't repeat yourself, DRY) y convención sobre configuración. DRY significa que las definiciones deberían hacerse una sola vez. Dado que Ruby on Rails es un framework de pila completa, los componentes están integrados de manera que no hace falta establecer puentes entre ellos. Mientras que convención sobre configuración significa que el programador sólo necesita definir aquella configuración que no es convencional. Ruby on Rails se ha convertido en un entorno muy poderoso para el desarrollo de aplicaciones Web y que cada día toma más auge dentro del mundo del desarrollo Web. Es importante señalar que en líneas posteriores serán descritas a profundidad las versiones de Ruby 1.9.2 y Rails 3.0 por ser estas las más recientes y con las cuales será desarrollada la propuesta del presente TEG. 4.1 Funcionamiento Ruby on Rails funciona bajo el paradigma MVC, (Burbeck, 1992) el cual es un patrón de arquitectura de software que separa los datos de una aplicación, la interfaz de usuario, y la lógica de control en tres componentes distintos, el cual aplicado a web la vista es un página HTML, o html.erb en caso de Rails, el cual contiene el HTML y el código que provee de datos dinámicos a la página. El modelo es el Sistema de Gestión de base de datos y la Lógica de negocio, y el controlador es el responsable de recibir los eventos de entrada desde la vista. Específicamente en Rails el modelo MVC se especifica de la siguiente manera: Capítulo II – Marco Referencial 32  Modelo: En las aplicaciones web orientadas a objetos sobre bases de datos, el Modelo consiste en las clases que representan a las tablas de la base de datos. En Ruby on Rails, las clases del Modelo son gestionadas por ActiveRecord. Por lo general, la única tarea que tiene un desarrollador es hacer que los modelos hereden de la clase ActiveRecord::Base, y Rails sabrá mediante las convenciones qué tabla usar y qué columnas tiene dicha tabla.  Vista: Es la lógica de visualización, es decir, cómo se muestran los datos provenientes del Controlador. Con frecuencia en las aplicaciones web la vista consiste en una cantidad mínima de código de algún lenguaje incluido en HTML. El método que se emplea en Rails por defecto es usar Ruby Embebido (archivos .rhtml, desde la versión 2.x en adelante de RoR archivos .html.erb), que son básicamente fragmentos de código HTML código en Ruby. También pueden construirse vistas en HTML y XML con Builder3 o usando el sistema de plantillas Liquid.  Controlador: Las clases del Controlador responden a la interacción del usuario e invocan a la lógica de la aplicación, que a su vez manipula los datos de las clases del Modelo y muestra los resultados usando las Vistas. En las aplicaciones web basadas en MVC, los métodos del controlador son invocados por el usuario usando el navegador web. La implementación del Controlador es manejada por el ActionPack de Rails, que contiene la clase ApplicationController. Un controlador en Rails debe heredar de esta clase y definir las acciones como métodos de dicha clase. 4.2 Arquitectura Según Ruby on Rails org. Web development that doesn’t hurt. Rails está separado en varios paquetes, los cuales en conjunto forman el framework. Básicamente los paquetes principales de los cuales se constituye Rails se mencionan a continuación:  ActiveRecord: es una alternativa que facilita acceder a los datos de una base de datos. Una fila en la tabla de la base de datos (o vista) se envuelve en una clase, de manera que se asocian filas únicas de la base de datos con objetos del lenguaje de programación usado. Cuando se crea uno de estos objetos, se añade una fila a la tabla de la base de datos. Cuando se modifican los atributos del objeto, se actualiza dicha la fila, por otra parte, la clase envoltorio implementa métodos de acceso para cada columna de la tabla o vista. Rails implementa este enfoque para proveer una interfaz hacia los datos que facilite su acceso y manipulación utilizando los http://es.wikipedia.org/wiki/ActiveRecord http://home.leetsoft.com/liquid/ http://es.wikipedia.org/w/index.php?title=ActionPack&action=edit&redlink=1 Capítulo II – Marco Referencial 33 modelos. La clase específica que implementa la interfaz se llama ActiveRecord::Base.  ActiveResource (ARes): es la clase principal utilizada para mapear recursos RESTful con modelos en una aplicación Rails. Es decir, ARes se encarga de proveer la interfaz de una aplicación Rails con una plataforma de servicios Web, permitiendo tanto recibir como crear servicios que funcionan bajo el enfoque REST. ARes conecta objetos de negocio y servicios Web REST e implementa el mapeo objeto relacional para proveer transparencia entre un cliente y un servicio RESTful.  Action Pack: divide la respuesta a una solicitud web en un controlador (ejecutando la lógica) y una vista (renderizando una plantilla). Este proceso en dos partes es conocido como una acción, la cual normalmente creará, leerá, actualizará o eliminará (create, read, update o delete, CRUD por sus siglas en ingles) alguna parte de un modelo (comúnmente soportado por una base de datos) antes de elegir renderizar una plantilla (vista) o redirigir a alguna otra acción. Action Pack implementa estas acciones como métodos públicos en Action Controllers y Action Views. Los Action controllers son los responsables de manejar todas las acciones relacionadas con la lógica de la aplicación. Este agrupamiento usualmente consiste de acciones de procesamiento y CRUDs alrededor de un modelo. Las plantillas Action View son escritas utilizando Ruby embebido mediante etiquetas en el código HTML. Para evitar llenar las plantillas con código, un manojo clases ayudantes (llamados helpers en Rails) proveen funcionalidades comunes como formularios, fechas y cadenas de caracteres.  ActiveSupport: es una colección de variedad de clases utilitarias y extensiones de librerías estándar que son de gran utilidad para Rails. Todas estas librerías fueron reunidas en este paquete para poder aprovechar todo el potencial que ofrece el lenguaje Ruby. En síntesis, son librerías de propósito general de Rails.  Action Mailer: este paquete permite el envió de correos electrónicos desde una aplicación Rails usando modelos y vistas llamadas mailers. Los modelos Mailer heredan de la clase ActionMailer::Base, así mismo, los correos son definidos creando métodos en este modelo los cuales manipulan ciertas variables que posteriormente serán usadas por la plantilla del Mailer. 4.3 Gemas Las gemas son plugins y/o codigos añadidos a un proyecto Ruby on Rails, que proveen nuevas funcionalidades como nuevos create, nuevas funciones pre escritas (como Capítulo II – Marco Referencial 34 login de usuarios) o nuevas herramientas para el desarrollo como puedan ser Haml y SASS (la primera es una nueva forma de template basada en html pero más sencilla y potente, y la segunda es igual pero para el caso de las CSS). (Wikipedia. Rails) 4.4 Soporte de servidores Web Para desarrollo y pruebas, se utiliza Mongrel o WEBrick, incluido con Ruby. Para utilizar Rails en servidores en producción se está extendiendo el uso de Passenger, una especie de mod_rails para Apache desarrollado en 2008 por la empresa holandesa Phusion. Otras opciones para producción son Nginx, Mongrel, Apache, Lighttpd con FastCGI o alguna combinación de ambos (por ejemplo utilizando Apache como proxy para los procesos Mongrel). Sobre Apache, mod ruby puede mejorar considerablemente el rendimiento, aunque su uso no se recomienda porque no es seguro utilizar múltiples aplicaciones RoR sobre Apache. (Wikipedia. Rails) 4.5 Soporte de Bases de Datos Dada que la arquitectura Rails favorece el uso de bases de datos se recomienda usar un sistema gestor de bases de datos relacionales (SGBDR) para almacenamiento de datos. Rails soporta la biblioteca SQLite por defecto. El acceso a la base de datos es totalmente abstracto desde el punto de vista del programador, es decir que es agnóstico a la base de datos, y Rails gestiona los accesos a la base de datos automáticamente (aunque, si se necesita, se pueden hacer consultas directas en SQL) Rails intenta mantener la neutralidad con respecto a la base de datos, la portatibilidad de la aplicación a diferentes sistemas de base de datos y la reutilización de bases de datos preexistentes. Sin embargo, debido a la diferente naturaleza y prestaciones de los SGBDRs el framework no puede garantizar la compatibilidad completa. Se soportan diferentes SGBDRs, incluyendo MySQL, PostgreSQL, SQLite, IBM DB2 y Oracle. (Wikipedia. Rails) 4.6 Requisitos Se necesita un servidor web como Apache 1.3.x or 2.x, lighttpd, algún servidor web compatible con FastCGI con un módulo similar a mod_rewrite, o Nginx. Para desarrolllo, Rails permite utilizar Mongrel (un servidor HTTP ligero creado para soportar aplicaciones en Ruby y muy extendido entre aplicaciones en producción) o WEBrick (un pequeño servidor a medida de rendimiento limitado y no recomendado para su uso en producción). Rails soporta la extensión mod ruby de Apache (servidor web). Por otra parte se necesita una base de datos, como por ejemplo: MySQL, PostgreSQL, o SQLite, entre otros. (Wikipedia. Rails) http://es.wikipedia.org/w/index.php?title=Mongrel&action=edit&redlink=1 http://es.wikipedia.org/w/index.php?title=WEBrick&action=edit&redlink=1 http://nginx.net/ http://mongrel.rubyforge.org/ http://es.wikipedia.org/wiki/Lighttpd http://es.wikipedia.org/wiki/FastCGI http://es.wikipedia.org/w/index.php?title=Mod_ruby&action=edit&redlink=1 http://es.wikipedia.org/wiki/SQLite http://es.wikipedia.org/w/index.php?title=SGBDR&action=edit&redlink=1 http://es.wikipedia.org/w/index.php?title=SGBDR&action=edit&redlink=1 http://es.wikipedia.org/wiki/MySQL http://es.wikipedia.org/wiki/PostgreSQL http://es.wikipedia.org/wiki/SQLite http://es.wikipedia.org/wiki/DB2 http://es.wikipedia.org/wiki/Lighttpd http://es.wikipedia.org/wiki/FastCGI http://nginx.net/ http://mongrel.rubyforge.org/ http://es.wikipedia.org/w/index.php?title=WEBrick&action=edit&redlink=1 http://es.wikipedia.org/w/index.php?title=Mod_ruby&action=edit&redlink=1 http://es.wikipedia.org/wiki/MySQL http://es.wikipedia.org/wiki/PostgreSQL http://es.wikipedia.org/wiki/SQLite Capítulo II – Marco Referencial 35 4.7 Entorno de Trabajo Existen muchas alternativas para trabajar con Ruby on Rails, tanto libres y gratuitas como de pago. Tomado de (Wikipedia. Rails), a continuación se listan las principales:  Aptana: multiplataforma, nació como un plugin de eclipse para la edición y desarrollo web. Actualmente puedes instalarlo como plugins o autónomo de forma independiente. Las últimas versiones están muy bien integradas con Ruby on Rails.  Netbeans: uno de los más usados, libre y totalmente gratuito.  TextMate: sólo para Mac. Es el entorno más usado entre la comunidad Rails. Es pago pero su potencia y forma de trabajo favorece la producción y desarrollo con Ruby on Rails.  Gmate: un proyecto libre y gratuito para convertir Gedit, el editor de texto de escritorio Gnome de Linux, en un clon muy aproximado de Textmate. 4.8 Nociones básicas de instalación y estructura de aplicación La instalación y configuración de un ambiente Rails es muy sencilla. Ruby es distribuido por Ruby Org (Ruby lang org. Ruby Language.), mientras que Rails es distribuido a través de Ruby gemas por Ruby on Rails Org (Ruby on Rails org. Web development that doesn’t hurt. ). La instalación de Ruby se realiza mediante un wizard en un ambiente Windows y mediante paquetes bajo UNIX. Una vez instalado Ruby, se puede obtener la gema de Rails mediante un comando en una consola o Shell estándar (ruby install rails) o desde el sitio oficial mediante una descarga. Para generar una aplicación Rails se debe utilizar una consola mediante la sintaxis provista por ellos (rails hola_mundo, donde hola_mundo sería el nombre de la aplicación) o utilizar un IDE para facilitar este proceso. Rails viene por defecto con una estructura de archivos definida, para facilitar las convenciones y el manejo MVC que este sostiene. El sistema de archivos que genera Rails por defecto se muestra a continuación en la Figura 3, donde se define una clara separación entre archivos de configuración, aplicación, entre otros. http://es.wikipedia.org/wiki/Aptana http://es.wikipedia.org/wiki/Netbeans http://es.wikipedia.org/wiki/TextMate http://es.wikipedia.org/w/index.php?title=Gmate&action=edit&redlink=1 http://es.wikipedia.org/wiki/Gnome Capítulo II – Marco Referencial 36 Figura 3 Estructura por defecto de una Aplicación en Rails (Ruby on Rails org. Web development that doesn’t hurt. ) 4.9 Ruby 1.9.2 Ruby 1.9.2 es compatible 1.9.1, si exceptuamos los siguientes cambios:  Nuevos métodos.  Nueva API de comunicaciones (soporte para IPv6).  Nuevas codificaciones.  Clase aleatoria que soporta múltiples generadores de números aleatorios.  La clase Time es reemplazada. Se elimina el problema del año 2038.  Algunos cambios en las expresiones regulares(regexp).  $: no incluirá nunca más el directorio actual.  dl ha sido reescrito sobre libffi.  Nueva librería psych que contiene libyaml. Se puede usar esta librería en lugar de syck. 4.9.1 Plataformas soportadas Ruby 1.9 incluye cuatro niveles de soporte.  Soportado: se verifica que Ruby 1.9.2 trabaja perfectamente en ella. Es posible mantener 1.9.2 en esta. o Debian GNU/Linux 5.0 sobre IA32.  Sin garantía de resultados: se verifica que Ruby 1.9.2 trabaja adecuadamente en ellos. Se observa la posibilidad de mantener los mismos. o mswin32, x64-mswin64, mingw32 o MacOS X 10.5 (Intel) y 10.6 Capítulo II – Marco Referencial 37 o FreeBSD 6 y posteriores (amd64, IA32) o Solaris 10 o Symbian OS  Probables: Ruby 1.9.2 funciona correctamente en ellos con pequeñas modificaciones, no han sido verificados. Se aceptan parches con objeto de mejorar la integración en estos. o Otras distribuciones Linux. o Otras versiones de MacOS X. o cygwin o AIX 5 o Otros sistemas compatibles POSIX o BeOS (Haiku)  No soportadas: no se tienen garantías de que Ruby 1.9.2 funciones en estos. Se aceptan migraciones. o Cualquier sistema no listado anteriormente. La librería estándar se instala en /usr/local/lib/ruby/1.9.1. Este número de versión es “la librería de versión de compatibilidad”. Ruby 1.9.2 es altamente compatible con 1.9.1 por lo que esta librería se instala en el directorio indicado. (Ruby lang org. Ruby Language.) 4.10 Rails 3.0 Según Ruby on Rails org. Web development that doesn’t hurt. Rails 3.0 fue prolongado durante más de dos años, en su desarrollo trabajaron más de 1.600 colaboradores. La tercera generación de Rails ha realizado grandes cambios para Rails 3 como son los siguientes:  Active Record ha adoptado el motor de consulta ARel para hacer aplicaciones y realizar las consultas más coherente y componibles. Ésto hace que sea mucho más fácil construir consultas complejas sobre varias iteraciones. También retrasar la ejecución real de la consulta hasta que sea necesario. A continuación un ejemplo sencillo: users = User.where(:name => "david").limit(20) users = users.where("age > 29") # SELECT * FROM users # WHERE name = "david" AND age > 29 Capítulo II – Marco Referencial 38 # ORDER BY name # LIMIT 20 users.order(:name).each { |user| puts user.name }  Nuevo Router para Action Controller, cuando pasaron a un enfoque basado en REST para los controladores en Rails 2, realizaron un parche sobre la sintaxis del router, mientras esperaban el análisis detallado del experimento. Así lo hicieron y para Rails 3 han vuelto renovados y la sintaxis completamente a favor del estilo REST con menos ruido y más flexibilidad.  Nuevo Action Mailer, nació con una personalidad dividida de la mitad del modelo, la mitad del controlador. En los Rails 3, se tomó la decisión de hacer todo controlador. Esto significa que la sensación y la funcionalidad estará mucho más cerca a la acción del controlador. El nuevo Action Mailer, se basa en la parte superior de la nueva gema de correo también.  Administrar dependencias con Bundler, la gestión de todas las dependencias de una aplicación Rails ha sido durante mucho tiempo una molestia de remiendos. Tuvieron config.gem, Capistrano externos, las tareas de configuración personalizada rastrillo, y otras soluciones incompletas. Bundler limpia todo eso y permite especificar las bibliotecas, los marcos, y los plugins de los cuales depende la aplicación. Todas las aplicaciones Rails 3 nacen con una Gemfile para controlar todo.  XSS (protección por defecto), han tenido MERC protección con la firma de forma por un tiempo y de inyección SQL protección desde el principio, pero Rails 3 incluye la protección XSS.  Problemas de codificación, este problema está muy generalizado, y es causado por mezclar y hacer coincidir el contenido con diferentes codificaciones. En un sistema como Rails, el contenido proviene de la base de datos, plantillas, archivos de código fuente, y por parte del usuario. Ruby 1.9 provee las herramientas para eliminar estos problemas.  Active Model: Para todos los modelos, las validaciones, las devoluciones de llamada, entre otras cosas, han extraído varios componentes solicitados de Active Record en el nuevo marco de Active modelo. Esto permite que un ORM como Mongoid usar las validaciones de Active Record, las devoluciones de llamada, la serialización y soporte de i18n. Además, en la reescritura de Action Controller, han eliminado cualquier referencia directa a Active Record, la definición de un limpio y simple API que puede implementar ORM. Si se utiliza una API compatible con ORM (como http://github.com/mongoid/mongoid/blob/master/lib/mongoid/validations.rb#L11 Capítulo II – Marco Referencial 39 DataMapper, Sequel, o Mongoid), se pueden utilizar funciones como form_for, link_to y redirect_to con objetos de los ORM sin ningún trabajo adicional.  Official plugin APIs, también reescribieron Railties con el objetivo expreso de utilizar el nuevo plugin de la API de todos los marcos de Rails, como Active Record y Action Mailer. Esto significa que los plugins de Rails como los de DataMapper y RSpec tienen acceso a todos los de la integración como la compatibilidad integrada de Active Record y Test:: Unit. La nueva API Railtie permite modificar el incorporado en los generadores, añadir tareas rake, configurar las opciones por defecto de Rails, y especificar que el código se ejecute tan pronto, o tan tarde como se necesite.  Rewritten internos, han reescrito la parte interna de Action Pack y Railties, haciéndolos mucho más flexible y más fácil de extender. En lugar de una sola ActionController monolítica:: Base, Rails 3 expone una serie de módulos, cada uno con las API definidas, que se pueden mezclar y combinar para crear controladores de propósito especial para su propio uso.  Agnosticism with jQuery, rSpec, y Data Mapper, Agnosticismo con jQuery, RSpec y asignador de datos, el reescrito interno y el nuevo plugin API han llevado a cierto agnosticismo Rails 3 para todos los componentes del marco.  Instalación: se realiza mediante el siguiente commando gem install rails --version 3.0.0 . gem install rails --version 3.0.0 . También tienen un Rails v3.0.0 etiquetas y un -0- rama estable 3. Rails 3.0, ha sido diseñado para trabajar con Ruby 1.8.7, 1.9.2 Ruby y JRuby 1.5.2 +. http://github.com/datamapper/dm-rails/blob/master/lib/dm-rails/railtie.rb#L23 http://github.com/rspec/rspec-rails/blob/master/lib/rspec-rails.rb#L3 Capítulo III – Marco Metodológico 40 Capítulo III Marco Metodológico En el presente capítulo se describirá el método de desarrollo que se utilizará para llevar a cabo el diseño y la implementación del repositorio de datos para la Fundación Venezolana de Investigaciones Sismológicas (FUNVISIS); el cual se basó en el método ágil “Programación Extrema” (XP). Este se fundamenta en la simplicidad, la comunicación, la retroalimentación y la refactorización de código (Jeffries, Anderson, & Hendrickson, 2000). A continuación se especifican los aspectos más resaltantes del método XP, su adaptación para el desarrollo del sistema y un análisis general del levantamiento de información inicial. Programación Extrema La programación extrema es un método ligero, iterativo e incremental, el cual se utiliza para desarrollar software en pequeños grupos de programadores, donde la codificación es la actividad primordial sobre la documentación exhaustiva (Pressman, 2007). Mediante este método se libera rápidamente a producción un sistema sencillo y, de igual manera, se liberan continuamente nuevas versiones en periodos cortos. Tanto los jefes de proyecto, los clientes y programadores, son parte del equipo y están involucrados en el desarrollo del software. A continuación se destacan las características principales de este método de trabajo (Jeffries, Anderson, & Hendrickson, 2000).  Planificación incremental.  Programación en parejas.  Propiedad colectiva del código.  Comunicación constante con el cliente.  Desarrollo guiado en pruebas.  Continúa integración.  Estándares de codificación.  Refactorización de código. Adaptación del Proceso de Desarrollo XP A continuación se describe todo lo relacionado a la adaptación del método XP que se utilizará durante el desarrollo de un repositorio de datos para FUNVISIS. Capítulo III – Marco Metodológico 41 Iteraciones Las iteraciones simbolizan los cambios incrementales generados a través de las pruebas y retroalimentaciones repetidas, que a futuro dan como resultado un sistema estable pero en evolución. Las iteraciones pueden ser de dos tipos principalmente: por objetivo o por lapsos de tiempo. En nuestro caso las iteraciones se realizaran por objetivo, en donde, cada iteración comprende la puesta en marcha de un requerimiento funcional. Historias de Usuarios Las historias de usuario son un elemento primordial en el desarrollo y planificación dentro del método XP, permiten establecer un vínculo comunicacional entre el cliente y los miembros del equipo. Ayuda a priorizar y equilibrar las necesidades con la finalidad de mejorar la toma de decisiones, en cuanto a que se debe desarrollar primero. En lo que a nuestro caso se refiere, se trabajaran en función del tiempo (utilizando los días como unidad de medición) y con el formato de: un número que servirá de identificador, un nombre, el tipo (nueva o modificación/mejora), una prioridad (alta, media o baja) una estimación del tiempo y una breve descripción sobre la historia de usuario. El formato es el que a continuación se muestra: Número: - Nombre: - Prioridad: - Tipo: - Tiempo Estimado: - Descripción: - Cuadro 5 Formato de registro para una Historia de Usuario Por otra parte, en cuanto a los tipos de historias de usuario utilizadas, aunque el método XP plantea que solamente los requerimientos funcionales son reportados; se incluyeron como historias de usuario, tanto eventos (reuniones, documentos, etc.), como requisitos funcionales del sistema. Actores y Responsabilidades Los actores son todas las personas involucradas en el desarrollo del proyecto, los cuales a su vez cumplen distintos roles o responsabilidades según su importancia y nivel de participación. A continuación se destacan los roles existentes en el presente proceso de desarrollo: Capítulo III – Marco Metodológico 42  Programador: es el pilar fundamental del desarrollo en XP, tiene grandes habilidades en cuanto a la comunicación y al desarrollo en equipo. Adicionalmente, tiene la capacidad de poder abordar de forma simple y sencilla problemas complejos.  Cliente: es el encargado de proveer las historias de usuario, realizar las pruebas de aceptación, requisitos funcionales y no funcionales deseables en la aplicación y la toma de decisiones acertadas sobre las características esenciales de la aplicación.  Probador: su función se centra en realizar las pruebas de integración al sistema del código provisto por los programadores y de verificar el correcto funcionamiento de la aplicación. También realiza pruebas regulares y da mantenimiento siempre sustentando los resultados con informes precisos.  Rastreador: se encarga de dar seguimiento al proceso general del grupo, calculando el tiempo que toman sus tareas y el progreso general a las metas que se quieren alcanzar. Realiza estimaciones de tiempo y da la retroalimentación al equipo con el fin de mejorar el rendimiento. Programador Cliente Probador Rastreador Enrique Buono X X Andrés Sanoja X X Adriana Liendo X Cuadro 6 Esquema de actores y roles que desempeñan Actividades de XP El método XP está compuesto por cuatro actividades fundamentales las cuales están contenidas en cada una de las iteraciones del proceso de desarrollo. A continuación una breve descripción y cómo será la adaptación de cada una de ellas: Planificación La actividad de planificación comienza creando una serie de historias de usuario que describen las funcionalidades requeridas por el cliente, proporcionando a su vez una estimación del tiempo necesario para el desarrollo. Capítulo III – Marco Metodológico 43 En principio, se realizará un análisis global del estado actual de cada una de las necesidades de la Fundación Venezolana de Investigaciones Sismológicas (FUNVISIS) y del levantamiento de información que se llevó a cabo al inicio del desarrollo. De este surgirá una lista de historias de usuarios las cuales serán organizadas y desarrolladas en un conjunto de iteraciones. Se utilizará un esquema (cuadro 7) al inicio de cada iteración el cual contendrá el número de la iteración, una descripción, el número y nombre de las historias de usuarios a desarrollar, la fecha de comienzo de cada historia, la fecha de inicio y la fecha de fin de la iteración. Iteración - Descripción - Fecha Inicio / Fecha Fin - Número Fecha Historia Tipo - - - - Cuadro 7 Esquema de planificación de cada iteración Diseño El diseño en XP sigue de forma rigurosa el principio de simplicidad, prefiriendo siempre un diseño simple respecto de una presentación más compleja. Además el diseño debe ofrecer una guía de implementación para una historia de usuario determinada. Basados en las prácticas XP, en cada iteración de la presente etapa se realizarán prototipos mostrando las interfaces a desarrollar que permitan mejorar la comprensión de las historias planteadas. Codificación Este método sugiere la programación en pareja, la cual consiste en que dos programadores trabajen juntos en una estación de trabajo al momento de crear el código de una historia de usuario, siguiendo en todo momento los estándares de programación, lo cual es otro aspecto de gran importancia en el método XP. Sin embargo, para el desarrollo de este proyecto no se utilizara la programación en pareja. Capítulo III – Marco Metodológico 44 El método XP también recomienda realizar frecuentes integraciones de código entre los grupos de trabajo, de tal forma que no se produzcan problemas de compatibilidad, ni de interfaz. En este sentido se adoptará la programación individual para desarrollar el código de las principales historias de usuario y siempre trabajando en una misma iteración. Aquellas historias de usuario que no sean de mayor complejidad y no representen una funcionalidad primordial en el sistema serán desarrolladas y luego integradas a dicho sistema. En esta etapa de codificación, se realizará la instalación y configuraciones del ambiente que sean necesarias, además de toda la codificación de las historias de usuario de cada una de las iteraciones. Con respecto a los estándares de programación se mantendrán los siguientes:  Desarrollar de forma modular el sistema.  Documentar cada método creado para un fácil entendimiento.  Cada método debe ser definido en minúscula, si son varios nombres estarán separados por el símbolo underscore ( _ ), si el método retorno un lógico (boolean) debe terminar con el símbolo de interrogación ( ? ).  Con respecto a la nomenclatura y variables, las palabras que tengan ñ se sustituirá por n, si tiene acentos se omiten y las variables con dos o más palabras estarán separadas por el símbolo underscore ( _ ).  Para la base de datos, los nombres de las tablas se declaran siempre en minúscula y en singular. En cuanto a las relaciones se mantiene las convenciones de Rails, nombre_tabla_nombre_campo. Pruebas El método XP establece realizar pruebas de todo aquello que se codifique, recomienda no dejar ninguna característica del sistema sin que haya sido probada. Dicho método propone pruebas unitarias (unit test), pruebas del programador (programmer test) y pruebas de aceptación (customer test), estas últimas son especificadas por el cliente y se enfocan en las características generales y la funcionalidad del sistema, elementos visibles y revisables por el cliente (Anderson & Hendrickson, 2000). Con respecto a este punto se realizarán pruebas del programador y pruebas de aceptación. Para las pruebas del programador se empleará una técnica simple que consistirá en evaluar parámetros de entrada seleccionado por los programadores y observar las salidas constatando que cumplan con lo esperado. Las pruebas de aceptación Capítulo III – Marco Metodológico 45 serán realizadas por los clientes, con el fin de comprobar que sus requerimientos hayan sido cumplidos satisfactoriamente. Además se utilizará un formato para registrar cada una de las pruebas que se realicen. Ver cuadro 8. Código Historias de Usuario involucradas Descripción del Caso de Prueba Resultado Esperado Resultado Obtenido - - - - - Cuadro 8 Formato de registro de Prueba de Aceptación Por lo general en cada iteración se desarrollarán cada una de las actividades mencionadas anteriormente. Sin embargo, en las primeras iteraciones puede darse el caso de no se desarrollen todas las actividades, debido a las tareas que involucran determinadas historias de usuario durante una iteración. Visión general de la Solución La visión general de la solución, consiste en la documentación de toda la labor llevada a cabo durante el levantamiento de información inicial, proceso que involucró tanto a nuestro tutor Andrés Sanoja como a la Ing. Adriana Liendo como únicos y principales clientes. A partir de todo esto, se obtuvo lo necesario para el desarrollo del repositorio de datos para la Fundación Venezolana de Investigaciones Sismológicas (FUNVISIS), las cuales estarían sustentadas en las historias de usuario provistas en reuniones con los clientes. A continuación se especifican las historias de usuario obtenidas: Historias de Usuario Número: 1 Nombre: Reunión inicial con el profesor Andrés Sanoja con base a la definición de la propuesta de tesis y el alcance de la misma Prioridad: Alta Tipo: Nueva Tiempo Estimado: 1 día Descripción: discutir el proyecto, el alcance que el mismo posee, como debe estar estructurado y cuál es el método de desarrollo a implementar. Capítulo III – Marco Metodológico 46 Número: 2 Nombre: Definir el índice a ser desarrollado en el TEG. Prioridad: Media Tipo: Nueva Tiempo Estimado: 7 días Descripción: establecer el índice del trabajo especial de grado, especificando el contenido a desarrollar como bases teóricas, así como las páginas dedicadas a cada uno de dichos tópicos. Número: 3 Nombre: Revisar y modificar el contenido del TEG correspondiente con los capítulos I, II y III. Prioridad: Alta Tipo: Modificación / Mejora Tiempo Estimado: 28 días Descripción: revisión de los capítulos I, II y III respectivamente del TEG. De igual manera se establecieron las respectivas observaciones a ser aplicadas y se estableció con fecha enero de 2011 revisar dichas observaciones, así como el fijar una reunión con el cliente Adriana Liendo a fin de poder establecer los requerimientos funcionales de la Fundación Venezolana de Investigaciones Sismológicas (FUNVISIS). Número: 4 Nombre: Revisar las correcciones de los capítulos I, II y III y modificar el contenido del TEG correspondiente al capítulo IV. Prioridad: Alta Tipo: Modificación / Mejora Tiempo Estimado: 1 día Descripción: revisión de las correcciones realizadas a los capítulos I, II y III respectivamente del TEG. De igual manera se estableció que el plan de iteraciones sería de 10 iteraciones. Por otra parte se fijo una reunión con el cliente Adriana Liendo para el día 01/02/2011 en FUNVISIS. Capítulo III – Marco Metodológico 47 Número: 5 Nombre: Reunión con el especialista Sr. Andrés Singer, explicando como es y cómo debe ser el manejo de la información actualmente en la Fundación Venezolana de Investigaciones Sismológicas. Prioridad: Alta Tipo: Nueva Tiempo Estimado: 1 día Descripción: el especialista Andrés Singer en esta reunión, expreso que la separación de la información en la fundación debía ser en 3 renglones como lo son: técnicas, sociales y científicas respectivamente. Por otra parte, destaco que cuentan con aplicaciones tales como una catalogo de inventarios sismológicos, así mismo poseen una aplicación dedicada al renglón social, denominada estudios y desastres. Dicha aplicación maneja eventos tecnológicos, movimientos en masa, hidrometeoro lógico y sísmico. De igual forma poseen un centro de documentación e información donde las vistas del mismo son realizadas mediante la aplicación ABCD, entre otras aplicaciones. Número: 6 Nombre: Asistir a charla divulgativa con la Jefa del departamento de sismología Sra. Gloria Romero, donde describe el catálogo sismológico de FUNVISIS. Prioridad: Alta Tipo: Nueva Tiempo Estimado: 1 día Descripción: la Msc. Gloria romero expreso, que la finalidad del catálogo sismológico es lograr ver las amenazas sísmicas y los riesgos en una región especifica. De igual manera destaco que existe una carencia en cuanto a que el catalogo no puede ser consultado. De dicha reunión, se evaluó el hecho de llevar estos datos generados por el SEISAN a las dimensiones correspondientes en el datawarehouse a ser desarrollado. Capítulo III – Marco Metodológico 48 Número: 7 Nombre: Establecer con la Jefa del departamento de informática Ing. Adriana Liendo y el Prof. Andrés Sanoja las actividades a ser realizadas en el desarrollo del TEG. Prioridad: Alta Tipo: Nueva Tiempo Estimado: 1 día Descripción: se especifico como es el directorio de archivos de la aplicación SEISAN, y de cómo a través de un middleware se realizaría la carga de los datos desde dicha aplicación hacia el datawarehouse. De igual manera se describió el manejador de bases de datos utilizado por la aplicación de estudios y desastres, a fin de establecer la manera en la cual sería cargados los datos desde dicho manejador de bases de datos hacia el datawarehouse. Para luego, finalmente definir las actividades a ser realizadas a lo largo del TEG. Número: 8 Nombre: Establecer con el Prof. Andrés Sanoja el plan de iteración tentativo para el TEG Prioridad: Alta Tipo: Nueva Tiempo Estimado: 1 día Descripción: el día de hoy se llevo a cabo una reunión con el Prof. Andrés Sanoja para definir el plan de iteración tentativo para el TEG; estableciendo que el mismo estaría comprendido por 12 semanas. Número: 9 Nombre: Revisar la estructura de directorios de la aplicación SEISAN Prioridad: Alta Tipo: Nueva Tiempo Estimado: 1 día Descripción: se instaló la aplicación SEISAN y se revisaron en compañía de la jefa del departamento de informática Ing. Adriana Liendo, los directorios de la misma. Capítulo III – Marco Metodológico 49 Número: 10 Nombre: Entrevistar a la Jefa del Departamento de Sismología Msc. Gloria Romero con la finalidad de establecer las preguntas referentes a los archivos en formato SEISAN, que se quiere sean respondidas con el datawarehouse. Prioridad: Alta Tipo: Nueva Tiempo Estimado: 2 días Descripción: se realizo la entrevista con la Msc. Gloria Romero obteniendo como resultados las siguientes preguntas que necesitan ser respondidas con la implementación del datawarehouse: 1. ¿Qué eventos sísmicos han ocurrido en una fecha específica? 2. ¿Qué eventos sísmicos han ocurrido en un periodo de tiempo? 3. ¿Qué eventos sísmicos han ocurrido con una longitud entre un valor x y un valor y y una latitud entre un valor z y un valor w? 4. ¿Qué eventos sísmicos han ocurrido con una magnitud mayor a un valor x? 5. ¿Qué eventos sísmicos han sido registrados con un RMS (Root-Mean-Square in Seconds) ubicado entre un valor x y un valor y? 6. ¿Qué eventos sísmicos han sido registrados con un error en la medición de la latitud ubicado entre un valor x y un valor y? 7. ¿Qué eventos sísmicos han sido registrados con un error en la medición de la de longitud ubicado entre un valor x y un valor y? 8. ¿Qué eventos sísmicos han sido registrados con comentarios sobre los mismos? 9. ¿Qué eventos sísmicos han sido distantes, locales o regionales? Número: 11 Nombre: Revisar los archivos de formato SEISAN Prioridad: Alta Tipo: Nueva Tiempo Estimado: 14 días Descripción: se realizó el estudio de cada una de las diferentes tipos de línea de los archivos SEISAN, a fin de poder realizar el middleware que permita la carga de la información desde los archivos hacia el datawarehouse. Capítulo III – Marco Metodológico 50 Número: 12 Nombre: Revisar el modelo de la base de datos de la aplicación estudios y desastres Prioridad: Alta Tipo: Nueva Tiempo Estimado: 14 días Descripción: se realizo la revisión y análisis del manual entregado por la urbanista Ketty Mendes, en donde se encontraba la descripción de cada una de las tablas de la base de datos. Con la finalidad de tomar los datos necesarios para luego realizar el diseño de las dimensiones correspondientes al datawarehouse. Número: 13 Nombre: Entrevistar a la Urbanista Ketty Mendes con la finalidad de establecer las preguntas referentes a la base de datos de la aplicación estudios y desastres, que se quiere sean respondidas con el datawarehouse Prioridad: Alta Tipo: Nueva Tiempo Estimado: 2 días Descripción: se realizo la entrevista con la Urbanista Ketty Mendes, obteniendo como resultado un informe en el cual se especifican las distintas preguntas que quieren ser respondidas, en total 23, las cuales se encuentran disponibles en el apéndice 4. Número: 14 Nombre: Instalar y configurar el sistema manejador de base de datos columnar Monet DB, así como crear el esquema del datawarehouse en dicho manejador. Prioridad: Alta Tipo: Nueva Tiempo Estimado: 7 días Descripción: realizar la instalación del sistema manejador de base de datos columnar Monet DB en el sistema operativo Ubuntu 10.04, de igual forma se configuro el cliente grafico Squirrel para poder observar la estructura de la base de datos. Seguidamente se procedió a crear el esquema “funvisis” del datawarehouse, dentro del cual posteriormente serán definidas las dimensiones y la o las tablas de hechos necesarias para dar cumplimiento a los requerimientos establecidos. Capítulo III – Marco Metodológico 51 Número: 15 Nombre: Diseñar e implementar las dimensiones correspondientes con los archivos de formato SEISAN Prioridad: Alta Tipo: Nueva Tiempo Estimado: 7 días Descripción: realizar el diseño y seguido a esto la implementación de las dimensiones correspondientes con los archivos del SEISAN en el datawarehouse, destacando que las dimensiones fueron creadas tomando en cuenta cada uno de los diferentes tipos de línea que poseen dichos archivos. Número: 16 Nombre: Diseñar e implementar la tabla de hechos “fact_evento” referente a los archivos de formato SEISAN Prioridad: Alta Tipo: Nueva Tiempo Estimado: 7 días Descripción: realizar el diseño y seguido a esto la implementación de la tabla de hechos eventos, con base a las preguntas que se quiere sean respondidas por parte de la jefa del departamento de sismología Msc. Gloria Romero, con las cuales se determino la granularidad y los hechos a incluir en dicha tabla. Número: 17 Nombre: Diseñar e implementar las dimensiones correspondientes con la aplicación estudios y desastres Prioridad: Alta Tipo: Nueva Tiempo Estimado: 7 días Descripción: realizar el diseño y seguido a esto la implementación de las dimensiones correspondientes con la aplicación estudios y desastres, con el fin de integrar toda la información tanto de esta aplicación, como de los archivos en formato SEISAN en el datawarehouse. Capítulo III – Marco Metodológico 52 Número: 18 Nombre: Diseñar e implementar la tabla de hechos “fact_estudios_desastres” referente a la aplicación estudios y desastres Prioridad: Alta Tipo: Nueva Tiempo Estimado: 7 días Descripción: realizar el diseño y seguido a esto la implementación de la tabla de hechos estudios y desastres con base a las preguntas que se quiere sean respondidas por parte de la urbanista Ketty Mendes, con las cuales se determino la granularidad y los hechos a incluir en dicha tabla. Número: 19 Nombre: Modificar las dimensiones y la tabla de hechos “fact_evento” del datawarehouse con el fin de poder unificar los datos tanto de la aplicación estudios y desastres como de los archivos en formato SEISAN Prioridad: Alta Tipo: Modificación / Mejora Tiempo Estimado: 2 días Descripción: realizar modificaciones sobre dimensiones como dim_comentarios_archivos_ondas ampliando la longitud de los campos comentarios a varchar(3000) por la cantidad de comentarios inmersos dentro de un archivo en formato SEISAN y archivo_onda a varchar(500), por las mismas razones descritas anteriormente; de igual manera se modificará la tabla de hechos, con la inclusión de los errores pre calculados de las medidas encontradas en los archivos SEISAN, entre otras modificaciones. Capítulo III – Marco Metodológico 53 Número: 20 Nombre: Modificar la dimensión “dim_estacion” y crear de la tabla de hechos “fact_estacion” Prioridad: Alta Tipo: Modificación / Mejora Tiempo Estimado: 2 días Descripción: modificar la dimensión “dim_estacion” por el hecho de que existen dos granos distintos encontrados en la tabla de hechos “fact_evento”, por lo cual se creara una tabla de hechos “fact_estacion” con el grano de las estaciones, en donde atributos resaltantes de esta nueva tabla de hechos son: duración, amplitud y periodo respectivamente. Además de modificar la dimensión estación, dejándola con todos los atributos descriptivos de una estación. Número: 21 Nombre: Crear la dimensión degenerada denominada “id_evento” Prioridad: Alta Tipo: Nueva Tiempo Estimado: 2 días Descripción: crear la dimensión degenerada id_evento e incluir en las tres tablas de hechos existentes, con el fin de poder relacionar la información dentro del datawarehouse. Número: 22 Nombre: Modificar el valor por defecto de los atributos de todas las dimensiones del datawarehouse. Prioridad: Alta Tipo: Modificación / Mejora Tiempo Estimado: 1 día Descripción: modificar los valores por defectos de todas las dimensiones, colocándolos por defecto en “null” a excepción de los atributos estrictamente necesarios para el almacenamiento de la información; esto debido a que el datawarehouse almacenará eventos de formatos de archivos SEISAN, eventos de la aplicación estudios y desastres, e incluso eventos cruzados entre las dos fuentes de datos descritas anteriormente. Capítulo III – Marco Metodológico 54 Número: 23 Nombre: Crear el modelo de datos del datawarehouse Prioridad: Alta Tipo: Nueva Tiempo Estimado: 1 día Descripción: crear el modelo de datos del datawarehouse con las dimensiones y tablas de hechos correspondientes. Número: 24 Nombre: Crear el archivo en formato SQL, con la estructura del datawarehouse. Prioridad: Alta Tipo: Nueva Tiempo Estimado: 1 día Descripción: crear el archivo en formato SQL con la estructura del datawarehouse, para de esta manera tener un respaldo de dicho repositorio. Número: 25 Nombre: Crear el archivo en formato SQL, con las inserciones de los datos de prueba para validar el diseño del datawarehouse. Prioridad: Alta Tipo: Nueva Tiempo Estimado: 2 días Descripción: crear el archivo en formato SQL con las inserciones correspondientes con un evento sismológico registrado tanto por la aplicación SEISAN, como por la aplicación de estudios y desastres. Con dicha carga se logró validar el correcto diseño del datawarehouse; obteniendo como resultado la inserción efectiva de los datos de prueba. Número: 26 Nombre: Generar consultas en lenguaje SQL con el fin de validar el diseño del datawarehouse. Prioridad: Alta Tipo: Nueva Tiempo Estimado: 2 días Descripción: generar las consultas en lenguaje SQL necesarias para validar que los datos inmersos en el datawarehouse, la cual fue provista por un evento sísmico registrado tanto en la aplicación SEISAN, como en la aplicación de estudios y desastres, que se encontraba unificada en el repositorio. El resultado obtenido fue el esperado, las consultas fueron realizadas con éxito. Capítulo III – Marco Metodológico 55 Número: 27 Nombre: Instalar el ambiente de desarrollo web, tanto para crear el middleware, como para crear la aplicación web mediante la cual serán realizadas las consultas sobre el datawarehouse. Prioridad: Alta Tipo: Nueva Tiempo Estimado: 2 días Descripción: instalar el lenguaje de programación Ruby en su versión 1.9.2, mediante el cual se crearan los archivos que permitan llevar la información desde las aplicaciones SEISAN (Seismic Analysis System) y estudios y desastres hacia el datawarehouse. De igual forma instalar el framework para aplicaciones web Rails en su versión 3.0.6, framework con el cual se creara la aplicación web, más orientada hacia un administrador de bases de datos, donde los usuarios podrán ver los resultados de las consultas que estos realicen sobre dicho repositorio. Número: 28 Nombre: Instalar y Configurar el cliente “ruby-monetdb-client” que permitirá la conexión entre el lenguaje de programación Ruby y el sistema manejador de bases de datos columnar MonetDB. Prioridad: Alta Tipo: Nueva Tiempo Estimado: 2 días Descripción: instalar y configurar el cliente “ruby-monetdb-client” mediante el gestor de paquetes synaptic, cliente que permite realizar la conexión entre el lenguaje Ruby y el sistema manejador de bases de datos MonetDB tanto via SQL, como por el uso de la clase activerecord. Número: 29 Nombre: Crear el middleware en el lenguaje de programación Ruby que permita la carga de los datos de las aplicaciones ya existentes hacia el datawarehouse. Prioridad: Alta Tipo: Nueva Tiempo Estimado: 21 días Descripción: crear el middleware mediante el cual se examinan todas las líneas de cada uno de los archivos contenidos en cada uno de los subdirectorios de la aplicación SEISAN, además de tomas la información contenida en la aplicación estudios y desastres, para luego dicha información ser vaciada en el datawarehouse y a su vez modificar el archivo “log.txt” correspondiente con dichas inserciones. Capítulo III – Marco Metodológico 56 Número: 30 Nombre: Crear los TRIGGERS (procedimientos almacenados en la base de datos) en el datawarehouse. Prioridad: Alta Tipo: Modificación / Mejora Tiempo Estimado: 7 días Descripción: crear los TRIGGERS en el datawarehouse por medio del cliente grafico Squirrel, necesarios para unificar los datos existentes en el datawarehouse y mantener la integridad de los datos en el mismo. Número: 31 Nombre: Crear la aplicación web que permita consultar la información registrada en el datawarehouse. Prioridad: Alta Tipo: Nueva Tiempo Estimado: 14 días Descripción: crear la aplicación web, desarrollada en el framework de aplicaciones web Rails en su versión 3.0.6, dicha aplicación más orientada hacia un administrador de bases de datos, donde el usuario podrá visualizar en base a un formulario de consulta, el resultado de las mismas aplicadas al datawarehouse. Número: 32 Nombre: Creación de Videos que faciliten la demostración del funcionamiento de la aplicación web de consulta en conjunto con el comportamiento del datawarehouse. Prioridad: Alta Tipo: Nueva Tiempo Estimado: 2 días Descripción: Generación de un conjunto de videos a modo de guía, con el propósito de brindarle a los usuarios la posibilidad de consultar la información registrada en el datawarehouse. Metáfora Con el propósito de poder brindarles a los usuarios (FUNVISIS), la posibilidad de obtener un datawarehouse para el manejo de la información del catalogo sismológico SEISAN y de la aplicación estudios y desastres. Capítulo III – Marco Metodológico 57 Básicamente se ofrece la funcionalidad de realizar consultas sobre el datawarehouse, así como de tener toda la información de las dos aplicaciones descritas anteriormente dentro del mismo. Esto llevado a cabo mediante un middleware entre las dos aplicaciones y el datawarehouse, que se encuentra desarrollado en el sistema manejador de base de datos Monet DB . Ver figura 4 Capítulo III – Marco Metodológico 58 Archivos SEISAN BD Estudios y Desastres Modulo de Carga de Datos Figura 4 Metáfora del Sistema Funvisis Internet Datawarehouse FUNVISIS Aplicación Web Capítulo IV – Marco Aplicativo 59 Capítulo 4 Marco Aplicativo Plan de Iteración Este proyecto de trabajo especial de grado al estar orientado a un método de desarrollo ágil, cuenta con una serie de historias de usuario distribuidas en un conjunto de iteraciones. Dichas historias están agrupadas de forma tal de alcanzar un objetivo en cada iteración, bajo unos criterios de codificación y con un grupo de casos de prueba, con el fin de establecer el ritmo de trabajo a seguir. El proyecto y su desarrollo, comprende un conjunto de 9 (nueve) iteraciones, estimadas en un tiempo de cumplimiento de 1 a 4 semanas cada una y su culminación implica la puesta en marcha de un requerimiento funcional. El periodo para llevar a cabo dicho proyecto y su documentación correspondiente fue desde el 26 de Noviembre de 2010 hasta el 08 de Mayo de 2011. Capítulo IV – Marco Aplicativo 60 Iteración 0  Planificación Iteración 0 Descripción Levantamiento de Requerimientos y construcción del documento del TEG Fecha Inicio / Fecha Fin 26-11-2010 / 21-01-2011 Númer o Fecha Historia Tipo 1 26-11-2010 Reunión inicial con el profesor Andrés Sanoja con base a la definición de la propuesta de tesis y el alcance de la misma Nueva 2 09-12-2010 Definir el índice a ser desarrollado en el TEG. Nueva 3 16-12-2010 Revisar y modificar el contenido del TEG correspondiente con los capítulos I, II y III. Modificación/ Mejora 4 21-01-2011 Revisar las correcciones de los capítulos I, II y III y modificar el contenido del TEG correspondiente al capítulo IV. Modificación/ Mejora  Codificación En la presente iteración, la etapa de codificación correspondió con el desarrollo del contenido de los capítulos I, II y III del Trabajo Especial de Grado (TEG) con base al levantamiento de requerimientos realizado, así como la definición de los lineamientos a seguir en el desarrollo del contenido del capítulo IV del TEG. Capítulo IV – Marco Aplicativo 61  Pruebas Las pruebas realizadas en la presente iteración, consistieron en verificar el contenido desarrollado para los capítulos I, II, III y IV respectivamente del Trabajo Especial de Grado (TEG). Iteración 1  Planificación Iteración 1 Descripción Definición del área de desarrollo y de las actividades a ser realizadas en el TEG Fecha Inicio / Fecha Fin 01/02/2011 / 14/02/2011 Númer o Fecha Historia Tipo 5 01/02/2011 Reunión con el especialista Sr. Andrés Singer, explicando como es y cómo debe ser el manejo de la información actualmente en la Fundación Venezolana de Investigaciones Sismológicas (FUNVISIS). Nueva 6 10/02/2011 Asistir a charla divulgativa con la Jefa del departamento de sismología Msc. Gloria Romero, donde describe el catálogo sismológico de FUNVISIS. Nueva 7 11/02/2011 Establecer con la Jefa del departamento de informática Ing. Adriana Liendo y el Prof. Andrés Sanoja las actividades a ser realizadas en el desarrollo del TEG. Nueva 8 14/02/2011 Establecer con el Prof. Andrés Sanoja el plan de iteración para el TEG Nueva Capítulo IV – Marco Aplicativo 62  Codificación En la presente iteración, la etapa de codificación correspondió tanto con la definición del área de desarrollo en la cual se encuentra enmarcado el presente TEG, así como con el establecimiento de las actividades a ser realizadas para cumplir con los requerimientos definidos por la Fundación Venezolana de Investigaciones Sismológicas.  Pruebas Las pruebas realizadas en esta iteración, consistieron en definir el plan de iteraciones a seguir en el TEG, donde en cada iteración se establecieron todas y cada una de las actividades a ser realizadas para cumplir con los requerimientos establecidos; dichos requerimientos fueron establecidos, con base a la información suministrada por la Jefa del Departamento de Informática Ing. Adriana Liendo. Iteración 2  Planificación Iteración 2 Descripción Levantamiento de Requerimientos funcionales con base a la aplicación SEISAN Fecha Inicio / Fecha Fin 16/02/2011 / 08/03/2011 Númer o Fecha Historia Tipo 9 16/02/2011 Revisar la estructura de directorios de la aplicación SEISAN Nueva 10 23/02/2011 Entrevistar a la Jefa del departamento de Sismología Msc. Gloria Romero con la finalidad de establecer las preguntas referentes a los archivos en formato SEISAN, que se quiere sean respondidas con el datawarehouse. Nueva 11 02/03/2011 Revisar los archivos de formato SEISAN Nueva Capítulo IV – Marco Aplicativo 63  Codificación En la presente iteración, la etapa de codificación se basó en la instalación de la aplicación SEISAN (Seismic Analysis System), con la finalidad de analizar la estructura de directorios de la misma, dicha aplicación se puede observar en la figura 5. Figura 5 Aplicación SEISAN (Seismic Analysis System)  Pruebas Las pruebas realizadas en esta iteración, consistieron en entrevistar a la Jefa del Departamento de Sismología, Msc. Gloria Romero, con la finalidad de entender mejor el formato de los archivos SEISAN y obtener a su vez, las preguntas que se quiere sean respondidas con la implementación del datawarehouse. De igual forma se analizaron cada una de las líneas inmersas dentro de los archivos en formato SEISAN, para poder llevar dicha información al datawarehouse; estas líneas descritas anteriormente, se pueden apreciar en la figura 6, la cual contiene un fragmento correspondiente con el archivo “select.out” generado por la aplicación. Capítulo IV – Marco Aplicativo 64 Figura 6 Fragmento del Archivo "select.out" generado por la aplicación SEISAN Es importante destacar que la descripción de cada una de las líneas encontradas en estos archivos en formato SEISAN, se encuentran descritas en el manual de referencia de la aplicación SEISAN; En la figura 7 puede apreciarse la descripción para el tipo de línea 1, destacando que el tipo de línea viene dado por el valor encontrado en la última columna de una línea. Capítulo IV – Marco Aplicativo 65 Figura 7 Descripción del formato de las líneas tipo 1 de los archivos en formato SEISAN Capítulo IV – Marco Aplicativo 66 Iteración 3  Planificación Iteración 3 Descripción Levantamiento de Requerimientos funcionales con base a la aplicación estudios y desastres e instalación del ambiente de desarrollo para el datawarehouse Fecha Inicio / Fecha Fin 09/03/2011 / 22/03/2011 Númer o Fecha Historia Tipo 12 09/03/2011 Revisar el modelo de la base de datos de la aplicación Estudio y Desastres Nueva 13 16/03/2011 Entrevistar a la Urbanista Ketty Mendes con la finalidad de establecer las preguntas referentes a la base de datos de la aplicación estudios y desastres, que se quiere sean respondidas con el datawarehouse Nueva 14 17/03/2011 Instalar y configurar el sistema manejador de base de datos columnar Monet DB, así como crear el esquema del datawarehouse en dicho manejador. Nueva  Codificación En la presente iteración, la etapa de codificación se basó en la instalación y configuración tanto del sistema manejador de bases de datos columnar MonetDB, como del cliente grafico Squirrel, el cual permite visualizar la estructura de la base de datos y ejecutar sentencias en lenguaje SQL. Capítulo IV – Marco Aplicativo 67 En primer lugar, se instaló el sistema manejador de bases de datos MonetDB siguiendo las instrucciones proporcionadas por la página oficial de dicho manejador, las cuales se pueden apreciar en la figura 8. Figura 8 Instrucciones para la Instalación del Sistema manejador de bases de datos columnar MonetDB Capítulo IV – Marco Aplicativo 68 Seguidamente se instaló el cliente gráfico Squirrel, el cual permite visualizar la estructura de la base de datos y ejecutar sentencias en lenguaje SQL. Obteniendo como resultado la interfaz presentada en la figura 9. Figura 9 Interfaz del Cliente Gráfico Squirrel Posterior a la instalación se procedió a configurar el controlador necesario para realizar la conexión con el sistema manejador de bases de datos columnar MonetDB; como se puede apreciar en la figura 10. Capítulo IV – Marco Aplicativo 69 Figura 10 Configuración del driver para realizar la conexión entre el Cliente Gráfico Squirrel y MonetDB Finalmente, terminando con la configuración del cliente gráfico Squirrel, se creó el alias con el cual se va a comunicar el sistema manejador de bases de datos con dicho cliente, dicha configuración se puede observar en la figura 11. Figura 11 Creación del Alias MonetDB - Test Por otra parte, se creó el esquema de la base de datos “funvisis” en el cual será desarrollado el datawarehouse; dicho esquema se creó con la siguiente codificación realizada en la consola del sistema operativo y cuyo resultado se puede apreciar en la figura 12, en la cual se muestra dicho esquema desde el cliente grafico Squirrel. Capítulo IV – Marco Aplicativo 70 sudo mclient -l sql -d test CREATE USER "funvisis" WITH PASSWORD 'funvisis' NAME 'funvisis Explorer' SCHEMA "sys"; CREATE SCHEMA "funvisis" AUTHORIZATION "funvisis"; ALTER USER "funvisis" SET SCHEMA "funvisis"; Figura 12 Visualización del Esquema "funvisis" del manejador de bases de datos MonetDB  Pruebas Las pruebas realizadas en esta iteración consistieron en la verificación del correcto funcionamiento del sistema manejador de bases de datos columnar MonetDB, en cuanto al levantamiento de su servidor y a la verificación del estatus de las bases de datos contenidas en el mismo. Dichas verificaciones se realizaron con éxito y se pueden apreciar en las figuras 13 y 14 respectivamente. Capítulo IV – Marco Aplicativo 71 Figura 13 Levantamiento del Servidor de MonetDB Figura 14 Verificación del Status de MonetDB De igual forma en esta etapa de pruebas, se realizó el análisis sobre la estructura de archivos de la aplicación estudios y desastres, para de esta manera entender el funcionamiento de dicha aplicación y detallar la manera en la cual es guardada la información, para luego llevar dicha información al datawarehouse. La estructura de archivos anteriormente mencionada se puede apreciar en la figura 15. Capítulo IV – Marco Aplicativo 72 Figura 15 Estructura de Archivos de la aplicación estudios y desastres Finalmente, las pruebas de esta iteración concluyeron con el análisis sobre el modelo de la base de datos de la aplicación estudios y desastres, con la finalidad de obtener los datos necesarios para realizar el diseño y la implementación de las dimensiones y tabla de hechos respectiva en el datawarehouse. El modelo de la base de datos se puede apreciar en la figura 16. Cabe destacar que las pruebas referidas a la verificación de la correcta instalación del cliente gráfico Squirrel, fueron validadas al momento de realizar la configuración del mismo con el sistema manejador de bases de datos columnar MonetDB, en la etapa de codificación. Capítulo IV – Marco Aplicativo 73 Figura 16 Modelo de la Base de datos de la Aplicación estudios y desastres Capítulo IV – Marco Aplicativo 74 Iteración 4  Planificación Iteración 4 Descripción Diseño e implementación del datawarehouse Fecha Inicio / Fecha Fin 23/03/2011 / 06/04/2011 Númer o Fecha Historia Tipo 15 23/03/2011 Diseñar e implementar las dimensiones correspondientes con los archivos de formato SEISAN Nueva 16 28/03/2011 Diseñar e implementar la tabla de hechos “fact_evento” referente a los archivos de formato SEISAN Nueva 17 01/04/2011 Diseñar e implementar las dimensiones correspondientes con la aplicación estudios y desastres Nueva 18 06/04/2011 Diseñar e implementar la tabla de hechos “fact_estudios_desastres” referente a la aplicación estudios y desastres Nueva  Diseño En esta iteración se lleva a cabo el desarrollo de las dimensiones y de la tabla de hechos correspondiente tanto de la aplicación SEISAN, como de la aplicación estudios y desastres. Con base a la información obtenida de la iteración anterior. En primer lugar, se llevó a cabo el diseño de las dimensiones con base al formato de Archivos SEISAN, se pueden apreciar en la figura 17, dentro de las cuales se registran los 8 diferentes tipos de líneas que poseen dichos archivos actualmente. Capítulo IV – Marco Aplicativo 75 Figura 17 Diseño de las dimensiones con base al formato de Archivos SEISAN Capítulo IV – Marco Aplicativo 76 Seguidamente, se procedió a diseñar la tabla de hechos correspondiente con la aplicación SEISAN, de donde se destaca que la granularidad de la misma viene dada por las mediciones de duración, amplitud, periodo, latitud y longitud de un evento sismológico. Ver figura 18. Figura 18 Diseño de la tabla de hechos correspondiente con la aplicación SEISAN Posteriormente, se llevó a cabo el diseño de las dimensiones correspondientes con la aplicación estudios y desastres, se pueden apreciar en la figura 19, dimensiones que hacen referencia tanto a la ubicación del evento registrado, como de la información del tipo al cual pertenece; Destacando que dicha aplicación maneja eventos del tipo tecnológico, hidrometeorológico, movimiento en masa y sísmico respectivamente. Capítulo IV – Marco Aplicativo 77 Figura 19 Diseño de las dimensiones correspondientes con la aplicación estudios y desastres Finalmente en esta etapa, se diseña la tabla de hechos correspondiente con la aplicación estudios y desastres; destacando que en la misma la granularidad se ve reflejada en el grado de afectación que un evento de los tipos descritos anteriormente genere. Ver figura 20. Capítulo IV – Marco Aplicativo 78 Figura 20 Diseño de la tabla de hechos correspondiente con la aplicación estudios y desastres Capítulo IV – Marco Aplicativo 79  Codificación En la presente iteración, la etapa de codificación se basó en la implementación de las dimensiones y tablas de hechos descritas en la etapa de diseño, mediante lenguaje SQL en el datawarehouse. En primera instancia, se crearon las dimensiones correspondientes con la aplicación SEISAN, ya que estas son necesarias para las referencias que posee la tabla de hechos hacia las mismas. Ver fragmento de dicho lenguaje SQL en la figura 21. Figura 21 Implementación de las dimensiones asociadas a la aplicación SEISAN mediante lenguaje SQL Seguidamente, se implementó de igual forma en lenguaje SQL la tabla de hechos correspondiente con la aplicación SEISAN. Ver figura 22. Capítulo IV – Marco Aplicativo 80 Figura 22 Implementación de la tabla de hechos correspondiente con la aplicación SEISAN “fact_evento” mediante lenguaje SQL Finalmente en esta etapa se implementaron en estricto orden las dimensiones correspondientes con la aplicación estudios y desastres y luego la tabla de hechos correspondientes con dicha aplicación a través de lenguaje SQL. Donde en las figuras 23 y 24 pueden ser apreciados fragmentos de dichas implementaciones. Capítulo IV – Marco Aplicativo 81 Figura 23 Implementación de las dimensiones asociadas a la aplicación estudios y desastres mediante lenguaje SQL Figura 24 Implementación de la tabla de hechos correspondiente con la aplicación estudios y desastres “fact_estudios_desastres” mediante lenguaje SQL Capítulo IV – Marco Aplicativo 82  Pruebas Las pruebas realizadas fueron del tipo funcional, verificando que la implementación de las dimensiones y las correspondientes tablas de hechos, de ambas aplicaciones descritas anteriormente se realizaran con éxito. Respetando las restricciones de integridad en cuanto a claves primarias y claves foráneas. No. H.U. involucradas Descripción del Caso de Prueba Resultado Esperado Resultado Obtenido 01 15,16,17, 18 Validar la correcta implementaci ón de las dimensiones y tablas de hechos, además de las restricciones de integridad en cuanto a claves primarias y claves foráneas. La implementación de las dimensiones y tablas de hechos correspondientes, tanto de la aplicación SEISAN, como de la aplicación estudios y desastres; deben poder realizarse con éxito respetando las restricciones de integridad. Es ejecutada la implementación tanto de las dimensiones como de las tablas de hechos correspondientes con las aplicaciones ya descritas y tal como se esperaba, dicha implementación fue realizada con éxito respetando las restricciones de integridad. Capítulo IV – Marco Aplicativo 83 Iteración 5  Planificación Iteración 5 Descripción Validación y Modificación de la estructura del datawarehouse Fecha Inicio / Fecha Fin 08/04/2011 / 17/04/2011 Númer o Fecha Historia Tipo 19 08/04/2011 Modificar las dimensiones y la tabla de hechos “fact_evento” del datawarehouse con el fin de poder unificar los datos tanto de la aplicación estudios y desastres como de los archivos en formato SEISAN Modificación/ Mejora 20 12/04/2011 Modificar la dimensión “dim_estacion” y crear de la tabla de hechos “fact_estacion” Modificación/ Mejora 21 13/04/2011 Crear la dimensión degenerada denominada “id_evento” Nueva 22 13/04/2011 Modificar el valor por defecto de los atributos de todas las dimensiones del datawarehouse. Modificación/ Mejora  Diseño En esta etapa al analizar los datos que se incluirían en el datawarehouse por parte de la aplicación SEISAN y la aplicación de estudios y desastres, se decide llevar a cabo la modificación de la tabla de hechos correspondiente con la aplicación SEISAN denominada “fact_evento”. En cuanto a la selección de sus atributos debido a que la misma poseía dos granularidades distintas, una referida a la amplitud, la duración y el periodo de un evento Capítulo IV – Marco Aplicativo 84 y otra granularidad referida a la latitud y la longitud de un evento; por lo cual se modifica dicha tabla, dejándola con un solo grano como debe ser, dicho grano se basa en la latitud y la longitud. Ver figura 25. Figura 25 Modificación a la tabla de hechos "fact_evento" Seguidamente, se realiza la modificación de la dimensión “dim_estacion”, eliminando de la misma los atributos que generarían duplicidad de los datos como lo son, amplitud, duración y periodo. Para luego crear la tabla de hechos “fact_estacion”, cuya granularidad viene dada por los atributos, duración, amplitud y periodo respectivamente. Ver figura 26 Figura 26 Modificación realizada a la dimensión "dim_estacion" y creación de la tabla de hehos "fact_estacion" Capítulo IV – Marco Aplicativo 85 Posteriormente se crea la dimensión degenerada “id_evento”, cuyo término hace referencia a un campo en este caso “id_evento”, que será utilizado como criterio de análisis y que es almacenado en las 3 tablas de hechos existentes en datawarehouse, como lo son “fact_evento”, “fact_estacion” y “fact_estudios_desastres” respectivamente. Esto con la finalidad de poder unificar los datos de tipo técnico, proveniente de la aplicación SEISAN y los datos de tipo social, proveniente de la aplicación estudios y desastres. Dicha dimensión degenerada se puede apreciar en la figura 27. Figura 27 Adición de la dimension degenerada "id_evento" a las tablas de hechos existentes Finalmente, en la etapa de diseño correspondiente con la presente iteración, se modifican los valores por defecto de los atributos de todas las dimensiones a “null”, a excepción de los atributos requeridos, como lo son las claves primarias, entre otros. Esto debido a que el datawarehouse registra la información tanto de un evento registrado en la aplicación SEISAN, como de un evento registrado en la aplicación estudios y desastres e incluso un evento registrado en ambas aplicaciones. Para de esta manera poder mantener la integridad y unicidad de los datos registrados en el repositorio de datos. Capítulo IV – Marco Aplicativo 86 Figura 28 Modificaciones realizadas a las dimensiones del datawarehouse y a la tabla de hechos "fact_estudios_desastres"  Codificación En la presente iteración, la etapa de codificación se basó, en la implementación de las modificaciones en cuanto al tipo de dato de algunos atributos en las dimensiones y de la modificación de la tabla de hecho “fact_evento” en lo que se refiere a la granularidad de la misma, destacando que dichas modificaciones son realizadas mediante lenguaje SQL. Ver fragmento de dicho lenguaje SQL en la figura 29. Capítulo IV – Marco Aplicativo 87 Figura 29 Modificación de la tabla de hecho “fact_evento” mediante lenguaje SQL Seguidamente, se realiza la modificación mediante lenguaje SQL, de la dimensión “dim_estacion”. Para luego crear la tabla de hechos “fact_estacion”, según las modificaciones descritas anteriormente en la etapa de diseño. Ver figura 30. Capítulo IV – Marco Aplicativo 88 Figura 30 Modificación mediante lenguaje SQL, de la dimensión “dim_estacion” y Creación de la tabla de hechos “fact_estacion” Posteriormente, se crea mediante lenguaje SQL, la dimensión degenerada “id_evento”, adicionándola como un campo dentro de las 3 tablas de hechos existentes en el datawarehouse. Para luego finalizar la etapa de codificación con la modificación de los valores por defecto de la gran mayoría de los atributos de todas las dimensiones a “null”. Ver figura 31. Capítulo IV – Marco Aplicativo 89 Figura 31 Modificación de los atributos de las dimensiones y adicion de la dimension degenerada "id_evento" a las tablas de hechos existentes Capítulo IV – Marco Aplicativo 90  Pruebas Las pruebas realizadas fueron del tipo funcional, verificando que la implementación de las modificaciones a las dimensiones y a las correspondientes tablas de hechos, de ambas aplicaciones tanto el SEISAN, como la aplicación estudios y desastres se realizaran con éxito. No. H.U. involucradas Descripción del Caso de Prueba Resultado Esperado Resultado Obtenido 02 19,20,21,22 Validar la correcta implementaci ón de las modificacione s descritas anteriorment e, a las dimensiones y a las tablas de hechos. La implementación de las modificaciones a las dimensiones y a las tablas de hechos correspondientes, tanto de la aplicación SEISAN, como de la aplicación estudios y desastres; deben poder realizarse con éxito respetando las restricciones de integridad. Es ejecutada la implementación de las modificaciones tanto de las dimensiones como de las tablas de hechos correspondientes con las aplicaciones ya descritas y tal como se esperaba, dicha implementación fue realizada con éxito respetando las restricciones de integridad. Capítulo IV – Marco Aplicativo 91 Iteración 6  Planificación Iteración 6 Descripción Inserción de los datos de prueba en el datawarehouse y validación mediante consultas SQL, del correcto funcionamiento del mismo. Fecha Inicio / Fecha Fin 14/04/2011 / 18/05/2011 Númer o Fecha Historia Tipo 23 14/04/2011 Crear el modelo de datos del datawarehouse Nueva 24 15/04/2011 Crear el archivo en formato SQL, con la estructura del datawarehouse. Nueva 25 15/04/2011 Crear el archivo en formato SQL, con las inserciones de los datos de prueba para validar el diseño del datawarehouse. Nueva 26 18/04/2011 Generar consultas en lenguaje SQL con el fin de validar el diseño del datawarehouse. Nueva 30 18/04/2011 Crear los TRIGGERS (procedimientos almacenados en la base de datos) en el datawarehouse. Nueva  Diseño En esta iteración, la etapa de diseño correspondió con el diseño del modelo del datawarehouse, luego de validado en la estructura del mismo en las iteraciones anteriores, dicho modelo se puede apreciar en la figura 32. Ver apéndice 2. Capítulo IV – Marco Aplicativo 92 Figura 32 Modelo de datos del datawarehouse Capítulo IV – Marco Aplicativo 93  Codificación En esta etapa, se realizó la creación de los archivos en lenguaje SQL, correspondientes con la estructura del datawarehouse y las inserciones de los datos de prueba que posteriormente en la etapa de pruebas de la presente iteración serán validadas. Cabe destacar que en la figura 37 se puede apreciar fragmentos del código SQL, con el cual se llevaron a cabo las inserciones correspondientes. No se hace referencia a la estructura del código SQL perteneciente a la creación del repositorio, ya que el mismo ha sido descrito en pequeños fragmentos en la iteración anterior.  Pruebas Las pruebas realizadas fueron del tipo funcional, verificando que la inserción de los datos de prueba en el datawarehouse se realizase con éxito, dicha verificación se realizó mediante el uso de consultas realizadas en lenguaje SQL. Los resultados obtenidos se pueden apreciar en las figuras 33, 34,35 y 36 respectivamente.  Descripción de las viviendas afectas en la aplicación estudios y desastres dado que el número de estaciones usadas para medir dicho evento sean 6 en la aplicación SEISAN. a. select fr.desc_per_viviendas from "funvisis"."fact_estudios_desastres" fr, "funvisis"."fact_evento" fe where fe.numero_estaciones_usadas = 6 and fe.id_evento = fr.id_evento; Figura 33 Consulta 1 Validación de las inserciones en el datawarehouse  Descripción de un evento dado que el evento en SEISAN posea longitud de -71.084 y no se posea información sobre el número de muertos en la aplicación estudios y desastres. Capítulo IV – Marco Aplicativo 94 a. select fr.descripcion from "funvisis"."fact_evento" fe, "funvisis"."fact_estudios_desastres" fr where fr.id_evento =fe.id_evento and fe.longitud=-71.084 and fr.muertos is null; Figura 34 Consulta 2 Validación de las inserciones en el datawarehouse  El código de la ficha dado que la longitud del evento en SEISAN esté entre -72 y -70 y no se posea información sobre el número de muertos en la aplicación estudios y desastres y el error de la longitud en SEISAN esté entre 10.4 y 10.8 a. select fr.id_ficha from "funvisis"."fact_evento" fe, "funvisis"."fact_estudios_desastres" fr where fr.id_evento =fe.id_evento and (fe.longitud between -72 and -70) and (fe.longitud_error between 10.4 and 10.8)and fr.muertos is null; Figura 35 Consulta 3 Validación de las inserciones en el datawarehouse Capítulo IV – Marco Aplicativo 95  Número de registros de estaciones para un evento que en la aplicación estudios y desastres tenga longitud entre 69 y 72 (tomar en cuenta el signo ojo) y que el número de estaciones usadas registradas por el SEISAN sea de 6. a. select count (distinct de.id_estacion) from "funvisis"."fact_estacion" fe, "funvisis"."dim_estacion" de, "funvisis"."fact_estudios_desastres" fr, "funvisis"."fact_evento" fev where fr.id_evento =fe.id_evento and (fr.longitud between 69 and 72) and fev.numero_estaciones_usadas = 6; Figura 36 Consulta 4 Validación de las inserciones en el datawarehouse Capítulo IV – Marco Aplicativo 96 Figura 37 Fragmento del Código SQL, correspondiente con la inserción de los datos de prueba en el datawarehouse Capítulo IV – Marco Aplicativo 97 Iteración 7  Planificación Iteración 7 Descripción Instalación y configuración del ambiente de desarrollo web; y creación del middleware que permita realizar la comunicación entre las aplicaciones existentes en FUNVISIS y el datawarehouse. Fecha Inicio / Fecha Fin 19/04/2011 / 26/04/2011 Númer o Fecha Historia Tipo 27 19/04/2011 Instalar el ambiente de desarrollo web, tanto para crear el middleware, como para crear la aplicación web mediante la cual serán realizadas las consultas sobre el datawarehouse. Nueva 28 19/04/2011 Instalar y Configurar el cliente “ruby- monetdb-client” que permitirá la conexión entre el lenguaje de programación Ruby y el sistema manejador de bases de datos columnar MonetDB. Nueva 29 20/04/2011 Crear el middleware en el lenguaje de programación Ruby que permita la carga de los datos de las aplicaciones ya existentes hacia el datawarehouse. Nueva  Codificación En la presente iteración se procedió a instalar todo lo necesario para que el sistema funcionara en las máquinas de trabajo personal, los programas instalados fueron: Ruby on Capítulo IV – Marco Aplicativo 98 Rails en conjunto con las dependencias necesarias, así como el cliente “ruby-monetdb- client” que permitirá la conexión entre el lenguaje de programación Ruby y el sistema manejador de bases de datos columnar MonetDB. Es importante destacar que dicha instalación fue realizada sobre el ambiente Linux, la cual se documentó con el fin de aportar una guía (ver apéndice 1) que sirva de apoyo para futuras instalaciones. Una vez instalado todo el ambiente de desarrollo, se creó el archivo en formato Ruby, el cual actuará como middleware entre las aplicaciones SEISAN y estudios y desastres, y el sistema manejador de bases de datos columnar MonetDB. Un fragmento del código de dicho archivo, donde se muestra el tratamiento para dos distintos tipos de líneas de los archivos en formato SEISAN, se puede apreciar en la figura 38. Figura 38 Fragmento de código en formato Ruby perteneciente al Middleware  Pruebas Las pruebas realizadas en la presente iteración, consistieron en verificar la correcta instalación del ambiente de desarrollo y el correcto funcionamiento del middleware. Este último encargado de llevar los datos desde las aplicaciones existentes hacia el datawarehouse. En la figura 39, se puede apreciar el resultado de ejecutar el middleware, mostrando en dicha ejecución el contenido de las variables, en las cuales se almacena la Capítulo IV – Marco Aplicativo 99 información correspondiente con las líneas tipo 1 de los archivos en formato SEISAN, antes de ser llevadas al datawarehouse. Figura 39 Ejecución del Middleware Capítulo IV – Marco Aplicativo 100 Iteración 8  Planificación Iteración 8 Descripción Creación de la aplicación web de consulta sobre el datawarehouse Fecha Inicio / Fecha Fin 27/04/2011 / 08/05/2011 Númer o Fecha Historia Tipo 31 27/04/2011 Crear la aplicación web que permita consultar la información registrada en el datawarehouse. Nueva 32 05/05/2011 Creación de videos que faciliten la demostración del funcionamiento de la aplicación web de consulta en conjunto con el comportamiento del datawarehouse. Nueva  Diseño En esta iteración se lleva a cabo el desarrollo de la funcionalidad que permite la visualización de los resultados obtenidos, luego de realizada una consulta sobre el datawarehouse en base a un formulario proporcionado por la aplicación web. Dicho prototipo de consulta, orientado hacia un administrador de bases de datos, se puede apreciar en la vista parcial encontrada en la figura 40. Capítulo IV – Marco Aplicativo 101 Figura 40 Vista del Prototipo de Consulta Web Sobre el datawarehouse  Codificación El código encargado de desplegar el prototipo de consulta web, con la especificación de la posición en la cual van cada uno de los campos, que permitirán realizar la consulta sobre el datawarehouse, se muestra en la figura 41 un fragmento del mismo. Capítulo IV – Marco Aplicativo 102 Figura 41 Fragmento del Código Perteneciente a la Vista desarrollada para el Prototipo de Consulta Web  Pruebas Las pruebas realizadas fueron del tipo funcional, verificando que la implementación del prototipo de consulta web más orientado éste, hacia un administrador de bases de datos, retornase de forma efectiva el resultado de la consulta aplicada sobre el datawarehouse, en base a los parámetros proporcionados por el formulario de dicho prototipo. Capítulo IV – Marco Aplicativo 103 No. H.U. involucradas Descripción del Caso de Prueba Resultado Esperado Resultado Obtenido 03 31 Validar la correcta implementa ción del prototipo de consulta web sobre el datawareho use. La implementación del prototipo de consulta web, debe retornar de forma efectiva el resultado de la consulta aplicada sobre el datawarehouse en base a los parámetros proporcionados por el formulario de dicho prototipo. Es ejecutada la implementación del prototipo de consulta web, y tal como se esperaba, dicha implementación fue realizada con éxito, obteniendo en la misma vista en el espacio asignado para el resultado de la consulta; el resultado de la misma valga la redundancia con base a los parámetros proporcionados por el formulario del prototipo de consulta. Conclusiones 104 Conclusiones El presente trabajo especial de grado tuvo como finalidad, realizar el diseño e implementación de un datawarehouse para la consolidación y consulta de eventos sismológicos y desastres naturales para la Fundación Venezolana de Investigaciones Sismológicas (FUNVISIS). Así como, de proveer a la fundación de un prototipo de consulta, orientado hacia un administrador de bases de datos, donde los usuarios visualizan el resultado de las consultas realizadas sobre el datawarehouse, en base a los parámetros establecidos en el formulario de dicho prototipo. Destacando que dicho prototipo funciona adecuadamente gracias a un middleware, el cual comunica las aplicaciones ya existentes en la fundación con el datawarehouse. Esté constituye un procedimiento para la incorporación de datos a dicho repositorio. Con estas nuevas opciones desarrolladas, La fundación cuenta con un repositorio para las aplicaciones SEISAN y la aplicación estudios y desastres. Agilizando el intercambio de información, así como también posee cierta estructura y organización. Otro aspecto de gran importancia es que para futuros desarrollos de sistemas en la Fundación, podría contarse con este repositorio como fuente de datos. Es importante destacar que, el diseño y la implementación consistieron en la elaboración de cada uno de los modelos de datos correspondientes, tanto con las diferentes dimensiones desarrolladas, como con las tablas de hechos asociadas a las mismas. Así mismo, se desarrolló el prototipo de interfaz con base a cada uno de los requerimientos solicitados, seguido de la implementación mediante el lenguaje de programación Ruby, el lenguaje de consultas SQL y el framework de desarrollo web Rails. Obteniendo de esta manera un repositorio de datos en el cual se logró unificar los datos tanto técnicos, como sociales manejados por las aplicaciones descritas anteriormente. Al comenzar el desarrollo del proyecto, encontré algunas dificultades y retos, la primera dificultad, fue conocer y revisar el estado actual de las aplicaciones existentes en la fundación. En este proceso se determinó que el tratamiento que se le daría a la información de ambas aplicaciones sería distinto, en primera instancia porque la aplicación SEISAN maneja información del tipo técnica, mientras que la aplicación estudios y desastres maneja información del tipo social. Segundo que la aplicación SEISAN maneja formatos de archivos “txt” con ciertas especificaciones, y la aplicación estudios y desastres implementa una base de datos MySQL. Esto me permitió mejorar mi conocimiento sobre el manejo de la información en la fundación, por parte de cada una de Conclusiones 105 las aplicaciones descritas anteriormente. Una vez superada esta etapa se presentó una situación que se inició como una dificultad pero que realmente era un reto, el mismo consistió en una nueva forma de programar, ya que se utilizaron nuevas y diversas tecnologías como el lenguaje de programación Ruby junto a su framework de desarrollo Rails, de las cuales se desconocían su sintaxis y convenciones establecidas. Sin embargo, con el pasar de las semanas se fueron adquiriendo habilidades para utilizar estas herramientas, logrando desarrollar una aplicación que se encuentra dentro de las nuevas y robustas tendencias de programación. Otra herramienta utilizada fue la adaptación del método ágil “Programación Extrema” (XP), la cual me facilitó trabajar de forma organizada al permitirme agrupar los requerimientos en un conjunto de iteraciones que se fueron desarrollando progresivamente, por otra parte. La comunicación constante con el cliente fue otro aspecto que nos brindo resultados positivos, ya que permitió realizar constante revisiones a los avances del sistema. Otro aspecto importante del método XP, es que ésta sugiere la programación en pareja, la cual no se utilizó y se opto por el programar de forma individual cada uno de los requerimientos planteados. Con todo esto se obtuvo la construcción de un repositorio de datos, acoplado a las necesidades del usuario, que en este caso fue FUNVISIS, además de dejarme conocimientos y experiencia para seguir asumiendo proyectos innovadores. Para finalizar, puedo afirmar que el desarrollo del repositorio de datos y demás aplicaciones, permitió unificar los datos de las aplicaciones existentes en la Fundación, agilizando el intercambio de información, así como también de darle estructura y organización al manejo de la información, lo cual no solo se realizó como un requisito para la elaboración del Trabajo Especial de Grado, sino también, para satisfacer algunas de las necesidades actuales de la fundación, sentar las bases para futuros desarrollos de sistemas en donde podría contarse con este repositorio como fuente de datos, dejando de esta forma un valioso aporte a FUNVISIS, además de fortalecer mi crecimiento personal y profesional. Recomendaciones 106 Recomendaciones Como toda aplicación que se encuentra en constante crecimiento, y como la Fundación Venezolana de Investigaciones Sismológicas (FUNVISIS), es importante dejar sentadas las bases que simplifiquen el diseño de nuevas funcionalidades y la realización de las futuras mejoras, tales como:  Poner a prueba el prototipo de consulta y el mismo datawarehouse, con un grupo variados de usuarios, con el fin de generar un informe completo de posibles mejoras y correcciones que adapten el repositorio y las aplicaciones asociadas al mismo a las necesidades de los usuarios.  Seguir los lineamientos o estándares de programación y la estructuración a nivel de base de datos utilizada durante el desarrollo del datawarehouse.  Añadir los datos de las demás aplicaciones existentes en la Fundación al repositorio de datos, que lo consoliden como principal fuente de datos.  Planificar reuniones mensuales con los usuarios donde se evalúe el estado actual del repositorio y esto sirva para la realización de depuraciones e incluso mejoras en la estructura del mismo.  Contar con un personal especializado, pasantes por ejemplo, que se encarguen del correcto funcionamiento del repositorio y de brindar soporte a las consultas realizadas por los usuarios. Referencias Bibliográficas 107 Referencias Bibliográficas Abadi, D. J., Boncz, P. A., & Harizopoulos, S. (2009). Column-oriented database system. VLDB Endowment. Anderson, J., & Hendrickson, C. (2000). Extreme Programming Installed. Addison-Wesley Longman Publishing Co. Becker, L., & Guting, R. (1992). Rule-based optimization and query processing. Bouman, R., & Dongen, J. v. (2009). Pentaho Solutions Business Intelligence and Data Warehousing with Pentaho and MySQL. Indianapolis: Wiley Publishing, Inc. Burbeck, S. (1992). Model-View-Controller Architecture. Recuperado el 10 de Diciembre de 2010, de Model-View-Controller Architecture: http://st- www.cs.illinois.edu/users/smarch/st-docs/mvc.html Comparison_of_relational_database_management_systems. (s.f.). Recuperado el 11 de Diciembre de 2010, de Wikipedia. Comparison_of_relational_database_management_systems: http://en.wikipedia.org/wiki/Comparison_of_relational_database_management_systems Ibarra, M. d. (2006). Procesamiento análitico en línea. Corrientes - Argentina. Informit. Ruby Language. (s.f.). Recuperado el 10 de Diciembre de 2010, de Informit. Ruby Language: http://www.informit.com/articles/article.asp?p=18225 Jeffries, R., Anderson, A., & Hendrickson, C. ( 2000). Extreme Programming Installed. Addison-Wesley Longman Publishing Co. Pressman, R. ( 2007). Ingeniería del Software Un enfoque práctico, Sexta Edición. Mc Graw Hill. Ruby lang org. Ruby Language. (s.f.). Recuperado el 10 de Diciembre de 2010, de Ruby lang org. Ruby Language.: http://www.ruby-lang.org/es/downloads Ruby on Rails org. Web development that doesn’t hurt. . (s.f.). Recuperado el 10 de Diciembre de 2010, de Ruby on Rails org. Web development that doesn’t hurt. : http://rubyonrails.org Stonebraker, M. (2005). A column-oriented DBMS. Referencias Bibliográficas 108 Vermeij, M., Quak, W., Kersten, M., & Nes, N. MonetDB, a novel spatial column-store DBMS. Wiskunde. Wikipedia. Rails. (s.f.). Recuperado el 10 de Diciembre de 2010, de Wikipedia. Rails: http://es.wikipedia.org/wiki/Rails www.funvisis.gob.ve. (s.f.). Recuperado el 12 de Diciembre de 2010, de www.funvisis.gob.ve: http://www.funvisis.gob.ve/organizacion.php Apéndice 109 Apéndice Apéndice 1 Pasos para realizar la Instalación del Ambiente de Desarrollo Ruby on Rails y configuración del cliente “ruby-monetdb-client”.  La computadora donde será instalada la aplicación debe constar con el Sistema Operativo Linux con distribución Ubuntu o Debian.  Utilizando la línea de comandos, ejecutar: a. $ sudo apt-get install gcc g++ build-essential libssl-dev libreadline5- dev zlib1g-dev linux-headers-generic libsqlite3-dev b. $ wget ftp://ftp.ruby-lang.org//pub/ruby/1.9/ruby- 1.9.2-p0.tar.gz c. $ tar –xvzf ruby-1.9.2-p0.tar.gz d. $ cd ruby-1.9.2-p0/ e. $ ./configure –prefix=/usr/local/ruby f. $ make && sudo make install g. $ sudo gedit /etc/environment i. PATH=”/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/ bin:/usr/games:/usr/local/ruby/bin” h. $ 109ails109 /etc/environment  Verificar la instalación de ruby desde la línea de comandos a. $ ruby –v b. Se deberá mostrar un mensaje como este: ruby 1.9.2p0 (2010-08-18 revision 29036) [x86_64-linux]  Crear un enlace entre Ruby y las gemas para los programas: a. $ sudo ln –s /usr/local/ruby/bin/ruby /usr/local/bin/ruby b. $ sudo ln –s /usr/local/ruby/bin/gem /usr/bin/gem  Seguidamente instalar los paquetes de las gemas requeridas incluidas en Rails 3. a. $ sudo gem install tzinfo builder memcache-client rack rack-test erubis mail text-format bundler thor i18n sqlite3-ruby b. $ sudo gem install rack-mount –version=0.4.0 c. $ sudo gem install rails –version 3.0.6  Verifique la versión del Framework Rails a. $ 109ails –v ftp://ftp.ruby-lang.org/pub/ruby/1.9/ruby-1.9.2-p0.tar.gz ftp://ftp.ruby-lang.org/pub/ruby/1.9/ruby-1.9.2-p0.tar.gz Apéndice 110  Posteriormente desde el gestor de paquetes Synaptic: a. Ubique el paquete “ruby-monetdb-client” b. Seleccionar el paquete para instalar c. Aplicar los cambios d. Dirigase al directorio /usr/lib/ruby/gems/1.8/ e. Copiar el archivo activerecord-monetdb-adapter-0.1.gemspec que esta en /usr/lib/ruby/gems/1.8/specifications$ en /usr/lib/ruby/gems/1.8/gems/activerecord-monetdb-adapter-0.1$ f. luego desde el directorio /usr/lib/ruby/gems/1.8/gems/activerecord- monetdb-adapter-0.1$ ejecutar: i. gem build activerecord-monetdb-adapter-0.1.gemspec y se debe crear este archivo activerecord-monetdb-adapter- 0.1.gem. ii. Seguidamente ejecutar este comando: 1. gem install activerecord-monetdb-adapter-0.1.gem g. Finalmente se deben seguir desde el paso e los mismos pasos para ruby- monetdb-sql-0.1. Apéndice 111 Apéndice 2 Modelo de datos del datawarehouse Apéndice 112 Apéndice 3 Índice de Siglas BD: base de datos DBMS: sistema manejador de bases de datos CWI: Centrum Wiskunde & Informática DW: datawarehouse FUNVISIS: Fundación Venezolana de Investigaciones Sismológicas HTML: lenguaje de marcado de hipertexto MVC: modelo vista controlador OLAP: procesamiento analítico en línea OLTP: procesamiento transaccional en línea ORM: mapeo objeto relacional RDBMS: sistema manejador de base de datos relacionales RoR: Ruby on Rails SEISAN: sistema de análisis sísmico SGBDR: sistema gestor de bases de datos relacionales SQL: lenguaje de consulta estructurado TEG: trabajo especial de grado XP: programación extrema Apéndice 113 Apéndice 4 Preguntas correspondientes con la aplicación estudios y desastres 1. Número de personas muertas por tipo de amenaza: movimiento en masa, tecnológico y sísmico. 2. Número de personas desaparecidas por tipo de amenaza: movimiento en masa, tecnológico y sísmico. 3. Número de personas lesionadas por tipo de amenaza: movimiento en masa, tecnológico y sísmico. 4. Número de personas damnificadas por tipo de amenaza: movimiento en masa, tecnológico y sísmico. 5. Número de personas afectadas por tipo de amenaza: movimiento en masa, tecnológico y sísmico. 6. Número de personas evacuadas por tipo de amenaza: movimiento en masa, tecnológico y sísmico. 7. Número de personas reubicadas por tipo de amenaza: movimiento en masa, tecnológico y sísmico. 8. Número de viviendas afectadas por tipo de amenaza: movimiento en masa, tecnológico y sísmico. 9. Número de viviendas destruidas por tipo de amenaza: movimiento en masa, tecnológico y sísmico. 10. Monto total en pérdidas en el sector infraestructura vial por tipo de amenaza: movimiento en masa, tecnológico y sísmico. 11. Monto total en pérdidas en el sector vivienda por tipo de amenaza: movimiento en masa, tecnológico y sísmico. 12. Monto total en pérdidas en el sector agrícola por tipo de amenaza: movimiento en masa, tecnológico y sísmico. 13. Monto total en pérdidas en el sector pecuario por tipo de amenaza: movimiento en masa, tecnológico y sísmico. 14. Monto total en pérdidas en el sector transporte por tipo de amenaza: movimiento en masa, tecnológico y sísmico. 15. Monto total en pérdidas en el sector comunicaciones por tipo de amenaza: movimiento en masa, tecnológico y sísmico. Apéndice 114 16. Monto total en pérdidas en el sector energía por tipo de amenaza: movimiento en masa, tecnológico y sísmico. 17. Monto total en pérdidas en el sector educación por tipo de amenaza: movimiento en masa, tecnológico y sísmico. 18. Monto total en pérdidas en el sector salud por tipo de amenaza: movimiento en masa, tecnológico y sísmico. 19. Monto total en pérdidas en el sector industria y comercio por tipo de amenaza: movimiento en masa, tecnológico y sísmico. 20. Monto total en pérdidas en el sector agua potable por tipo de amenaza: movimiento en masa, tecnológico y sísmico. 21. Monto total en pérdidas en el sector agua servida por tipo de amenaza: movimiento en masa, tecnológico y sísmico. 22. Monto total en pérdidas en el sector otros por tipo de amenaza: movimiento en masa, tecnológico y sísmico. 23. Monto total en pérdidas en Bs. Por: estado, municipio, centro poblado y localidad. Apéndice 115 Apéndice 5 Descripción de cada una de las líneas correspondientes con los archivos de la aplicación SEISAN, según el manual de dicha aplicación.Universidad Central de Venezuela Facultad de Ciencias Escuela de Computación Laboratorio de Sistemas Paralelos y Distribuidos Diseño e implementación de un datawarehouse para la consolidación y consulta de eventos sismológicos y desastres naturales Trabajo Especial de Grado presentado ante la ilustre Universidad Central de Venezuela por el Bachiller: Enrique Buono C.I.: 19.223.511 Email: buono862@gmail.com Para optar al título de Licenciado en Computación Tutor: Prof. Andrés Sanoja Caracas, Mayo 2011 mailto:buono862@gmail.com II Universidad Central de Venezuela Facultad de Ciencias Escuela de Computación Laboratorio de Sistemas Paralelos y Distribuidos ACTA DEL VEREDICTO Quienes suscriben, Miembros del Jurado designado por el Consejo de la Escuela de Computación para examinar el Trabajo Especial de Grado, presentado por el Bachiller Enrique Buono C.I.: 19.223.511, con el título “Diseño e implementación de un datawarehouse para la consolidación y consulta de eventos sismológicos y desastres naturales”, a los fines de cumplir con el requisito legal para optar al título de Licenciado en Computación, dejan constancia de lo siguiente: Leído el trabajo por cada uno de los Miembros del Jurado, se fijó el día 27 de mayo de 2011, a las 02:00pm, para que su autor lo defendiera en forma pública, en la Escuela de Computación, Facultad de Ciencias de la Universidad Central de Venezuela, lo cual este realizó mediante una exposición oral de su contenido, y luego respondió satisfactoriamente a las preguntas que les fueron formuladas por el Jurado, todo ello conforme a lo dispuesto en la Ley de Universidades y demás normativas vigentes de la Universidad Central de Venezuela. Finalizada la defensa pública del Trabajo Especial de Grado, el jurado decidió aprobarlo. En fe de lo cual se levanta la presente acta, en Caracas el 27 de mayo de 2011, dejándose también constancia de que actuó como Coordinador del Jurado el Profesor Tutor Andrés Sanoja. ______________________ Prof. Andrés Sanoja (Tutor) ______________________ ______________________ Prof. Adriana Liendo Prof. Joali Moreno (Jurado Principal) (Jurado Principal) III Agradecimientos En primer lugar a Dios por haberme guiado por el camino del bien hasta ahora; en segundo lugar a cada uno de los que son parte de mi familia, a mi MADRE Niurka Rodriguez, la cual siempre creyó en mí, mi PADRE, MIS ABUELOS, MI TÍA Yolanda, y a mi hermano; por siempre haberme dado su fuerza y apoyo incondicional, ellos quienes me han ayudado a ser la persona que soy hoy por hoy y me han llevado hasta donde estoy. En especial agradezco a mi novia María G. De Freitas, quien fue mi apoyo, mi base, ese ser que estuvo tanto en mis momentos de felicidad al lograr un avance, así como en esos malos momentos donde pensaba que no podía más, le agradezco por siempre darme esas palabras de aliento y la fuerza necesaria para salir adelante y Por último pero no menos importante, a mis compañeros de estudio, porque en todo momento que los necesite para una duda o un consejo siempre estuvieron ahí, en especial a Marco Gómez y a Carlos Villasana; al personal de la Fundación Venezolana de Investigaciones Sismológicas (FUNVISIS) por siempre brindarme su apoyo en todo momento, en especial a la Jefa del departamento de informática Ing. Adriana Liendo y a la Ing. Mirna Freitez y claro está, a mi tutor de tesis, persona a la que admiro por todos sus logros y dedicación, quién me guió y ayudó en todo momento, Msc. Andrés Sanoja. IV Resumen La Fundación Venezolana de Investigaciones Sismológicas (FUNVISIS), maneja varios departamentos donde los datos son cargados de diversas formas mediante el uso de aplicaciones: desde archivos de texto, Microsoft Excel e incluso sistemas, lo cual conlleva a que la fundación no posea los datos integrados en un solo repositorio. El presente Trabajo Especial de Grado se realizó con la finalidad de desarrollar un repositorio de datos para FUNVISIS, además de realizar un middleware que permita comunicar las aplicaciones ya existentes con dicho repositorio para unificar de esta manera la información; para luego proponer una aplicación web orientada hacia un administrador de base de datos, en la cual los usuarios puedan visualizar las consultas que se deseen hacer sobre la base de datos. El desarrollo del sistema fue guiado por el método ágil “Programación Extrema” (XP), el cual se enfoca en reforzar la simplicidad, comunicación, retroalimentación y refactorización de código. Entre las tecnologías usadas se destaca el lenguaje de programación Ruby 1.9.2, su framework de desarrollo web Rails 3.0.6 y el sistema manejador de base de datos columnares Monet DB. El resultado es el desarrollo del repositorio de datos para FUNVISIS, donde se encuentra unificada la información generada por la aplicación SEISAN (Seismic Analysis System), así como también de los datos correspondientes con la aplicación estudios y desastres. De igual forma se obtuvo un módulo de carga de datos, el cual permite llevar los archivos en formato SEISAN y los datos de la aplicación de estudios y desastres al repositorio de datos, representando dicho modulo el proceso de extracción, transformación y carga de los datos (ETL). Finalmente el último producto obtenido es una aplicación web, mediante la cual los usuarios de FUNVISIS pueden realizar consultas sobre el repositorio desarrollado. La creación de este repositorio y demás aplicaciones aporta un agregado significativo al manejo de la información, tanto técnica como social dentro de FUNVISIS al unificar los datos y permitir la consulta sobre la misma. El presente trabajo está enmarcado dentro del proyecto de investigación “programa integral de capacitación y adiestramiento de talento humano de Funvisis y actualización tecnología”. Palabras claves: datawarehouse, FUNVISIS, SEISAN, Eventos sismológicos, Estudios y Desastre. ÍNDICE V ÍNDICE ÍNDICE DE FIGURAS ................................................................................... VIII ÍNDICE DE CUADROS ....................................................................................... X INTRODUCCIÓN ............................................................................................. 11 CAPÍTULO I ................................................................................................... 13 PLANTEAMIENTO DEL PROBLEMA ............................................................................. 13 Titulo ....................................................................................................... 13 Planteamiento del Problema .................................................................... 13 Objetivo general ...................................................................................... 13 Objetivos Específicos ............................................................................... 13 Importancia y justificación ...................................................................... 13 Propuesta de la solución .......................................................................... 14 Alcances .................................................................................................. 15 CAPÍTULO II .................................................................................................. 16 MARCO REFERENCIAL ......................................................................................... 16 1. Fundación Venezolana de Investigaciones Sismológicas .................... 16 1.1 Misión ................................................................................................................................................ 17 1.2 Visión ................................................................................................................................................. 17 1.3 Organigrama ................................................................................................................................... 17 2. Almacén de Datos ................................................................................ 17 2.1 Conceptos asociados a un datawarehouse .......................................................................... 18 2.2 Características de un datawarehouse ................................................................................... 19 2.3 Ventajas y desventajas de un datawarehouse ................................................................... 20 2.4 Arquitectura de un datawarehouse ....................................................................................... 21 3. Sistemas manejadores de bases de datos orientados a columnas ....... 23 3.1 Descripción ...................................................................................................................................... 23 3.2 Beneficios ......................................................................................................................................... 24 3.3 Implementaciones ........................................................................................................................ 25 3.4 Descripción de MonetDB ........................................................................................................... 27 3.4.1 Características de MonetDB .................................................................................................. 27 ÍNDICE VI 3.4.2 Arquitectura de MonetDB ...................................................................................................... 28 3.4.3 Funcionalidades de MonetDB .............................................................................................. 29 4. Ruby on Rails ....................................................................................... 30 4.1 Funcionamiento ............................................................................................................................. 31 4.2 Arquitectura .................................................................................................................................... 32 4.3 Gemas ................................................................................................................................................. 33 4.4 Soporte de servidores Web ....................................................................................................... 34 4.5 Soporte de Bases de Datos ........................................................................................................ 34 4.6 Requisitos ......................................................................................................................................... 34 4.7 Entorno de Trabajo ...................................................................................................................... 35 4.8 Nociones básicas de instalación y estructura de aplicación ........................................ 35 4.9 Ruby 1.9.2 ......................................................................................................................................... 36 4.10 Rails 3.0 .......................................................................................................................................... 37 CAPÍTULO III ................................................................................................ 40 MARCO METODOLÓGICO ...................................................................................... 40 Programación Extrema ............................................................................ 40 Adaptación del Proceso de Desarrollo XP ................................................ 40 CAPÍTULO 4 ................................................................................................... 59 MARCO APLICATIVO ........................................................................................... 59 Plan de Iteración ..................................................................................... 59 Iteración 0............................................................................................... 60 Iteración 1............................................................................................... 61 Iteración 2............................................................................................... 62 Iteración 3............................................................................................... 66 Iteración 4............................................................................................... 74 Iteración 5............................................................................................... 83 Iteración 6............................................................................................... 91 Iteración 7............................................................................................... 97 Iteración 8............................................................................................. 100 CONCLUSIONES ........................................................................................... 104 RECOMENDACIONES .................................................................................... 106 REFERENCIAS BIBLIOGRÁFICAS .................................................................. 107 ÍNDICE VII APÉNDICE .................................................................................................... 109 Índice de Figuras VIII Índice de Figuras Figura 1 Organigrama FUNVISIS (www.funvisis.gob.ve) ................................................................... 17 Figura 2 Arquitectura de un Datawarehouse (Bouman & Dongen, 2009) .................................. 22 Figura 3 Estructura por defecto de una Aplicación en Rails (Ruby on Rails org. Web development that doesn’t hurt. ) .................................................................................................................. 36 Figura 4 Metáfora del Sistema ....................................................................................................................... 58 Figura 5 Aplicación SEISAN (Seismic Analysis System) ..................................................................... 63 Figura 6 Fragmento del Archivo "select.out" generado por la aplicación SEISAN .................. 64 Figura 7 Descripción del formato de las líneas tipo 1 de los archivos en formato SEISAN.. 65 Figura 8 Instrucciones para la Instalación del Sistema manejador de bases de datos columnar MonetDB ............................................................................................................................................ 67 Figura 9 Interfaz del Cliente Gráfico Squirrel ......................................................................................... 68 Figura 10 Configuración del driver para realizar la conexión entre el Cliente Gráfico Squirrel y MonetDB ............................................................................................................................................ 69 Figura 11 Creación del Alias MonetDB - Test .......................................................................................... 69 Figura 12 Visualización del Esquema "funvisis" del manejador de bases de datos MonetDB .................................................................................................................................................................................... 70 Figura 13 Levantamiento del Servidor de MonetDB ............................................................................ 71 Figura 14 Verificación del Status de MonetDB ....................................................................................... 71 Figura 15 Estructura de Archivos de la aplicación estudios y desastres ..................................... 72 Figura 16 Modelo de la Base de datos de la Aplicación estudios y desastres ............................ 73 Figura 17 Diseño de las dimensiones con base al formato de Archivos SEISAN ...................... 75 Figura 18 Diseño de la tabla de hechos correspondiente con la aplicación SEISAN ............... 76 Figura 19 Diseño de las dimensiones correspondientes con la aplicación estudios y desastres ................................................................................................................................................................. 77 Figura 20 Diseño de la tabla de hechos correspondiente con la aplicación estudios y desastres ................................................................................................................................................................. 78 Figura 21 Implementación de las dimensiones asociadas a la aplicación SEISAN mediante lenguaje SQL .......................................................................................................................................................... 79 Figura 22 Implementación de la tabla de hechos correspondiente con la aplicación SEISAN “fact_evento” mediante lenguaje SQL ......................................................................................................... 80 Figura 23 Implementación de las dimensiones asociadas a la aplicación estudios y desastres mediante lenguaje SQL ................................................................................................................ 81 Índice de Figuras IX Figura 24 Implementación de la tabla de hechos correspondiente con la aplicación estudios y desastres “fact_estudios_desastres” mediante lenguaje SQL ...................................... 81 Figura 25 Modificación a la tabla de hechos "fact_evento"................................................................ 84 Figura 26 Modificación realizada a la dimensión "dim_estacion" y creación de la tabla de hehos "fact_estacion"......................................................................................................................................... 84 Figura 27 Adición de la dimension degenerada "id_evento" a las tablas de hechos existentes ............................................................................................................................................................... 85 Figura 28 Modificaciones realizadas a las dimensiones del datawarehouse y a la tabla de hechos "fact_estudios_desastres" ................................................................................................................. 86 Figura 29 Modificación de la tabla de hecho “fact_evento” mediante lenguaje SQL .............. 87 Figura 30 Modificación mediante lenguaje SQL, de la dimensión “dim_estacion” y Creación de la tabla de hechos “fact_estacion” .......................................................................................................... 88 Figura 31 Modificación de los atributos de las dimensiones y adicion de la dimension degenerada "id_evento" a las tablas de hechos existentes ................................................................ 89 Figura 32 Modelo de datos del datawarehouse ...................................................................................... 92 Figura 33 Consulta 1 Validación de las inserciones en el datawarehouse .................................. 93 Figura 34 Consulta 2 Validación de las inserciones en el datawarehouse .................................. 94 Figura 35 Consulta 3 Validación de las inserciones en el datawarehouse .................................. 94 Figura 36 Consulta 4 Validación de las inserciones en el datawarehouse .................................. 95 Figura 37 Fragmento del Código SQL, correspondiente con la inserción de los datos de prueba en el datawarehouse .......................................................................................................................... 96 Figura 38 Fragmento de código en formato Ruby perteneciente al Middleware ..................... 98 Figura 39 Ejecución del Middleware .......................................................................................................... 99 Figura 40 Vista del Prototipo de Consulta Web Sobre el datawarehouse ................................ 101 Figura 41 Fragmento del Código Perteneciente a la Vista desarrollada para el Prototipo de Consulta Web ..................................................................................................................................................... 102 Índice de Cuadros X Índice de Cuadros Cuadro 1 Información General MonetDB .................................................................................................. 29 Cuadro 2 Sistemas Operativos Soportados por MonetDB ................................................................. 30 Cuadro 3 Características Fundamentales MonetDB ............................................................................. 30 Cuadro 4 Índices en MonetDB ....................................................................................................................... 30 Cuadro 5 Formato de registro para una Historia de Usuario ........................................................... 41 Cuadro 6 Esquema de actores y roles que desempeñan .................................................................... 42 Cuadro 7 Esquema de planificación de cada iteración ........................................................................ 43 Cuadro 8 Formato de registro de Prueba de Aceptación ................................................................... 45 Introducción 11 Introducción La explosión de nuevas tecnologías y con ella los desarrollos tecnológicos, actualmente se han extendido y son de vital importancia para la sociedad, donde las bases de datos, ocupan un lugar determinante en cualquier área del quehacer humano, comercial, tecnológico, entre otros; En particular los datawarehouse los cuales dan lugar a una serie de importantes beneficios para una organización, como lo es el apoyo en la toma de decisiones. En cualquier caso, su utilización permite que la información de gestión sea: accesible, correcta, uniforme y actualizada. De igual forma se cuenta con desarrollos en cuanto a la web se refiere, la cual ha crecido muy rápidamente por las distintas utilidades inherentes que posee. Así como también, por su amplio alcance dentro del campo de la información y las comunicaciones, por lo cual, se ha tomado en cuenta como una herramienta muy poderosa para el desarrollo de aplicaciones que ayuden a aligerar la carga de actividades cotidianas. FUNVISIS, actualmente maneja varios departamentos donde los datos son cargados de diversas formas mediante el uso de aplicaciones: desde archivos de texto, Microsoft Excel e incluso sistemas; Lo cual conlleva a que la Fundación no posea todos los datos integrados en un solo repositorio. En este sentido el presente trabajo plantea desarrollar un repositorio de datos (datawarehouse) para FUNVISIS, además de realizar un middleware que permita comunicar los archivos y aplicaciones ya existentes con dicho repositorio para unificar de esta manera la información; Para luego proponer una aplicación web orientada hacia un administrador de base de datos, en la cual los usuarios puedan visualizar las consultas que se deseen hacer sobre la misma. Todo esto con la finalidad de que las nuevas aplicaciones que sean desarrolladas puedan contar con este repositorio unificado. Para llevar a cabo el objetivo anteriormente mencionado se presenta el siguiente Trabajo Especial de Grado el cual está estructurado en cuatro capítulos: Capítulo I: Planteamiento del Problema, en el cual se expone el problema, los objetivos a desarrollar, importancia y justificación, propuesta de la solución y alcances de la investigación. Capítulo II: Marco Referencial, comprende la descripción de FUNVISIS y su estructura organizativa, las características, arquitectura, ventajas y demás funcionalidades Introducción 12 de un datawarehouse, la descripción del manejador de bases de datos Monet DB, y por último la tecnología Ruby on Rails. Capítulo III: Marco Metodológico, donde se describe el proceso de desarrollo del sistema, el cual se basa en el método ágil programación extrema. Capítulo IV: Marco Aplicativo, en el que se especifican las actividades realizadas en cada una de las iteraciones que conforman el desarrollo del sistema. Finalmente se presentan las conclusiones y recomendaciones de la investigación. Capítulo I – Planteamiento del Problema 13 Capítulo I Planteamiento del problema Titulo Desarrollo de un Repositorio de Datos para la Fundación Venezolana de Investigaciones Sismológicas. Planteamiento del Problema Hoy en día, la Fundación Venezolana de Investigaciones Sismológicas, maneja varios departamentos donde los datos son cargados de diversas formas mediante el uso de aplicaciones: desde archivos de texto, Microsoft Excel e incluso sistemas; Lo cual conlleva a que la fundación no posea todos los datos integrados en un solo repositorio. Es por ello que se quiere integrar en una aplicación todos esos datos y guardarlos en un único repositorio. Incluso realizar una aplicación orientada hacia un administrador de bases de datos en la cual le permita visualizar las consultas (querys) que los usuarios deseen hacer sobre la base de datos. Objetivo general Diseñar e implementar un datawarehouse para la consolidación y consulta de eventos sismológicos y desastres naturales para la Fundación Venezolana de Investigaciones Sismológicas. Objetivos Específicos 1. Identificar el estado actual de los datos en la fundación según las necesidades en general y por departamento. 2. Identificar las necesidades y disponibilidad de información en la fundación. 3. Diseñar el modelo lógico de la base de datos. 4. Implementar la base de datos. 5. Diseñar e implementar mecanismos para la incorporación de los datos al repositorio. 6. Diseñar e implementar una aplicación web para consultas básicas generales. 7. Preparar la transferencia tecnológica y manuales de usuario. Importancia y justificación La Fundación podrá contar con un repositorio para todas sus aplicaciones o datos que se requieran registrar. Al contar con un repositorio de estas características es posible agilizar el intercambio de información, así como también darle cierta estructura y Capítulo I – Planteamiento del Problema 14 organización. De igual manera, para futuros desarrollos de sistemas en la fundación podría contarse con este repositorio como fuente de datos. Propuesta de la solución Con la finalidad de integrar en un datawarehouse toda la información, tanto técnica como social, almacenada en aplicaciones; desde archivos de texto, Microsoft Excel e incluso sistemas de FUNVISIS, se propone diseñar e implementar un datawarehouse para dicha fundación, además de realizar un middleware que permita comunicar los archivos y aplicaciones ya existentes con dicho repositorio, para unificar de esta manera la información. Para luego proponer una aplicación web orientada hacia un administrador de base de datos, en la cual los usuarios puedan visualizar las consultas que se deseen hacer sobre la misma. Para ello es necesario primeramente el análisis y revisión de los distintos archivos en los cuales es almacenada la información, así como de las distintas aplicaciones y sistemas existentes, siendo estas las fuentes de datos las cuales proveerán información indispensable para el desarrollo de dicho datawarehouse. En este orden de ideas, en primer lugar se realizará el análisis y la revisión de los archivos en formato SEISAN, pertenecientes a la aplicación SEISAN (Seismic Analysis System). Así como las entrevistas que necesarias con las cuales se obtendrán las preguntas, que se quiere sean respondidas con la implementación del datawarehouse; cabe destacar que en dicha aplicación el manejo de la información es de tipo técnica. De esta manera se obtendrán los datos requeridos para el diseño e implementación de las dimensiones y las tablas de hechos correspondientes con dicha aplicación en el datawarehouse. De igual forma se verificará la aplicación estudios y desastres, aplicación en la cual el manejo de la información es de carácter social. Esto con el fin de obtener los datos necesarios para el diseño e implementación de las dimensiones y las tablas de hechos, correspondientes con dicha aplicación en el datawarehouse. De ser necesario se realizarán modificaciones al diseño del datawarehouse en busca de unificar los datos de las dos aplicaciones descritas anteriormente. Finalmente, se realizará un middleware que permita comunicar los archivos en formato SEISAN y la aplicación estudios y desastres con el datawarehouse, para de esta manera unificar la información. Adicionalmente se propondrá una aplicación web orientada hacia un administrador de base de datos, en la cual los usuarios puedan Capítulo I – Planteamiento del Problema 15 visualizar los resultados obtenidos de las consultas que estos realicen sobre dicho repositorio. Alcances  El sistema debe estar en producción al final del proyecto. Se requerirá como mínimo la base de datos implementada, la aplicación web de consulta general y al menos dos (2) mecanismos de incorporación de datos.  El sistema debe estar corriendo en el ambiente de producción.  En el datawarehouse se unificarán los datos del tipo técnico, provenientes de la aplicación SEISAN y los datos del tipo social, provenientes de la aplicación estudios y desastres.  El prototipo de consulta permitirá la visualización de los datos inmersos en el datawarehouse en base a un formulario preestablecido. Capítulo II – Marco Referencial 16 Capítulo II Marco Referencial En el presente capítulo se exponen los fundamentos conceptuales que fueron utilizados durante el proceso de investigación y desarrollo. Éste, comprende 4 secciones las cuales serán descritas a continuación. La primera sección corresponde con una descripción general de la Fundación Venezolana de Investigaciones Sismológicas (FUNVISIS), donde se implementará el sistema, se explica su estructura organizacional, misión, visión entre otros. En la segunda sección se encuentra la descripción de las características, arquitectura, ventajas y demás funcionalidades de un datawarehouse. La tercera sección del capítulo abarca el manejador de bases de datos Monet DB, donde se destacan las características de los sistemas manejadores de bases de datos orientados a columnas. Así como también las características y funcionalidades provistas por el manejador. La cuarta y última sección, se refiere a la tecnología Ruby on Rails, de donde se destacan las funcionalidades, características y arquitectura de la misma, de igual forma se realizan comparaciones entre las diversas versiones manejadas, haciendo énfasis en la versión más actual. 1. Fundación Venezolana de Investigaciones Sismológicas La Fundación Venezolana de Investigaciones Sismológicas, adscrita al Ministerio del Poder Popular para Ciencia, Tecnología e Industrias Intermedias (MPPCTII), es una institución que promueve de forma permanente investigaciones y estudios especializados en sismología, ciencias geológicas e ingeniería sísmica, con el propósito de contribuir a la reducción de la vulnerabilidad en el país. Asimismo, FUNVISIS, se encarga de divulgar el conocimiento relacionado con las técnicas de prevención a través del programa Aula Sísmica, promueve la formación de personal especializado en el área sismológica y es el ente encargado de instalar, operar y mantener la Red Sismológica y la Red Acelerográfica Nacional (www.funvisis.gob.ve). Capítulo II – Marco Referencial 17 1.1 Misión Ejecutar y promover, permanentemente, investigaciones y estudios sismológicos destinados a atender la demanda de seguridad en la población ante la amenaza sísmica en el territorio nacional, la formación de personal especializado y divulgar los nuevos conocimientos de las ciencias. 1.2 Visión Ser una organización de excelencia en el área de protección a la colectividad frente a la amenaza sísmica, de referencia nacional e internacional, distinguida por su capacidad de servicio, la calidad de su investigación y su desarrollo técnico y científico. 1.3 Organigrama A continuación en la Figura 1 se muestra el organigrama representativo de FUNVISIS. Figura 1 Organigrama FUNVISIS (www.funvisis.gob.ve) 2. Almacén de Datos Según, Bill Inmon en el año de 1995 en su libro titulado “¿What is a Datawarehouse?”, define un almacén de datos (DW, datawarehouse por sus siglas en ingles), como una colección de datos orientados a un tema, integrados, no volátiles e Capítulo II – Marco Referencial 18 historiados, y organizados para el apoyo de un proceso de ayuda a la decisión. De igual manera un DW se caracteriza por ser:  Integrado: los datos almacenados en el DW deben integrarse en una estructura consistente, por lo que las inconsistencias existentes entre los diversos sistemas operacionales deben ser eliminadas.  Temático: sólo los datos necesarios para el proceso de generación del conocimiento del negocio se integran desde el entorno operacional. Los datos se organizan por temas para facilitar su acceso y entendimiento por parte de los usuarios finales. Por ejemplo, todos los datos sobre clientes pueden ser consolidados en una única tabla del DW. De esta forma, las peticiones de información sobre clientes serán más fáciles de responder dado que toda la información reside en el mismo lugar.  Histórico: el tiempo es parte implícita de la información contenida en un datawarehouse. En los sistemas operacionales, los datos siempre reflejan el estado de la actividad del negocio en el momento presente. Por el contrario, la información almacenada en el DW sirve, entre otras cosas, para realizar análisis de tendencias. Por lo tanto, el DW se carga con los distintos valores que toma una variable en el tiempo para permitir comparaciones.  No volátil: el almacén de información de un DW existe para ser leído, pero no modificado. La información es por tanto permanente, significando la actualización del DW la incorporación de los últimos valores que tomaron las distintas variables contenidas en él sin ningún tipo de acción sobre lo que ya existía. 2.1 Conceptos asociados a un datawarehouse Es importante destacar los conceptos descritos a continuación, ya que los mismos son la base para la construcción de un DW, en base a lo siguiente: (Ibarra, 2006).  Multidimensionalidad: se refiere a convertir los datos de varias fuentes, tablas relacionales o archivos planos en una estructura donde los datos estén agrupados en dimensiones separadas y heterogéneas, que generalmente son llamadas cubos.  Data Mart: es una versión especial de un almacén de datos. Son subconjuntos de datos con el propósito de ayudar a que un área específica dentro del negocio pueda tomar mejores decisiones. Los datos existentes en este contexto pueden ser agrupados, explorados y propagados de múltiples formas para que diversos grupos de usuarios realicen la explotación de los mismos de la forma más conveniente según sus necesidades. Capítulo II – Marco Referencial 19  Esquema en estrella: es un modo de representar datos multidimensionales en una base de datos relacional, donde las tablas de dimensión guardan información descriptiva acerca de sus miembros y sus relaciones, mientras que las tablas de hechos almacenan datos del negocio.  Medidas: es un tipo de dato cuya información es usada por los analistas en sus consultas (querys), para medir el rendimiento del comportamiento de un proceso o un objeto del negocio. Las medidas candidatas son los datos numéricos, pero no todo dato numérico es una medida candidata, de igual forma las medidas se encuentran involucradas con los cálculos de los resúmenes.  Dimensiones: es una entidad o una colección de entidades relacionadas, usadas por los analistas para identificar el contexto de las medidas con las que trabajan, estas determinan el contexto para las medidas. Es debido señalar que las dimensiones son referenciadas por las llamadas llaves de dimensión y que estas poseen entidades, atributos, jerarquías e incluso niveles de agregación.  Hechos: es una colección de medidas relacionadas con sus dimensiones asociadas, representadas por las llaves de dimensión. De igual forma un hecho puede representar un objeto de negocio, una transacción o un evento que es utilizado por el analista de información.  Granularidad: se refiere al nivel de detalle en el cual los datos se almacenan en los datawarehouse. La regla de oro es almacenar los datos en el nivel más bajo de detalle posible. 2.2 Características de un datawarehouse Con base a la definición de Bill Inmon descrita en líneas anteriores serán descritas a continuación las características provistas por un almacén de datos.  Orientado a temas: una primera característica de un DW es que la información se clasifica en base a los aspectos que son de interés para la empresa. Siendo así, los datos tomados están en contraste con los clásicos procesos orientados a las aplicaciones. Los datos en la base de datos están organizados de manera que todos los elementos de datos relativos al mismo evento u objeto del mundo real queden unidos entre sí. Las diferencias entre la orientación de procesos y funciones de las aplicaciones y la orientación a temas, radican en el contenido de los datos a nivel detallado. En el DW se excluye la información que no será usada por el proceso de sistemas de soporte de decisiones, mientras que la información de las orientadas a las aplicaciones, contiene datos para satisfacer de inmediato los requerimientos Capítulo II – Marco Referencial 20 funcionales y de proceso, que pueden ser usados o no por el analista de soporte de decisiones.  Variante en el tiempo: los cambios producidos en los datos a lo largo del tiempo quedan registrados para que los informes que se puedan generar reflejen esas variaciones. Los datos son relativos a un periodo de tiempo (semestre, año, entre otros) y deben ser incrementados periódicamente. Toda la información del DW es requerida en algún momento. Esta característica básica de los datawarehouse, es muy diferente de la información encontrada en el ambiente operacional. En éstos, la información se requiere al momento de ser accedida.  No volátil: la información no se modifica ni se elimina, una vez almacenado un dato, éste se convierte en información de sólo lectura, y se mantiene para futuras consultas. Los datos almacenados no son actualizados, sólo son incrementados. Cabe destacar que posee dos únicos tipos de operaciones: la carga inicial de datos y el acceso a los mismos.  Integrado: la base de datos contiene los datos de todos los sistemas operacionales de la organización, y dichos datos deben ser consistentes. Integra datos recogidos de diferentes sistemas operacionales de la organización (y/o fuentes externas). Se construye mediante de fuentes de datos múltiples y heterogéneas. Cualquiera que sea la forma del diseño, el resultado es el mismo, la información necesita ser almacenada en el DW en un modelo globalmente aceptable y singular, aun cuando los sistemas operacionales subyacentes almacenen los datos de manera diferente. Es importante señalar que en un DW se aplican técnicas de limpieza e integración como lo son el asegurar la consistencia en el nombrado en las estructuras codificadas, tipos de datos de los atributos, y demás aspectos entre las múltiples bases de datos. Asimismo cuando los datos se mueven al DW, éstos deben ser transformados según sean los requerimientos operacionales. 2.3 Ventajas y desventajas de un datawarehouse Un DW puede dar lugar a una serie de importantes beneficios para una organización. En cualquier caso, su utilización permitirá que la información de gestión sea: accesible, correcta, uniforme y actualizada. A continuación se describen algunas de estas ventajas:  Menor coste en la toma de decisiones: se suprime el despilfarro de tiempo que se podía producir al intentar ejecutar consultas de datos largas y complejas con Capítulo II – Marco Referencial 21 bases de datos, que estaban diseñadas específicamente para transacciones más cortas y sencillas.  Mayor flexibilidad ante el entorno: un DW convierte los datos operacionales en información relacionada y estructurada, que genera el "conocimiento" necesario para la toma de decisiones. Esto permite establecer una base única del modelo de información de la organización, que puede dar lugar a una visión global de la información en base a los conceptos de negocio que tratan los usuarios.  Mejor servicio al cliente: el hecho de que un DW implique una mayor flexibilidad ante el entorno, tiene una consecuencia directa en una mayor capacidad para responder a las necesidades de los clientes.  Rediseño de procesos: un DW ofrece a los usuarios una capacidad de análisis de la información de su negocio, que tiende a ser ilimitada y que permite con frecuencia obtener una visión más profunda y clara de los procesos de negocio propiamente dichos, lo que a su vez permite obtener ideas renovadoras para la rediseño de los mismos. Por otra parte es importante señalar que utilizar almacenes de datos también plantea algunos inconvenientes, entre los cuales se encuentran:  Altos Costos: a lo largo de su vida los almacenes de datos pueden suponer altos costos. El almacén de datos no suele ser estático. Los costos de mantenimiento son elevados.  Tiempo de vida útil: los almacenes de datos se pueden quedar obsoletos relativamente pronto.  Consultas: a veces, ante una petición de información estos devuelven una información sub óptima, que también supone una pérdida para la organización. 2.4 Arquitectura de un datawarehouse Según (Bouman & Dongen, 2009), la arquitectura de un DW viene determinada por su situación central como fuente de información para las herramientas de análisis, con base a ello a continuación se describen los componentes mostrados en la Figura 2. Capítulo II – Marco Referencial 22 Figura 2 Arquitectura de un Datawarehouse (Bouman & Dongen, 2009)  Fuente de Datos: uno o más sistemas de fuente, como lo son archivos, sistemas manejadores de bases de datos (DBMS, por sus siglas en ingles), entre otros.  Un proceso de Extracción, Transformación y Carga de los datos: realiza las funciones de extracción de las fuentes de datos (transaccionales o externas), transformación (limpieza, consolidación, entre otros) y la carga del almacén de datos (ordenación, agregación, entre otros), e incluso refrescamiento del almacén, es decir, la operación periódica que propaga los cambios de las fuentes externas al almacén de datos. A menudo este proceso contiene un área de ensayo utilizada como área intermedia en donde se extraen los datos y se realiza la transformación de los datos iniciales y su limpieza. Los datos de ensayo pueden ser usados tanto una base de datos como en ficheros planos. En muchos casos mediante archivos planos se permite un procesamiento más rápido.  El almacén de datos: que consiste en la base de datos del almacén central y cero o más Data Marts. Posee información relevante, metadatos. Los metadatos son básicamente datos acerca de los datos contenidos en el DW, es la manera de describir propiedades de las bases de datos y sus atributos, incluyendo tablas y nombres de las columnas, atributos de columnas (tamaño y tipo de dato) de las tablas de las bases de datos, así como claves primarias y relaciones con claves foráneas. En sí el almacén de datos es la base fundamental para establecer la completa integración de los datos de la empresa.  La capa de usuario final identificada como (EUL): se refiere a las diversas herramientas para trabajar con los datos, como lo son informes, cuadros de mando, hojas de cálculo y los documentos publicados. Generalmente, la combinación del almacén central y los data marts es considerada como el almacén de datos, y el término de datawarehouse es utilizado para denotar el proceso completo de construcción, carga y la gestión de los datos del almacén. Capítulo II – Marco Referencial 23 3. Sistemas manejadores de bases de datos orientados a columnas Un sistema manejador de bases de datos orientado a columnas, es un sistema de gestión de base de datos, que almacena el contenido de la columna en lugar de la fila. Esto tiene ventajas para los almacenes de datos y catálogos de la biblioteca, donde los agregados se calculan sobre un gran número de elementos de datos similares. Es posible obtener algunos beneficios de la organización orientada a columnas y por hilera con cualquier base de datos. Cuando se trata de, orientada a columnas nos referimos tanto a la facilidad de expresión de una estructura orientada a la columna como al foco en la optimización de las cargas de trabajo orientadas a columnas. Este enfoque contrasta con el orientado a fila y con bases de datos de correlación, que utilizan una base de almacenamiento de la estructura de valor. (Abadi, Boncz, & Harizopoulos, 2009) 3.1 Descripción Un programa de base de datos debe mostrar sus datos como tablas de dos dimensiones, de columnas y filas, pero lo almacenan como cadenas de una sola dimensión. Por ejemplo, una base de datos podría tener los siguientes datos. EmpId Apellido Nombre Salario 1 Smith Joe 40000 2 Jones María 50000 3 Johnson Cathy 44000 De esta información es posible apreciar un simple empleado de identificador (EmpId), campos de nombre (nombre y apellido) y un salario (sueldo). Aunque las unidades de memoria (RAM) y almacenamiento (disco duro) difieren mecánicamente, el sistema operativo del equipo se resume en ellos. Sin embargo, la base de datos debe convertir a su tabla de dos dimensiones en una serie unidimensional de bytes. Para así el sistema operativo pueda escribir en cualquiera de la memoria RAM o disco duro, o ambos. Una base de datos orientada a filas serializa todos los valores de una fila juntos, entonces los valores de la fila siguiente, y así sucesivamente, como por ejemplo: 1, Smith, Joe, 40000; 2, Jones, Mary, 50000; 3, Johnson, Cathy, 44.000; Capítulo II – Marco Referencial 24 Por otro lado una base de datos orientada a columnas serializa todos los valores de una columna en conjunto, los valores de la columna siguiente, y así sucesivamente, como por ejemplo. 1,2,3; Smith, Jones, Johnson; Joe, María, Catalina; 40000, 50000, 44000; Las particiones, la indexación, el almacenamiento en caché, los cubos de procesamiento analítico en línea (OLAP, por sus siglas en ingles) y los sistemas de procesamiento transaccionales en línea (OLTP, por sus siglas en ingles), tales como escribir por delante de registro o control de concurrencia multiversión; todos afectan dramáticamente la organización física. Dicho esto, el procesamiento de transacciones en línea centrada en los sistemas manejadores de bases de datos relacionales (RDBMS) más orientada a la fila, mientras que en el procesamiento analítico en línea, son un balance de los orientados a filas y de los orientados a columnas. 3.2 Beneficios Las comparaciones entre sistemas manejadores de bases de datos orientados a filas y los orientados a columnas, son típicamente relacionadas con la eficiencia de acceso al disco duro para una determinada carga de trabajo, como el tiempo de búsqueda es muy largo comparado con los retrasos en otras computadoras. A veces, la lectura de un megabyte de datos almacenado de forma secuencial, no tiene en el tiempo más de un acceso al azar. Además, debido a que el tiempo de búsqueda está mejorando a un ritmo lento en relación a la potencia de la CPU, este enfoque probablemente continuará en los sistemas que dependen de discos duros para su almacenamiento. A continuación se presenta un conjunto de observaciones con base a las compensaciones entre las organizaciones de los orientados a columnas y los orientados a filas.  Sistemas orientados a columnas, son más eficientes cuando un agregado debe ser calculado a lo largo de filas, pero sólo para un subconjunto notablemente más pequeño de todas las columnas de datos, ya que la lectura que los pequeños subconjunto de datos puede ser más rápido que leer todos los datos.  Sistemas orientados a columnas, son más eficientes cuando los nuevos valores de una columna se suministran para todas las filas a la vez, debido a que los datos de la columna se puede escribir de manera eficiente y reemplazar los datos de la columna vieja sin tocar las otras columnas de las filas. Capítulo II – Marco Referencial 25  Sistemas orientados a filas, son más eficientes cuando varías columnas de una sola fila se requiere al mismo tiempo, y cuando la fila de tamaño es relativamente pequeño, ya que toda la fila se pueden recuperar con una sola búsqueda en disco.  Sistemas orientados a filas, son más eficientes cuando se escribe una nueva fila si todos los datos de la columna se suministra al mismo tiempo, como toda la fila se puede escribir con una sola búsqueda en disco. En la práctica, las arquitecturas orientadas a filas, están bien adaptadas para OLTP como las cargas de trabajo, que están mucho más cargadas de transacciones interactivas. Almacenes orientados a columnas son muy adecuados para OLAP, como las cargas de trabajo (por ejemplo, almacenes de datos), que suelen implicar un menor número de consultas muy complejo en todos los datos (posiblemente terabytes). Sin embargo, hay un número de pruebas realizadas, basada en filas RDBMS OLAP que se encarga de terabytes, o incluso petabytes de datos, como Teradata. (Abadi, Boncz, & Harizopoulos, 2009) 3.3 Implementaciones Almacenes de columnas o archivos de transposición se han aplicado desde los primeros días del desarrollo de los DBMS, a partir de la década de 1970. Por ejemplo, la empresa Estadísticas Canadá implementó en 1976 y un sistema, el cual se utilizó para el procesamiento y la recuperación del censo canadiense de población y vivienda, así como varias aplicaciones de estadística. Los resultados de este sistema eran compartidos con otras organizaciones estadísticas en todo el mundo y utilizados ampliamente en la década de 1980. Durante muchos años, sólo el DMMS Sybase IQ, era el único producto comercialmente disponible en los DBMS orientado a la clase de la columna. Sin embargo, eso ha cambiado rápidamente en los últimos años, tanto con las implementaciones en código abierto, como con las implementaciones comerciales. Ejemplos actuales de DBMS en columnas incluyen:  Comercial o Oracle Application predicativo Servir al por menor (RPA) o ARENA CDBMS o SenSage o HassoDB o Sybase IQ o SADAS http://translate.googleusercontent.com/translate_c?hl=es&sl=en&tl=es&u=http://en.wikipedia.org/wiki/Petabyte&rurl=translate.google.com&twu=1&usg=ALkJrhibAXwJLL34txPH7nDlGGfqEFki9A http://translate.googleusercontent.com/translate_c?hl=es&sl=en&tl=es&u=http://en.wikipedia.org/wiki/Teradata&rurl=translate.google.com&twu=1&usg=ALkJrhjB1S3WR4guBX5G_W4149ZC33DKjA http://translate.googleusercontent.com/translate_c?hl=es&sl=en&tl=es&u=http://en.wikipedia.org/wiki/Sybase_IQ&rurl=translate.google.com&twu=1&usg=ALkJrhiX8MdwqPaWJUU4xof_cwwk9D4Bqw Capítulo II – Marco Referencial 26 o Vertica y sus académicos de código abierto primo de la tienda C- o Valentina base de datos o KDB o Addamark, ahora el SenSage registro del servidor escalable o 1010data 's de base de datos Tenbase o Dataprobe o EXASolution o Skytide servidor XOLAP o SuperStar desde el Espacio-Tiempo de Investigación o ParAccel analítico de base de datos o Datos Aster Sistemas o FluidDB o Ingres y Vectorwise iniciativa  De código abierto ( software propietario ) o Calpont de InfiniDB Enterprise Edition-front-end de MySQL o Infobright Enterprise Edition, se integra con MySQL (antes Brighthouse) o RC21 proyecto de código abierto comercial o Xplain semántica de base de datos (llamados archivos incorporado). El software ya no está disponible.  De código abierto ( software libre ) o Calpont de InfiniDB Community Edition, MySQL-Front End, GPLv2 o C-Store nueva versión desde octubre 2006 o GenoByte column, sistema de almacenamiento basada en la API para el manejo de datos genotipo o Lemur Bitmap Index C++ Library (GPL) o FastBIT o Infobright Community Edition o LucidDB y Eigenbase o MonetDB o Metakit o El lenguaje de programación S y R de GNU incorporado en estructuras de datos orientadas a columnas para análisis estadísticos De todos los sistemas manejadores de bases datos orientados a columnas expuestos en líneas anteriores, será descrito en profundidad a MonetDB perteneciente al grupo de los sistemas manejadores de bases de datos de código abierto de software libre; http://translate.googleusercontent.com/translate_c?hl=es&sl=en&tl=es&u=http://en.wikipedia.org/wiki/Vertica&rurl=translate.google.com&twu=1&usg=ALkJrhjUVPkllpvasDXZHVoj4sDQkn6KPA http://translate.googleusercontent.com/translate_c?hl=es&sl=en&tl=es&u=http://www.sensage.com/&rurl=translate.google.com&twu=1&usg=ALkJrhhNmUC99S9xJfd7f6CR35Gmy5TO2Q http://translate.googleusercontent.com/translate_c?hl=es&sl=en&tl=es&u=http://en.wikipedia.org/wiki/Infobright&rurl=translate.google.com&twu=1&usg=ALkJrhjWktPea_CtpVSiFAAZKYU1sGbB6Q http://translate.googleusercontent.com/translate_c?hl=es&sl=en&tl=es&u=http://en.wikipedia.org/wiki/MySQL&rurl=translate.google.com&twu=1&usg=ALkJrhjN8uhY3M18G3NTdXIm1zmaprk01g http://translate.googleusercontent.com/translate_c?hl=es&sl=en&tl=es&u=http://www.jhterbekke.net/XplainDBMS.html&rurl=translate.google.com&twu=1&usg=ALkJrhj_NcZ0QhBlFTCAQfyef7Gqakditw http://translate.googleusercontent.com/translate_c?hl=es&sl=en&tl=es&u=http://www.obiba.org/%3Fq%3Dnode/75&rurl=translate.google.com&twu=1&usg=ALkJrhi014RSXat3g_0oO_NmwsyaD0FNGw http://translate.googleusercontent.com/translate_c?hl=es&sl=en&tl=es&u=http://en.wikipedia.org/wiki/LucidDB&rurl=translate.google.com&twu=1&usg=ALkJrhjt953ape9vn11Z5ZB9kv-LG3ZxtQ Capítulo II – Marco Referencial 27 por ser este uno de los más eficientes para la creación y manipulación de un almacén de datos (Datawarehouse). 3.4 Descripción de MonetDB Según Vermeij, Quak, Kersten, & Nes, el sistema manejador de bases de datos MonetDB es un sistema de gestión de alto rendimiento y de código abierto, desarrollado en el instituto de investigación nacional para las matemáticas y de informática (CWI; En Informática de Wiskunde del voor) en los Países Bajos. Fue diseñado para proporcionar alto rendimiento en preguntas complejas contra bases de datos grandes. MonetDB se ha aplicado con éxito en actividades de alto rendimiento para Explotación minera de datos, OLAP, pregunta XML, recuperación del texto y de las multimedias, entre otras. La representación de datos internos de MonetDB es almacenada en la memoria, confiando en las gamas enormes del registro de dirección de la memoria de CPU contemporáneas, y así saliendo del DBMS tradicional diseña la participación de la gerencia compleja de los almacenes grandes de los datos en memoria limitada. MonetDB introdujo innovaciones en todas las capas de un DBMS, un modelo de almacenamiento basado en la Fragmentación vertical, una CPU moderna, una arquitectura vectorizada en la ejecución de la consulta, eso a menudo da a MonetDB más que diez veces una ventaja neta, en cuanto a la velocidad en el mismo algoritmo ejecutado sobre un típico intérprete para un RDBMS. La familia de MonetDB consiste en:  MonetDB/SQL: la solución de la base de datos relacional  MonetDB/XQuery: la solución de la base de datos de XML  Servidor de MonetDB: el servidor de base de datos del multi-modelo 3.4.1 Características de MonetDB Las tres (3) principales características de MonetDB son:  La fragmentación vertical, utilizada por MonetDB para almacenar sus datos es muy beneficioso para el procesamiento de consultas espaciales. La razón principal es que con las técnicas espaciales de filtro, sólo una fracción de las geometrías de una tabla son realmente necesarios en la mayoría de los casos. En un modelo tradicional de tupla de almacenamiento basado en los datos de geometría se encuentra todavía en el camino. Debido al tamaño de la geometría sólo pocas tuplas son las que pueden ser almacenadas en un bloque de disco. La http://enciclopediaespana.com/Base_de_datis_relacional.html Capítulo II – Marco Referencial 28 fragmentación vertical asegura que los atributos que no se necesitan no se encuentren en el camino.  Consultas espaciales son a menudo muy difíciles de manejar. A menudo, el optimizador de consultas tiene que ser ayudado por las pistas dadas por el optimizador de SQL. Durante años, se han hecho varios intentos para crear un optimizador de consultas redestinable o modular. Los más prometedores se basan en la reescritura de plazo, lo que proporciona un ajuste a la razón de su corrección (Becker & Guting, 1992). Sin embargo, se sabe también que muchas dependen tanto de la semántica inherente al lenguaje de consulta e información circunstancial, como la disponibilidad de los índices, los algoritmos y el nivel de protección de la transacción. En estos casos, la regla de re escritura de forma rápida se hace difícil de seguir y mantener la coherencia. El software MonetDB ofrece un esquema fácil de depurar, desplegar y optimizadores de seguimiento orientado a tareas bien definidas.  En el código XML dominio espacial (y específicamente GML) es cada vez más utilizado. Sin embargo, hacer consultas a un gran documento XML sigue siendo complicado. MonetDB tiene un historial de rentabilidad demostrado, encontrado en su motor XQuery. La combinación de la funcionalidad de XQuery eficiente de MonetDB con el módulo espacial, conlleva a una poderosa solución de procesamiento de GML. Cabe destacar que en la actualidad la relación entre SQL / XML de integración está en desarrollo. 3.4.2 Arquitectura de MonetDB En esta sección se presentan brevemente el servidor MonetDB y el compilador de SQL. Una creciente clase de los motores de bases de datos están orientados a la explotación de un almacén de datos orientado a columnas (Stonebraker, 2005). En este campo, tablas relacionales se dividen verticalmente en cada columna que representa un atributo relacional único. Casi como si cada columna se almacena en una tabla separada o incluso una matriz común, pero con una implementación que se orienta a explotar de manera óptima esta estructura. Este enfoque conduce a una arquitectura de sistema muy simplificado y abre muchos caminos para aumentar el rendimiento. Los beneficios provienen de una mejor racionalización del flujo de datos desde el disco a través de la memoria en la caché de la CPU. Almacenes de datos orientados a columnas son especialmente beneficiosos en datawarehouse y aplicaciones de minería de datos, que a menudo se utilizan en bases de datos científicas. La razón principal es que la mayoría de las aplicaciones no necesitan los cientos de columnas de una tabla relacional con los datos Capítulo II – Marco Referencial 29 de medición científica, sino que simplemente requieren una labor de sólo unas pocas a la vez, para el análisis estadístico. El beneficio inmediato del enfoque de la columna del almacén de datos, es que sólo los datos que son relevantes para el proceso son los que se traen desde el disco. MonetDB es una pilar completamente funcional del almacén de datos desarrollado a lo largo de una década en el CWI (Centrum Wiskunde & Informática). Se trata de una arquitectura de dos capas de un servidor de base de datos y una serie de interfaces. En la actualidad dispone de interfaces que proporcionan una para SQL y una para la interfaz XQuery con el servidor de base de datos. El servidor se aborda en un lenguaje propio, llamado lenguaje para MonetDB ensamblador (LMA). LMA es un lenguaje de álgebra relacional que soporta una gran colección de primitivas relacionales, funciones y fácil vinculación con las funciones definidas por el usuario. Este enfoque simplifica considerablemente los compiladores de interfaces, la interfaz analiza las consultas SQL y los compila en los planes de LMA semi-optimizado que explotan el lenguaje SQL y la semántica del esquema. Sólo se centran en la reducción de volumen posible. El compilador de aplicaciones para usuario también selecciona los componentes LMA optimizador para ser activado, por ejemplo, eliminación de la expresión común, la eliminación de código muerto, paralelismo, entre otros. De esta manera, un optimizador de la arquitectura de tres niveles se logra con una clara división de tareas. La capa inferior se centra en la optimización operacional con el estado actual de la máquina. La capa superior está orientada a la explotación de la semántica del esquema, y la capa media está orientada a las decisiones tácticas. 3.4.3 Funcionalidades de MonetDB A continuación se presentan una serie de cuadros, con un resumen de las funcionalidades provistas por el sistema manejador de bases de datos MonetDB. (Comparison_of_relational_database_management_systems). Información General Mantenedor Primera Fecha de Lanzamiento Ultima versión Última Fecha de Lanzamiento Licencia de Software MonetDB El equipo de desarrolladores MonetDB 2004 5.6 06 2008 MonetDB Licencia Pública v1.1 Cuadro 1 Información General MonetDB http://translate.googleusercontent.com/translate_c?hl=es&sl=en&u=http://monetdb.cwi.nl/Legal/MonetDBLicense-1.1.html&prev=/search%3Fq%3DMonetDB%2B%252B%2Bwikipedia%26hl%3Des%26biw%3D1280%26bih%3D608%26prmd%3Div&rurl=translate.google.co.ve&twu=1&usg=ALkJrhhvR9FJU5onpW7HmSlBtVu5OGhwxA http://translate.googleusercontent.com/translate_c?hl=es&sl=en&u=http://monetdb.cwi.nl/Legal/MonetDBLicense-1.1.html&prev=/search%3Fq%3DMonetDB%2B%252B%2Bwikipedia%26hl%3Des%26biw%3D1280%26bih%3D608%26prmd%3Div&rurl=translate.google.co.ve&twu=1&usg=ALkJrhhvR9FJU5onpW7HmSlBtVu5OGhwxA http://translate.googleusercontent.com/translate_c?hl=es&sl=en&u=http://monetdb.cwi.nl/Legal/MonetDBLicense-1.1.html&prev=/search%3Fq%3DMonetDB%2B%252B%2Bwikipedia%26hl%3Des%26biw%3D1280%26bih%3D608%26prmd%3Div&rurl=translate.google.co.ve&twu=1&usg=ALkJrhhvR9FJU5onpW7HmSlBtVu5OGhwxA Capítulo II – Marco Referencial 30 Sistemas Operativos Windows Mac OS X Linux BSD UNIX AmigaOS Symbian z/OS 1 MonetDB SI SI SI NO SI NO NO NO Cuadro 2 Sistemas Operativos Soportados por MonetDB Características Fundamentales MonetDB ACID SI Integridad Referencial SI Transacciones SI Unicode SI Tabla Temporal SI Materializado Vista NO Cuadro 3 Características Fundamentales MonetDB Índices MonetDB -R / + R árbol NO Hash SI Expresión NO Parcial NO Inversa NO Mapa de bits NO GiST NO GIN NO Cuadro 4 Índices en MonetDB 4. Ruby on Rails Según Ruby on Rails org. Web development that doesn’t hurt. Ruby on Rails es un entorno de desarrollo web de código abierto que está optimizado para satisfacción de los programadores y de la productividad. Permite escribir un buen código favoreciendo la convención antes que la configuración. http://translate.googleusercontent.com/translate_c?hl=es&sl=en&u=http://en.wikipedia.org/wiki/AmigaOS&prev=/search%3Fq%3DMonetDB%2B%252B%2Bwikipedia%26hl%3Des%26biw%3D1280%26bih%3D608%26prmd%3Div&rurl=translate.google.co.ve&twu=1&usg=ALkJrhiWhbaVE64wY14OeLS8BCIkW7vyKw http://translate.googleusercontent.com/translate_c?hl=es&sl=en&u=http://en.wikipedia.org/wiki/Symbian&prev=/search%3Fq%3DMonetDB%2B%252B%2Bwikipedia%26hl%3Des%26biw%3D1280%26bih%3D608%26prmd%3Div&rurl=translate.google.co.ve&twu=1&usg=ALkJrhjAzcEvCq6DoWjzn_CKRDcvNcZwmQ http://translate.googleusercontent.com/translate_c?hl=es&sl=en&u=http://en.wikipedia.org/wiki/Z/OS&prev=/search%3Fq%3DMonetDB%2B%252B%2Bwikipedia%26hl%3Des%26biw%3D1280%26bih%3D608%26prmd%3Div&rurl=translate.google.co.ve&twu=1&usg=ALkJrhhxlCPOccA8uOIrWKf4gK4clQRTHg http://translate.googleusercontent.com/translate_c?hl=es&sl=en&u=http://en.wikipedia.org/wiki/Comparison_of_relational_database_management_systems&prev=/search%3Fq%3DMonetDB%2B%252B%2Bwikipedia%26hl%3Des%26biw%3D1280%26bih%3D608%26prmd%3Div&rurl=translate.google.co.ve&twu=1&usg=ALkJrhizYJLnNJYWKd9l02FP4Kz_5KZBSg#os_1 http://translate.googleusercontent.com/translate_c?hl=es&sl=en&u=http://en.wikipedia.org/wiki/R-tree&prev=/search%3Fq%3DMonetDB%2B%252B%2Bwikipedia%26hl%3Des%26biw%3D1280%26bih%3D608%26prmd%3Div&rurl=translate.google.co.ve&twu=1&usg=ALkJrhhxWf8OhbGTjMcQdwgclpg9W3Zo1w http://translate.googleusercontent.com/translate_c?hl=es&sl=en&u=http://en.wikipedia.org/wiki/R%252B_tree&prev=/search%3Fq%3DMonetDB%2B%252B%2Bwikipedia%26hl%3Des%26biw%3D1280%26bih%3D608%26prmd%3Div&rurl=translate.google.co.ve&twu=1&usg=ALkJrhgJt9dEQPVdhG-EO1kF0D7NKawiaw http://translate.googleusercontent.com/translate_c?hl=es&sl=en&u=http://en.wikipedia.org/wiki/GiST&prev=/search%3Fq%3DMonetDB%2B%252B%2Bwikipedia%26hl%3Des%26biw%3D1280%26bih%3D608%26prmd%3Div&rurl=translate.google.co.ve&twu=1&usg=ALkJrhjgFqPLTC1Uk9HMVuI6ZrgbuyST8A Capítulo II – Marco Referencial 31 En este concepto es importante definir la separación entre los dos entes importantes que conforman este entorno, como lo son Ruby y Rails. Por su parte, según Informit (Informit. Ruby Language), Ruby es un lenguaje de programación interpretado, reflexivo y orientado a objetos, creado por el programador japonés Yukihiro "Matz" Matsumoto, es un lenguaje de programación interpretado en una sola pasada y su implementación oficial es distribuida bajo una licencia de software libre. Según su creador, Ruby está diseñado para la productividad y la diversión del desarrollador, siguiendo los principios de una buena interfaz de usuario. Sostiene que el diseño de sistemas necesita enfatizar las necesidades humanas más que las de la máquina. Por otro lado, Rails, según Ruby on Rails Org, es un completo entorno para desarrollar aplicaciones web con base de datos de acuerdo con la estructura Modelo Vista Controlador (MVC). Desde el Ajax en la vista, a la petición y respuesta en el controlador, hasta el modelo, Rails proporciona un entorno de desarrollo de Ruby. Para probarlo, solo se necesita una base de datos y un servidor web. El desarrollo sobre este entorno está basado en dos filosofías, no te repitas (del inglés Don't repeat yourself, DRY) y convención sobre configuración. DRY significa que las definiciones deberían hacerse una sola vez. Dado que Ruby on Rails es un framework de pila completa, los componentes están integrados de manera que no hace falta establecer puentes entre ellos. Mientras que convención sobre configuración significa que el programador sólo necesita definir aquella configuración que no es convencional. Ruby on Rails se ha convertido en un entorno muy poderoso para el desarrollo de aplicaciones Web y que cada día toma más auge dentro del mundo del desarrollo Web. Es importante señalar que en líneas posteriores serán descritas a profundidad las versiones de Ruby 1.9.2 y Rails 3.0 por ser estas las más recientes y con las cuales será desarrollada la propuesta del presente TEG. 4.1 Funcionamiento Ruby on Rails funciona bajo el paradigma MVC, (Burbeck, 1992) el cual es un patrón de arquitectura de software que separa los datos de una aplicación, la interfaz de usuario, y la lógica de control en tres componentes distintos, el cual aplicado a web la vista es un página HTML, o html.erb en caso de Rails, el cual contiene el HTML y el código que provee de datos dinámicos a la página. El modelo es el Sistema de Gestión de base de datos y la Lógica de negocio, y el controlador es el responsable de recibir los eventos de entrada desde la vista. Específicamente en Rails el modelo MVC se especifica de la siguiente manera: Capítulo II – Marco Referencial 32  Modelo: En las aplicaciones web orientadas a objetos sobre bases de datos, el Modelo consiste en las clases que representan a las tablas de la base de datos. En Ruby on Rails, las clases del Modelo son gestionadas por ActiveRecord. Por lo general, la única tarea que tiene un desarrollador es hacer que los modelos hereden de la clase ActiveRecord::Base, y Rails sabrá mediante las convenciones qué tabla usar y qué columnas tiene dicha tabla.  Vista: Es la lógica de visualización, es decir, cómo se muestran los datos provenientes del Controlador. Con frecuencia en las aplicaciones web la vista consiste en una cantidad mínima de código de algún lenguaje incluido en HTML. El método que se emplea en Rails por defecto es usar Ruby Embebido (archivos .rhtml, desde la versión 2.x en adelante de RoR archivos .html.erb), que son básicamente fragmentos de código HTML código en Ruby. También pueden construirse vistas en HTML y XML con Builder3 o usando el sistema de plantillas Liquid.  Controlador: Las clases del Controlador responden a la interacción del usuario e invocan a la lógica de la aplicación, que a su vez manipula los datos de las clases del Modelo y muestra los resultados usando las Vistas. En las aplicaciones web basadas en MVC, los métodos del controlador son invocados por el usuario usando el navegador web. La implementación del Controlador es manejada por el ActionPack de Rails, que contiene la clase ApplicationController. Un controlador en Rails debe heredar de esta clase y definir las acciones como métodos de dicha clase. 4.2 Arquitectura Según Ruby on Rails org. Web development that doesn’t hurt. Rails está separado en varios paquetes, los cuales en conjunto forman el framework. Básicamente los paquetes principales de los cuales se constituye Rails se mencionan a continuación:  ActiveRecord: es una alternativa que facilita acceder a los datos de una base de datos. Una fila en la tabla de la base de datos (o vista) se envuelve en una clase, de manera que se asocian filas únicas de la base de datos con objetos del lenguaje de programación usado. Cuando se crea uno de estos objetos, se añade una fila a la tabla de la base de datos. Cuando se modifican los atributos del objeto, se actualiza dicha la fila, por otra parte, la clase envoltorio implementa métodos de acceso para cada columna de la tabla o vista. Rails implementa este enfoque para proveer una interfaz hacia los datos que facilite su acceso y manipulación utilizando los http://es.wikipedia.org/wiki/ActiveRecord http://home.leetsoft.com/liquid/ http://es.wikipedia.org/w/index.php?title=ActionPack&action=edit&redlink=1 Capítulo II – Marco Referencial 33 modelos. La clase específica que implementa la interfaz se llama ActiveRecord::Base.  ActiveResource (ARes): es la clase principal utilizada para mapear recursos RESTful con modelos en una aplicación Rails. Es decir, ARes se encarga de proveer la interfaz de una aplicación Rails con una plataforma de servicios Web, permitiendo tanto recibir como crear servicios que funcionan bajo el enfoque REST. ARes conecta objetos de negocio y servicios Web REST e implementa el mapeo objeto relacional para proveer transparencia entre un cliente y un servicio RESTful.  Action Pack: divide la respuesta a una solicitud web en un controlador (ejecutando la lógica) y una vista (renderizando una plantilla). Este proceso en dos partes es conocido como una acción, la cual normalmente creará, leerá, actualizará o eliminará (create, read, update o delete, CRUD por sus siglas en ingles) alguna parte de un modelo (comúnmente soportado por una base de datos) antes de elegir renderizar una plantilla (vista) o redirigir a alguna otra acción. Action Pack implementa estas acciones como métodos públicos en Action Controllers y Action Views. Los Action controllers son los responsables de manejar todas las acciones relacionadas con la lógica de la aplicación. Este agrupamiento usualmente consiste de acciones de procesamiento y CRUDs alrededor de un modelo. Las plantillas Action View son escritas utilizando Ruby embebido mediante etiquetas en el código HTML. Para evitar llenar las plantillas con código, un manojo clases ayudantes (llamados helpers en Rails) proveen funcionalidades comunes como formularios, fechas y cadenas de caracteres.  ActiveSupport: es una colección de variedad de clases utilitarias y extensiones de librerías estándar que son de gran utilidad para Rails. Todas estas librerías fueron reunidas en este paquete para poder aprovechar todo el potencial que ofrece el lenguaje Ruby. En síntesis, son librerías de propósito general de Rails.  Action Mailer: este paquete permite el envió de correos electrónicos desde una aplicación Rails usando modelos y vistas llamadas mailers. Los modelos Mailer heredan de la clase ActionMailer::Base, así mismo, los correos son definidos creando métodos en este modelo los cuales manipulan ciertas variables que posteriormente serán usadas por la plantilla del Mailer. 4.3 Gemas Las gemas son plugins y/o codigos añadidos a un proyecto Ruby on Rails, que proveen nuevas funcionalidades como nuevos create, nuevas funciones pre escritas (como Capítulo II – Marco Referencial 34 login de usuarios) o nuevas herramientas para el desarrollo como puedan ser Haml y SASS (la primera es una nueva forma de template basada en html pero más sencilla y potente, y la segunda es igual pero para el caso de las CSS). (Wikipedia. Rails) 4.4 Soporte de servidores Web Para desarrollo y pruebas, se utiliza Mongrel o WEBrick, incluido con Ruby. Para utilizar Rails en servidores en producción se está extendiendo el uso de Passenger, una especie de mod_rails para Apache desarrollado en 2008 por la empresa holandesa Phusion. Otras opciones para producción son Nginx, Mongrel, Apache, Lighttpd con FastCGI o alguna combinación de ambos (por ejemplo utilizando Apache como proxy para los procesos Mongrel). Sobre Apache, mod ruby puede mejorar considerablemente el rendimiento, aunque su uso no se recomienda porque no es seguro utilizar múltiples aplicaciones RoR sobre Apache. (Wikipedia. Rails) 4.5 Soporte de Bases de Datos Dada que la arquitectura Rails favorece el uso de bases de datos se recomienda usar un sistema gestor de bases de datos relacionales (SGBDR) para almacenamiento de datos. Rails soporta la biblioteca SQLite por defecto. El acceso a la base de datos es totalmente abstracto desde el punto de vista del programador, es decir que es agnóstico a la base de datos, y Rails gestiona los accesos a la base de datos automáticamente (aunque, si se necesita, se pueden hacer consultas directas en SQL) Rails intenta mantener la neutralidad con respecto a la base de datos, la portatibilidad de la aplicación a diferentes sistemas de base de datos y la reutilización de bases de datos preexistentes. Sin embargo, debido a la diferente naturaleza y prestaciones de los SGBDRs el framework no puede garantizar la compatibilidad completa. Se soportan diferentes SGBDRs, incluyendo MySQL, PostgreSQL, SQLite, IBM DB2 y Oracle. (Wikipedia. Rails) 4.6 Requisitos Se necesita un servidor web como Apache 1.3.x or 2.x, lighttpd, algún servidor web compatible con FastCGI con un módulo similar a mod_rewrite, o Nginx. Para desarrolllo, Rails permite utilizar Mongrel (un servidor HTTP ligero creado para soportar aplicaciones en Ruby y muy extendido entre aplicaciones en producción) o WEBrick (un pequeño servidor a medida de rendimiento limitado y no recomendado para su uso en producción). Rails soporta la extensión mod ruby de Apache (servidor web). Por otra parte se necesita una base de datos, como por ejemplo: MySQL, PostgreSQL, o SQLite, entre otros. (Wikipedia. Rails) http://es.wikipedia.org/w/index.php?title=Mongrel&action=edit&redlink=1 http://es.wikipedia.org/w/index.php?title=WEBrick&action=edit&redlink=1 http://nginx.net/ http://mongrel.rubyforge.org/ http://es.wikipedia.org/wiki/Lighttpd http://es.wikipedia.org/wiki/FastCGI http://es.wikipedia.org/w/index.php?title=Mod_ruby&action=edit&redlink=1 http://es.wikipedia.org/wiki/SQLite http://es.wikipedia.org/w/index.php?title=SGBDR&action=edit&redlink=1 http://es.wikipedia.org/w/index.php?title=SGBDR&action=edit&redlink=1 http://es.wikipedia.org/wiki/MySQL http://es.wikipedia.org/wiki/PostgreSQL http://es.wikipedia.org/wiki/SQLite http://es.wikipedia.org/wiki/DB2 http://es.wikipedia.org/wiki/Lighttpd http://es.wikipedia.org/wiki/FastCGI http://nginx.net/ http://mongrel.rubyforge.org/ http://es.wikipedia.org/w/index.php?title=WEBrick&action=edit&redlink=1 http://es.wikipedia.org/w/index.php?title=Mod_ruby&action=edit&redlink=1 http://es.wikipedia.org/wiki/MySQL http://es.wikipedia.org/wiki/PostgreSQL http://es.wikipedia.org/wiki/SQLite Capítulo II – Marco Referencial 35 4.7 Entorno de Trabajo Existen muchas alternativas para trabajar con Ruby on Rails, tanto libres y gratuitas como de pago. Tomado de (Wikipedia. Rails), a continuación se listan las principales:  Aptana: multiplataforma, nació como un plugin de eclipse para la edición y desarrollo web. Actualmente puedes instalarlo como plugins o autónomo de forma independiente. Las últimas versiones están muy bien integradas con Ruby on Rails.  Netbeans: uno de los más usados, libre y totalmente gratuito.  TextMate: sólo para Mac. Es el entorno más usado entre la comunidad Rails. Es pago pero su potencia y forma de trabajo favorece la producción y desarrollo con Ruby on Rails.  Gmate: un proyecto libre y gratuito para convertir Gedit, el editor de texto de escritorio Gnome de Linux, en un clon muy aproximado de Textmate. 4.8 Nociones básicas de instalación y estructura de aplicación La instalación y configuración de un ambiente Rails es muy sencilla. Ruby es distribuido por Ruby Org (Ruby lang org. Ruby Language.), mientras que Rails es distribuido a través de Ruby gemas por Ruby on Rails Org (Ruby on Rails org. Web development that doesn’t hurt. ). La instalación de Ruby se realiza mediante un wizard en un ambiente Windows y mediante paquetes bajo UNIX. Una vez instalado Ruby, se puede obtener la gema de Rails mediante un comando en una consola o Shell estándar (ruby install rails) o desde el sitio oficial mediante una descarga. Para generar una aplicación Rails se debe utilizar una consola mediante la sintaxis provista por ellos (rails hola_mundo, donde hola_mundo sería el nombre de la aplicación) o utilizar un IDE para facilitar este proceso. Rails viene por defecto con una estructura de archivos definida, para facilitar las convenciones y el manejo MVC que este sostiene. El sistema de archivos que genera Rails por defecto se muestra a continuación en la Figura 3, donde se define una clara separación entre archivos de configuración, aplicación, entre otros. http://es.wikipedia.org/wiki/Aptana http://es.wikipedia.org/wiki/Netbeans http://es.wikipedia.org/wiki/TextMate http://es.wikipedia.org/w/index.php?title=Gmate&action=edit&redlink=1 http://es.wikipedia.org/wiki/Gnome Capítulo II – Marco Referencial 36 Figura 3 Estructura por defecto de una Aplicación en Rails (Ruby on Rails org. Web development that doesn’t hurt. ) 4.9 Ruby 1.9.2 Ruby 1.9.2 es compatible 1.9.1, si exceptuamos los siguientes cambios:  Nuevos métodos.  Nueva API de comunicaciones (soporte para IPv6).  Nuevas codificaciones.  Clase aleatoria que soporta múltiples generadores de números aleatorios.  La clase Time es reemplazada. Se elimina el problema del año 2038.  Algunos cambios en las expresiones regulares(regexp).  $: no incluirá nunca más el directorio actual.  dl ha sido reescrito sobre libffi.  Nueva librería psych que contiene libyaml. Se puede usar esta librería en lugar de syck. 4.9.1 Plataformas soportadas Ruby 1.9 incluye cuatro niveles de soporte.  Soportado: se verifica que Ruby 1.9.2 trabaja perfectamente en ella. Es posible mantener 1.9.2 en esta. o Debian GNU/Linux 5.0 sobre IA32.  Sin garantía de resultados: se verifica que Ruby 1.9.2 trabaja adecuadamente en ellos. Se observa la posibilidad de mantener los mismos. o mswin32, x64-mswin64, mingw32 o MacOS X 10.5 (Intel) y 10.6 Capítulo II – Marco Referencial 37 o FreeBSD 6 y posteriores (amd64, IA32) o Solaris 10 o Symbian OS  Probables: Ruby 1.9.2 funciona correctamente en ellos con pequeñas modificaciones, no han sido verificados. Se aceptan parches con objeto de mejorar la integración en estos. o Otras distribuciones Linux. o Otras versiones de MacOS X. o cygwin o AIX 5 o Otros sistemas compatibles POSIX o BeOS (Haiku)  No soportadas: no se tienen garantías de que Ruby 1.9.2 funciones en estos. Se aceptan migraciones. o Cualquier sistema no listado anteriormente. La librería estándar se instala en /usr/local/lib/ruby/1.9.1. Este número de versión es “la librería de versión de compatibilidad”. Ruby 1.9.2 es altamente compatible con 1.9.1 por lo que esta librería se instala en el directorio indicado. (Ruby lang org. Ruby Language.) 4.10 Rails 3.0 Según Ruby on Rails org. Web development that doesn’t hurt. Rails 3.0 fue prolongado durante más de dos años, en su desarrollo trabajaron más de 1.600 colaboradores. La tercera generación de Rails ha realizado grandes cambios para Rails 3 como son los siguientes:  Active Record ha adoptado el motor de consulta ARel para hacer aplicaciones y realizar las consultas más coherente y componibles. Ésto hace que sea mucho más fácil construir consultas complejas sobre varias iteraciones. También retrasar la ejecución real de la consulta hasta que sea necesario. A continuación un ejemplo sencillo: users = User.where(:name => "david").limit(20) users = users.where("age > 29") # SELECT * FROM users # WHERE name = "david" AND age > 29 Capítulo II – Marco Referencial 38 # ORDER BY name # LIMIT 20 users.order(:name).each { |user| puts user.name }  Nuevo Router para Action Controller, cuando pasaron a un enfoque basado en REST para los controladores en Rails 2, realizaron un parche sobre la sintaxis del router, mientras esperaban el análisis detallado del experimento. Así lo hicieron y para Rails 3 han vuelto renovados y la sintaxis completamente a favor del estilo REST con menos ruido y más flexibilidad.  Nuevo Action Mailer, nació con una personalidad dividida de la mitad del modelo, la mitad del controlador. En los Rails 3, se tomó la decisión de hacer todo controlador. Esto significa que la sensación y la funcionalidad estará mucho más cerca a la acción del controlador. El nuevo Action Mailer, se basa en la parte superior de la nueva gema de correo también.  Administrar dependencias con Bundler, la gestión de todas las dependencias de una aplicación Rails ha sido durante mucho tiempo una molestia de remiendos. Tuvieron config.gem, Capistrano externos, las tareas de configuración personalizada rastrillo, y otras soluciones incompletas. Bundler limpia todo eso y permite especificar las bibliotecas, los marcos, y los plugins de los cuales depende la aplicación. Todas las aplicaciones Rails 3 nacen con una Gemfile para controlar todo.  XSS (protección por defecto), han tenido MERC protección con la firma de forma por un tiempo y de inyección SQL protección desde el principio, pero Rails 3 incluye la protección XSS.  Problemas de codificación, este problema está muy generalizado, y es causado por mezclar y hacer coincidir el contenido con diferentes codificaciones. En un sistema como Rails, el contenido proviene de la base de datos, plantillas, archivos de código fuente, y por parte del usuario. Ruby 1.9 provee las herramientas para eliminar estos problemas.  Active Model: Para todos los modelos, las validaciones, las devoluciones de llamada, entre otras cosas, han extraído varios componentes solicitados de Active Record en el nuevo marco de Active modelo. Esto permite que un ORM como Mongoid usar las validaciones de Active Record, las devoluciones de llamada, la serialización y soporte de i18n. Además, en la reescritura de Action Controller, han eliminado cualquier referencia directa a Active Record, la definición de un limpio y simple API que puede implementar ORM. Si se utiliza una API compatible con ORM (como http://github.com/mongoid/mongoid/blob/master/lib/mongoid/validations.rb#L11 Capítulo II – Marco Referencial 39 DataMapper, Sequel, o Mongoid), se pueden utilizar funciones como form_for, link_to y redirect_to con objetos de los ORM sin ningún trabajo adicional.  Official plugin APIs, también reescribieron Railties con el objetivo expreso de utilizar el nuevo plugin de la API de todos los marcos de Rails, como Active Record y Action Mailer. Esto significa que los plugins de Rails como los de DataMapper y RSpec tienen acceso a todos los de la integración como la compatibilidad integrada de Active Record y Test:: Unit. La nueva API Railtie permite modificar el incorporado en los generadores, añadir tareas rake, configurar las opciones por defecto de Rails, y especificar que el código se ejecute tan pronto, o tan tarde como se necesite.  Rewritten internos, han reescrito la parte interna de Action Pack y Railties, haciéndolos mucho más flexible y más fácil de extender. En lugar de una sola ActionController monolítica:: Base, Rails 3 expone una serie de módulos, cada uno con las API definidas, que se pueden mezclar y combinar para crear controladores de propósito especial para su propio uso.  Agnosticism with jQuery, rSpec, y Data Mapper, Agnosticismo con jQuery, RSpec y asignador de datos, el reescrito interno y el nuevo plugin API han llevado a cierto agnosticismo Rails 3 para todos los componentes del marco.  Instalación: se realiza mediante el siguiente commando gem install rails --version 3.0.0 . gem install rails --version 3.0.0 . También tienen un Rails v3.0.0 etiquetas y un -0- rama estable 3. Rails 3.0, ha sido diseñado para trabajar con Ruby 1.8.7, 1.9.2 Ruby y JRuby 1.5.2 +. http://github.com/datamapper/dm-rails/blob/master/lib/dm-rails/railtie.rb#L23 http://github.com/rspec/rspec-rails/blob/master/lib/rspec-rails.rb#L3 Capítulo III – Marco Metodológico 40 Capítulo III Marco Metodológico En el presente capítulo se describirá el método de desarrollo que se utilizará para llevar a cabo el diseño y la implementación del repositorio de datos para la Fundación Venezolana de Investigaciones Sismológicas (FUNVISIS); el cual se basó en el método ágil “Programación Extrema” (XP). Este se fundamenta en la simplicidad, la comunicación, la retroalimentación y la refactorización de código (Jeffries, Anderson, & Hendrickson, 2000). A continuación se especifican los aspectos más resaltantes del método XP, su adaptación para el desarrollo del sistema y un análisis general del levantamiento de información inicial. Programación Extrema La programación extrema es un método ligero, iterativo e incremental, el cual se utiliza para desarrollar software en pequeños grupos de programadores, donde la codificación es la actividad primordial sobre la documentación exhaustiva (Pressman, 2007). Mediante este método se libera rápidamente a producción un sistema sencillo y, de igual manera, se liberan continuamente nuevas versiones en periodos cortos. Tanto los jefes de proyecto, los clientes y programadores, son parte del equipo y están involucrados en el desarrollo del software. A continuación se destacan las características principales de este método de trabajo (Jeffries, Anderson, & Hendrickson, 2000).  Planificación incremental.  Programación en parejas.  Propiedad colectiva del código.  Comunicación constante con el cliente.  Desarrollo guiado en pruebas.  Continúa integración.  Estándares de codificación.  Refactorización de código. Adaptación del Proceso de Desarrollo XP A continuación se describe todo lo relacionado a la adaptación del método XP que se utilizará durante el desarrollo de un repositorio de datos para FUNVISIS. Capítulo III – Marco Metodológico 41 Iteraciones Las iteraciones simbolizan los cambios incrementales generados a través de las pruebas y retroalimentaciones repetidas, que a futuro dan como resultado un sistema estable pero en evolución. Las iteraciones pueden ser de dos tipos principalmente: por objetivo o por lapsos de tiempo. En nuestro caso las iteraciones se realizaran por objetivo, en donde, cada iteración comprende la puesta en marcha de un requerimiento funcional. Historias de Usuarios Las historias de usuario son un elemento primordial en el desarrollo y planificación dentro del método XP, permiten establecer un vínculo comunicacional entre el cliente y los miembros del equipo. Ayuda a priorizar y equilibrar las necesidades con la finalidad de mejorar la toma de decisiones, en cuanto a que se debe desarrollar primero. En lo que a nuestro caso se refiere, se trabajaran en función del tiempo (utilizando los días como unidad de medición) y con el formato de: un número que servirá de identificador, un nombre, el tipo (nueva o modificación/mejora), una prioridad (alta, media o baja) una estimación del tiempo y una breve descripción sobre la historia de usuario. El formato es el que a continuación se muestra: Número: - Nombre: - Prioridad: - Tipo: - Tiempo Estimado: - Descripción: - Cuadro 5 Formato de registro para una Historia de Usuario Por otra parte, en cuanto a los tipos de historias de usuario utilizadas, aunque el método XP plantea que solamente los requerimientos funcionales son reportados; se incluyeron como historias de usuario, tanto eventos (reuniones, documentos, etc.), como requisitos funcionales del sistema. Actores y Responsabilidades Los actores son todas las personas involucradas en el desarrollo del proyecto, los cuales a su vez cumplen distintos roles o responsabilidades según su importancia y nivel de participación. A continuación se destacan los roles existentes en el presente proceso de desarrollo: Capítulo III – Marco Metodológico 42  Programador: es el pilar fundamental del desarrollo en XP, tiene grandes habilidades en cuanto a la comunicación y al desarrollo en equipo. Adicionalmente, tiene la capacidad de poder abordar de forma simple y sencilla problemas complejos.  Cliente: es el encargado de proveer las historias de usuario, realizar las pruebas de aceptación, requisitos funcionales y no funcionales deseables en la aplicación y la toma de decisiones acertadas sobre las características esenciales de la aplicación.  Probador: su función se centra en realizar las pruebas de integración al sistema del código provisto por los programadores y de verificar el correcto funcionamiento de la aplicación. También realiza pruebas regulares y da mantenimiento siempre sustentando los resultados con informes precisos.  Rastreador: se encarga de dar seguimiento al proceso general del grupo, calculando el tiempo que toman sus tareas y el progreso general a las metas que se quieren alcanzar. Realiza estimaciones de tiempo y da la retroalimentación al equipo con el fin de mejorar el rendimiento. Programador Cliente Probador Rastreador Enrique Buono X X Andrés Sanoja X X Adriana Liendo X Cuadro 6 Esquema de actores y roles que desempeñan Actividades de XP El método XP está compuesto por cuatro actividades fundamentales las cuales están contenidas en cada una de las iteraciones del proceso de desarrollo. A continuación una breve descripción y cómo será la adaptación de cada una de ellas: Planificación La actividad de planificación comienza creando una serie de historias de usuario que describen las funcionalidades requeridas por el cliente, proporcionando a su vez una estimación del tiempo necesario para el desarrollo. Capítulo III – Marco Metodológico 43 En principio, se realizará un análisis global del estado actual de cada una de las necesidades de la Fundación Venezolana de Investigaciones Sismológicas (FUNVISIS) y del levantamiento de información que se llevó a cabo al inicio del desarrollo. De este surgirá una lista de historias de usuarios las cuales serán organizadas y desarrolladas en un conjunto de iteraciones. Se utilizará un esquema (cuadro 7) al inicio de cada iteración el cual contendrá el número de la iteración, una descripción, el número y nombre de las historias de usuarios a desarrollar, la fecha de comienzo de cada historia, la fecha de inicio y la fecha de fin de la iteración. Iteración - Descripción - Fecha Inicio / Fecha Fin - Número Fecha Historia Tipo - - - - Cuadro 7 Esquema de planificación de cada iteración Diseño El diseño en XP sigue de forma rigurosa el principio de simplicidad, prefiriendo siempre un diseño simple respecto de una presentación más compleja. Además el diseño debe ofrecer una guía de implementación para una historia de usuario determinada. Basados en las prácticas XP, en cada iteración de la presente etapa se realizarán prototipos mostrando las interfaces a desarrollar que permitan mejorar la comprensión de las historias planteadas. Codificación Este método sugiere la programación en pareja, la cual consiste en que dos programadores trabajen juntos en una estación de trabajo al momento de crear el código de una historia de usuario, siguiendo en todo momento los estándares de programación, lo cual es otro aspecto de gran importancia en el método XP. Sin embargo, para el desarrollo de este proyecto no se utilizara la programación en pareja. Capítulo III – Marco Metodológico 44 El método XP también recomienda realizar frecuentes integraciones de código entre los grupos de trabajo, de tal forma que no se produzcan problemas de compatibilidad, ni de interfaz. En este sentido se adoptará la programación individual para desarrollar el código de las principales historias de usuario y siempre trabajando en una misma iteración. Aquellas historias de usuario que no sean de mayor complejidad y no representen una funcionalidad primordial en el sistema serán desarrolladas y luego integradas a dicho sistema. En esta etapa de codificación, se realizará la instalación y configuraciones del ambiente que sean necesarias, además de toda la codificación de las historias de usuario de cada una de las iteraciones. Con respecto a los estándares de programación se mantendrán los siguientes:  Desarrollar de forma modular el sistema.  Documentar cada método creado para un fácil entendimiento.  Cada método debe ser definido en minúscula, si son varios nombres estarán separados por el símbolo underscore ( _ ), si el método retorno un lógico (boolean) debe terminar con el símbolo de interrogación ( ? ).  Con respecto a la nomenclatura y variables, las palabras que tengan ñ se sustituirá por n, si tiene acentos se omiten y las variables con dos o más palabras estarán separadas por el símbolo underscore ( _ ).  Para la base de datos, los nombres de las tablas se declaran siempre en minúscula y en singular. En cuanto a las relaciones se mantiene las convenciones de Rails, nombre_tabla_nombre_campo. Pruebas El método XP establece realizar pruebas de todo aquello que se codifique, recomienda no dejar ninguna característica del sistema sin que haya sido probada. Dicho método propone pruebas unitarias (unit test), pruebas del programador (programmer test) y pruebas de aceptación (customer test), estas últimas son especificadas por el cliente y se enfocan en las características generales y la funcionalidad del sistema, elementos visibles y revisables por el cliente (Anderson & Hendrickson, 2000). Con respecto a este punto se realizarán pruebas del programador y pruebas de aceptación. Para las pruebas del programador se empleará una técnica simple que consistirá en evaluar parámetros de entrada seleccionado por los programadores y observar las salidas constatando que cumplan con lo esperado. Las pruebas de aceptación Capítulo III – Marco Metodológico 45 serán realizadas por los clientes, con el fin de comprobar que sus requerimientos hayan sido cumplidos satisfactoriamente. Además se utilizará un formato para registrar cada una de las pruebas que se realicen. Ver cuadro 8. Código Historias de Usuario involucradas Descripción del Caso de Prueba Resultado Esperado Resultado Obtenido - - - - - Cuadro 8 Formato de registro de Prueba de Aceptación Por lo general en cada iteración se desarrollarán cada una de las actividades mencionadas anteriormente. Sin embargo, en las primeras iteraciones puede darse el caso de no se desarrollen todas las actividades, debido a las tareas que involucran determinadas historias de usuario durante una iteración. Visión general de la Solución La visión general de la solución, consiste en la documentación de toda la labor llevada a cabo durante el levantamiento de información inicial, proceso que involucró tanto a nuestro tutor Andrés Sanoja como a la Ing. Adriana Liendo como únicos y principales clientes. A partir de todo esto, se obtuvo lo necesario para el desarrollo del repositorio de datos para la Fundación Venezolana de Investigaciones Sismológicas (FUNVISIS), las cuales estarían sustentadas en las historias de usuario provistas en reuniones con los clientes. A continuación se especifican las historias de usuario obtenidas: Historias de Usuario Número: 1 Nombre: Reunión inicial con el profesor Andrés Sanoja con base a la definición de la propuesta de tesis y el alcance de la misma Prioridad: Alta Tipo: Nueva Tiempo Estimado: 1 día Descripción: discutir el proyecto, el alcance que el mismo posee, como debe estar estructurado y cuál es el método de desarrollo a implementar. Capítulo III – Marco Metodológico 46 Número: 2 Nombre: Definir el índice a ser desarrollado en el TEG. Prioridad: Media Tipo: Nueva Tiempo Estimado: 7 días Descripción: establecer el índice del trabajo especial de grado, especificando el contenido a desarrollar como bases teóricas, así como las páginas dedicadas a cada uno de dichos tópicos. Número: 3 Nombre: Revisar y modificar el contenido del TEG correspondiente con los capítulos I, II y III. Prioridad: Alta Tipo: Modificación / Mejora Tiempo Estimado: 28 días Descripción: revisión de los capítulos I, II y III respectivamente del TEG. De igual manera se establecieron las respectivas observaciones a ser aplicadas y se estableció con fecha enero de 2011 revisar dichas observaciones, así como el fijar una reunión con el cliente Adriana Liendo a fin de poder establecer los requerimientos funcionales de la Fundación Venezolana de Investigaciones Sismológicas (FUNVISIS). Número: 4 Nombre: Revisar las correcciones de los capítulos I, II y III y modificar el contenido del TEG correspondiente al capítulo IV. Prioridad: Alta Tipo: Modificación / Mejora Tiempo Estimado: 1 día Descripción: revisión de las correcciones realizadas a los capítulos I, II y III respectivamente del TEG. De igual manera se estableció que el plan de iteraciones sería de 10 iteraciones. Por otra parte se fijo una reunión con el cliente Adriana Liendo para el día 01/02/2011 en FUNVISIS. Capítulo III – Marco Metodológico 47 Número: 5 Nombre: Reunión con el especialista Sr. Andrés Singer, explicando como es y cómo debe ser el manejo de la información actualmente en la Fundación Venezolana de Investigaciones Sismológicas. Prioridad: Alta Tipo: Nueva Tiempo Estimado: 1 día Descripción: el especialista Andrés Singer en esta reunión, expreso que la separación de la información en la fundación debía ser en 3 renglones como lo son: técnicas, sociales y científicas respectivamente. Por otra parte, destaco que cuentan con aplicaciones tales como una catalogo de inventarios sismológicos, así mismo poseen una aplicación dedicada al renglón social, denominada estudios y desastres. Dicha aplicación maneja eventos tecnológicos, movimientos en masa, hidrometeoro lógico y sísmico. De igual forma poseen un centro de documentación e información donde las vistas del mismo son realizadas mediante la aplicación ABCD, entre otras aplicaciones. Número: 6 Nombre: Asistir a charla divulgativa con la Jefa del departamento de sismología Sra. Gloria Romero, donde describe el catálogo sismológico de FUNVISIS. Prioridad: Alta Tipo: Nueva Tiempo Estimado: 1 día Descripción: la Msc. Gloria romero expreso, que la finalidad del catálogo sismológico es lograr ver las amenazas sísmicas y los riesgos en una región especifica. De igual manera destaco que existe una carencia en cuanto a que el catalogo no puede ser consultado. De dicha reunión, se evaluó el hecho de llevar estos datos generados por el SEISAN a las dimensiones correspondientes en el datawarehouse a ser desarrollado. Capítulo III – Marco Metodológico 48 Número: 7 Nombre: Establecer con la Jefa del departamento de informática Ing. Adriana Liendo y el Prof. Andrés Sanoja las actividades a ser realizadas en el desarrollo del TEG. Prioridad: Alta Tipo: Nueva Tiempo Estimado: 1 día Descripción: se especifico como es el directorio de archivos de la aplicación SEISAN, y de cómo a través de un middleware se realizaría la carga de los datos desde dicha aplicación hacia el datawarehouse. De igual manera se describió el manejador de bases de datos utilizado por la aplicación de estudios y desastres, a fin de establecer la manera en la cual sería cargados los datos desde dicho manejador de bases de datos hacia el datawarehouse. Para luego, finalmente definir las actividades a ser realizadas a lo largo del TEG. Número: 8 Nombre: Establecer con el Prof. Andrés Sanoja el plan de iteración tentativo para el TEG Prioridad: Alta Tipo: Nueva Tiempo Estimado: 1 día Descripción: el día de hoy se llevo a cabo una reunión con el Prof. Andrés Sanoja para definir el plan de iteración tentativo para el TEG; estableciendo que el mismo estaría comprendido por 12 semanas. Número: 9 Nombre: Revisar la estructura de directorios de la aplicación SEISAN Prioridad: Alta Tipo: Nueva Tiempo Estimado: 1 día Descripción: se instaló la aplicación SEISAN y se revisaron en compañía de la jefa del departamento de informática Ing. Adriana Liendo, los directorios de la misma. Capítulo III – Marco Metodológico 49 Número: 10 Nombre: Entrevistar a la Jefa del Departamento de Sismología Msc. Gloria Romero con la finalidad de establecer las preguntas referentes a los archivos en formato SEISAN, que se quiere sean respondidas con el datawarehouse. Prioridad: Alta Tipo: Nueva Tiempo Estimado: 2 días Descripción: se realizo la entrevista con la Msc. Gloria Romero obteniendo como resultados las siguientes preguntas que necesitan ser respondidas con la implementación del datawarehouse: 1. ¿Qué eventos sísmicos han ocurrido en una fecha específica? 2. ¿Qué eventos sísmicos han ocurrido en un periodo de tiempo? 3. ¿Qué eventos sísmicos han ocurrido con una longitud entre un valor x y un valor y y una latitud entre un valor z y un valor w? 4. ¿Qué eventos sísmicos han ocurrido con una magnitud mayor a un valor x? 5. ¿Qué eventos sísmicos han sido registrados con un RMS (Root-Mean-Square in Seconds) ubicado entre un valor x y un valor y? 6. ¿Qué eventos sísmicos han sido registrados con un error en la medición de la latitud ubicado entre un valor x y un valor y? 7. ¿Qué eventos sísmicos han sido registrados con un error en la medición de la de longitud ubicado entre un valor x y un valor y? 8. ¿Qué eventos sísmicos han sido registrados con comentarios sobre los mismos? 9. ¿Qué eventos sísmicos han sido distantes, locales o regionales? Número: 11 Nombre: Revisar los archivos de formato SEISAN Prioridad: Alta Tipo: Nueva Tiempo Estimado: 14 días Descripción: se realizó el estudio de cada una de las diferentes tipos de línea de los archivos SEISAN, a fin de poder realizar el middleware que permita la carga de la información desde los archivos hacia el datawarehouse. Capítulo III – Marco Metodológico 50 Número: 12 Nombre: Revisar el modelo de la base de datos de la aplicación estudios y desastres Prioridad: Alta Tipo: Nueva Tiempo Estimado: 14 días Descripción: se realizo la revisión y análisis del manual entregado por la urbanista Ketty Mendes, en donde se encontraba la descripción de cada una de las tablas de la base de datos. Con la finalidad de tomar los datos necesarios para luego realizar el diseño de las dimensiones correspondientes al datawarehouse. Número: 13 Nombre: Entrevistar a la Urbanista Ketty Mendes con la finalidad de establecer las preguntas referentes a la base de datos de la aplicación estudios y desastres, que se quiere sean respondidas con el datawarehouse Prioridad: Alta Tipo: Nueva Tiempo Estimado: 2 días Descripción: se realizo la entrevista con la Urbanista Ketty Mendes, obteniendo como resultado un informe en el cual se especifican las distintas preguntas que quieren ser respondidas, en total 23, las cuales se encuentran disponibles en el apéndice 4. Número: 14 Nombre: Instalar y configurar el sistema manejador de base de datos columnar Monet DB, así como crear el esquema del datawarehouse en dicho manejador. Prioridad: Alta Tipo: Nueva Tiempo Estimado: 7 días Descripción: realizar la instalación del sistema manejador de base de datos columnar Monet DB en el sistema operativo Ubuntu 10.04, de igual forma se configuro el cliente grafico Squirrel para poder observar la estructura de la base de datos. Seguidamente se procedió a crear el esquema “funvisis” del datawarehouse, dentro del cual posteriormente serán definidas las dimensiones y la o las tablas de hechos necesarias para dar cumplimiento a los requerimientos establecidos. Capítulo III – Marco Metodológico 51 Número: 15 Nombre: Diseñar e implementar las dimensiones correspondientes con los archivos de formato SEISAN Prioridad: Alta Tipo: Nueva Tiempo Estimado: 7 días Descripción: realizar el diseño y seguido a esto la implementación de las dimensiones correspondientes con los archivos del SEISAN en el datawarehouse, destacando que las dimensiones fueron creadas tomando en cuenta cada uno de los diferentes tipos de línea que poseen dichos archivos. Número: 16 Nombre: Diseñar e implementar la tabla de hechos “fact_evento” referente a los archivos de formato SEISAN Prioridad: Alta Tipo: Nueva Tiempo Estimado: 7 días Descripción: realizar el diseño y seguido a esto la implementación de la tabla de hechos eventos, con base a las preguntas que se quiere sean respondidas por parte de la jefa del departamento de sismología Msc. Gloria Romero, con las cuales se determino la granularidad y los hechos a incluir en dicha tabla. Número: 17 Nombre: Diseñar e implementar las dimensiones correspondientes con la aplicación estudios y desastres Prioridad: Alta Tipo: Nueva Tiempo Estimado: 7 días Descripción: realizar el diseño y seguido a esto la implementación de las dimensiones correspondientes con la aplicación estudios y desastres, con el fin de integrar toda la información tanto de esta aplicación, como de los archivos en formato SEISAN en el datawarehouse. Capítulo III – Marco Metodológico 52 Número: 18 Nombre: Diseñar e implementar la tabla de hechos “fact_estudios_desastres” referente a la aplicación estudios y desastres Prioridad: Alta Tipo: Nueva Tiempo Estimado: 7 días Descripción: realizar el diseño y seguido a esto la implementación de la tabla de hechos estudios y desastres con base a las preguntas que se quiere sean respondidas por parte de la urbanista Ketty Mendes, con las cuales se determino la granularidad y los hechos a incluir en dicha tabla. Número: 19 Nombre: Modificar las dimensiones y la tabla de hechos “fact_evento” del datawarehouse con el fin de poder unificar los datos tanto de la aplicación estudios y desastres como de los archivos en formato SEISAN Prioridad: Alta Tipo: Modificación / Mejora Tiempo Estimado: 2 días Descripción: realizar modificaciones sobre dimensiones como dim_comentarios_archivos_ondas ampliando la longitud de los campos comentarios a varchar(3000) por la cantidad de comentarios inmersos dentro de un archivo en formato SEISAN y archivo_onda a varchar(500), por las mismas razones descritas anteriormente; de igual manera se modificará la tabla de hechos, con la inclusión de los errores pre calculados de las medidas encontradas en los archivos SEISAN, entre otras modificaciones. Capítulo III – Marco Metodológico 53 Número: 20 Nombre: Modificar la dimensión “dim_estacion” y crear de la tabla de hechos “fact_estacion” Prioridad: Alta Tipo: Modificación / Mejora Tiempo Estimado: 2 días Descripción: modificar la dimensión “dim_estacion” por el hecho de que existen dos granos distintos encontrados en la tabla de hechos “fact_evento”, por lo cual se creara una tabla de hechos “fact_estacion” con el grano de las estaciones, en donde atributos resaltantes de esta nueva tabla de hechos son: duración, amplitud y periodo respectivamente. Además de modificar la dimensión estación, dejándola con todos los atributos descriptivos de una estación. Número: 21 Nombre: Crear la dimensión degenerada denominada “id_evento” Prioridad: Alta Tipo: Nueva Tiempo Estimado: 2 días Descripción: crear la dimensión degenerada id_evento e incluir en las tres tablas de hechos existentes, con el fin de poder relacionar la información dentro del datawarehouse. Número: 22 Nombre: Modificar el valor por defecto de los atributos de todas las dimensiones del datawarehouse. Prioridad: Alta Tipo: Modificación / Mejora Tiempo Estimado: 1 día Descripción: modificar los valores por defectos de todas las dimensiones, colocándolos por defecto en “null” a excepción de los atributos estrictamente necesarios para el almacenamiento de la información; esto debido a que el datawarehouse almacenará eventos de formatos de archivos SEISAN, eventos de la aplicación estudios y desastres, e incluso eventos cruzados entre las dos fuentes de datos descritas anteriormente. Capítulo III – Marco Metodológico 54 Número: 23 Nombre: Crear el modelo de datos del datawarehouse Prioridad: Alta Tipo: Nueva Tiempo Estimado: 1 día Descripción: crear el modelo de datos del datawarehouse con las dimensiones y tablas de hechos correspondientes. Número: 24 Nombre: Crear el archivo en formato SQL, con la estructura del datawarehouse. Prioridad: Alta Tipo: Nueva Tiempo Estimado: 1 día Descripción: crear el archivo en formato SQL con la estructura del datawarehouse, para de esta manera tener un respaldo de dicho repositorio. Número: 25 Nombre: Crear el archivo en formato SQL, con las inserciones de los datos de prueba para validar el diseño del datawarehouse. Prioridad: Alta Tipo: Nueva Tiempo Estimado: 2 días Descripción: crear el archivo en formato SQL con las inserciones correspondientes con un evento sismológico registrado tanto por la aplicación SEISAN, como por la aplicación de estudios y desastres. Con dicha carga se logró validar el correcto diseño del datawarehouse; obteniendo como resultado la inserción efectiva de los datos de prueba. Número: 26 Nombre: Generar consultas en lenguaje SQL con el fin de validar el diseño del datawarehouse. Prioridad: Alta Tipo: Nueva Tiempo Estimado: 2 días Descripción: generar las consultas en lenguaje SQL necesarias para validar que los datos inmersos en el datawarehouse, la cual fue provista por un evento sísmico registrado tanto en la aplicación SEISAN, como en la aplicación de estudios y desastres, que se encontraba unificada en el repositorio. El resultado obtenido fue el esperado, las consultas fueron realizadas con éxito. Capítulo III – Marco Metodológico 55 Número: 27 Nombre: Instalar el ambiente de desarrollo web, tanto para crear el middleware, como para crear la aplicación web mediante la cual serán realizadas las consultas sobre el datawarehouse. Prioridad: Alta Tipo: Nueva Tiempo Estimado: 2 días Descripción: instalar el lenguaje de programación Ruby en su versión 1.9.2, mediante el cual se crearan los archivos que permitan llevar la información desde las aplicaciones SEISAN (Seismic Analysis System) y estudios y desastres hacia el datawarehouse. De igual forma instalar el framework para aplicaciones web Rails en su versión 3.0.6, framework con el cual se creara la aplicación web, más orientada hacia un administrador de bases de datos, donde los usuarios podrán ver los resultados de las consultas que estos realicen sobre dicho repositorio. Número: 28 Nombre: Instalar y Configurar el cliente “ruby-monetdb-client” que permitirá la conexión entre el lenguaje de programación Ruby y el sistema manejador de bases de datos columnar MonetDB. Prioridad: Alta Tipo: Nueva Tiempo Estimado: 2 días Descripción: instalar y configurar el cliente “ruby-monetdb-client” mediante el gestor de paquetes synaptic, cliente que permite realizar la conexión entre el lenguaje Ruby y el sistema manejador de bases de datos MonetDB tanto via SQL, como por el uso de la clase activerecord. Número: 29 Nombre: Crear el middleware en el lenguaje de programación Ruby que permita la carga de los datos de las aplicaciones ya existentes hacia el datawarehouse. Prioridad: Alta Tipo: Nueva Tiempo Estimado: 21 días Descripción: crear el middleware mediante el cual se examinan todas las líneas de cada uno de los archivos contenidos en cada uno de los subdirectorios de la aplicación SEISAN, además de tomas la información contenida en la aplicación estudios y desastres, para luego dicha información ser vaciada en el datawarehouse y a su vez modificar el archivo “log.txt” correspondiente con dichas inserciones. Capítulo III – Marco Metodológico 56 Número: 30 Nombre: Crear los TRIGGERS (procedimientos almacenados en la base de datos) en el datawarehouse. Prioridad: Alta Tipo: Modificación / Mejora Tiempo Estimado: 7 días Descripción: crear los TRIGGERS en el datawarehouse por medio del cliente grafico Squirrel, necesarios para unificar los datos existentes en el datawarehouse y mantener la integridad de los datos en el mismo. Número: 31 Nombre: Crear la aplicación web que permita consultar la información registrada en el datawarehouse. Prioridad: Alta Tipo: Nueva Tiempo Estimado: 14 días Descripción: crear la aplicación web, desarrollada en el framework de aplicaciones web Rails en su versión 3.0.6, dicha aplicación más orientada hacia un administrador de bases de datos, donde el usuario podrá visualizar en base a un formulario de consulta, el resultado de las mismas aplicadas al datawarehouse. Número: 32 Nombre: Creación de Videos que faciliten la demostración del funcionamiento de la aplicación web de consulta en conjunto con el comportamiento del datawarehouse. Prioridad: Alta Tipo: Nueva Tiempo Estimado: 2 días Descripción: Generación de un conjunto de videos a modo de guía, con el propósito de brindarle a los usuarios la posibilidad de consultar la información registrada en el datawarehouse. Metáfora Con el propósito de poder brindarles a los usuarios (FUNVISIS), la posibilidad de obtener un datawarehouse para el manejo de la información del catalogo sismológico SEISAN y de la aplicación estudios y desastres. Capítulo III – Marco Metodológico 57 Básicamente se ofrece la funcionalidad de realizar consultas sobre el datawarehouse, así como de tener toda la información de las dos aplicaciones descritas anteriormente dentro del mismo. Esto llevado a cabo mediante un middleware entre las dos aplicaciones y el datawarehouse, que se encuentra desarrollado en el sistema manejador de base de datos Monet DB . Ver figura 4 Capítulo III – Marco Metodológico 58 Archivos SEISAN BD Estudios y Desastres Modulo de Carga de Datos Figura 4 Metáfora del Sistema Funvisis Internet Datawarehouse FUNVISIS Aplicación Web Capítulo IV – Marco Aplicativo 59 Capítulo 4 Marco Aplicativo Plan de Iteración Este proyecto de trabajo especial de grado al estar orientado a un método de desarrollo ágil, cuenta con una serie de historias de usuario distribuidas en un conjunto de iteraciones. Dichas historias están agrupadas de forma tal de alcanzar un objetivo en cada iteración, bajo unos criterios de codificación y con un grupo de casos de prueba, con el fin de establecer el ritmo de trabajo a seguir. El proyecto y su desarrollo, comprende un conjunto de 9 (nueve) iteraciones, estimadas en un tiempo de cumplimiento de 1 a 4 semanas cada una y su culminación implica la puesta en marcha de un requerimiento funcional. El periodo para llevar a cabo dicho proyecto y su documentación correspondiente fue desde el 26 de Noviembre de 2010 hasta el 08 de Mayo de 2011. Capítulo IV – Marco Aplicativo 60 Iteración 0  Planificación Iteración 0 Descripción Levantamiento de Requerimientos y construcción del documento del TEG Fecha Inicio / Fecha Fin 26-11-2010 / 21-01-2011 Númer o Fecha Historia Tipo 1 26-11-2010 Reunión inicial con el profesor Andrés Sanoja con base a la definición de la propuesta de tesis y el alcance de la misma Nueva 2 09-12-2010 Definir el índice a ser desarrollado en el TEG. Nueva 3 16-12-2010 Revisar y modificar el contenido del TEG correspondiente con los capítulos I, II y III. Modificación/ Mejora 4 21-01-2011 Revisar las correcciones de los capítulos I, II y III y modificar el contenido del TEG correspondiente al capítulo IV. Modificación/ Mejora  Codificación En la presente iteración, la etapa de codificación correspondió con el desarrollo del contenido de los capítulos I, II y III del Trabajo Especial de Grado (TEG) con base al levantamiento de requerimientos realizado, así como la definición de los lineamientos a seguir en el desarrollo del contenido del capítulo IV del TEG. Capítulo IV – Marco Aplicativo 61  Pruebas Las pruebas realizadas en la presente iteración, consistieron en verificar el contenido desarrollado para los capítulos I, II, III y IV respectivamente del Trabajo Especial de Grado (TEG). Iteración 1  Planificación Iteración 1 Descripción Definición del área de desarrollo y de las actividades a ser realizadas en el TEG Fecha Inicio / Fecha Fin 01/02/2011 / 14/02/2011 Númer o Fecha Historia Tipo 5 01/02/2011 Reunión con el especialista Sr. Andrés Singer, explicando como es y cómo debe ser el manejo de la información actualmente en la Fundación Venezolana de Investigaciones Sismológicas (FUNVISIS). Nueva 6 10/02/2011 Asistir a charla divulgativa con la Jefa del departamento de sismología Msc. Gloria Romero, donde describe el catálogo sismológico de FUNVISIS. Nueva 7 11/02/2011 Establecer con la Jefa del departamento de informática Ing. Adriana Liendo y el Prof. Andrés Sanoja las actividades a ser realizadas en el desarrollo del TEG. Nueva 8 14/02/2011 Establecer con el Prof. Andrés Sanoja el plan de iteración para el TEG Nueva Capítulo IV – Marco Aplicativo 62  Codificación En la presente iteración, la etapa de codificación correspondió tanto con la definición del área de desarrollo en la cual se encuentra enmarcado el presente TEG, así como con el establecimiento de las actividades a ser realizadas para cumplir con los requerimientos definidos por la Fundación Venezolana de Investigaciones Sismológicas.  Pruebas Las pruebas realizadas en esta iteración, consistieron en definir el plan de iteraciones a seguir en el TEG, donde en cada iteración se establecieron todas y cada una de las actividades a ser realizadas para cumplir con los requerimientos establecidos; dichos requerimientos fueron establecidos, con base a la información suministrada por la Jefa del Departamento de Informática Ing. Adriana Liendo. Iteración 2  Planificación Iteración 2 Descripción Levantamiento de Requerimientos funcionales con base a la aplicación SEISAN Fecha Inicio / Fecha Fin 16/02/2011 / 08/03/2011 Númer o Fecha Historia Tipo 9 16/02/2011 Revisar la estructura de directorios de la aplicación SEISAN Nueva 10 23/02/2011 Entrevistar a la Jefa del departamento de Sismología Msc. Gloria Romero con la finalidad de establecer las preguntas referentes a los archivos en formato SEISAN, que se quiere sean respondidas con el datawarehouse. Nueva 11 02/03/2011 Revisar los archivos de formato SEISAN Nueva Capítulo IV – Marco Aplicativo 63  Codificación En la presente iteración, la etapa de codificación se basó en la instalación de la aplicación SEISAN (Seismic Analysis System), con la finalidad de analizar la estructura de directorios de la misma, dicha aplicación se puede observar en la figura 5. Figura 5 Aplicación SEISAN (Seismic Analysis System)  Pruebas Las pruebas realizadas en esta iteración, consistieron en entrevistar a la Jefa del Departamento de Sismología, Msc. Gloria Romero, con la finalidad de entender mejor el formato de los archivos SEISAN y obtener a su vez, las preguntas que se quiere sean respondidas con la implementación del datawarehouse. De igual forma se analizaron cada una de las líneas inmersas dentro de los archivos en formato SEISAN, para poder llevar dicha información al datawarehouse; estas líneas descritas anteriormente, se pueden apreciar en la figura 6, la cual contiene un fragmento correspondiente con el archivo “select.out” generado por la aplicación. Capítulo IV – Marco Aplicativo 64 Figura 6 Fragmento del Archivo "select.out" generado por la aplicación SEISAN Es importante destacar que la descripción de cada una de las líneas encontradas en estos archivos en formato SEISAN, se encuentran descritas en el manual de referencia de la aplicación SEISAN; En la figura 7 puede apreciarse la descripción para el tipo de línea 1, destacando que el tipo de línea viene dado por el valor encontrado en la última columna de una línea. Capítulo IV – Marco Aplicativo 65 Figura 7 Descripción del formato de las líneas tipo 1 de los archivos en formato SEISAN Capítulo IV – Marco Aplicativo 66 Iteración 3  Planificación Iteración 3 Descripción Levantamiento de Requerimientos funcionales con base a la aplicación estudios y desastres e instalación del ambiente de desarrollo para el datawarehouse Fecha Inicio / Fecha Fin 09/03/2011 / 22/03/2011 Númer o Fecha Historia Tipo 12 09/03/2011 Revisar el modelo de la base de datos de la aplicación Estudio y Desastres Nueva 13 16/03/2011 Entrevistar a la Urbanista Ketty Mendes con la finalidad de establecer las preguntas referentes a la base de datos de la aplicación estudios y desastres, que se quiere sean respondidas con el datawarehouse Nueva 14 17/03/2011 Instalar y configurar el sistema manejador de base de datos columnar Monet DB, así como crear el esquema del datawarehouse en dicho manejador. Nueva  Codificación En la presente iteración, la etapa de codificación se basó en la instalación y configuración tanto del sistema manejador de bases de datos columnar MonetDB, como del cliente grafico Squirrel, el cual permite visualizar la estructura de la base de datos y ejecutar sentencias en lenguaje SQL. Capítulo IV – Marco Aplicativo 67 En primer lugar, se instaló el sistema manejador de bases de datos MonetDB siguiendo las instrucciones proporcionadas por la página oficial de dicho manejador, las cuales se pueden apreciar en la figura 8. Figura 8 Instrucciones para la Instalación del Sistema manejador de bases de datos columnar MonetDB Capítulo IV – Marco Aplicativo 68 Seguidamente se instaló el cliente gráfico Squirrel, el cual permite visualizar la estructura de la base de datos y ejecutar sentencias en lenguaje SQL. Obteniendo como resultado la interfaz presentada en la figura 9. Figura 9 Interfaz del Cliente Gráfico Squirrel Posterior a la instalación se procedió a configurar el controlador necesario para realizar la conexión con el sistema manejador de bases de datos columnar MonetDB; como se puede apreciar en la figura 10. Capítulo IV – Marco Aplicativo 69 Figura 10 Configuración del driver para realizar la conexión entre el Cliente Gráfico Squirrel y MonetDB Finalmente, terminando con la configuración del cliente gráfico Squirrel, se creó el alias con el cual se va a comunicar el sistema manejador de bases de datos con dicho cliente, dicha configuración se puede observar en la figura 11. Figura 11 Creación del Alias MonetDB - Test Por otra parte, se creó el esquema de la base de datos “funvisis” en el cual será desarrollado el datawarehouse; dicho esquema se creó con la siguiente codificación realizada en la consola del sistema operativo y cuyo resultado se puede apreciar en la figura 12, en la cual se muestra dicho esquema desde el cliente grafico Squirrel. Capítulo IV – Marco Aplicativo 70 sudo mclient -l sql -d test CREATE USER "funvisis" WITH PASSWORD 'funvisis' NAME 'funvisis Explorer' SCHEMA "sys"; CREATE SCHEMA "funvisis" AUTHORIZATION "funvisis"; ALTER USER "funvisis" SET SCHEMA "funvisis"; Figura 12 Visualización del Esquema "funvisis" del manejador de bases de datos MonetDB  Pruebas Las pruebas realizadas en esta iteración consistieron en la verificación del correcto funcionamiento del sistema manejador de bases de datos columnar MonetDB, en cuanto al levantamiento de su servidor y a la verificación del estatus de las bases de datos contenidas en el mismo. Dichas verificaciones se realizaron con éxito y se pueden apreciar en las figuras 13 y 14 respectivamente. Capítulo IV – Marco Aplicativo 71 Figura 13 Levantamiento del Servidor de MonetDB Figura 14 Verificación del Status de MonetDB De igual forma en esta etapa de pruebas, se realizó el análisis sobre la estructura de archivos de la aplicación estudios y desastres, para de esta manera entender el funcionamiento de dicha aplicación y detallar la manera en la cual es guardada la información, para luego llevar dicha información al datawarehouse. La estructura de archivos anteriormente mencionada se puede apreciar en la figura 15. Capítulo IV – Marco Aplicativo 72 Figura 15 Estructura de Archivos de la aplicación estudios y desastres Finalmente, las pruebas de esta iteración concluyeron con el análisis sobre el modelo de la base de datos de la aplicación estudios y desastres, con la finalidad de obtener los datos necesarios para realizar el diseño y la implementación de las dimensiones y tabla de hechos respectiva en el datawarehouse. El modelo de la base de datos se puede apreciar en la figura 16. Cabe destacar que las pruebas referidas a la verificación de la correcta instalación del cliente gráfico Squirrel, fueron validadas al momento de realizar la configuración del mismo con el sistema manejador de bases de datos columnar MonetDB, en la etapa de codificación. Capítulo IV – Marco Aplicativo 73 Figura 16 Modelo de la Base de datos de la Aplicación estudios y desastres Capítulo IV – Marco Aplicativo 74 Iteración 4  Planificación Iteración 4 Descripción Diseño e implementación del datawarehouse Fecha Inicio / Fecha Fin 23/03/2011 / 06/04/2011 Númer o Fecha Historia Tipo 15 23/03/2011 Diseñar e implementar las dimensiones correspondientes con los archivos de formato SEISAN Nueva 16 28/03/2011 Diseñar e implementar la tabla de hechos “fact_evento” referente a los archivos de formato SEISAN Nueva 17 01/04/2011 Diseñar e implementar las dimensiones correspondientes con la aplicación estudios y desastres Nueva 18 06/04/2011 Diseñar e implementar la tabla de hechos “fact_estudios_desastres” referente a la aplicación estudios y desastres Nueva  Diseño En esta iteración se lleva a cabo el desarrollo de las dimensiones y de la tabla de hechos correspondiente tanto de la aplicación SEISAN, como de la aplicación estudios y desastres. Con base a la información obtenida de la iteración anterior. En primer lugar, se llevó a cabo el diseño de las dimensiones con base al formato de Archivos SEISAN, se pueden apreciar en la figura 17, dentro de las cuales se registran los 8 diferentes tipos de líneas que poseen dichos archivos actualmente. Capítulo IV – Marco Aplicativo 75 Figura 17 Diseño de las dimensiones con base al formato de Archivos SEISAN Capítulo IV – Marco Aplicativo 76 Seguidamente, se procedió a diseñar la tabla de hechos correspondiente con la aplicación SEISAN, de donde se destaca que la granularidad de la misma viene dada por las mediciones de duración, amplitud, periodo, latitud y longitud de un evento sismológico. Ver figura 18. Figura 18 Diseño de la tabla de hechos correspondiente con la aplicación SEISAN Posteriormente, se llevó a cabo el diseño de las dimensiones correspondientes con la aplicación estudios y desastres, se pueden apreciar en la figura 19, dimensiones que hacen referencia tanto a la ubicación del evento registrado, como de la información del tipo al cual pertenece; Destacando que dicha aplicación maneja eventos del tipo tecnológico, hidrometeorológico, movimiento en masa y sísmico respectivamente. Capítulo IV – Marco Aplicativo 77 Figura 19 Diseño de las dimensiones correspondientes con la aplicación estudios y desastres Finalmente en esta etapa, se diseña la tabla de hechos correspondiente con la aplicación estudios y desastres; destacando que en la misma la granularidad se ve reflejada en el grado de afectación que un evento de los tipos descritos anteriormente genere. Ver figura 20. Capítulo IV – Marco Aplicativo 78 Figura 20 Diseño de la tabla de hechos correspondiente con la aplicación estudios y desastres Capítulo IV – Marco Aplicativo 79  Codificación En la presente iteración, la etapa de codificación se basó en la implementación de las dimensiones y tablas de hechos descritas en la etapa de diseño, mediante lenguaje SQL en el datawarehouse. En primera instancia, se crearon las dimensiones correspondientes con la aplicación SEISAN, ya que estas son necesarias para las referencias que posee la tabla de hechos hacia las mismas. Ver fragmento de dicho lenguaje SQL en la figura 21. Figura 21 Implementación de las dimensiones asociadas a la aplicación SEISAN mediante lenguaje SQL Seguidamente, se implementó de igual forma en lenguaje SQL la tabla de hechos correspondiente con la aplicación SEISAN. Ver figura 22. Capítulo IV – Marco Aplicativo 80 Figura 22 Implementación de la tabla de hechos correspondiente con la aplicación SEISAN “fact_evento” mediante lenguaje SQL Finalmente en esta etapa se implementaron en estricto orden las dimensiones correspondientes con la aplicación estudios y desastres y luego la tabla de hechos correspondientes con dicha aplicación a través de lenguaje SQL. Donde en las figuras 23 y 24 pueden ser apreciados fragmentos de dichas implementaciones. Capítulo IV – Marco Aplicativo 81 Figura 23 Implementación de las dimensiones asociadas a la aplicación estudios y desastres mediante lenguaje SQL Figura 24 Implementación de la tabla de hechos correspondiente con la aplicación estudios y desastres “fact_estudios_desastres” mediante lenguaje SQL Capítulo IV – Marco Aplicativo 82  Pruebas Las pruebas realizadas fueron del tipo funcional, verificando que la implementación de las dimensiones y las correspondientes tablas de hechos, de ambas aplicaciones descritas anteriormente se realizaran con éxito. Respetando las restricciones de integridad en cuanto a claves primarias y claves foráneas. No. H.U. involucradas Descripción del Caso de Prueba Resultado Esperado Resultado Obtenido 01 15,16,17, 18 Validar la correcta implementaci ón de las dimensiones y tablas de hechos, además de las restricciones de integridad en cuanto a claves primarias y claves foráneas. La implementación de las dimensiones y tablas de hechos correspondientes, tanto de la aplicación SEISAN, como de la aplicación estudios y desastres; deben poder realizarse con éxito respetando las restricciones de integridad. Es ejecutada la implementación tanto de las dimensiones como de las tablas de hechos correspondientes con las aplicaciones ya descritas y tal como se esperaba, dicha implementación fue realizada con éxito respetando las restricciones de integridad. Capítulo IV – Marco Aplicativo 83 Iteración 5  Planificación Iteración 5 Descripción Validación y Modificación de la estructura del datawarehouse Fecha Inicio / Fecha Fin 08/04/2011 / 17/04/2011 Númer o Fecha Historia Tipo 19 08/04/2011 Modificar las dimensiones y la tabla de hechos “fact_evento” del datawarehouse con el fin de poder unificar los datos tanto de la aplicación estudios y desastres como de los archivos en formato SEISAN Modificación/ Mejora 20 12/04/2011 Modificar la dimensión “dim_estacion” y crear de la tabla de hechos “fact_estacion” Modificación/ Mejora 21 13/04/2011 Crear la dimensión degenerada denominada “id_evento” Nueva 22 13/04/2011 Modificar el valor por defecto de los atributos de todas las dimensiones del datawarehouse. Modificación/ Mejora  Diseño En esta etapa al analizar los datos que se incluirían en el datawarehouse por parte de la aplicación SEISAN y la aplicación de estudios y desastres, se decide llevar a cabo la modificación de la tabla de hechos correspondiente con la aplicación SEISAN denominada “fact_evento”. En cuanto a la selección de sus atributos debido a que la misma poseía dos granularidades distintas, una referida a la amplitud, la duración y el periodo de un evento Capítulo IV – Marco Aplicativo 84 y otra granularidad referida a la latitud y la longitud de un evento; por lo cual se modifica dicha tabla, dejándola con un solo grano como debe ser, dicho grano se basa en la latitud y la longitud. Ver figura 25. Figura 25 Modificación a la tabla de hechos "fact_evento" Seguidamente, se realiza la modificación de la dimensión “dim_estacion”, eliminando de la misma los atributos que generarían duplicidad de los datos como lo son, amplitud, duración y periodo. Para luego crear la tabla de hechos “fact_estacion”, cuya granularidad viene dada por los atributos, duración, amplitud y periodo respectivamente. Ver figura 26 Figura 26 Modificación realizada a la dimensión "dim_estacion" y creación de la tabla de hehos "fact_estacion" Capítulo IV – Marco Aplicativo 85 Posteriormente se crea la dimensión degenerada “id_evento”, cuyo término hace referencia a un campo en este caso “id_evento”, que será utilizado como criterio de análisis y que es almacenado en las 3 tablas de hechos existentes en datawarehouse, como lo son “fact_evento”, “fact_estacion” y “fact_estudios_desastres” respectivamente. Esto con la finalidad de poder unificar los datos de tipo técnico, proveniente de la aplicación SEISAN y los datos de tipo social, proveniente de la aplicación estudios y desastres. Dicha dimensión degenerada se puede apreciar en la figura 27. Figura 27 Adición de la dimension degenerada "id_evento" a las tablas de hechos existentes Finalmente, en la etapa de diseño correspondiente con la presente iteración, se modifican los valores por defecto de los atributos de todas las dimensiones a “null”, a excepción de los atributos requeridos, como lo son las claves primarias, entre otros. Esto debido a que el datawarehouse registra la información tanto de un evento registrado en la aplicación SEISAN, como de un evento registrado en la aplicación estudios y desastres e incluso un evento registrado en ambas aplicaciones. Para de esta manera poder mantener la integridad y unicidad de los datos registrados en el repositorio de datos. Capítulo IV – Marco Aplicativo 86 Figura 28 Modificaciones realizadas a las dimensiones del datawarehouse y a la tabla de hechos "fact_estudios_desastres"  Codificación En la presente iteración, la etapa de codificación se basó, en la implementación de las modificaciones en cuanto al tipo de dato de algunos atributos en las dimensiones y de la modificación de la tabla de hecho “fact_evento” en lo que se refiere a la granularidad de la misma, destacando que dichas modificaciones son realizadas mediante lenguaje SQL. Ver fragmento de dicho lenguaje SQL en la figura 29. Capítulo IV – Marco Aplicativo 87 Figura 29 Modificación de la tabla de hecho “fact_evento” mediante lenguaje SQL Seguidamente, se realiza la modificación mediante lenguaje SQL, de la dimensión “dim_estacion”. Para luego crear la tabla de hechos “fact_estacion”, según las modificaciones descritas anteriormente en la etapa de diseño. Ver figura 30. Capítulo IV – Marco Aplicativo 88 Figura 30 Modificación mediante lenguaje SQL, de la dimensión “dim_estacion” y Creación de la tabla de hechos “fact_estacion” Posteriormente, se crea mediante lenguaje SQL, la dimensión degenerada “id_evento”, adicionándola como un campo dentro de las 3 tablas de hechos existentes en el datawarehouse. Para luego finalizar la etapa de codificación con la modificación de los valores por defecto de la gran mayoría de los atributos de todas las dimensiones a “null”. Ver figura 31. Capítulo IV – Marco Aplicativo 89 Figura 31 Modificación de los atributos de las dimensiones y adicion de la dimension degenerada "id_evento" a las tablas de hechos existentes Capítulo IV – Marco Aplicativo 90  Pruebas Las pruebas realizadas fueron del tipo funcional, verificando que la implementación de las modificaciones a las dimensiones y a las correspondientes tablas de hechos, de ambas aplicaciones tanto el SEISAN, como la aplicación estudios y desastres se realizaran con éxito. No. H.U. involucradas Descripción del Caso de Prueba Resultado Esperado Resultado Obtenido 02 19,20,21,22 Validar la correcta implementaci ón de las modificacione s descritas anteriorment e, a las dimensiones y a las tablas de hechos. La implementación de las modificaciones a las dimensiones y a las tablas de hechos correspondientes, tanto de la aplicación SEISAN, como de la aplicación estudios y desastres; deben poder realizarse con éxito respetando las restricciones de integridad. Es ejecutada la implementación de las modificaciones tanto de las dimensiones como de las tablas de hechos correspondientes con las aplicaciones ya descritas y tal como se esperaba, dicha implementación fue realizada con éxito respetando las restricciones de integridad. Capítulo IV – Marco Aplicativo 91 Iteración 6  Planificación Iteración 6 Descripción Inserción de los datos de prueba en el datawarehouse y validación mediante consultas SQL, del correcto funcionamiento del mismo. Fecha Inicio / Fecha Fin 14/04/2011 / 18/05/2011 Númer o Fecha Historia Tipo 23 14/04/2011 Crear el modelo de datos del datawarehouse Nueva 24 15/04/2011 Crear el archivo en formato SQL, con la estructura del datawarehouse. Nueva 25 15/04/2011 Crear el archivo en formato SQL, con las inserciones de los datos de prueba para validar el diseño del datawarehouse. Nueva 26 18/04/2011 Generar consultas en lenguaje SQL con el fin de validar el diseño del datawarehouse. Nueva 30 18/04/2011 Crear los TRIGGERS (procedimientos almacenados en la base de datos) en el datawarehouse. Nueva  Diseño En esta iteración, la etapa de diseño correspondió con el diseño del modelo del datawarehouse, luego de validado en la estructura del mismo en las iteraciones anteriores, dicho modelo se puede apreciar en la figura 32. Ver apéndice 2. Capítulo IV – Marco Aplicativo 92 Figura 32 Modelo de datos del datawarehouse Capítulo IV – Marco Aplicativo 93  Codificación En esta etapa, se realizó la creación de los archivos en lenguaje SQL, correspondientes con la estructura del datawarehouse y las inserciones de los datos de prueba que posteriormente en la etapa de pruebas de la presente iteración serán validadas. Cabe destacar que en la figura 37 se puede apreciar fragmentos del código SQL, con el cual se llevaron a cabo las inserciones correspondientes. No se hace referencia a la estructura del código SQL perteneciente a la creación del repositorio, ya que el mismo ha sido descrito en pequeños fragmentos en la iteración anterior.  Pruebas Las pruebas realizadas fueron del tipo funcional, verificando que la inserción de los datos de prueba en el datawarehouse se realizase con éxito, dicha verificación se realizó mediante el uso de consultas realizadas en lenguaje SQL. Los resultados obtenidos se pueden apreciar en las figuras 33, 34,35 y 36 respectivamente.  Descripción de las viviendas afectas en la aplicación estudios y desastres dado que el número de estaciones usadas para medir dicho evento sean 6 en la aplicación SEISAN. a. select fr.desc_per_viviendas from "funvisis"."fact_estudios_desastres" fr, "funvisis"."fact_evento" fe where fe.numero_estaciones_usadas = 6 and fe.id_evento = fr.id_evento; Figura 33 Consulta 1 Validación de las inserciones en el datawarehouse  Descripción de un evento dado que el evento en SEISAN posea longitud de -71.084 y no se posea información sobre el número de muertos en la aplicación estudios y desastres. Capítulo IV – Marco Aplicativo 94 a. select fr.descripcion from "funvisis"."fact_evento" fe, "funvisis"."fact_estudios_desastres" fr where fr.id_evento =fe.id_evento and fe.longitud=-71.084 and fr.muertos is null; Figura 34 Consulta 2 Validación de las inserciones en el datawarehouse  El código de la ficha dado que la longitud del evento en SEISAN esté entre -72 y -70 y no se posea información sobre el número de muertos en la aplicación estudios y desastres y el error de la longitud en SEISAN esté entre 10.4 y 10.8 a. select fr.id_ficha from "funvisis"."fact_evento" fe, "funvisis"."fact_estudios_desastres" fr where fr.id_evento =fe.id_evento and (fe.longitud between -72 and -70) and (fe.longitud_error between 10.4 and 10.8)and fr.muertos is null; Figura 35 Consulta 3 Validación de las inserciones en el datawarehouse Capítulo IV – Marco Aplicativo 95  Número de registros de estaciones para un evento que en la aplicación estudios y desastres tenga longitud entre 69 y 72 (tomar en cuenta el signo ojo) y que el número de estaciones usadas registradas por el SEISAN sea de 6. a. select count (distinct de.id_estacion) from "funvisis"."fact_estacion" fe, "funvisis"."dim_estacion" de, "funvisis"."fact_estudios_desastres" fr, "funvisis"."fact_evento" fev where fr.id_evento =fe.id_evento and (fr.longitud between 69 and 72) and fev.numero_estaciones_usadas = 6; Figura 36 Consulta 4 Validación de las inserciones en el datawarehouse Capítulo IV – Marco Aplicativo 96 Figura 37 Fragmento del Código SQL, correspondiente con la inserción de los datos de prueba en el datawarehouse Capítulo IV – Marco Aplicativo 97 Iteración 7  Planificación Iteración 7 Descripción Instalación y configuración del ambiente de desarrollo web; y creación del middleware que permita realizar la comunicación entre las aplicaciones existentes en FUNVISIS y el datawarehouse. Fecha Inicio / Fecha Fin 19/04/2011 / 26/04/2011 Númer o Fecha Historia Tipo 27 19/04/2011 Instalar el ambiente de desarrollo web, tanto para crear el middleware, como para crear la aplicación web mediante la cual serán realizadas las consultas sobre el datawarehouse. Nueva 28 19/04/2011 Instalar y Configurar el cliente “ruby- monetdb-client” que permitirá la conexión entre el lenguaje de programación Ruby y el sistema manejador de bases de datos columnar MonetDB. Nueva 29 20/04/2011 Crear el middleware en el lenguaje de programación Ruby que permita la carga de los datos de las aplicaciones ya existentes hacia el datawarehouse. Nueva  Codificación En la presente iteración se procedió a instalar todo lo necesario para que el sistema funcionara en las máquinas de trabajo personal, los programas instalados fueron: Ruby on Capítulo IV – Marco Aplicativo 98 Rails en conjunto con las dependencias necesarias, así como el cliente “ruby-monetdb- client” que permitirá la conexión entre el lenguaje de programación Ruby y el sistema manejador de bases de datos columnar MonetDB. Es importante destacar que dicha instalación fue realizada sobre el ambiente Linux, la cual se documentó con el fin de aportar una guía (ver apéndice 1) que sirva de apoyo para futuras instalaciones. Una vez instalado todo el ambiente de desarrollo, se creó el archivo en formato Ruby, el cual actuará como middleware entre las aplicaciones SEISAN y estudios y desastres, y el sistema manejador de bases de datos columnar MonetDB. Un fragmento del código de dicho archivo, donde se muestra el tratamiento para dos distintos tipos de líneas de los archivos en formato SEISAN, se puede apreciar en la figura 38. Figura 38 Fragmento de código en formato Ruby perteneciente al Middleware  Pruebas Las pruebas realizadas en la presente iteración, consistieron en verificar la correcta instalación del ambiente de desarrollo y el correcto funcionamiento del middleware. Este último encargado de llevar los datos desde las aplicaciones existentes hacia el datawarehouse. En la figura 39, se puede apreciar el resultado de ejecutar el middleware, mostrando en dicha ejecución el contenido de las variables, en las cuales se almacena la Capítulo IV – Marco Aplicativo 99 información correspondiente con las líneas tipo 1 de los archivos en formato SEISAN, antes de ser llevadas al datawarehouse. Figura 39 Ejecución del Middleware Capítulo IV – Marco Aplicativo 100 Iteración 8  Planificación Iteración 8 Descripción Creación de la aplicación web de consulta sobre el datawarehouse Fecha Inicio / Fecha Fin 27/04/2011 / 08/05/2011 Númer o Fecha Historia Tipo 31 27/04/2011 Crear la aplicación web que permita consultar la información registrada en el datawarehouse. Nueva 32 05/05/2011 Creación de videos que faciliten la demostración del funcionamiento de la aplicación web de consulta en conjunto con el comportamiento del datawarehouse. Nueva  Diseño En esta iteración se lleva a cabo el desarrollo de la funcionalidad que permite la visualización de los resultados obtenidos, luego de realizada una consulta sobre el datawarehouse en base a un formulario proporcionado por la aplicación web. Dicho prototipo de consulta, orientado hacia un administrador de bases de datos, se puede apreciar en la vista parcial encontrada en la figura 40. Capítulo IV – Marco Aplicativo 101 Figura 40 Vista del Prototipo de Consulta Web Sobre el datawarehouse  Codificación El código encargado de desplegar el prototipo de consulta web, con la especificación de la posición en la cual van cada uno de los campos, que permitirán realizar la consulta sobre el datawarehouse, se muestra en la figura 41 un fragmento del mismo. Capítulo IV – Marco Aplicativo 102 Figura 41 Fragmento del Código Perteneciente a la Vista desarrollada para el Prototipo de Consulta Web  Pruebas Las pruebas realizadas fueron del tipo funcional, verificando que la implementación del prototipo de consulta web más orientado éste, hacia un administrador de bases de datos, retornase de forma efectiva el resultado de la consulta aplicada sobre el datawarehouse, en base a los parámetros proporcionados por el formulario de dicho prototipo. Capítulo IV – Marco Aplicativo 103 No. H.U. involucradas Descripción del Caso de Prueba Resultado Esperado Resultado Obtenido 03 31 Validar la correcta implementa ción del prototipo de consulta web sobre el datawareho use. La implementación del prototipo de consulta web, debe retornar de forma efectiva el resultado de la consulta aplicada sobre el datawarehouse en base a los parámetros proporcionados por el formulario de dicho prototipo. Es ejecutada la implementación del prototipo de consulta web, y tal como se esperaba, dicha implementación fue realizada con éxito, obteniendo en la misma vista en el espacio asignado para el resultado de la consulta; el resultado de la misma valga la redundancia con base a los parámetros proporcionados por el formulario del prototipo de consulta. Conclusiones 104 Conclusiones El presente trabajo especial de grado tuvo como finalidad, realizar el diseño e implementación de un datawarehouse para la consolidación y consulta de eventos sismológicos y desastres naturales para la Fundación Venezolana de Investigaciones Sismológicas (FUNVISIS). Así como, de proveer a la fundación de un prototipo de consulta, orientado hacia un administrador de bases de datos, donde los usuarios visualizan el resultado de las consultas realizadas sobre el datawarehouse, en base a los parámetros establecidos en el formulario de dicho prototipo. Destacando que dicho prototipo funciona adecuadamente gracias a un middleware, el cual comunica las aplicaciones ya existentes en la fundación con el datawarehouse. Esté constituye un procedimiento para la incorporación de datos a dicho repositorio. Con estas nuevas opciones desarrolladas, La fundación cuenta con un repositorio para las aplicaciones SEISAN y la aplicación estudios y desastres. Agilizando el intercambio de información, así como también posee cierta estructura y organización. Otro aspecto de gran importancia es que para futuros desarrollos de sistemas en la Fundación, podría contarse con este repositorio como fuente de datos. Es importante destacar que, el diseño y la implementación consistieron en la elaboración de cada uno de los modelos de datos correspondientes, tanto con las diferentes dimensiones desarrolladas, como con las tablas de hechos asociadas a las mismas. Así mismo, se desarrolló el prototipo de interfaz con base a cada uno de los requerimientos solicitados, seguido de la implementación mediante el lenguaje de programación Ruby, el lenguaje de consultas SQL y el framework de desarrollo web Rails. Obteniendo de esta manera un repositorio de datos en el cual se logró unificar los datos tanto técnicos, como sociales manejados por las aplicaciones descritas anteriormente. Al comenzar el desarrollo del proyecto, encontré algunas dificultades y retos, la primera dificultad, fue conocer y revisar el estado actual de las aplicaciones existentes en la fundación. En este proceso se determinó que el tratamiento que se le daría a la información de ambas aplicaciones sería distinto, en primera instancia porque la aplicación SEISAN maneja información del tipo técnica, mientras que la aplicación estudios y desastres maneja información del tipo social. Segundo que la aplicación SEISAN maneja formatos de archivos “txt” con ciertas especificaciones, y la aplicación estudios y desastres implementa una base de datos MySQL. Esto me permitió mejorar mi conocimiento sobre el manejo de la información en la fundación, por parte de cada una de Conclusiones 105 las aplicaciones descritas anteriormente. Una vez superada esta etapa se presentó una situación que se inició como una dificultad pero que realmente era un reto, el mismo consistió en una nueva forma de programar, ya que se utilizaron nuevas y diversas tecnologías como el lenguaje de programación Ruby junto a su framework de desarrollo Rails, de las cuales se desconocían su sintaxis y convenciones establecidas. Sin embargo, con el pasar de las semanas se fueron adquiriendo habilidades para utilizar estas herramientas, logrando desarrollar una aplicación que se encuentra dentro de las nuevas y robustas tendencias de programación. Otra herramienta utilizada fue la adaptación del método ágil “Programación Extrema” (XP), la cual me facilitó trabajar de forma organizada al permitirme agrupar los requerimientos en un conjunto de iteraciones que se fueron desarrollando progresivamente, por otra parte. La comunicación constante con el cliente fue otro aspecto que nos brindo resultados positivos, ya que permitió realizar constante revisiones a los avances del sistema. Otro aspecto importante del método XP, es que ésta sugiere la programación en pareja, la cual no se utilizó y se opto por el programar de forma individual cada uno de los requerimientos planteados. Con todo esto se obtuvo la construcción de un repositorio de datos, acoplado a las necesidades del usuario, que en este caso fue FUNVISIS, además de dejarme conocimientos y experiencia para seguir asumiendo proyectos innovadores. Para finalizar, puedo afirmar que el desarrollo del repositorio de datos y demás aplicaciones, permitió unificar los datos de las aplicaciones existentes en la Fundación, agilizando el intercambio de información, así como también de darle estructura y organización al manejo de la información, lo cual no solo se realizó como un requisito para la elaboración del Trabajo Especial de Grado, sino también, para satisfacer algunas de las necesidades actuales de la fundación, sentar las bases para futuros desarrollos de sistemas en donde podría contarse con este repositorio como fuente de datos, dejando de esta forma un valioso aporte a FUNVISIS, además de fortalecer mi crecimiento personal y profesional. Recomendaciones 106 Recomendaciones Como toda aplicación que se encuentra en constante crecimiento, y como la Fundación Venezolana de Investigaciones Sismológicas (FUNVISIS), es importante dejar sentadas las bases que simplifiquen el diseño de nuevas funcionalidades y la realización de las futuras mejoras, tales como:  Poner a prueba el prototipo de consulta y el mismo datawarehouse, con un grupo variados de usuarios, con el fin de generar un informe completo de posibles mejoras y correcciones que adapten el repositorio y las aplicaciones asociadas al mismo a las necesidades de los usuarios.  Seguir los lineamientos o estándares de programación y la estructuración a nivel de base de datos utilizada durante el desarrollo del datawarehouse.  Añadir los datos de las demás aplicaciones existentes en la Fundación al repositorio de datos, que lo consoliden como principal fuente de datos.  Planificar reuniones mensuales con los usuarios donde se evalúe el estado actual del repositorio y esto sirva para la realización de depuraciones e incluso mejoras en la estructura del mismo.  Contar con un personal especializado, pasantes por ejemplo, que se encarguen del correcto funcionamiento del repositorio y de brindar soporte a las consultas realizadas por los usuarios. Referencias Bibliográficas 107 Referencias Bibliográficas Abadi, D. J., Boncz, P. A., & Harizopoulos, S. (2009). Column-oriented database system. VLDB Endowment. Anderson, J., & Hendrickson, C. (2000). Extreme Programming Installed. Addison-Wesley Longman Publishing Co. Becker, L., & Guting, R. (1992). Rule-based optimization and query processing. Bouman, R., & Dongen, J. v. (2009). Pentaho Solutions Business Intelligence and Data Warehousing with Pentaho and MySQL. Indianapolis: Wiley Publishing, Inc. Burbeck, S. (1992). Model-View-Controller Architecture. Recuperado el 10 de Diciembre de 2010, de Model-View-Controller Architecture: http://st- www.cs.illinois.edu/users/smarch/st-docs/mvc.html Comparison_of_relational_database_management_systems. (s.f.). Recuperado el 11 de Diciembre de 2010, de Wikipedia. Comparison_of_relational_database_management_systems: http://en.wikipedia.org/wiki/Comparison_of_relational_database_management_systems Ibarra, M. d. (2006). Procesamiento análitico en línea. Corrientes - Argentina. Informit. Ruby Language. (s.f.). Recuperado el 10 de Diciembre de 2010, de Informit. Ruby Language: http://www.informit.com/articles/article.asp?p=18225 Jeffries, R., Anderson, A., & Hendrickson, C. ( 2000). Extreme Programming Installed. Addison-Wesley Longman Publishing Co. Pressman, R. ( 2007). Ingeniería del Software Un enfoque práctico, Sexta Edición. Mc Graw Hill. Ruby lang org. Ruby Language. (s.f.). Recuperado el 10 de Diciembre de 2010, de Ruby lang org. Ruby Language.: http://www.ruby-lang.org/es/downloads Ruby on Rails org. Web development that doesn’t hurt. . (s.f.). Recuperado el 10 de Diciembre de 2010, de Ruby on Rails org. Web development that doesn’t hurt. : http://rubyonrails.org Stonebraker, M. (2005). A column-oriented DBMS. Referencias Bibliográficas 108 Vermeij, M., Quak, W., Kersten, M., & Nes, N. MonetDB, a novel spatial column-store DBMS. Wiskunde. Wikipedia. Rails. (s.f.). Recuperado el 10 de Diciembre de 2010, de Wikipedia. Rails: http://es.wikipedia.org/wiki/Rails www.funvisis.gob.ve. (s.f.). Recuperado el 12 de Diciembre de 2010, de www.funvisis.gob.ve: http://www.funvisis.gob.ve/organizacion.php Apéndice 109 Apéndice Apéndice 1 Pasos para realizar la Instalación del Ambiente de Desarrollo Ruby on Rails y configuración del cliente “ruby-monetdb-client”.  La computadora donde será instalada la aplicación debe constar con el Sistema Operativo Linux con distribución Ubuntu o Debian.  Utilizando la línea de comandos, ejecutar: a. $ sudo apt-get install gcc g++ build-essential libssl-dev libreadline5- dev zlib1g-dev linux-headers-generic libsqlite3-dev b. $ wget ftp://ftp.ruby-lang.org//pub/ruby/1.9/ruby- 1.9.2-p0.tar.gz c. $ tar –xvzf ruby-1.9.2-p0.tar.gz d. $ cd ruby-1.9.2-p0/ e. $ ./configure –prefix=/usr/local/ruby f. $ make && sudo make install g. $ sudo gedit /etc/environment i. PATH=”/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/ bin:/usr/games:/usr/local/ruby/bin” h. $ 109ails109 /etc/environment  Verificar la instalación de ruby desde la línea de comandos a. $ ruby –v b. Se deberá mostrar un mensaje como este: ruby 1.9.2p0 (2010-08-18 revision 29036) [x86_64-linux]  Crear un enlace entre Ruby y las gemas para los programas: a. $ sudo ln –s /usr/local/ruby/bin/ruby /usr/local/bin/ruby b. $ sudo ln –s /usr/local/ruby/bin/gem /usr/bin/gem  Seguidamente instalar los paquetes de las gemas requeridas incluidas en Rails 3. a. $ sudo gem install tzinfo builder memcache-client rack rack-test erubis mail text-format bundler thor i18n sqlite3-ruby b. $ sudo gem install rack-mount –version=0.4.0 c. $ sudo gem install rails –version 3.0.6  Verifique la versión del Framework Rails a. $ 109ails –v ftp://ftp.ruby-lang.org/pub/ruby/1.9/ruby-1.9.2-p0.tar.gz ftp://ftp.ruby-lang.org/pub/ruby/1.9/ruby-1.9.2-p0.tar.gz Apéndice 110  Posteriormente desde el gestor de paquetes Synaptic: a. Ubique el paquete “ruby-monetdb-client” b. Seleccionar el paquete para instalar c. Aplicar los cambios d. Dirigase al directorio /usr/lib/ruby/gems/1.8/ e. Copiar el archivo activerecord-monetdb-adapter-0.1.gemspec que esta en /usr/lib/ruby/gems/1.8/specifications$ en /usr/lib/ruby/gems/1.8/gems/activerecord-monetdb-adapter-0.1$ f. luego desde el directorio /usr/lib/ruby/gems/1.8/gems/activerecord- monetdb-adapter-0.1$ ejecutar: i. gem build activerecord-monetdb-adapter-0.1.gemspec y se debe crear este archivo activerecord-monetdb-adapter- 0.1.gem. ii. Seguidamente ejecutar este comando: 1. gem install activerecord-monetdb-adapter-0.1.gem g. Finalmente se deben seguir desde el paso e los mismos pasos para ruby- monetdb-sql-0.1. Apéndice 111 Apéndice 2 Modelo de datos del datawarehouse Apéndice 112 Apéndice 3 Índice de Siglas BD: base de datos DBMS: sistema manejador de bases de datos CWI: Centrum Wiskunde & Informática DW: datawarehouse FUNVISIS: Fundación Venezolana de Investigaciones Sismológicas HTML: lenguaje de marcado de hipertexto MVC: modelo vista controlador OLAP: procesamiento analítico en línea OLTP: procesamiento transaccional en línea ORM: mapeo objeto relacional RDBMS: sistema manejador de base de datos relacionales RoR: Ruby on Rails SEISAN: sistema de análisis sísmico SGBDR: sistema gestor de bases de datos relacionales SQL: lenguaje de consulta estructurado TEG: trabajo especial de grado XP: programación extrema Apéndice 113 Apéndice 4 Preguntas correspondientes con la aplicación estudios y desastres 1. Número de personas muertas por tipo de amenaza: movimiento en masa, tecnológico y sísmico. 2. Número de personas desaparecidas por tipo de amenaza: movimiento en masa, tecnológico y sísmico. 3. Número de personas lesionadas por tipo de amenaza: movimiento en masa, tecnológico y sísmico. 4. Número de personas damnificadas por tipo de amenaza: movimiento en masa, tecnológico y sísmico. 5. Número de personas afectadas por tipo de amenaza: movimiento en masa, tecnológico y sísmico. 6. Número de personas evacuadas por tipo de amenaza: movimiento en masa, tecnológico y sísmico. 7. Número de personas reubicadas por tipo de amenaza: movimiento en masa, tecnológico y sísmico. 8. Número de viviendas afectadas por tipo de amenaza: movimiento en masa, tecnológico y sísmico. 9. Número de viviendas destruidas por tipo de amenaza: movimiento en masa, tecnológico y sísmico. 10. Monto total en pérdidas en el sector infraestructura vial por tipo de amenaza: movimiento en masa, tecnológico y sísmico. 11. Monto total en pérdidas en el sector vivienda por tipo de amenaza: movimiento en masa, tecnológico y sísmico. 12. Monto total en pérdidas en el sector agrícola por tipo de amenaza: movimiento en masa, tecnológico y sísmico. 13. Monto total en pérdidas en el sector pecuario por tipo de amenaza: movimiento en masa, tecnológico y sísmico. 14. Monto total en pérdidas en el sector transporte por tipo de amenaza: movimiento en masa, tecnológico y sísmico. 15. Monto total en pérdidas en el sector comunicaciones por tipo de amenaza: movimiento en masa, tecnológico y sísmico. Apéndice 114 16. Monto total en pérdidas en el sector energía por tipo de amenaza: movimiento en masa, tecnológico y sísmico. 17. Monto total en pérdidas en el sector educación por tipo de amenaza: movimiento en masa, tecnológico y sísmico. 18. Monto total en pérdidas en el sector salud por tipo de amenaza: movimiento en masa, tecnológico y sísmico. 19. Monto total en pérdidas en el sector industria y comercio por tipo de amenaza: movimiento en masa, tecnológico y sísmico. 20. Monto total en pérdidas en el sector agua potable por tipo de amenaza: movimiento en masa, tecnológico y sísmico. 21. Monto total en pérdidas en el sector agua servida por tipo de amenaza: movimiento en masa, tecnológico y sísmico. 22. Monto total en pérdidas en el sector otros por tipo de amenaza: movimiento en masa, tecnológico y sísmico. 23. Monto total en pérdidas en Bs. Por: estado, municipio, centro poblado y localidad. Apéndice 115 Apéndice 5 Descripción de cada una de las líneas correspondientes con los archivos de la aplicación SEISAN, según el manual de dicha aplicación.