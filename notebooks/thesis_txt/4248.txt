UNIVERSIDAD CENTRAL DE VENEZUELA FACULTAD DE CIENCIAS ESCUELA DE COMPUTACIÃ“N CENTRO DE COMPUTACIÃ“N GRÃFICA VisualizaciÃ³n de volÃºmenes multi-resoluciÃ³n con manejo eficiente de la segmentaciÃ³n de la textura atlas Trabajo Especial de Grado presentado ante la ilustre Universidad Central de Venezuela para optar al tÃ­tulo de Licenciados en ComputaciÃ³n Br. Zilerimar Carolina FernÃ¡ndez Hensen Br. Augusto AndrÃ©s RamÃ­rez Colmenares Tutor: Prof. RhadamÃ©s Carmona Caracas, Mayo 2015 UNIVERSIDAD CENTRAL DE VENEZUELA FACULTAD DE CIENCIAS ESCUELA DE COMPUTACIÃ“N CENTRO DE COMPUTACIÃ“N GRÃFICA - CCG ACTA Quienes suscriben, miembros del jurado designado por el Consejo de la Escuela de ComputaciÃ³n, para examinar el Trabajo Especial de Grado titulado â€œVisualizaciÃ³n de volÃºmenes multi-resoluciÃ³n con manejo eficiente de la segmentaciÃ³n de la textura atlasâ€ y presentado por los Brs. Zilerimar Carolina FernÃ¡ndez Hensen (C.I. V- 16.683.087) y Augusto AndrÃ©s RamÃ­rez Colmenares (C.I V- 18.002.913), a los fines de optar al tÃ­tulo de Licenciados en ComputaciÃ³n, dejamos constancia de lo siguiente: LeÃ­do como fue dicho trabajo, por cada uno de los miembros del jurado, se fijÃ³ el dÃ­a __ de ________ de _____, a las ________ horas, para que el (los) autor(es) lo defendiera(n) en forma pÃºblica, lo que este (esta/estos) hizo (hicieron) en ____________________ de la Escuela de ComputaciÃ³n, mediante una presentaciÃ³n oral de su contenido, luego de lo cual respondieron a las preguntas formuladas. Finalizada la defensa pÃºblica del Trabajo Especial de Grado, el jurado decidiÃ³ aprobar con la nota de ____ puntos. En fe de lo cual se levanta la presente Acta, en Caracas el dÃ­a ___ de __________ de ____. _________________________ Prof. RhadamÃ©s Carmona (Tutor) _________________________ _______________________ Prof(a), Francisco Sans Prof(a), Jaime Blanco (Jurado) (Jurado) Universidad Central de Venezuela Facultad de Ciencias Escuela de ComputaciÃ³n CCG Autores: Zilerimar Carolina FernÃ¡ndez Hensen y Augusto AndrÃ©s RamÃ­rez Colmenares. Tutor: Prof. RhadamÃ©s Carmona. Fecha: 15/05/2015. RESUMEN El despliegue de volÃºmenes es un Ã¡rea muy demandada en la actualidad. Con el desarrollo de nuevas tecnologÃ­as para la captura de volÃºmenes, se ha mejorado la resoluciÃ³n de los datos volumÃ©tricos, lo cual implica un aumento considerable en el tamaÃ±o de los mismos. Los computadores convencionales, e incluso las estaciones de trabajo, comÃºnmente no tienen la capacidad para desplegar estos volÃºmenes, a menos que se visualice solo una sub-Ã¡rea del volumen, o se utilicen tÃ©cnicas multi-resoluciÃ³n. Entre las tÃ©cnicas multi-resoluciÃ³n se destaca aquella basada en la jerarquÃ­a por bloques con despliegue de un pasada mediante la tÃ©cnica de Ray Casting. Los bloques son almacenados en la memoria de tarjeta de video como un conjunto de texturas, empaquetadas en una Ãºnica textura denominada textura atlas. Debido a que los bloques almacenados no son del mismo tamaÃ±o, la fragmentaciÃ³n de la memoria de textura es un aspecto importante a considerar, pues un uso ineficiente de esta memoria redundarÃ¡ en la pÃ©rdida de calidad global en el rendering. En este trabajo se presenta un algoritmo que mantiene un orden especial de los bloques en la textura atlas, el cual minimiza su fragmentaciÃ³n, y permite su fÃ¡cil actualizaciÃ³n conforme las prioridades de los bloques cambien entre cuadros de imagen. Los bloques son ordenados de forma decreciente dentro de la textura atlas a travÃ©s de un algoritmo denominado Z-Order. Con este ordenamiento, las operaciones de refinamiento y reducciÃ³n de resoluciÃ³n se efectÃºan eficientemente, con una fragmentaciÃ³n de la textura atlas insignificante. Se realizaron pruebas con volÃºmenes de gran tamaÃ±o, donde se obtuvieron resultados bastantes satisfactorios con respecto a tiempos de respuesta y fragmentaciÃ³n en la textura atlas. Palabras Clave: despliegue de volÃºmenes, tÃ©cnicas multi-resoluciÃ³n, Ray Casting, textura atlas, jerarquÃ­a por bloques, Refinamiento y Colapso, mÃ©trica de distancia, Z-Order. Tabla de contenido i Tabla de Contenido TABLA DE CONTENIDO .................................................................................................................... I INTRODUCCIÃ“N ........................................................................................................................... IV CAPÃTULO I .................................................................................................................................... 1 1.1 SITUACIÃ“N ACTUAL ............................................................................................................. 1 1.2 PLANTEAMIENTO DEL PROBLEMA ....................................................................................... 2 1.3 SOLUCIÃ“N PROPUESTA ........................................................................................................ 2 1.4 OBJETIVO GENERAL ............................................................................................................. 3 1.5 OBJETIVOS ESPECÃFICOS ...................................................................................................... 3 1.6 ALCANCE .............................................................................................................................. 4 CAPÃTULO II ................................................................................................................................... 5 2.1 VISUALIZACIÃ“N DE VOLÃšMENES ......................................................................................... 5 2.2 VÃ“XELES Y CELDAS .............................................................................................................. 6 2.3 TIPOS DE VISUALIZACIÃ“N .................................................................................................... 7 2.4 VOLUME RENDERING DIRECTO ............................................................................................ 8 2.4.1 FRONT TO BACK ............................................................................................................ 10 2.4.2 BACK TO FRONT ............................................................................................................ 11 2.5 CLASIFICACIÃ“N DE LOS DATOS VOLUMÃ‰TRICOS ................................................................ 11 2.5.1 PRE-CLASIFICACIÃ“N ....................................................................................................... 12 2.5.2 POST-CLASIFICACIÃ“N .................................................................................................... 13 2.5.3 CLASIFICACIÃ“N PRE-INTEGRADA ................................................................................... 15 2.6 ALGORITMOS PARA LA VISUALIZACIÃ“N DE VOLÃšMENES ................................................... 16 2.6.1 RAY CASTING ............................................................ Â¡ERROR! MARCADOR NO DEFINIDO. 2.7 VOLÃšMENES DE GRAN TAMAÃ‘O ....................................................................................... 18 2.8 BRICKING ........................................................................................................................... 18 Tabla de contenido ii 2.9 VOLUME ROAMING ........................................................................................................... 19 2.10 VISUALIZACIÃ“N DE VOLÃšMENES MULTI-RESOLUCIÃ“N. ................................................. 20 2.10.1 ALMACENAMIENTO DEL VOLUMEN .............................................................................. 20 2.10.1.1 JERARQUÃA OCTREE .................................................................................................. 21 2.10.1.2 JERARQUÃA POR BLOQUES ........................................................................................ 21 2.10.2 CRITERIO DE SELECCIÃ“N ................................................................................................ 26 2.10.3 MÃ‰TRICAS DE ERROR..................................................................................................... 29 2.10.4 BASADO EN LA DISTANCIA ............................................................................................ 29 2.10.5 PROCESO DE DESPLIEGUE ............................................................................................. 31 2.11 FRAGMENTACIÃ“N DEL ATLAS ........................................................................................ 34 2.12 JERARQUÃA DE MEMORIA DE TEXTURA EN GPU ............................................................ 35 2.13 USANDO MEMORIA DE TEXTURA CON OPENGL ............................................................ 36 2.14 ALGORITMOS DE EMPAQUETAMIENTO ........................................................................ 38 2.14.1 STRIP PACKING .............................................................................................................. 38 2.14.2 BIN PACKING ................................................................................................................. 39 2.15 MORTON ORDER ........................................................................................................... 45 CAPÃTULO 3 ................................................................................................................................. 47 3.1 METODOLOGÃA DE DESARROLLO ....................................................................................... 47 3.2 VISUALIZACIÃ“N DE VOLÃšMENES MULTI-RESOLUCIÃ“N. ...................................................... 51 3.3 CARGA DE VOLUMEN ........................................................................................................ 52 3.4 JERARQUÃA MULTI-RESOLUCIÃ“N BASADA EN BLOQUES .................................................... 53 3.5 CRITERIO DE SELECCIÃ“N .................................................................................................... 54 3.5.1 PUNTO DE INTERÃ‰S ....................................................................................................... 55 3.5.2 PROCESO DE REFINAMIENTO ........................................................................................ 56 3.6 DESPLIEGUE DEL VOLUMEN ............................................................................................... 57 3.7 TEXTURA ATLAS ................................................................................................................. 58 3.8 ALGORITMOS PROPUESTOS ............................................................................................... 58 3.8.1 BIN PACKING RECURSIVO .............................................................................................. 58 3.8.1.1 EXTREME POINTS ..................................................................................................... 60 Tabla de contenido iii 3.8.2 STRIPS AND POINTERS .................................................................................................. 61 3.8.3 3D Z-ORDER STRIP ......................................................................................................... 64 4.1 AMBIENTE DE PRUEBAS ..................................................................................................... 73 4.2 ESPECIFICACIONES DE HARDWARE .................................................................................... 73 4.3 ESPECIFICACIONES DE SOFTWARE ..................................................................................... 74 4.4 DATASETS .......................................................................................................................... 74 4.4.1 VOLUMEN 1 .................................................................................................................. 74 4.4.2 VOLUMEN 2 .................................................................................................................. 75 4.4.3 VOLUMEN 3 .................................................................................................................. 76 4.5 RESULTADOS CUANTITATIVOS ........................................................................................... 76 4.5.1 ETAPA DE PRE-PROCESAMIENTO .................................................................................. 76 4.5.2 REFINAMIENTO ............................................................................................................. 77 4.6 RESULTADOS CUALITATIVOS ............................................................................................. 80 4.7 COMPARACIÃ“N CON TRABAJOS PREVIOS .......................................................................... 84 CONCLUSIONES Y TRABAJOS FUTUROS ........................................................................................ 87 REFERENCIAS ............................................................................................................................... 89 IntroducciÃ³n iv IntroducciÃ³n En el mundo de la computaciÃ³n grÃ¡fica existen diversas tÃ©cnicas para visualizar volÃºmenes en una computadora convencional. Entre estas tÃ©cnicas, tenemos dos vertientes: Indirect Volume Rendering (IVR) [2] o Rendering Indirecto de VolÃºmenes, en donde el volumen es desplegado mediante iso-superficies, y Direct Volume Rendering (DVR) [4] o Rendering Directo de VolÃºmenes, en donde se despliega el volumen usando trazos de rayos, tomando en cuenta la emisiÃ³n y la absorciÃ³n de la luz a lo largo del volumen. La tÃ©cnica de DVR obtiene resultados de mejor calidad que en IVR, ya que permite definir caracterÃ­sticas visuales como transparencia, color por material, etc., y ademÃ¡s no se tiene limitaciones en cuanto a la cantidad de polÃ­gonos que pueden llegar a generarse cuando se despliega un volumen con la tÃ©cnica de IVR. Los volÃºmenes se consideran de gran tamaÃ±o cuando sobrepasan la capacidad de memoria disponible en el computador (ya sea la memoria del GPU o la memoria principal), y por ende requieren de un gran tiempo de procesamiento para su despliegue. Para estos volÃºmenes, se requieren de tÃ©cnicas especiales para su procesamiento y despliegue. Diversos autores han propuesto algoritmos que pueden ser usados para lidiar con estos volÃºmenes. Como principales tÃ©cnicas, tenemos bricking (despliegue por ladrillos) [4], donde se particiona el volumen en un conjunto de sub-volÃºmenes de igual tamaÃ±o, en donde cada ladrillo sÃ­ puede ajustarse al espacio de GPU o CPU disponible. AsÃ­, el volumen es proyectado ladrillo a ladrillo, mientras se van mezclando para componer la imagen final. TambiÃ©n se puede desplegar el volumen mediante un Ã¡rea de interÃ©s, en donde interactivamente podemos elegir una zona del volumen que se quiera visualizar. Otra soluciÃ³n consiste en desplegar el volumen mediante tÃ©cnicas de despliegue multi-resoluciÃ³n. Estas tÃ©cnicas asignan una resoluciÃ³n a cada Ã¡rea del volumen para luego ser desplegados. El pipeline grÃ¡fico para las tÃ©cnicas multi- IntroducciÃ³n v resoluciÃ³n consta de la carga del volumen, generaciÃ³n de niveles de detalle por cada zona, criterio de selecciÃ³n de niveles de detalles y despliegue final del volumen. Las ventajas de las tÃ©cnicas multi-resoluciÃ³n es que permiten darle mayor nivel de detalle a las Ã¡reas de interÃ©s en el volumen para el usuario y reducir el detalle en las Ã¡reas que no son de gran importancia para el mismo. Como principal desventaja, tenemos que estos algoritmos multi-resoluciÃ³n generan artefactos en la visualizaciÃ³n final, ademÃ¡s de requerir un overead en tiempo de cÃ³mputo para seleccionar las distintas resoluciones y hacer el despliegue. R. Carmona [4] desarrollÃ³ un algoritmo Ã³ptimo polinomial, que obtiene la representaciÃ³n multi-resoluciÃ³n con mÃ­nimo error, cuando se utiliza una jerarquÃ­a multi- resoluciÃ³n de Octree. Implementa tÃ©cnicas de aceleraciÃ³n como el salto de espacios vacÃ­os y terminaciÃ³n temprana del rayo. K. LÃ³pez [28] propuso un algoritmo para desplegar volÃºmenes multi-resoluciÃ³n usando Ray Casting de una pasada, utilizando una jerarquÃ­a multi-resoluciÃ³n por bloques con tres niveles de detalles y una textura tridimensional denominada textura atlas, para almacenar los bloques a ser desplegados por el GPU. En este trabajo se plantea utilizar una jerarquÃ­a por bloques similar a K. LÃ³pez [28], lidiando efectivamente con el problema de fragmentaciÃ³n de la textura atlas. Se propone utilizar un proceso de refinado compuesto por 2 sub-procesos encargados de realizar la reorganizaciÃ³n de bloques dentro de la textura atlas, de manera tal de tener un control de la ubicaciÃ³n de cada bloque y cada espacio disponible en la misma. Estos sub-procesos determinan que bloques deben moverse para aprovechar los espacios de la mejor manera siempre intentando de minimizar la cantidad de bloques a mover. Como consecuencia de esto no es necesario implementar un algoritmo para realizar la compactaciÃ³n bloques en memoria. Este trabajo especial de grado estÃ¡ estructurado por capÃ­tulos. En el primer capÃ­tulo se explica el problema principal para visualizar volÃºmenes multi-resoluciÃ³n utilizando la memoria disponible de manera adecuada y algunas propuestas para solucionarlo. El segundo capÃ­tulos explica los conceptos y definiciones necesarias para el desarrollo de la aplicaciÃ³n. El tercer capÃ­tulo describe la metodologÃ­a y algoritmos realizados para la implementaciÃ³n de la aplicaciÃ³n. En el cuarto capÃ­tulo se presentan las pruebas IntroducciÃ³n vi realizadas sobre 3 volÃºmenes, para luego finalizar con las conclusiones y trabajos futuros. CapÃ­tulo I 1 CapÃ­tulo I Propuesta de Trabajo de Especial de Grado En este capÃ­tulo se describe brevemente el problema principal del algoritmo de inserciÃ³n de bloques en la textura atlas para volÃºmenes multi-resoluciÃ³n y se realiza una propuesta para su soluciÃ³n. 1.1 SituaciÃ³n actual Actualmente los sistemas de computadores convencionales no tienen la capacidad de procesar volÃºmenes de gran tamaÃ±o en su representaciÃ³n mÃ¡s fina de forma eficiente. Para esto se han propuestos varios trabajos donde muestran una soluciÃ³n al despliegue de volÃºmenes usando tÃ©cnicas multi-resoluciÃ³n. Con estas tÃ©cnicas se logra hacer el despliegue del volumen en tiempo real; sin embargo, aÃºn se presentan problemas de artefactos en la imagen final, y sub utilizaciÃ³n de la memoria del GPU por fragmentaciÃ³n de la misma. Para este trabajo especial de grado se ha tomado como caso de estudio el algoritmo de despliegue de volÃºmenes multi-resoluciÃ³n utilizando la tÃ©cnica de Ray Casting de una pasada en GPU, utilizando una jerarquÃ­a por bloques. En esta tÃ©cnica, el volumen multi resoluciÃ³n es almacenado en una textura de atlas, la cual es por lo general sub utilizada debido al problema de la fragmentaciÃ³n. La desfragmentaciÃ³n de la memoria puede limitar momentÃ¡neamente la interactividad en la visualizaciÃ³n, por lo que definir una tÃ©cnica que CapÃ­tulo I 2 evite la fragmentaciÃ³n de la memoria es de suma importancia. Evitando la fragmentaciÃ³n de la memoria atlas, permitirÃ¡ mantener mÃ¡s informaciÃ³n del volumen en la textura atlas, que redundarÃ¡ en una mejora en la calidad del rendering. 1.2 Planteamiento del problema Existen diversas tÃ©cnicas de almacenamiento para la visualizaciÃ³n de volÃºmenes multi- resoluciÃ³n. Una de ellas utiliza una jerarquÃ­a por bloques. En una jerarquÃ­a por bloques, el volumen es inicialmente particionado en bloques de igual tamaÃ±o. Cada uno de estos bloques es representado en distintos niveles de detalle. Cada nivel de detalle tiene aproximadamente un octavo del espacio que ocupa su nivel de detalle inmediatamente superior. AsÃ­, por cada bloque del volumen original, se tiene una lista de bloques que representan el espacio ocupado por dicho bloque con distintos niveles de detalle. Durante el rendering, se toma la resoluciÃ³n adecuada de cada bloque segÃºn una mÃ©trica de error. Estos bloques son empaquetados en una Ãºnica textura atlas (por ejemplo, de 0.5GB). Durante la interacciÃ³n del usuario con el volumen, los bloques son reemplazados por otro nivel de detalle que requiere mÃ¡s o menos memoria que el bloque actualmente almacenado. Esto crea un problema de fragmentaciÃ³n de la memoria, con la desventaja de tener que realizar compactaciÃ³n o desfragmentaciÃ³n de la misma, ya que en el proceso de almacenamiento e inserciÃ³n de bloques se desperdicia memoria que puede ser utilizada por otros bloques. Es por esto que surge la necesidad de mejorar el proceso de inserciÃ³n, para utilizar el mayor espacio disponible de manera eficiente y minimizar el espacio perdido por la fragmentaciÃ³n en la memoria de textura. Por consiguiente, es de interÃ©s la implementaciÃ³n de un algoritmo de segmentaciÃ³n que permita organizar y mover bloques dentro del atlas, y que minimice la necesidad de desfragmentar dicha memoria. 1.3 SoluciÃ³n propuesta En este trabajo especial de grado se plantea el desarrollo de una aplicaciÃ³n que permita el despliegue de volÃºmenes multi-resoluciÃ³n usando la tÃ©cnica de Ray Casting de una pasada por GPU. Para el almacenamiento del volumen se desea implementar una jerarquÃ­a por bloques con distintos niveles de detalle; el volumen original es dividido en bloques y CapÃ­tulo I 3 cada nivel de detalle siguiente se obtiene de la interpolaciÃ³n de los bloques del nivel de detalle anterior. Para la elecciÃ³n de bloques a desplegar se utilizarÃ¡ el punto de interÃ©s y la coordenada de ojo en espacio objeto como criterio de selecciÃ³n. Esto permite darle a cada bloque una prioridad calculada segÃºn ambas distancias. Una vez seleccionados los bloques a desplegar, se almacenan en una textura atlas indexada en otra textura de menor tamaÃ±o, conocida como textura de Ã­ndices. Para la inserciÃ³n de bloques en la textura atlas se implementarÃ¡ una indexaciÃ³n de bloques que permita su organizaciÃ³n en la textura atlas de forma eficiente y permita aprovechar el mÃ¡ximo espacio disponible. Para el refinamiento y reducciÃ³n de bloques se implementarÃ¡n dos algoritmos que determinarÃ¡n quÃ© bloques deben ser movidos y en quÃ© espacios deben ser reinsertados, siempre teniendo en cuenta que se debe hacer el mÃ­nimo de movimientos de bloques posible, sin afectar drÃ¡sticamente la calidad visual del volumen. 1.4 Objetivo General Desarrollar un sistema de despliegue de volÃºmenes multi-resoluciÃ³n almacenado en una jerarquÃ­a por bloques con la tÃ©cnica de Ray Casting en GPU de una pasada, que permita organizar los bloques en una textura atlas usando la mayor cantidad de espacio disponible tratando de evitar la fragmentaciÃ³n de la memoria. 1.5 Objetivos EspecÃ­ficos ï‚· Cargar en memoria el volumen y generar los niveles de detalles utilizando la jerarquÃ­a por bloques. ï‚· Implementar el sistema de despliegue de volÃºmenes multi-resoluciÃ³n basado en Ray Casting en GPU de una pasada, basÃ¡ndose en un criterio de selecciÃ³n que tome en cuenta al menos la distancia a un punto de interÃ©s, refinando y reduciendo (split & collapse) bloques por una mÃ©trica de distancia. ï‚· Implementar un algoritmo de inserciÃ³n y reacomodo de bloques en la textura atlas que permita usar el espacio eficientemente, evitando la fragmentaciÃ³n de memoria CapÃ­tulo I 4 durante el proceso de reducciÃ³n y refinado de bloques, minimizando la cantidad de movimientos de bloques. ï‚· Realizar pruebas de rendimiento del sistema de despliegue, incluyendo la generaciÃ³n de los niveles de detalle, el algoritmo de segmentaciÃ³n y rendering. 1.6 Alcance ï‚· Se requiere una tarjeta grÃ¡fica con soporte de texturas 3D, OpenGLÂ® versiÃ³n 4.0, y GLSL (OpenGL Shading Language) versiÃ³n Y.Y. . ï‚· El tamaÃ±o mÃ¡ximo de los datos volumÃ©tricos se restringe a un mÃ¡ximo de 3 GB de memoria, por lo cual se requiere como mÃ­nimo 4GB de RAM disponibles para la aplicaciÃ³n. ï‚· El sistema serÃ¡ desarrollado y probado en una plataforma basada en Windows 8.1 de 64bits, utilizando como lenguaje de programaciÃ³n C++ bajo el entorno de desarrollo Visual C++ 2012. Se utilizarÃ¡ OpenMP para realizar tambiÃ©n algunos procesos en paralelo en el CPU. CapÃ­tulo II 5 CapÃ­tulo II Marco TeÃ³rico Hoy en dÃ­a existen diversos algoritmos para poder visualizar volÃºmenes en una computadora convencional. En este capÃ­tulo se estudian los conceptos bÃ¡sicos para el despliegue de volumen, explicando cada uno de los pasos a seguir para su adecuada visualizaciÃ³n, los cuales son la carga del volumen, clasificaciÃ³n de los datos y el despliegue utilizando la tÃ©cnica de Ray Casting. 2.1 VisualizaciÃ³n de VolÃºmenes La visualizaciÃ³n de volÃºmenes ha adquirido una gran importancia a travÃ©s de los aÃ±os, ya que es una tÃ©cnica muy utilizada en diversos campos cientÃ­ficos. Como por ejemplo, la sismologÃ­a, la medicina, la fÃ­sica, la quÃ­mica, entre otros. Incluso puede ser utilizada en Ã¡reas que necesiten simular estructuras multidimensionales haciendo uso del computador. La visualizaciÃ³n de volÃºmenes tiene como objetivo proyectar un conjunto de datos multidimensionales, llamado dataset, en un plano de imagen bidimensional (ver Figura 2.1) con el propÃ³sito de entender la topologÃ­a de la estructura contenida en los datos volumÃ©tricos [1]. AdemÃ¡s ofrece la capacidad de manipular la estructura de manera rÃ¡pida y con gran precisiÃ³n segÃºn los parÃ¡metros definidos por el usuario. La estructura representada por el dataset es lo que se denomina volumen. CapÃ­tulo II 6 Un volumen puede ser definido como un conjunto de muestras de una funciÃ³n escalar continua, representado por una malla regular, compuesta por un conjunto de celdas, y almacenado en un arreglo tridimensional de escalares [4]. Figura 2.1: VisualizaciÃ³n de un dataset de una iguana usando tÃ©cnicas de visualizaciÃ³n de volÃºmenes. 2.2 VÃ³xeles y Celdas Como mencionamos anteriormente el volumen no es mÃ¡s que un conjunto de datos multidimensionales, dentro de un arreglo tridimensional. Este conjunto de datos puede ser manipulado como un arreglo de elementos volumÃ©tricos [1]; Ã©stos son conocidos como vÃ³xeles (acrÃ³nimo de volumen y pÃ­xel). Un vÃ³xel puede considerarse como un pÃ­xel en un espacio tridimensional. Las celdas se componen por grupos de 8 vÃ³xeles y un conjunto de celdas forman el grid (mallado) del volumen (ver Figura 2.2). En este trabajo, se define un vÃ³xel como un punto correspondiente a una muestra del volumen. CapÃ­tulo II 7 Figura 2.2: RepresentaciÃ³n grÃ¡fica de una Celda y un Grid 2.3 Tipos de VisualizaciÃ³n La tÃ©cnica de visualizaciÃ³n de volÃºmenes se puede clasificar en dos (2) tipos: (i) (IVR) Indirect Volume Rendering (Rendering Indirecto de VolÃºmenes) y (ii) (DVR) Direct Volume Rendering (Rendering Directo de VolÃºmenes). El primer tipo, IVR, consiste en transformar el volumen a una representaciÃ³n â€œintermediaâ€ capaz de ser desplegada [2]. Esta representaciÃ³n â€œintermediaâ€ es una aproximaciÃ³n a una superficie del volumen a travÃ©s de la generaciÃ³n de geometrÃ­as (triÃ¡ngulos, cuadrados, etc.), es decir, El IVR es un proceso de correspondencia entre cada uno de los vÃ³xeles y la geometrÃ­a siguiendo una funciÃ³n de interpolaciÃ³n. Existen diversos algoritmos para el IVR, entre ellos tenemos: Marching Cubes (Cubos Marchantes), Marching Tetrahedra (Tetracubos Marchantes), Contour- Connecting (ConexiÃ³n de Contornos) [3], entre otros. El segundo tipo de visualizaciÃ³n de volÃºmenes, DVR, consiste en desplegar el volumen sin hacer uso de la representaciÃ³n â€œintermediaâ€ (ver Figura 2.3). Este trabajo estÃ¡ basado en DVR, el cual serÃ¡ explicado detalladamente en la siguiente secciÃ³n [4]. CapÃ­tulo II 8 Figura 2.3: Despliegue de volÃºmenes usando Marching Cubes para IVR y el algoritmo de Ray Casting en GPU para el DVR. 2.4 Rendering Directo de VolÃºmenes Este tipo de visualizaciÃ³n (DVR) estÃ¡ basado en la composiciÃ³n de las propiedades visuales de un objeto semitransparente (volumen), simulando el paso de rayos de luz a travÃ©s del mismo tomando en cuenta la emisiÃ³n y absorciÃ³n de la luz, con lo cual obtenemos los colores en cada pÃ­xel de la imagen a generar. Para obtener el color de un pÃ­xel simulando el paso de un rayo a travÃ©s del volumen se hace uso de la Ec. 2.1 [4]: ğ¶ = âˆ« ğ‘(ğœ†)ğ‘¡(ğœ†)ğ‘’âˆ’ âˆ« ğ‘¡(ğœ† â€²)ğ‘‘ğœ†â€² ğœ† 0 ğ· 0 ğ‘‘ğœ†, [Ec. 2.1] donde ğ¶ es el color resultante, ğ· es la distancia que recorre el rayo dentro del volumen, ğ‘(ğœ†) y ğ‘¡(ğœ†) son el color y factor de absorciÃ³n a una distancia ğœ† de la entrada del rayo en el CapÃ­tulo II 9 volumen respectivamente. La integral representa la emisiÃ³n de la luz desde la entrada del rayo (ğœ† = 0) hasta la salida del mismo (ğœ† = ğ·). La exponencial representa el factor de extinciÃ³n acumulado hasta ese punto [3], que se puede interpretar como la transparencia ğ‘‡(ğœ†) del volumen hasta la distancia (ğœ†) [4]. Note que con este factor de atenuaciÃ³n, a medida que el rayo avanza dentro del volumen se acumula mÃ¡s opacidad (menos transparencia) y la atenuaciÃ³n del color es mayor. Como podemos observar, la Ec. 2.1 es una ecuaciÃ³n continua, pero en el plano donde se proyectan los datos es discreto, y el volumen a su vez estÃ¡ dado por muestras discretas. Una manera de evaluar la ecuaciÃ³n es utilizar la suma de Reimann [68], la cual a travÃ©s de subdivisiones finitas rectangulares del Ã¡rea bajo la curva obtenemos una aproximaciÃ³n discreta de la ecuaciÃ³n. Aplicando lo anterior obtenemos la siguiente ecuaciÃ³n discreta para la composiciÃ³n del color (ver Ec. 2.2) [4]: ğ¶ â‰ˆ âˆ‘ ğ›¼ğ‘–ğ‘ğ‘– âˆ (1 âˆ’ ğ›¼ğ‘—) ğ‘–âˆ’1 ğ‘—=0 ğ‘ ğ‘–=0 , [Ec. 2.2] donde ğ‘ representa la cantidad de muestras del volumen a evaluar, ci representa la muestra i-Ã©sima clasificada mediante una funciÃ³n de transferencia [3] y ğ›¼ğ‘– es la opacidad de la muestra i-Ã©sima en el rayo. En forma general, la opacidad acumulada la podemos definir como, ğ›¼ = 1 âˆ’ ğ‘‡(ğœ†), [Ec. 2.3] donde ğ›¼ se define como la opacidad acumulada del a una distancia ğœ†[4], donde ğ‘‡(ï¬) = âˆ(1 âˆ’ ğ›¼ğ‘—) . CapÃ­tulo II 10 Figura 2.4: Trazo de un rayo de luz a travÃ©s del volumen. La Ec. 2.2 se puede evaluar de dos maneras diferentes: front to back (de adelante hacia atrÃ¡s) y back to front (de atrÃ¡s hacia adelante). A continuaciÃ³n se describen estos dos enfoques. 2.4.1 Front To Back Consiste en evaluar y acumular las muestras desde la mÃ¡s cercana a la mÃ¡s lejana. Esto puede expresarse mediante la Ec. 2.4 de forma iterativa, donde ğ¶ğ‘› es equivalente al color ğ¶ de la Ec. 2.2. ğ¶0 = 0, ğ¶ğ‘–+1 = ğ¶ğ‘– + ğ´ğ‘–ğ›¼ğ‘–ğ‘ğ‘– ,, ğ´0 = 1, ğ´ğ‘–+1 = ğ´ğ‘–(1 âˆ’ ğ›¼ğ‘–âˆ’1), [Ec. 2.4] ğ¶ğ‘– y ğ´ğ‘– son el color y el factor de extinciÃ³n acumulado respectivamente, despuÃ©s de evaluar ğ‘– muestras [3]. El color final del pÃ­xel (ğ¶ğ‘›) es aquÃ©l que resulta de evaluar las ğ‘ muestras. CapÃ­tulo II 11 2.4.2 Back To Front Es el caso contrario de front to back; consiste en evaluar y acumular las muestras desde la mÃ¡s lejana a la mÃ¡s cercana esto puede expresarse iterativamente en la Ec. 2.5, ğ¶ğ‘› = 0, ğ¶ğ‘– = ğ›¼ğ‘–ğ‘ğ‘– + ğ¶ğ‘–+1(1 âˆ’ ğ›¼ğ‘–), [Ec. 2.5] donde ğ¶ğ‘– es el color acumulado cuando quedan ğ‘– muestras por evaluar. El color final pÃ­xelğ¶0 es aquel obtenido cuando no quedan muestras por evaluar. Se puede demostrar que ambos procedimientos son equivalentes [3]. 2.5 ClasificaciÃ³n de los Datos VolumÃ©tricos Para poder visualizar el volumen se requiere de la clasificaciÃ³n de los datos. Si estamos hablando de IVR, la clasificaciÃ³n se elige mediante un umbral para poder representar la superficie en el espacio 3D [2]. En el caso de DVR, a cada vÃ³xel se le asigna su emisiÃ³n ğ‘ y absorciÃ³n ğ‘¡, que se combinarÃ¡n adecuadamente para generar la imagen final. Estas propiedades pueden ser asignadas al volumen mediante segmentaciÃ³n del volumen en partes especÃ­ficas, o manipulando una funciÃ³n que tÃ­picamente es denominada funciÃ³n de transferencia [28]. Figura 2.5: Un volumen proyectado con diferentes valores en la funciÃ³n de transferencia da como resultado la visualizaciÃ³n de distintas partes del volumen. La funciÃ³n de transferencia asigna el valor ğ‘ y ğ‘¡ dependiendo del valor escalar de cada vÃ³xel en el volumen, dando como resultado un color (generalmente en formato ğ‘…ğºğµğ´) en cada muestra. Como podemos ver en la Figura 2.5 con la funciÃ³n de transferencia podemos CapÃ­tulo II 12 visualizar diferentes partes de un volumen asignÃ¡ndole un color especÃ­fico. Por lo general, se usan funciones de transferencia unidimensionales, que Ãºnicamente utilizan el valor del vÃ³xel para su clasificaciÃ³n. TambiÃ©n existen las funciones de transferencia multidimensionales, los cuales consideran entre otros parÃ¡metros a la normal del vÃ³xel; estas permiten resaltar las fronteras entre los distintos materiales del volumen, pero requieren un nivel de complejidad mayor en su ediciÃ³n [28]. Las funciones de transferencias unidimensionales son tÃ­picamente funciones lineales a trozos (Ver Figura 2.6), donde cada extremo de un trozo (punto de control) representa un color ğ‘…ğºğµğ´ con respecto al valor ğ‘  que contiene el de un vÃ³xel. El color y la absorciÃ³n de los vÃ³xeles que estÃ¡n entre un par de puntos de control son calculados mediante interpolaciÃ³n lineal por cada uno de los canales de color [4]. Figura 2.6: Los canales RGBA representan la coordenada ğ’š de la funciÃ³n, donde se puede apreciar que mientras mÃ¡s se aproxime a 0, mÃ¡s transparencia tiene el voxel. El eje ğ’™ representa el voxel ğ’” evaluado en ğ’”(ğ’™, ğ’š, ğ’›) dentro del volumen. Entre cada par de puntos en la funciÃ³n de transferencia se realiza una interpolaciÃ³n entre cada canal de color. En DVR, existen 3 tipos de clasificaciÃ³n de datos para el proceso de visualizaciÃ³n de volÃºmenes. Pre-ClasificaciÃ³n, Post-ClasificaciÃ³n y ClasificaciÃ³n Pre-Integrada. A continuaciÃ³n se definirÃ¡n cada una. 2.5.1 Pre-ClasificaciÃ³n La Pre-ClasificaciÃ³n aplica la funciÃ³n de transferencia a los vÃ³xeles del volumen antes de la interpolaciÃ³n entre sus muestras (como se observa en el trabajo [4] en la fase de reconstrucciÃ³n), asignando a cada vÃ³xel el valor ğ‘…ğºğµğ´ correspondiente de la funciÃ³n de CapÃ­tulo II 13 transferencia, dando como consecuencia la atenuaciÃ³n de las altas frecuencias en el despliegue final. 2.5.2 Post-ClasificaciÃ³n La Post-ClasificaciÃ³n aplica la funciÃ³n de transferencia despuÃ©s de realizar la interpolaciÃ³n de las muestras escalares del volumen. Mediante esta tÃ©cnica, se mantienen las altas frecuencias de la funciÃ³n de transferencia en la imagen final. La Pre y Post ClasificaciÃ³n producen diferentes resultados salvo cuando la funciÃ³n de transferencia es la funciÃ³n identidad, donde la interpolaciÃ³n de muestras puede conmutar con la funciÃ³n de transferencia [5]. Reescribiendo la Ec. 2.1 para post-clasificaciÃ³n, se obtiene: ğ¶ = âˆ« ğ‘ (ğ‘ (ğ‘¥(ğœ†))) ğ‘¡(ğ‘ (ğ‘¥(ğœ†)))ğ‘’âˆ’ âˆ« ğ‘¡(ğ‘ (ğ‘¥(ğœ† â€²)))ğ‘‘ğœ†â€² ğœ† 0 ğ· 0 ğ‘‘ğœ†, [Ec. 2.6] donde ğ‘¥(ğœ†) representa un punto (ğ‘¥, ğ‘¦, ğ‘§) a una distancia ğœ†, y ğ‘ (ğ‘¥(ğœ†)) es la muestra interpolada del volumen en el punto ğ‘¥(ğœ†). De esta forma, se puede aplicar la funciÃ³n de transferencia para obtener su color c y absorciÃ³n t [4]. Siguiendo la Ec. 2.6, se debe discretizar el rayo para evaluar la integral numÃ©ricamente. Para esto, el rayo es dividido en ğ‘› = [ğ·/â„] segmentos, con un paso fijo â„ (Ver Figura 2.7) [4]. Figura 2.7: Discretizando el rayo con un paso h. CapÃ­tulo II 14 Una vez discretizado el rayo, se puede ver la Ec. 2.6 como: ğ¶ â‰ˆ âˆ‘ âˆ« ğ‘ (ğ‘ (ğ‘¥(ğœ†))) ğ‘¡(ğ‘ (ğ‘¥(ğœ†)))ğ‘’âˆ’ âˆ« ğ‘¡(ğ‘ (ğ‘¥(ğœ† â€²)))ğ‘‘ğœ†â€² ğœ† 0 â„ğ‘– â„ğ‘–âˆ’1 ğ‘‘ğœ† ğ‘› ğ‘–=1 [Ec. 2.7] Asumiendo que ğ‘ (ğ‘¥(ğœ†)) es constante en cada integral, ğ‘ (ğ‘¥(ğœ†)) se sustituye por ğ‘†ğ‘–, y asumiento que la funciÃ³n de transferencia es lineal a trozos, la Ec. 2.7 se reescribe como: ğ¶ â‰ˆ âˆ‘ âˆ ğ‘’âˆ’â„ğ‘¡(ğ‘†ğ‘–)ğ‘(ğ‘†ğ‘–)(1 âˆ’ ğ‘’ âˆ’â„ğ‘¡(ğ‘†ğ‘–)) ğ‘–âˆ’1 ğ‘—=0 ğ‘›âˆ’1 ğ‘–=1 [Ec. 2.8] Si sustituimos ğ‘ğ‘–= ğ‘(ğ‘†ğ‘–) y ğ›¼ğ‘– = 1 âˆ’ ğ‘’ âˆ’â„ğ‘¡(ğ‘†ğ‘–) tenemos que: ğ¶ â‰ˆ âˆ‘ ğ›¼ğ‘–ğ‘ğ‘– âˆ(1 âˆ’ ğ›¼ğ‘—) ğ‘–âˆ’1 ğ‘—=0 ğ‘›âˆ’1 ğ‘–=1 [Ec. 2.9] Si se quiere estudiar todo el proceso de desarrollo de la ecuaciÃ³n del rayo de luz en el volumen, se puede consultar el trabajo de Carmona [4]. Podemos evaluar la Ec. 2.9 con el operador under iterativamente, tomando las muestras desde las mÃ¡s cercanas hasta las mÃ¡s lejanas del volumen [8] (front to back). La operaciÃ³n es definida de la siguiente manera: ğ‘ = (1 âˆ’ ğ›¼)ğ›¼ğ‘–ğ‘ğ‘– + ğ‘ ğ›¼ = (1 âˆ’ ğ›¼)ğ›¼ğ‘– + ğ›¼ [Ec. 2.10] En la Ec. 2.9 tambiÃ©n puede ser evaluada desde las muestras mÃ¡s lejanas hasta las mÃ¡s cercanas, con el operador over (back to front) [9]. De esta forma: ğ‘ = ğ›¼ğ‘–ğ‘ğ‘– + (1 âˆ’ ğ›¼)ğ‘ CapÃ­tulo II 15 ğ›¼ = ğ›¼ğ‘– + (1 âˆ’ ğ›¼ğ‘–)ğ›¼, [Ec. 2.11] donde ğ‘ y ğ›¼ son valores acumulativos iniciados en 0. El operador over es el mÃ¡s usado debido a que saca mayor provecho del hardware grÃ¡fico, texturizando polÃ­gonos y desplegÃ¡ndolos desde el corte mÃ¡s lejano hasta el mÃ¡s cercano. Como ejemplo, estas operaciones son definidas en OpenGL mediante la funciÃ³n glBlend [4]. 2.5.3 ClasificaciÃ³n Pre-Integrada Cuando aplicamos Post-ClasificaciÃ³n, en algunos casos, la cantidad de muestras procesadas en el rayo de visualizaciÃ³n no son suficientes para reproducir las altas frecuencias de la funciÃ³n de transferencia. En este caso podemos aumentar significativamente la frecuencia de muestreo para captar todos los detalles de la funciÃ³n de transferencia, dando como resultado una imagen mÃ¡s fidedigna, pero con un rendimiento inferior. La clasificaciÃ³n pre-integrada, a diferencia de los otros tipos de clasificaciÃ³n, no evalÃºa cada una de las muestras individualmente. Busca pre-clasificar a segmentos delimitados por pares de muestras ğ‘ ğ‘“ y ğ‘ ğ‘, en donde por cada segmento cuantizado [ğ‘ ğ‘“,ğ‘ ğ‘] se pre-calcula la integral del rayo y se almacena en una tabla bidimensional, donde posteriormente se puede acceder al color y a la opacidad dados los valores ğ‘ ğ‘“ y ğ‘ ğ‘ (Ver Figura 2.8). Una forma eficiente de poder guardar esta tabla es en una textura 2D. Si la distancia h (distancia entre cada par de muestras) no es la misma (Muestreo Adaptativo) [61] se requiere una textura 3D para almacenar la tabla de pre-integraciÃ³n. En el trabajo [4] se puede conseguir en detalle todo el proceso de despliegue de volÃºmenes con una funciÃ³n de transferencia Pre-Integrada. Con la clasificaciÃ³n Pre-Integrada podemos ver que la calidad del rendering aumenta considerablemente con un pequeÃ±o overhead de procesamiento [5]. CapÃ­tulo II 16 Figura 2.8: Despliegue de volÃºmenes utilizando clasificaciÃ³n pre-integrada. (a) RepresentarÃ­a el intervalo entre dos muestra en la funciÃ³n de transferencia. (b) son las integrales de cada canal (ğ‘¹ğ‘®ğ‘©ğ‘¨) entre todos los posibles pares de muestras ğ’”ğ’‡, ğ’”ğ’ƒ (c) Una ilustraciÃ³n de segmento de rayo cuyas muestras son ğ’”ğ’‡ y ğ’”ğ’ƒ. A continuaciÃ³n se mencionan las tÃ©cnicas mÃ¡s comunes para el despliegue del volumen, tanto basados en software, como acelerados por el hardware grÃ¡fico. 2.6 Algoritmos para la VisualizaciÃ³n de VolÃºmenes Los algoritmos mÃ¡s usados para el despliegue de volÃºmenes son Ray Casting, Splating y Shear-Warp a nivel de software, aunque en investigaciones recientes se ha demostrado que pueden ser acelerados por hardware grÃ¡ficos para mejorar el tiempo de respuesta. Las tÃ©cnicas aceleradas por hardware estÃ¡n basadas en texturizado de polÃ­gonos [4], en las cuales tenemos Planos Alineados al Objeto, Planos Alineados al Viewport y Spherical Shells. En todas estas tÃ©cnicas se pueden utilizar pre-clasificaciÃ³n, post-clasificaciÃ³n o clasificaciÃ³n pre-integrada para el despliegue del volumen. En este trabajo se describe Ãºnicamente la tÃ©cnica de Ray Casting, pues genera imÃ¡genes de gran calidad, y puede implementarse fÃ¡cilmente con aceleraciÃ³n de GPU [6]. 2.6.1 Ray Casting Este algoritmo bÃ¡sico de Ray Casting consiste en el lanzamiento de un rayo por cada pÃ­xel de la imagen final, desde el centro de proyecciÃ³n, atravesando el volumen, para evaluar la ecuaciÃ³n de composiciÃ³n volumÃ©trica (e.g. Ec. 2.9) directamente. Al discretizar un rayo, se deben obtener las muestras escalares del volumen a lo largo del rayo, lo que CapÃ­tulo II 17 requiere de interpolaciÃ³n entre vÃ³xeles para encontrar el valor de cada muestra. Las muestras clasificadas en ğ‘(ğœ†) y ğ‘¡(ğœ†) encontrados a lo largo del rayo se combinan para obtener la opacidad y el color del pÃ­xel. Las muestras dentro del rayo estÃ¡n distanciadas a una longitud constante â„, aunque puede ser variable al considerar el muestreo adaptativo [61]. El algoritmo de Ray Casting da como resultado una imagen de alta calidad pero presenta algunos inconvenientes. Entre estos estÃ¡ el problema de localidad espacial que se produce debido a que cuando se recorre el volumen en la direcciÃ³n del rayo estamos accediendo a posiciones no contiguas en memoria, aumentando el tiempo de respuesta de despliegue. Este algoritmo puede ser acelerado por las tÃ©cnicas de terminaciÃ³n temprana del rayo, muestreo adaptativo, entre otros [61]. Figura 2.9: Recorrido del rayo desde la coordenada de ojo hasta cada posiciÃ³n final del volumen a desplegar. Los puntos morados representan la entrada del rayo. El Ray Casting pude ser implementado tanto en software, como acelerada por hardware grÃ¡fico. Podemos ver en el trabajo [6] una tÃ©cnica que aprovecha el procesador de fragmentos del GPU para realizar el algoritmo. Este algoritmo se puede dividir en 3 pasos. En el primer paso se determina el punto de entrada del rayo (Ver Figura 2.9). Para esto se despliega el bounding box del volumen como un cubo cromÃ¡tico. Al desplegar las caras frontales y traseras de este cubo, se obtiene posiciÃ³n inicial y final de cada rayo. En el segundo paso se determina la direcciÃ³n de los rayos en el operador de fragmentos. Una vez que se tiene la direcciÃ³n del rayo, se procede a recorrer el volumen para generar el color final por cada fragmento (Ver Figura 2.10). CapÃ­tulo II 18 Figura 2.10: Ray Casting acelerado por GPU.(a) se rasterizan las caras frontales y traseras del cubo cromÃ¡tico, y considerando el volumen (b) como una textura 3D, y a la funciÃ³n de transferencia (c) como una textura 1D, se obtiene el resultado de Ray Casting en GPU en (d). En el Ã¡rea de visualizaciÃ³n de volÃºmenes, puede existir el caso de tener un dataset con miles de millones de datos, estos son conocidos como â€œVolumen de Gran TamaÃ±oâ€. Es por esto, que en el prÃ³ximo capÃ­tulo se procederÃ¡ a estudiar el despliegue de estos. 2.7 VolÃºmenes de gran tamaÃ±o En la actualidad existen dispositivos de captura de imÃ¡genes de gran resoluciÃ³n, que pueden llegar a generar un volumen extremadamente grande. El procesamiento de estos volÃºmenes requiere de un algoritmo de mayor complejidad en computadores convencionales, debido a que el volumen puede superar en tamaÃ±o a la memoria principal y no es soportado por el hardware grÃ¡fico en memoria de textura. Algunos de los algoritmos para el despliegue de volÃºmenes de gran tamaÃ±o serÃ¡n explicados a continuaciÃ³n en el documento, de los cuales tenemos la particiÃ³n del volumen, Ã¡rea de interÃ©s y tÃ©cnicas multi- resoluciÃ³n. Como ejemplos de estos volÃºmenes de gran resoluciÃ³n tenemos el proyecto del Humano Visible [10] y volÃºmenes obtenidos por simulaciones [11]. 2.8 Bricking Bricking (despliegue por ladrillos) es una de las tÃ©cnicas para desplegar un volumen de gran tamaÃ±o [4]. Consiste en particionar el volumen en pequeÃ±os sub-volÃºmenes llamados bricks (ladrillos), donde cada uno posee el mismo tamaÃ±o (Ver Figura 2.11). Para el despliegue se seleccionan tÃ­picamente los bricks desde el mÃ¡s lejano al mÃ¡s cercano en coordenadas de ojo, haciendo la composiciÃ³n de las muestras con el operador over. CapÃ­tulo II 19 Figura 2.11: TÃ©cnica de Bricking. El volumen es dividido en sub-volÃºmenes que son desplegados desde el mÃ¡s lejano al mÃ¡s cercano. El cubo morado representa uno de los sub-volÃºmenes. En esta tÃ©cnica, cada brick se despliega independientemente. Sin embargo, esta independencia puede traer problemas en las fronteras de los bricks, pues para una consistente interpolaciÃ³n se requiere de los vÃ³xeles frontera de bricks adyacentes. Debido a que un brick no tiene acceso a los bricks vecinos, se extiende el tamaÃ±o del brick para incluir los vÃ³xeles fronterizos de cada brick adyacente. Como consecuencia, el tamaÃ±o total del volumen aumenta y produce cierto overhead (sobrecarga) en memoria (Ver Figura 2.12). Figura 2.12: Los puntos azules representan los pÃ­xeles. Se puede observar cÃ³mo se comparte un vÃ³xel en la frontera entre los bricks A y B. Por simplicidad se muestran los bricks en una dimensiÃ³n. AdemÃ¡s de estas limitantes, tenemos tambiÃ©n que esta tÃ©cnica es muy poco prÃ¡ctica en tiempo real, debido a que se debe guardar en memoria principal cada uno de los bricks para subirlos a memoria de textura durante el rendering. Se sabe que el ancho de banda es limitado, y puede acarrear demoras en el tiempo de respuesta. 2.9 Volume Roaming TambiÃ©n conocida como despliegue de un Ã¡rea de interÃ©s, es una tÃ©cnica donde solo se selecciona para visualizar una zona especÃ­fica del volumen, no mayor al tamaÃ±o de memoria de textura [12][13]. Se puede seleccionar el Ã¡rea deseada de forma interactiva por el usuario, para luego ser cargada y procesada. El Ã¡rea de interÃ©s se especifica generalmente a travÃ©s de un cubo, un punto o corte del volumen. Se puede acotar que al cambiar el Ã¡rea CapÃ­tulo II 20 de interÃ©s, Ã©sta genera latencia en el despliegue, ya que se requiere de un nuevo sub- volumen en la memoria de textura. Para poder solucionar esto, se puede utilizar Bricking y coherencia frame to frame (cuadro a cuadro), ya que solo se cargan los nuevos bricks a ser desplegados y no todo un sub-volumen nuevo. 2.10 VisualizaciÃ³n de VolÃºmenes Multi-ResoluciÃ³n. Las tÃ©cnicas de despliegue de volÃºmenes de gran tamaÃ±o mÃ¡s utilizadas son las llamadas multi-resoluciÃ³n, en donde se despliegan distintas zonas del volumen con distinto nivel de detalle en base a una prioridad, que incluye la capacidad de memoria. Como podemos ver en la Figura 2.13 los pasos a seguir para el despliegue de volÃºmenes multi-resoluciÃ³n se pueden resumir en de la siguiente forma: almacenamiento del volumen, organizaciÃ³n en niveles de detalle, criterio de selecciÃ³n y despliegue del volumen. Figura 2.13: El proceso de despliegue de volÃºmenes utilizando tÃ©cnicas multi-resoluciÃ³n consta de:(a) cargar el volumen en memoria, (b) almacenar los datos en una estructura de datos y organizarlo en niveles de detalles, (c) seleccionar los niveles de detalles a desplegar, y (d) desplegar del volumen en forma de multi-resoluciÃ³n. 2.10.1 Almacenamiento del Volumen En la aplicaciÃ³n se debe almacenar el volumen de gran tamaÃ±o en una estructura de datos estable y eficiente para poder tener una visualizaciÃ³n en tiempo real. AdemÃ¡s debe soportar niveles de detalle. Entre los trabajos investigados se presentan principalmente dos jerarquÃ­as de almacenamiento del volumen: Octree (Ãrbol de ocho nodos hijos) [14] y Blocks (Bloques) [16] [17] [28]. CapÃ­tulo II 21 2.10.1.1 JerarquÃ­a Octree El volumen puede ser almacenado y organizado jerÃ¡rquicamente en una estructura de datos Octree [14][15], donde cada nivel del Ã¡rbol corresponde un nivel de detalle del volumen. Cada nodo del Ã¡rbol representa un brick del volumen a un determinado nivel de detalle. Los nodos hoja representan el nivel mÃ¡s fino de detalle, y los nodos internos se obtienen mediante la reducciÃ³n del nivel de detalle de sus hijos (Ver Figura 2.14). Figura 2.14: El volumen puede ser representado en un nivel de detalle burdo con un solo nodo del Ã¡rbol Octree (a) o desplegando cada uno de los posibles cortes del Octree (b), donde cada nivel del Ã¡rbol corresponde a un nivel de detalle del volumen. ğ’ğ’Šrepresenta el nivel del Ã¡rbol. Los nodos hojas representan el nivel mÃ¡s fino de detalle. 2.10.1.2 JerarquÃ­a por bloques El volumen original se particiona inicialmente en bloques. Luego, cada bloque independientemente se sub-muestrea iterativamente generando todos sus niveles de detalle, hasta obtener el tamaÃ±o de bloque mÃ¡s pequeÃ±o que por lo general es 1x1x1 [16][17]. Para la visualizaciÃ³n, el nivel de detalle que se le asigna a cada bloque es establecido a travÃ©s de un conjunto de parÃ¡metros del criterio de selecciÃ³n. La ventaja de usar bloques, en comparaciÃ³n con Octree, es que los recorridos en la estructura de datos son mÃ¡s simples, y logra un particionamiento mÃ¡s fino en el volumen. En esta jerarquÃ­a, la cantidad de vÃ³xeles que tiene un bloque varÃ­a segÃºn el nivel de detalle (Ver Figura 2.15). Por el contrario, en la estructura del Octree, todos los bricks poseen la misma cantidad de vÃ³xeles en todos los niveles del Ã¡rbol, pero representando Ã¡reas de distintos tamaÃ±os dentro del volumen. CapÃ­tulo II 22 Figura 2.15: Ejemplo de una jerarquÃ­a por bloques. En un primer nivel tenemos la subdivisiÃ³n en bloques del volumen, seguido se muestra los vÃ³xeles de un bloque y tres niveles de detalles locales al bloque. Tenemos que cada bloque de la estructura es independiente de los demÃ¡s bloques, exceptuando la necesidad de compartir vÃ³xeles vecinos en las fronteras de cada bloque. En la selecciÃ³n del LOD (level of detail o nivel de detalle), a cada bloque se le asigna una resoluciÃ³n independiente del resto de los bloques. En cambio, la jerarquÃ­a Octree no maneja los cambios de LOD por bricks, sino jerÃ¡rquicamente por Ã¡reas representadas en la estructura de datos. Para poder explicar de una forma sencilla el proceso por el cual se genera un bloque, se representarÃ¡ Ã©sta en una estructura unidimensional en la Figura 2.16. Cuando se quieren generar todos los bloques en un volumen, se deben generar los LOD y almacenar cada uno de estos. Supongamos que el tamaÃ±o del bloque original es ğ‘› = 2ğ‘˜, para generar los siguientes bloques se debe ir dividiendo el tamaÃ±o en ğ‘› 2 , ğ‘› 4 , â€¦ y asÃ­ sucesivamente hasta llegar al nivel de detalle donde un bloque ocupa un solo vÃ³xel, teniendo ğ‘˜ + 1 LOD. Figura 2.16: Un ejemplo de los niveles de detalles de un bloque 1D. La parte gris representa el Ã¡rea de la interpolaciÃ³n. El nivel 0 representa a la textura original y el 4 es el nivel de detalle mÃ¡s burdo. AsÃ­, cada vÃ³xel de un nivel de detalle representa dos vÃ³xeles de su nivel de detalle superior. En la Figura 2.16 se puede ver por cada nivel de detalle el dominio de interpolaciÃ³n el cual representa el bloque, en donde las fronteras que representan el dominio de CapÃ­tulo II 23 interpolaciÃ³n toman medio pÃ­xel de tamaÃ±o, ya que necesita el pÃ­xel de frontera del vecino para poder realizar la interpolaciÃ³n. A nivel lÃ³gico, cada bloque representa el mismo espacio dentro del volumen. Lo que varÃ­a es la cantidad de pÃ­xeles de cada nivel, ocupando menos memoria para el despliegue. Por esta razÃ³n, basÃ¡ndonos en la Figura 2.16, hay que escalar cada uno de los bloques normalizando el dominio de interpolaciÃ³n en un rango de [ 1 2ğ‘› , 1 âˆ’ 1 2ğ‘› ], donde ğ‘› es el nÃºmero de pÃ­xeles en el nivel de detalle. En la Figura 2.17, se puede ver cÃ³mo se lleva a cabo este proceso, dando como consecuencia que un pÃ­xel de un nivel de detalle es representado por mÃ¡s de dos pÃ­xeles del nivel de detalle superior, teniendo que generar un filtro muy complejo. Figura 2.17: Niveles de detalles alineados al dominio de interpolaciÃ³n, por cada pÃ­xel del nivel de detalle intervienen ğŸ o ğŸ‘ pÃ­xeles del nivel de detalles ğ’… âˆ’ ğŸ. Este problema de gran complejidad se puede resolver si alineamos los bloques agregando un pÃ­xel de holgura. La resoluciÃ³n de un nivel de detalle ğ‘‘, no es exactamente la mitad del nivel de detalle ğ‘‘ âˆ’ 1. ğ‘¡ğ‘ğ‘šğ‘ğ‘–ğ‘£ğ‘’ğ‘™(ğ‘–, ğ‘›) = (ğ‘› ğ‘‘ğ‘–ğ‘£ 2ğ‘– + 1)3 [Ec. 2.12] Figura 2.18: Niveles de detalle agregando un pÃ­xel de holgura por cada nivel de detalle. CapÃ­tulo II 24 Tenemos en la Figura 2.18 que cada pÃ­xel del nivel ğ‘‘ cubre un Ã¡rea de 2 pÃ­xeles del nivel ğ‘‘ âˆ’ 1: el pÃ­xel central y dos medios pÃ­xeles (ver Ã¡rea grises). Los niveles 0, 1, 2 ğ‘¦ 3 tienen 17, 9, 5, 3 pÃ­xeles respectivamente. Siguiendo la Ec. 2.12, en cada nivel de detalle ğ‘‘ se utiliza el pÃ­xel de holgura (ver Ã¡reas azules) para alinear los dominios de interpolaciÃ³n entre los niveles de detalle, y adicionalmente es compartido con el primer pÃ­xel del siguiente bloque para el proceso de interpolaciÃ³n entre vecinos. A pesar de que esta soluciÃ³n no requiere de muchos cÃ¡lculos, se debe utilizar un pÃ­xel de holgura en cada nivel de detalle en el caso 1D. Para el caso 3D, se puede ver en la Ec. 2.13 que se requieren de 3 âˆ— ğ‘›2 + 3 âˆ— ğ‘› + 1 vÃ³xeles de holgura por cada bloque. (ğ‘› + 1)3 âˆ’ ğ‘›3 = (ğ‘›3 + 3 âˆ— ğ‘›2 + 3 âˆ— ğ‘› + 1) âˆ’ ğ‘›3 = 3 âˆ— ğ‘›2 + 3 âˆ— ğ‘› + 1 [Ec. 2.13] Entonces, si tenemos un bloque de 323 vÃ³xeles, se requieren 3 âˆ— 322 + 3 âˆ— 32 + 1 = 3169 vÃ³xeles de holgura para el nivel de detalle mÃ¡s fino. Haciendo analogÃ­a, para un bloque de 163, tendrÃ­amos 817 vÃ³xeles de holgura, para uno de 83, 217 de holgura, y asÃ­ sucesivamente. Sumando los vÃ³xeles de holgura para todos los niveles de detalle de un bloque, se obtiene 4290 vÃ³xeles ocupando un 27% de memoria adicional [28]. K. LÃ³pez utilizÃ³ Ãºnicamente el pÃ­xel central del nivel mÃ¡s fino sin aplicar ningÃºn tipo de filtro (ver Figura 2.18). El objetivo de utilizar solo el pÃ­xel central es evitar la perturbaciÃ³n de los datos, ya que si se observa la Figura 2.19a el pÃ­xel central perdiÃ³ su intensidad original cuando se mezclÃ³ con sus vecinos. Como consecuencia obtenemos un cambio en los datos provocando una clasificaciÃ³n errÃ³nea al momento de aplicar la funciÃ³n de transferencia. Este problema se puede observar con mayor frecuencia entre los contornos de algÃºn objeto. Por eso al no mezclar con los vecinos, como en la Figura 2.19b, en el proceso de filtrado no se perturbarÃ­an los datos originales. CapÃ­tulo II 25 Figura 2.19: En la figura (a) se puede observar la generaciÃ³n de los niveles de detalle considerando los 3 pÃ­xeles que intervienen en el solapamiento. En la figura (b) los niveles de detalles son generados considerando solamente el pÃ­xel central. Observe como la intensidad del pÃ­xel central fue perdido por completo en la figura (a) [28]. Ljung et. al [26] genera los bloques sin descartar el medio pÃ­xel en los bordes del dominio de interpolaciÃ³n. Esto es asÃ­ ya que proponen un algoritmo para la interpolaciÃ³n de bloques entre fronteras, para evitar la redundancia de datos en la memoria Este algoritmo se divide en 2 etapas: en la primera etapa se despliegan de manera convencional los vÃ³xeles que no forman parte de la frontera del bloque. En la segunda etapa, se despliegan los vÃ³xeles que estÃ¡n en la frontera usando la interpolaciÃ³n entre bloques. Con esta tÃ©cnica se le asigna un peso a cada uno de los bordes del bloque para hallar los pesos de cada bloque vecino. Con los pesos de los bloques ğœ”ğ‘ y las muestras de cada bloque vecino ğœ‘ğ‘ podemos hallar el valor ğœ‘ para generar la interpolaciÃ³n entre bloques. Para generar los niveles de detalles (Figura 2.8), Ljung et. al. [26] utiliza dos (2) pÃ­xeles en vez del pÃ­xel central y 2 medio pÃ­xeles de los pÃ­xel adyacentes ya que el dominio de interpolaciÃ³n no descarta los medio pÃ­xeles de las fronteras. Figura 2.20: Niveles de detalle agregando un pÃ­xel de holgura por cada nivel de detalle. CapÃ­tulo II 26 Una vez generados y cargados todos los bloques en memoria, se procederÃ¡ a seleccionar los niveles de detalle aplicando un algoritmo de selecciÃ³n. 2.10.2 Criterio de SelecciÃ³n DespuÃ©s de almacenar el volumen en memoria y dividirlo en niveles de detalle, se debe seleccionar la resoluciÃ³n de cada Ã¡rea del volumen a desplegar. Los criterios que se deben tomar para seleccionar el nivel de detalle adecuado se indican mediante parÃ¡metros de visualizaciÃ³n, como la distancia a un punto de interÃ©s, o a una regiÃ³n de interÃ©s. Otros criterios de selecciÃ³n son basados en los datos, como la distorsiÃ³n de representar un Ã¡rea del volumen con un determinado nivel de detalle, la homogeneidad del brick, entre otros. Se debe tomar en cuenta las limitaciones del hardware para poder realizar este proceso, debido a que puede acaparar tiempo de cÃ³mputo necesario para hacer otras tareas como el despliegue. TambiÃ©n se debe tener un mayor refinamiento de las Ã¡reas con mayor interÃ©s, sin perder tanta informaciÃ³n del resto del volumen. A continuaciÃ³n se presentan trabajos donde explican las diferentes formas de realizar el criterio de selecciÃ³n. LaMar et al. [19]realizaron la selecciÃ³n mediante dos aspectos, basado en la distancia con respecto a un punto de interÃ©s y la relaciÃ³n entre el Ã¡ngulo de visiÃ³n y el Ã¡ngulo que genera la diagonal proyectada del brick. El algoritmo es recorrido en pre-orden; si el nodo esta fuera de la pirÃ¡mide de visualizaciÃ³n, no se despliega, en caso contrario, se despliega cumpliendo las siguientes condiciones (Ver Figura 2.21): ï‚· La distancia desde el punto de interÃ©s al centro del brick debe ser mayor que la diagonal del brick, y el Ã¡ngulo proyectado tiene que ser menor que la mitad del Ã¡ngulo de visiÃ³n. ï‚· Se alcance un nodo hoja, ya que se alcanza el nivel de detalle con mayor resoluciÃ³n. CapÃ­tulo II 27 Figura 2.21: Criterio de selecciÃ³n basÃ¡ndose en la distancia al punto de interÃ©s y el Ã¡ngulo de proyecciÃ³n del brick. En la imagen (a) se puede ver una representaciÃ³n de lo que serÃ­a un Octree en 2D. En este ejemplo, se seleccionaron sÃ³lo 34 bricks, cuando su representaciÃ³n mÃ¡s fina es de 256 bricks. En la imagen (b) se puede ilustrar la representaciÃ³n del Ã¡ngulo proyectado del brick ğœ· y Ã¡ngulo de visiÃ³n ğœ¶. Boada et al. [20] proponen darle importancia a las regiones de interÃ©s del volumen, asÃ­ como la homogeneidad del brick y al tamaÃ±o de memoria de textura. Se debe subdividir el volumen con el propÃ³sito de maximizar la obtenciÃ³n de los bloques homogÃ©neos de mayor tamaÃ±o. Esto es para disminuir la cantidad de polÃ­gonos en el despliegue. Las Ã¡reas no homogÃ©neas se representan con distintos niveles de detalles. Para el despliegue, se toman en cuenta un valor de predicciÃ³n de la velocidad de despliegue del bloque, la opacidad del mismo, la distancia al ojo y el tamaÃ±o del bloque proyectado. Guthe et al. [21]limitan la cantidad de bloques a ser desplegados en memoria de textura. Para esto se usa una cola de prioridad, donde se almacenan los bloques a memoria de textura. La prioridad ğ‘ƒ es otorgada a los bloques mÃ¡s cercanos al ojo ğ‘ y la medida de error del bloque ğ¸ (distorsiÃ³n), para tener la prioridad del bloque ğ‘ como ğ‘ƒ(ğ‘) = ğ¸(ğ‘)/ğ‘(ğ‘). El brick con mayor prioridad es reemplazado por sus hijos. Este proceso es realizado hasta alcanzar el nivel de detalle mÃ¡s fino o llenar al tope la capacidad de memoria de textura El error es recalculado cada vez que cambia la funciÃ³n de transferencia. Plate et al. [22]toma en cuenta la cantidad de bricks que se pueden cargar por cada frame, asÃ­ como la capacidad de memoria de textura. Los bricks adyacentes que se seleccionan pueden diferir mÃ¡ximo en un nivel de detalle, teniendo como posiciÃ³n inicial las coordenadas del ojo. Usando coherencia frame to frame, se determina cuantos bricks serÃ¡n cargados entre cada frame, con la finalidad de cargar los niveles mÃ¡s burdos primero, para luego ir refinando hasta alcanzar el umbral deseado que no exceda la capacidad de la memoria de textura. CapÃ­tulo II 28 Carmona [4] utiliza un algoritmo denominado Split-and-Collapse, un algoritmo voraz incremental en el campo de visualizaciÃ³n de volÃºmenes multi-resoluciÃ³n, el cual utiliza coherencia frame to frame para actualizar la representaciÃ³n multi-resoluciÃ³n del volumen. Usa una funciÃ³n de prioridad, que indica la prÃ³xima operaciÃ³n a refinar Split (dividir) y reducciÃ³n Collapse (colapso) a ejecutar para lograr la representaciÃ³n deseada. Cabe acotar que la cantidad de bricks que se transfieren al GPU en un frame dependerÃ¡n del ancho de banda requerido. En este trabajo se consideran diversos parÃ¡metros para el criterio de selecciÃ³n, tales como la distancia al punto o Ã¡rea de interÃ©s, la distancia a la coordenada de ojo, la distorsiÃ³n multi-resoluciÃ³n de los vÃ³xeles clasificados y limitaciones de hardware tales como ancho de banda o capacidad de memoria de textura. Carmona [4] desarrollÃ³ en su trabajo un algoritmo Ã³ptimo para determinar la selecciÃ³n con mÃ­nimo error. A pesar de requerir mucho tiempo de cÃ³mputo, se utilizÃ³ para demostrar que su algoritmo voraz genera resultados cercanos al Ã³ptimo. K. LÃ³pez [28] utilizÃ³ como criterio de selecciÃ³n la distancia con respecto a un punto de interÃ©s, la distorsiÃ³n de los niveles de detalles considerando la funciÃ³n de transferencia y la uniÃ³n de ambos. En un inicio los bloques son colocados en una cola de prioridad con el menor nivel de detalle. Los bloques se ordenan segÃºn una prioridad, que puede basarse en la distorsiÃ³n y/o distancia al punto de interÃ©s. Luego, se aplica un proceso de refinamiento el cual consiste en extraer el primer bloque de la cola, subirle un nivel de detalle y reinsertarlo en la cola segÃºn su nueva prioridad. Este proceso es realizado hasta que se agote el espacio de la textura atlas o hasta que el volumen quede totalmente refinado. K. LÃ³pez [28] implementÃ³ un refinamiento frame to frame (cuadro a cuadro) similar al trabajo realizado por R. Carmona [4]. Es posible aplicar la uniÃ³n de los criterios de distorsiÃ³n y distancia al punto de interÃ©s, pero hay que considerar que la distorsiÃ³n es proporcional a la prioridad, mientras que la distancia es inversamente proporcional. AsÃ­, la ecuaciÃ³n que mezcla ambos criterios es descrita en la Ec. 2.14: ğ‘ğ‘Ÿğ‘–ğ‘œğ‘Ÿğ‘–ğ‘‘ğ‘ğ‘‘ = ğ‘‘ğ‘–ğ‘ ğ‘¡ğ‘ğ‘›ğ‘ğ‘–ğ‘ + ğ‘‘ğ‘–ğ‘ğ‘” ğ‘‘ğ‘–ğ‘ ğ‘¡ğ‘œğ‘Ÿğ‘ ğ‘–Ã³ğ‘› [Ec. 2.14] CapÃ­tulo II 29 Figura 2.21: En esta imagen se puede observar como a medida que transcurre el tiempo, el volumen va siendo refinado [28]. En todos estos trabajos mencionados anteriormente, se genera una visualizaciÃ³n multi- resoluciÃ³n del volumen, pero se generan muchos artefactos entre niveles de detalle. Por lo tanto, se deben desarrollar nuevas tÃ©cnicas para minimizar los artefactos en estos volÃºmenes. A continuaciÃ³n se explicarÃ¡ con detalles como hacer el cÃ¡lculo de las medidas de error para seleccionar los bricks con determinado nivel de detalle. 2.10.3 MÃ©tricas de Error Estas mÃ©tricas se utilizan para determinar la correcta selecciÃ³n de los niveles de detalles del brick. EstÃ¡n determinadas por varios parÃ¡metros, basado por los datos, en donde se mide la distorsiÃ³n de los datos del volumen, basado en la imagen, que intenta captar la calidad perdida en la imagen final que percibe el usuario, y basado en la distancia a un punto de interÃ©s donde se da prioridad a los bricks mÃ¡s cercanos al punto. 2.10.4 MÃ©tricas Basadas en la Distancia En este Trabajo Especial de Grado, se implementarÃ¡ la mÃ©trica basada en la distancia. A continuaciÃ³n se describen trabajos donde explican las diferentes formas de calcular las mÃ©tricas de distancia. CapÃ­tulo II 30 Carmona [4] considera la distancia al ojo, el nÃºmero de bricks, nivel de detalle y la distancia a un punto o a un Ã¡rea de interÃ©s. La funciÃ³n de prioridad ha sido definida de manera tal que: prioritize los bricks cercanos al punto de interÃ©s o Ã¡rea de interÃ©s, penalice la diferencia en nivel de detalle entre bricks adyacentes y priorice mÃ¡s suavemente a los bricks mÃ¡s cercanos al ojo, puesto que la prioridad principal es la distancia al punto o Ã¡rea de interÃ©s. Figura 2.22: Criterio de selecciÃ³n basado en colas de prioridades. El valor de d(x,y)=distancia(x,y) representa la distancia del centro de brick x al objeto y, que puede ser el punto de interÃ©s o el lens o cubo de interÃ©s, o el ojo En la Figura 2.22 se muestran los volÃºmenes resultantes, dependiendo de la ecuaciÃ³n de mÃ©trica de distancia utilizada. Aceptables resultados han sido obtenidos mediante la siguiente funciÃ³n de penalizaciÃ³n. ğ‘ƒ(ğ‘¥) = (2 âˆ— ğ‘‘ğ‘–ğ‘ ğ‘¡ğ‘ğ‘›ğ‘ğ‘–ğ‘(ğ‘¥, ğ‘–ğ‘) + ğ‘‘ğ‘–ğ‘ ğ‘¡ğ‘ğ‘›ğ‘ğ‘–ğ‘(ğ‘¥, ğ‘œğ‘—ğ‘œ)) âˆ— ğ‘›ğ‘–ğ‘£ğ‘’ğ‘™(ğ‘¥) [Ec. 2.15] en donde ğ‘‘ğ‘–ğ‘ ğ‘¡ğ‘ğ‘›ğ‘ğ‘–ğ‘(ğ‘¥, ğ‘¦) es la distancia euclÃ­dea entre el centro del brick ğ‘¥ y el objeto ğ‘¦, y ğ‘›ğ‘–ğ‘£ğ‘’ğ‘™(ğ‘¥) es el nivel del brick ğ‘¥ en el Octree (0 para el nodo raÃ­z que representa el nivel de CapÃ­tulo II 31 detalle mÃ¡s burdo). A menor penalizaciÃ³n ğ‘ƒ(ğ‘¥) mayor prioridad de refinar un brick ğ‘¥. Observe que los criterios (Figura 2.22.a) y (Figura 2.22.c) estÃ¡n reflejados en los tÃ©rminos 2 âˆ— ğ‘‘ğ‘–ğ‘ ğ‘¡ğ‘ğ‘›ğ‘ğ‘–ğ‘(ğ‘¥, ğ‘–ğ‘) y ğ‘‘ğ‘–ğ‘ ğ‘¡ğ‘ğ‘›ğ‘ğ‘–ğ‘(ğ‘¥, ğ‘œğ‘—ğ‘œ), mientras que la diferencia de nivel de detalle en la multiplicaciÃ³n por ğ‘›ğ‘–ğ‘£ğ‘’ğ‘™(ğ‘¥). K. LÃ³pez [28] considera que la prioridad de los bloques de menor resoluciÃ³n viene dada por la suma de la diagonal del bloque a dicha distancia (ver Figura 2.23). Debemos tener en cuenta que la diagonal es calculada en funciÃ³n al nÃºmero de vÃ³xeles del bloque. Figura 2.23: En la imagen se puede observar que la suma ğ’…ğ’Šğ’‚ğ’ˆğŸ + ğ’…ğŸ > ğ’…ğ’Šğ’‚ğ’ˆğŸ + ğ’…ğŸ, por lo tanto el bloque 2 tendrÃ¡ mayor prioridad de refinamiento [28]. 2.10.5 Proceso de Rendering Para visualizar el volumen es necesario pasar por un proceso del despliegue el cual consiste en desplegar los datos que han sido seleccionados de manera ordenada. Luego, se aplica alguna tÃ©cnica de visualizaciÃ³n de volÃºmenes, (ver SecciÃ³n 2.6). Existen varias formas de desplegar el volumen, entre las mÃ¡s usada se tiene el despliegue individual de cada brick (pero mezclÃ¡ndose en el bÃºfer de color) [4] y el despliegue en una sola pasada [28]. Se puede mejorar su desempeÃ±o aplicando tÃ©cnicas como terminaciÃ³n temprana del rayo y saltos de espacios vacÃ­os [61] [28]. Lux et al. [32] implementaron una forma diferente de almacenar el conjunto de texturas multi-resoluciÃ³n, al cual llamaron â€œAtlasâ€. Su sistema estÃ¡ basado en un (BSP) Binary Space Partitioning (Particionamiento de Espacio Binario) para realizar el despliegue de varios volÃºmenes en una misma escena, utilizando una jerarquÃ­a Octree para cada uno CapÃ­tulo II 32 de los volÃºmenes. Se construye una textura la cual es almacenada en el GPU (Atlas). En ella se organizan todos los bricks de los volÃºmenes seleccionados para el despliegue. Adicionalmente, crean un Ã­ndice para identificar en quÃ© posiciÃ³n del atlas se encuentra cada brick (ver Figura 2.24). Posteriormente utilizaron el algoritmo de Ray Casting basado en GPU, aplicando algunos ajustes para la visualizaciÃ³n de varios volÃºmenes al mismo tiempo. Figura 2.24: Atlas. Debemos recordar que en una jerarquÃ­a Octree cada brick ocupa el mismo tamaÃ±o en memoria, sin importar el nivel de detalle que tenga. Por lo tanto no va haber fragmentaciÃ³n en la memoria de textura ni en la memoria principal a la hora de reemplazar los bricks. K. LÃ³pez [28] adaptÃ³ el esquema propuesto por Lux et al. [39] a una jerarquÃ­a por bloques para generar la textura Atlas para el proceso de visualizaciÃ³n. Este mÃ©todo consiste en tener los bloques que se van a mostrar almacenados en una sola textura e indexarlas en otra textura de Ã­ndices (ver Figura 2.25). CapÃ­tulo II 33 Figura 2.25: Cada vÃ³xel de la textura de Ã­ndices tiene una tupla RGBA (ğ’‘ğ’™, ğ’‘ğ’š, ğ’‘ğ’›, ğ’ğ’ğ’…). Utilizando una representaciÃ³n 2D se puede observar la interacciÃ³n entre la textura de Ã­ndice y el atlas en cada paso del rayo. La dimensiÃ³n de la textura de Ã­ndices viene dada por: ğ‘†(ğ‘‡ğ‘–ğ‘›ğ‘‘ğ‘–ğ‘ğ‘’) = ([ ğ‘†ğ‘¥ âˆ’ 1 ğ‘› âˆ’ 1 ] , [ ğ‘†ğ‘¦ âˆ’ 1 ğ‘› âˆ’ 1 ] , [ ğ‘†ğ‘§ âˆ’ 1 ğ‘› âˆ’ 1 ]), [Ec. 2.16] donde ğ‘†ğ‘¥, ğ‘†ğ‘¦ y ğ‘†ğ‘§ es el tamaÃ±o del volumen y ğ‘› es el tamaÃ±o que va a tener el bloque de mayor nivel de detalle. Una vez que todos los bloques son almacenados en la textura de atlas e indexados mediante la textura de Ã­ndices, se realiza un Ray Casting de la textura de Ã­ndices para recorrer adecuadamente la textura de atlas. Para realizar el Ray Casting, se le aplica la textura de Ã­ndices a un cubo unitario y se despliegan las caras frontales para obtener el punto de entrada de cada rayo en el volumen [6]. La importancia de este mÃ©todo de visualizaciÃ³n radica en que sÃ³lo se necesita realizar una pasada del Ray Casting para visualizar todo el volumen multi-resoluciÃ³n. Para administrar el espacio de la textura atlas se generÃ³ un algoritmo bÃ¡sico que consiste en dividir la misma en distintas Ã¡reas dependiendo de los requerimientos del criterio de selecciÃ³n. Cuando se refina un bloque se reserva un espacio de memoria con la dimensiÃ³n del nuevo nivel de detalle y se libera el espacio utilizado por el nivel burdo. Este algoritmo tiene como desventaja la fragmentaciÃ³n de la memoria Atlas que se genera a CapÃ­tulo II 34 medida que cambian los niveles de detalles. Como consecuencia se desaprovecha el espacio disponible por la desorganizaciÃ³n de las Ã¡reas pequeÃ±as que surgen de la subdivisiÃ³n. Como se puede observar hay distintas formas de realizar el despliegue de volÃºmenes multi-resoluciÃ³n. SÃ³lo hay que tener en cuenta cuÃ¡les son los resultados esperados y saber que cada tÃ©cnica tiene sus requerimientos de procesamiento que genera distintos tiempos de respuesta. Adicionalmente, la calidad de los resultados finales puede variar de tÃ©cnica a tÃ©cnica. Siguiendo con el punto anterior, se explicarÃ¡ a continuaciÃ³n cÃ³mo se fragmenta la textura atlas, cuando se utiliza una jerarquÃ­a multi-resoluciÃ³n por bloques. 2.11 FragmentaciÃ³n del Atlas En la Figura 2.26 se puede ver con claridad la fragmentaciÃ³n que genera el algoritmo anteriormente descrito. AdemÃ¡s, se puede observar que los espacios liberados por el refinamiento de bloques pasan a ser inutilizados si no hay mÃ¡s bloques por refinar que puedan ser almacenados en ese espacio disponible. Figura 2.26: Proceso de inserciÃ³n y refinamiento de los bloques en la textura Atlas. En la regiÃ³n roja se pueden notar las Ã¡reas que son demasiado pequeÃ±as como para almacenar un bloque. En cada subdivisiÃ³n se generan 2 nuevas Ã¡reas vacÃ­as, en el caso 3D se generarÃ­an 3 nuevas Ã¡reas. K. LÃ³pez [28] desarrollÃ³ este mÃ©todo partiendo de la siguiente premisa, si el volumen multi-resoluciÃ³n no pudo ser refinado por completo y el atlas tiene espacio disponible pero fragmentado, se realiza un borrado y reinserciÃ³n de todos los bloques, reagrupando los CapÃ­tulo II 35 bloques por orden de tamaÃ±o de manera descendente (del mÃ¡s grande al mÃ¡s pequeÃ±o). Posteriormente se continÃºa con el proceso de refinamiento. Esto se repite hasta que la cantidad de bloques que no pudieron ser refinados sea igual antes y despuÃ©s de una desfragmentaciÃ³n (ver Figura 2.27). El problema de esta tÃ©cnica radica en que se cada vez que se realiza un borrado y reinserciÃ³n de todos los bloques, se hace un uso excesivo del ancho de banda de la memoria de textura y genera ineficiencia en el despliegue. Figura 2.27: En la primera imagen podemos observar que no hay espacio suficiente para poder refinar mÃ¡s los bloques que tienen mayor tamaÃ±o. Aplicando el algoritmo de desfragmentaciÃ³n note que se acoplan los bloques permitiendo utilizar mejor el espacio restante del atlas y refinar mÃ¡s bloques. Las lÃ­neas de colores punteadas indican que bloques se han refinado luego de aplicar el algoritmo de desfragmentaciÃ³n. 2.12 JerarquÃ­a de Memoria de Textura en GPU Un factor importante que afecta al rendimiento de la GPU es el tiempo de acceso a los datos [43]. Por esto, es muy importante la gestiÃ³n de memoria en las tarjetas grÃ¡ficas de forma estructurada, eficiente y eficaz. Las jerarquÃ­as de memorias de las GPUâ€™s varÃ­an segÃºn el fabricante y el modelo de la tarjeta grÃ¡fica, asÃ­ que se procederÃ¡ a explicar de forma general por el fabricante Nvidia. Se deben tener en cuenta dos grandes aspectos en el manejo de memoria de textura: localidad espacial y el ancho de banda. La memoria de textura permite almacenar arreglos 1D de color RGBA, imÃ¡genes 2D, volÃºmenes 3D, etc. Estas texturas pueden tener distintas funciones, pueden servir para darle mayor realismo a cualquier aplicaciÃ³n grÃ¡fica, almacenar informaciÃ³n a ser procesada por el procesador de texturas, entre otros. Las tarjetas grÃ¡ficas requieren un manejo sencillo de estas texturas, para que se puedan realizar todo tipo de transformaciones de tamaÃ±o y forma, para poder aplicarlas en un modelo tridimensional, sin que se vea afectado negativamente su aspecto final. CapÃ­tulo II 36 AdemÃ¡s de almacenar un conjunto de valores de color RGBA, tambiÃ©n se pueden almacenar los valores de luz de cada punto de textura, estas son llamadas texturas planas. TambiÃ©n podemos usar los filtros que ofrece la tarjeta de video a nivel de hardware (ALUs) Arithmetic Logic Units (Unidades AritmÃ©ticas LÃ³gicas) para hacer cÃ¡lculo de redimensiones, filtrados de texturas, etc. Las librerÃ­as mÃ¡s usadas para el uso de texturas son OpenGL y Direct3D. Ahora se procederÃ¡ a explicar el manejo de texturas en OpenGL. 2.13 Usando Memoria de Textura con OpenGL Hoy en dÃ­a en los sistemas donde interviene el pipeline grafico se estÃ¡ buscando un mayor realismo en la imagen final de una escena. Para esto, OpenGL ofrece una soluciÃ³n para mapear texturas en las primitivas grÃ¡ficas. Texture Mapping (Mapeo de Texturas) [44] tiene muchas funciones dentro de los sistemas grÃ¡ficos. Su funciÃ³n mÃ¡s comÃºn es mapear una imagen 2D a un conjunto de primitivas para dar una sensaciÃ³n mÃ¡s real al render. TambiÃ©n se pueden almacenar texturas 1D, que pueden ser usadas para almacenar un arreglo de colores en la memoria de textura, como por ejemplo la funciÃ³n de transferencia en Volume Rendering. Las texturas 3D tambiÃ©n pueden ser almacenadas con OpenGL, pudiendo almacenar un dataset (conjunto de datos) de algÃºn volumen. Para usar mapeo de textura, se pueden seguir los siguientes pasos: ï‚· Se crea un objeto del tipo texture (textura) y se especifica una textura para ese objeto. ï‚· Se indica cÃ³mo va a ser aplicada la textura por cada pÃ­xel y los filtros a usar. ï‚· Se habilita el mapeo de texturas. ï‚· Se dibuja la escena, indicando las coordenadas geomÃ©tricas y de textura. Para almacenar una imagen o un volumen en la memoria de textura, se usa la funciÃ³n ğ‘”ğ‘™ğ‘‡ğ‘’ğ‘¥ğ¼ğ‘šğ‘ğ‘”ğ‘’ğ‘¥ğ·(â€¦ ), donde ğ‘¥ğ· es para diferenciar entre una textura 1D, 2D o 3D. Entre los parÃ¡metros a pasar a esta funciÃ³n tenemos el tipo de textura, nivel de textura usado (para mÃºltiples resoluciones del mapeo de textura), formato de color de la textura, tamaÃ±o CapÃ­tulo II 37 del ancho y largo de la textura (por lo general debe ser en base a 2), el ancho del borde, el formato y el tipo de dato de los datos, y los pÃ­xeles de la imagen. Figura 2.28: Mapeo de Textura. TambiÃ©n tenemos otras funciones tales como ğ‘”ğ‘™ğ‘¢ğ‘†ğ‘ğ‘ğ‘™ğ‘’ğ¼ğ‘šğ‘ğ‘”ğ‘’(â€¦ ), para poder escalar el tamaÃ±o de la imagen, ğ‘”ğ‘™ğ¶ğ‘œğ‘ğ‘¦ğ‘‡ğ‘’ğ‘¥ğ¼ğ‘šğ‘ğ‘”ğ‘’ğ‘¥ğ·(â€¦ ), para crear una textura usando la data contenida en el Framebuffer para definir los tÃ©xeles. De la misma forma en la que se almacena el volumen en la memoria de textura, se puede tambiÃ©n modificar una parte de ella o reemplazarla. OpenGL define la funciÃ³n ğ‘”ğ‘™ğ‘‡ğ‘’ğ‘¥ğ‘†ğ‘¢ğ‘ğ¼ğ‘šğ‘ğ‘”ğ‘’ğ‘¥ğ·(â€¦ ) para este fin, que a diferencia de ğ‘”ğ‘™ğ‘‡ğ‘’ğ‘¥ğ¼ğ‘šğ‘ğ‘”ğ‘’ğ‘¥ğ·(â€¦ ), podemos remplazar toda la textura o una sub regiÃ³n de la misma, como se puede ver en la figura 2.28. Figura 2.28: Mapeo de textura por Sub-RegiÃ³n En la actualidad, debemos optimizar el espacio en la memoria de textura para poder tener un manejo mÃ¡s eficiente del mismo. Una forma de aprovechar el espacio es usando CapÃ­tulo II 38 texturas Atlas [45], en donde podemos combinar muchas imÃ¡genes dentro de una misma textura, evitando declarar una textura nueva por cada imagen, y como resultado acelera el proceso de render. Figura 2.29: Textura Atlas utilizadas para organizar un conjunto de texturas de forma eficiente. 2.14 Algoritmos de Empaquetamiento Se puede optimizar el espacio de la textura Atlas a travÃ©s de algoritmos de empaquetamiento, para poder insertar las imÃ¡genes en la textura minimizando el espacio inutilizado. Entre los algoritmos de empaquetamiento mÃ¡s usados, tenemos el algoritmo de Bin Packing (Empaquetamiento Binario) N-dimensional, un problema de optimizaciÃ³n combinatoria NP-duro, en donde tenemos unidades de elementos finitos, y el objetivo es empaquetar todos los elementos en el nÃºmero mÃ­nimo de contenedores. TambiÃ©n tenemos el algoritmo de Strip Packing (Empaquetamiento por tiras), en donde solo se tiene una sola unidad de anchura dada, y el objetivo es empaquetar todos los elementos dentro de una altura mÃ­nima. 2.14.1 Strip Packing Corman el al. [46] plantean que la mayorÃ­a de estos algoritmos son enfocados en shelf â€“ algoritms (Algoritmos de Estantes), los cuales hacen el proceso de empaquetamiento en filas, de izquierda a derecha, creando un conjunto de shelfs por niveles (En el caso de dos dimensiones). Para poder empaquetar los elementos, se tienen tres estrategias de inserciÃ³n en los shelfs (ver Figura 2.30): CapÃ­tulo II 39 (NFDH) Next-Fit Decreasing Height (Siguiente Ajuste de Altura Decreciente), en donde los elementos son empacados justificados en la izquierda del shelf actual, si encajan. En caso contrario, se crea un nuevo shelf y se ajusta el elemento a este. (FFDH) First-fit Decreasing Height (Primer Ajuste de Altura Decreciente), donde encajamos el elemento en el primer shelf en donde se ajuste. Si no se encuentra ningÃºn shelf, se procede a usar NFDH. (BFDH)Best-Fit Decreasing Height (Mejor Ajuste de Altura Decreciente), el elemento es empaquetado en donde encaje, donde el espacio horizontal sea el mÃ­nimo posible. Igual que FFDH, si no encaja en ningÃºn shelf, se usa NFDH. Figura 2.30: En el NFDH se tiene que si no encaja un estante, se crea uno nuevo del tamaÃ±o del nuevo objeto. En el FFDH se inserta en el primer shelf en donde encaje y en BFDH en donde mejor encajen. Se insertan en orden del 1 al 6. 2.14.2 Bin Packing Diversos autores han estudiado soluciones para resolver el problema de Bin Packing. Chung et al. [47] divide la soluciÃ³n en en dos fases, la primera en donde se usa el algoritmo (HFF) Hybrid First-Fit (Primer Ajuste HÃ­brido) que consiste en obtener un strip usando FFDH de la secciÃ³n anterior. En la segunda fase se procede a empaquetar los strips en conjuntos finitos de contenedores usando el algoritmo (FFD) First-Fit Decreacing (Primer Ajuste Decreciente), en donde se insertan cada uno de estos en el primer lugar que encajen en orden decreciente en los contenedores. Lo mismo se puede aplicar con los algoritmos NFDH y BFDH. CapÃ­tulo II 40 Berkey y Wang [48]se basaron en HFF (ver Figura 2.31) para crear un algoritmo de dos fases llamado (FBS) Finite Best-Strip (Mejor Tira Finita), donde llevan a cabo como primera fase el algoritmo BFDH, y como segunda fase se utiliza un algoritmo de mejor ajuste decreciente: se inserta el estante actual en un contenedor de mayor tamaÃ±o (si existe), donde quepa y donde el espacio vertical inutilizado sea el menor, o se crea un nuevo contenedor para insertar el estante. Figura 2.31: HFF Otra estrategia del tipo shelf packing se basa en la soluciÃ³n adoptada en el problema de la mochila (KP) Knapsack Packing (Empaquetamiento por Mochila) propuesto por Lodi et al. [49]. En un problema tradicional del mochilero se tiene que seleccionar un sub- conjunto de ğ‘› elementos, cada uno tiene un beneficio y peso, por lo que el peso total no exceda la capacidad y ganancia total sea mÃ¡xima. En la primera fase se inicializa un estante con un elemento de gran altura, en donde los pesos vienen denotados por el ancho de cada elemento, y la ganancia viene dada por el Ã¡rea del elemento. Se aplica el algoritmo KP, tratando de maximizar el nÃºmero de elementos a insertar en un estante, con la mayor Ã¡rea ocupada posible. Una vez obtenido los shelfs, se insertan en un nÃºmero finito de contenedores usando el algoritmo (BFD) Best-Fit Decreacing (Mejor Ajuste Decreciente). Este algoritmo lo podemos desarrollar en una sola fase, trabajando con los shelfs directamente en los contenedores, Evaluados por Berkey y Wang [48]. Se han propuestos diferentes algoritmos para trabajar con estantes, entre estos estÃ¡n (FNF) Finite Next-Fit y (FFF) Finite First-Fit. El algoritmo (FNF) Finite Next-Fit CapÃ­tulo II 41 (Siguiente Ajuste Finito) empaqueta directamente los elementos en nÃºmeros finitos de contenedores exactamente de la misma forma que HNF. Algoritmo (FFF) Finite First-Fit (Siguiente Ajuste Finito) (Figura 2.32) es muy parecida a FFDH. Se inserta el elemento en el estante mÃ¡s bajo en el primer contenedor donde encaje; si no encaja en ningÃºn shelf, se debe crear en el primer contenedor adecuado. Figura 2.32: FFF TambiÃ©n podemos ver que existen algunas estrategias sin el uso de estantes para insertar elementos en los contenedores. La principal estrategia sin estantes es conocida como (BL) Bottom-Left (Abajo-Izquierda), y consiste en empacar los elementos actuales en la mÃ¡s baja posiciÃ³n posible, justificado a la izquierda. Baker et al. [50] analizaron el rendimiento del peor caso del algoritmo resultante, y obtuvieron lo siguiente: si los elementos no estÃ¡n ordenados, BL puede ser arbitrariamente malo; si los elementos estÃ¡n ordenado por anchura no-incremental, entonces se puede conseguir un algoritmo Ã³ptimo, con los lÃ­mites ajustados. Berkey y Wang [48]propusieron la estrategia BL para un nÃºmero finito de contenedores. Su algoritmo es llamado (FBL) Finite Bottom-Left (Abajo-Izquierda Finito), donde inicialmente se ordenan los elementos por anchura no creciente. Luego, el elemento actual es empaquetado en la posiciÃ³n mÃ¡s baja del contenedor inicializado, justificado a la izquierda; Si ningÃºn contenedor puede ser asignado, uno nuevo se inicializa. Este algoritmo produce un empaquetamiento en orden ğ‘‚(ğ‘›2). MartÃ­nez Bayona [45] utiliza un algoritmo de Bin Packing de dos dimensiones para empaquetar un conjunto de imÃ¡genes en una textura altas de forma optimizada. Para esto, utiliza la estrategia FFD, con la particularidad que utiliza un algoritmo para calcular el mÃ­nimo espacio que pueda tener la textura atlas, tomando en cuenta los tamaÃ±os de cada CapÃ­tulo II 42 una de las texturas de entrada. En este caso especÃ­fico, podemos observar que a diferencia de las demÃ¡s tÃ©cnicas, Ã©sta solo requiere un contenedor. Para calcular el mÃ­nimo espacio que puede tener la textura atlas se toma como parÃ¡metro de entrada el conjunto de texturas ğ¼ = ğ‘–1, ğ‘–2 â€¦ ğ‘–ğ‘›. El tamaÃ±o inicial del ancho y largo de la textura serÃ¡: ğ›¼ = ğ‘™ğ‘œğ‘”2(âˆ‘ ğ‘–ğ‘¤ğ‘–ğ‘‘ğ‘¡â„ğ‘— ğ‘› ğ‘—=1 ğ‘¥ ğ‘–â„ğ‘’ğ‘–ğ‘”â„ğ‘¡ğ‘—) ğ‘¤ğ‘–ğ‘‘ğ‘¡â„ = 2 [ ğ›¼ 2 ] , â„ğ‘’ğ‘–ğ‘”â„ğ‘¡ = 2 ğ›¼âˆ’ [ ğ›¼ 2 ] [Ec. 2.17] Esta fÃ³rmula retorna en potencia de dos el ancho y el largo del tamaÃ±o mÃ­nimo del atlas. Para incrementar el tamaÃ±o de la textura atlas, le sumas una unidad a ğ›¼ y se actualizan los tamaÃ±os. Otra particularidad de este algoritmo de empaquetamiento, es la forma de insertar las texturas de entrada en el contenedor. Para esto se usa un Ã¡rbol BSP. Cada nodo del Ã¡rbol define una regiÃ³n rectangular de la textura atlas. La raÃ­z define el espacio total a utilizar. Si un nodo es una hoja, este puede o no ser ocupado por una textura. En caso contrario, se tienen dos hijos que superpone todo el espacio del nodo padre, como se muestra en la Figura 2.33. El algoritmo propuesto tiene un tiempo de ğ‘‚(ğ‘™ğ‘œğ‘”(ğ‘›)), donde ğ‘› es la cantidad de nodos del Ã¡rbol. CapÃ­tulo II 43 Figura 2.33: Ãrbol BSP generado para insertar en la textura atlas cada uno de los elementos a desplegar. Los nodos hoja son espacios vacÃ­os o un espacio ocupado. Los demÃ¡s nodos son las divisiones del contenedor. Una vez insertado todas las texturas de entrada en la textura atlas, MartÃ­nez Bayona desarrolla dos algoritmos para optimizar el espacio de esta textura, extendiendo cada una de las texturas al tamaÃ±o total del atlas, y cambiando de lugar algunas texturas para ocupar el mayor espacio posible. Gordon Jake [51] propone un algoritmo de empaquetamiento para utilizar una imagen compuesta por varias para auto-generar CSS Sprites. Al igual que MartÃ­nez Bayona, desarrolla un algoritmo de Bin Packing usando la heurÃ­stica FFD y un Ã¡rbol de particionamiento de espacio binario para realizar la inserciÃ³n de los objetos. Para calcular el tamaÃ±o estimado del contenedor, siendo ğ‘› el nÃºmero de bloques a insertar: ğ‘¤ğ‘–ğ‘‘ğ‘¡â„ = ğ‘ğ‘£ğ‘”(ğ‘¤ğ‘–ğ‘‘ğ‘¡â„) âˆ— âˆšğ‘› 2 , â„ğ‘’ğ‘–ğ‘”â„ğ‘¡ = ğ‘ğ‘£ğ‘”(â„ğ‘’ğ‘–ğ‘”â„ğ‘¡) âˆ— âˆšğ‘› 2 [Ec. 2.18] Gordon Jake desarrolla un algoritmo para generar el CSS Sprites sin tomar en cuenta el lÃ­mite del contenedor. Al igual que MartÃ­nez Bayona, solo es requerido un solo contenedor. Tomando como base el tamaÃ±o del primer bloque, podemos ir aumentando el tamaÃ±o de la imagen por la derecha o por debajo del espacio ya particionado. No podemos insertar un bloque por debajo del espacio si el ancho del bloque a insertar es mayor al espacio particionado. Igualmente, si es mayor el largo del bloque al insertar por la derecha, no puede ser insertado el bloque. Si el bloque a insertar es mayor que el ancho y el largo del contenedor, no podemos insertar el bloque. Para esto, Gordon Jake propone que los bloques mÃ¡s grandes sean insertados primero. El orden de los bloques es significativo para el resultado final. Podemos ordenar la lista de bloques a insertar por el tamaÃ±o del ancho, el largo, el Ã¡rea mÃ¡xima, el lado mÃ¡ximo, y aleatorio (ver Figura 2.34). CapÃ­tulo II 44 Figura 2.34: Resultados del Algoritmo de Bin Packing segÃºn el orden, en (a) podemos ver como esta ordenado el empaquetamiento por orden de tamaÃ±o, en caso contrario, (b) esta ordenado de forma aleatoria. Con estas tÃ©cnicas podemos insertar elementos en los contenedores de una forma sencilla, pero en nuestro caso, se debe aprovechar la mayor cantidad de espacio posible en un contenedor, para esto podemos usar tÃ©cnicas meta heurÃ­sticas para minimizar el espacio inutilizado. Crainic et. al [69] propone un algoritmo eficiente para empaquetar bloques a travÃ©s de puntos extremos (ver Figura 2.35), los cuales generan puntos en los esquinas del Ã¡rea llena, donde a medida en que se vaya insertando, se van generando nuevos puntos. Con esto, se pueden explorar los espacios libres y comparar en base a los puntos adyacentes para saber si se puede insertar un bloque. Adicionalmente, proponen una heurÃ­stica de inserciÃ³n EP- FFD (Extreme point First Fit Decreasing) donde se insertan de forma decreciente los bloques en el primer punto extremo donde encajen. TambiÃ©n proponen EP-BFD (Extreme point Best Fit Decreasing) el cual insertan en el Ã¡rea donde generen menos espacio residual mediante una funciÃ³n de mÃ©rito que busca la mejor Ã¡rea a insertar. CapÃ­tulo II 45 Figura 2.35: Algoritmo de puntos extremos, en (a) podemos ver el algoritmo de EP en 3D, en caso contrario, (b) representa el algoritmo en 2D, donde el Ã¡rea gris es el espacio residual. El algoritmo de Bin Packing puede ser desarrollado bajo un ambiente 3D, teniendo en cuenta que se trabaja con un valor ğ‘ de profundidad. Puede ser utilizado para solucionar el problema de fragmentaciÃ³n de la textura atlas, con el propÃ³sito de poder insertar la mayor cantidad de bloques en la textura, dÃ¡ndole una mejor visualizaciÃ³n al volumen. 2.15 Morton Order Para el ordenamiento de una serie de bloques en un arreglo unidimensional a un ambiente 2D se puede usar el algoritmo propuesto por G. M. Morton [70]. Morton Order, que es una funciÃ³n que hace una correspondencia entre los datos multidimensionales a una dimensiÃ³n mientras preserva la localidad de los puntos. El valor de ğ‘§ de un punto en un espacio multidimensional es simplemente calculado intercalando la representaciÃ³n binaria de sus valores de coordenadas. Una vez que la data estÃ¡ almacenada en este orden, cualquier estructura de datos unidimensional puede ser usada como un Ãrbol Binario de BÃºsqueda, B-Tree, Listas o Tablas Hash. El resultado de ordenar puede ser equivalentemente descrito como el orden que se obtendrÃ­a de un recorrido en profundidad de un quad-tree. http://en.wikipedia.org/w/index.php?title=G._M._Morton&action=edit&redlink=1 CapÃ­tulo II 46 Figura 2.36: RepresentaciÃ³n en 2D del algoritmo Morton Order. Se puede ver como el orden converge a la forma de una letra Z. En el prÃ³ximo capÃ­tulo se procede a explicar la propuesta de trabajo especial de grado. CapÃ­tulo III 47 CapÃ­tulo 3 Marco Aplicativo Ya estudiado los distintos mÃ©todos utilizados para el despliegue de volÃºmenes de gran tamaÃ±o, utilizando tÃ©cnicas multi-resoluciÃ³n y el manejo de memoria de textura, se procederÃ¡ a explicar la propuesta de tesis. Se explicarÃ¡ la metodologÃ­a utilizada y cada uno de los aspectos resaltantes en el desarrollo. 3.1 MetodologÃ­a de desarrollo Para la gestiÃ³n de la propuesta de tesis se usÃ³ como marco la metodologÃ­a Ã¡gil SCRUM (K. Schwaber [71]), que hoy en dÃ­a se puede decir que es la metodologÃ­a Ã¡gil mÃ¡s popular utilizada para desarrollar productos de software. Las caracterÃ­sticas principales de SCRUM pueden resumirse en dos: ï‚· El desarrollo software mediante iteraciones incrementales (entregas de pequeÃ±as porciones de software en un mÃ¡ximo de 4 semanas). ï‚· Las reuniones a lo largo del proyecto. Como se indica K. Schwaber [71], existen tres pilares en los que se basa: ï‚· Transparencia: todos los aspectos del proceso que afectan al resultado son visibles para todos aquellos que administran dicho resultado. Por ejemplo, se CapÃ­tulo III 48 utilizan pizarras y otros mecanismos o tÃ©cnicas colaborativas para mejorar la comunicaciÃ³n. ï‚· InspecciÃ³n: se debe controlar con la frecuencia suficiente los diversos aspectos del proceso para que puedan detectarse variaciones inaceptables en el mismo. ï‚· RevisiÃ³n: el producto debe estar dentro de los lÃ­mites aceptables. En caso de desviaciÃ³n se procederÃ¡ a una adaptaciÃ³n del proceso y el material procesado. En las metodologÃ­as Ã¡giles la descripciÃ³n de estas necesidades se realiza a partir de las Historias de Usuario que son, principalmente, lo que el cliente o el usuario quiere que se implemente; es decir, son una descripciÃ³n breve, de una funcionalidad software tal y como la percibe el usuario (M. Cohn, [72]). En SCRUM a cada iteraciÃ³n se le denomina Sprint. SCRUM recomienda iteraciones cortas, por lo que cada Sprint durarÃ¡ entre 1 y 4 semanas (ver Figura 3.1). Y como resultado se crearÃ¡ un producto software potencialmente entregable, un prototipo operativo. Figura 3.1: Como primera fase, tenemos el Product Backlog (a) que consiste en un listado de historias de usuario que se incorporarÃ¡n al producto de software a medida en incremente el desarrollo. Seguido del Sprint Backlog (b), donde se apilan las historias de usuarios que se vayan a desarrollar a lo largo de la iteraciÃ³n. El Sprint es la iteraciÃ³n de desarrollo en sÃ­ (c), y al final de cada una de estas, se debe entregar un producto potencialmente operativo (d). Uno de los aspectos mÃ¡s importantes en cualquier proyecto, y tambiÃ©n en los proyectos Ã¡giles, es el establecimiento del equipo. Los roles y responsabilidades deben ser claros y conocidos por todos los integrantes del mismo. Cada equipo SCRUM tiene tres roles: CapÃ­tulo III 49 ï‚· Scrum Master: es el responsable de asegurar que el equipo SCRUM siga las prÃ¡cticas de SCRUM. ï‚· Propietario del Producto (Product Owner): es la persona responsable de gestionar las necesidades que serÃ¡n satisfechas por el proyecto y asegurar el valor del trabajo que el equipo lleva a cabo. ï‚· Equipo de desarrollo: El equipo estÃ¡ formado por los desarrolladores, que convertirÃ¡n las necesidades del Product Owner en un conjunto de nuevas funcionalidades, modificaciones o incrementos del producto software final (ver Figura 3.2). Figura 3.2: ConformaciÃ³n del equipo SCRUM. El Product Owner es un ente directamente relacionado con el cliente. Las reuniones son un pilar importante dentro de Scrum. Se realizan a lo largo de todo el Sprint como muestra la Figura 3.1. Se definen diversos tipos de reuniones: ReuniÃ³n de planificaciÃ³n del Sprint (Sprint Planning Meeting), que se lleva a cabo al principio de cada Sprint, definiendo en ella que se va a realizar en ese Sprint. Esta reuniÃ³n da lugar al Sprint Backlog. En esta reuniÃ³n participan todos los roles. El Product Owner presenta el conjunto de historias de usuario en el Product Backlog y el equipo de desarrollo selecciona las historias de usuario sobre las que se trabajarÃ¡. El siguiente tipo es la reuniÃ³n diaria, es de no mÃ¡s de 15 minutos en la que participan el equipo de desarrollo y el Scrum Master. En esta reuniÃ³n cada miembro del equipo presenta lo quÃ© hizo el dÃ­a anterior, lo quÃ© va a hacer hoy CapÃ­tulo III 50 y los impedimentos que se ha encontrado. TambiÃ©n tenemos la reuniÃ³n de revisiÃ³n del Sprint (Sprint Review Meeting): se realiza al final del Sprint. Durante la misma se indica quÃ© ha podido completarse y quÃ© no, presentando el trabajo realizado al Product Owner. Por su parte el Product Owner (y demÃ¡s interesados) verifican el incremento del producto y obtienen informaciÃ³n necesaria para actualizar el Product Backlog con nuevas historias de usuario. Por Ãºltimo se realiza retrospectiva del Sprint (Sprint Retrospective), tambiÃ©n al final del Sprint, sirve para que los integrantes del equipo Scrum y el Scrum Master den sus impresiones sobre el Sprint que acaba de terminar. Se utiliza para la mejora del proceso y normalmente se trabaja con dos columnas, con los aspectos positivos y negativos del Sprint. En la figura 3.3 se describe el ciclo de vida Scrum. Figura 3.3: Ciclo de vida Scrum. Se resaltan las reuniones. La propuesta de tesis se desarrollÃ³ a lo largo de 10 Sprints, con una duraciÃ³n de 4 semanas. A continuaciÃ³n desglosan cada uno de ellos: ï‚· Sprint 1: Toma de decisiones, donde se crea el entorno de desarrollo para el proyecto, con su respectivo repositorio remoto y se crean las clases necesarias. CapÃ­tulo III 51 ï‚· Sprint 2: Montar y ejecutar las librerÃ­as del motor grÃ¡fico, tambiÃ©n se desarrollaron clases para generar los resultados, para mediciÃ³n del tiempo y librerÃ­as matemÃ¡ticas. ï‚· Sprint 3: Se procede a la fase de carga del volumen, donde se generan los diferentes niveles de detalle del volumen en memoria RAM. ï‚· Sprint 4: Se desarrolla un algoritmo para la inserciÃ³n de bloques en la textura atlas recursivo en particiones fijas para luego comenzar a desarrollar el despliegue del volumen con Ray Casting. ï‚· Sprint 5: Se implementa la funciÃ³n de transferencia, se desarrolla un algoritmo de selecciÃ³n con cola de prioridad sin colapso de bloques. Se termina de desplegar el volumen de forma correcta. ï‚· Sprint 6: Se inicia el desarrollo de un algoritmo eficiente para el almacenamiento de bloques. Se elimina la recursividad a travÃ©s de una estructura de pila y se desarrolla un intercambio de nodos en el atlas. ï‚· Sprint 7: Se propone un algoritmo que genere un aumento del tamaÃ±o de la textura atlas para generar sub-estantes horizontales y verticales. ï‚· Sprint 8: Se desarrolla una forma de inserciÃ³n usando Extreme Points. Se comienza a desarrollar un algoritmo de apuntadores ordenado de mayor a menor. Se acomodan bugs de carga del volumen. ï‚· Sprint 9: Se optimiza el algoritmo de apuntadores y se genera el algoritmo de selecciÃ³n para refinar y colapsar bloques. ï‚· Sprint 10: Se hacen las pruebas pertinentes con tres tipos de volÃºmenes distintos. A continuaciÃ³n se procede a explicar el proceso de visualizaciÃ³n multi-resoluciÃ³n planteado en el trabajo especial de grado. 3.2 VisualizaciÃ³n de volÃºmenes multi-resoluciÃ³n. Como se mencionÃ³ anteriormente, existen diversas tÃ©cnicas para la visualizaciÃ³n de volÃºmenes multi-resoluciÃ³n. En este trabajo se implementÃ³ la tÃ©cnica de Ray Casting en GPU de una pasada aplicada a una jerarquÃ­a por bloques almacenada en una textura atlas. CapÃ­tulo III 52 Los pasos para el despliegue del volumen multi-resoluciÃ³n son los siguientes (ver Figura 3.4): carga del volumen, almacenamiento de datos volumÃ©tricos en una estructura de bloques, generaciÃ³n de niveles de detalle, criterio de selecciÃ³n y finalmente el despliegue del volumen multi-resoluciÃ³n. Figura 3.4: El proceso de despliegue de volÃºmenes multi-resoluciÃ³n utilizado consta de: cargar el volumen en memoria con los parÃ¡metros indicados en el archivo de configuraciÃ³n, almacenar los datos en una estructura de datos por bloques, generar los niveles de detalles y almacenarlos en la textura atlas, aplicar los parÃ¡metros de visualizaciÃ³n, seleccionar los niveles de detalles a desplegar, buscar los bloques en la textura atlas y desplegar del volumen en forma de multi-resoluciÃ³n. 3.3 Carga de volumen Los datos volumÃ©tricos se encuentran almacenados en un dataset que tiene un archivo de configuraciÃ³n que especifica los parÃ¡metros iniciales para la carga del volumen- Estos parÃ¡metros son: tipo de dataset (raw o pvm), ruta y nombre del dataset, tipo de datos (8 bits o 16 bits), dimensiones del volumen en ğ’™, ğ’š, y ğ’›, tamaÃ±o del bloque, dimensiones de la textura atlas (ğ’™, ğ’š, ğ’›) y por Ãºltimo los parÃ¡metros de escalado del volumen en sus componentes (ğ’™, ğ’š, ğ’›). Este archivo es leÃ­do por la aplicaciÃ³n para la carga de datos del volumen en memoria principal. Una vez cargada esta informaciÃ³n se procede a organizarla en una jerarquÃ­a por bloques que se explicarÃ¡ a continuaciÃ³n. CapÃ­tulo III 53 3.4 JerarquÃ­a multi-resoluciÃ³n basada en bloques Para este trabajo especial de grado se utilizÃ³ una jerarquÃ­a por bloques para la representaciÃ³n del volumen multi-resoluciÃ³n. Inicialmente Ã©sta jerarquÃ­a particiona el volumen en bloques (ver Figura 3.5), generando el nivel de detalle 0 del volumen, el cual representa los datos en su mayor resoluciÃ³n. Los bloques iniciales tienen un tamaÃ±o de ğ’ğŸ‘, donde ğ’ representa el tamaÃ±o del bloque en una dimensiÃ³n. Una vez obtenidos los bloques del primer nivel de detalle se procede a generar los niveles de detalle siguientes. Para este proceso se utilizÃ³ la tÃ©cnica de interpolar los datos del nivel de detalle anterior como se describe en la Figura 3.6 (a), donde 1 pÃ­xel representa 2 pÃ­xeles del nivel de detalle anterior en una representaciÃ³n unidimensional. La ventaja de usar esta tÃ©cnica es que no es necesario utilizar el pÃ­xel de holgura, por lo que se elimina el overhead que conlleva compartir medio vÃ³xel entre bloques adyacentes, dando asÃ­ espacio para almacenar mÃ¡s informaciÃ³n sin redundancia. Figura 3.5: RepresentaciÃ³n de un volumen en jerarquÃ­a por bloques y 3 niveles de detalle por cada bloque del volumen. CapÃ­tulo III 54 Figura 3.6: (a) GeneraciÃ³n de niveles de detalle calculando el promedio de los pÃ­xeles del nivel de detalle anterior. (b) RepresentaciÃ³n 1D de los niveles de detalle en una jerarquÃ­a por bloques. Como se puede ver en la figura, un pÃ­xel del nivel de detalle ğ’… + ğŸ representa 2 pÃ­xeles del nivel de detalle ğ’…. En esta implementaciÃ³n, las coordenadas de textura en cada bloque serÃ¡ [0,1]. Siguiendo esto, se puede decir que se obtendrÃ¡n ğ’ğŸ‘ ğŸğ’ğ’ğ’… bloques por nivel de detalle, donde ğ’ğ’ğ’… es un entero mayor o igual que 0 que representa el nivel de detalle. Una vez que se obtienen todos los niveles de detalles se seleccionan los bloques que serÃ¡n desplegados mediante un criterio de selecciÃ³n. 3.5 Criterio de selecciÃ³n Para el despliegue de los bloques se utilizÃ³ como criterio de selecciÃ³n la distancia con respecto a un punto de interÃ©s, el cual es especificado por el usuario final en la interfaz de la aplicaciÃ³n (ver Figura 3.7). El criterio de selecciÃ³n permite determinar cuÃ¡les bloques deben ser desplegados y en quÃ© resoluciÃ³n, teniendo en cuenta que el Ã¡rea de interÃ©s debe tener una mejor calidad de imagen que las Ã¡reas del volumen que estÃ¡n mÃ¡s alejadas del mismo. CapÃ­tulo III 55 Figura 3.7: Opciones de criterio de selecciÃ³n y refinamiento de bloques en la interfaz grÃ¡fica de la aplicaciÃ³n. Inicialmente los bloques del menor nivel de detalle son insertados en una cola de prioridad. La prioridad es dada segÃºn una distancia al punto de interÃ©s y la distancia al ojo en coordenadas de mundo, donde ordena los bloques desde el mÃ¡s cercano hasta el mÃ¡s lejano. Cabe destacar que los bloques completamente transparentes son omitidos para el cÃ¡lculo de la prioridad, ya que estos no aportan valor a la imagen final y ocupan un espacio en memoria que puede ser usado por otros bloques. 3.5.1 Punto de interÃ©s La prioridad de cada bloque es calculada con la ecuaciÃ³n Ec. 3.1 que es una relaciÃ³n entre la distancia del punto de interÃ©s al centro del bloque, la distancia al ojo en coordenadas de objeto y la diagonal del bloque (ver Figura 3.8). De esta manera se le darÃ¡ mayor prioridad para ser refinado a los bloques de menor resoluciÃ³n, mÃ¡s cercanas al punto de interÃ©s y al ojo. Debemos tener en cuenta que la diagonal es calculada en funciÃ³n al nÃºmero de vÃ³xeles del bloque. ğ‘’ğ‘‘ğ‘–ğ‘ ğ‘¡ = ğ‘‘ğ‘–ğ‘ğ‘” / (ğ‘‘ğ‘–ğ‘ğ‘” + ğ‘‘ğ‘–ğ‘ ğ‘¡ (ğ‘, ğ‘–ğ‘)) [Ec. 3.1] Donde ğ‘‘ğ‘–ğ‘ğ‘” es la diagonal del bloque y ğ‘‘ğ‘–ğ‘ ğ‘¡(ğ‘, ğ‘–ğ‘) es la distancia desde el centro del bloque al punto de interÃ©s. CapÃ­tulo III 56 Figura 3.8: En la imagen se puede observar que la suma ğ’…ğ’Šğ’‚ğ’ˆğŸ + ğ’…ğŸ > ğ’…ğ’Šğ’‚ğ’ˆğŸ + ğ’…ğŸ, por lo tanto el bloque 2 tendrÃ¡ mayor prioridad de refinamiento. Una vez se hayan calculado las prioridades se inicia el proceso de refinamiento de bloques. Este proceso puede acarrear un gran tiempo de cÃ³mputo que es proporcional a la cantidad de bloques existente en la cola de prioridad. Es por esto que se ha implementado un refinamiento cuadro a cuadro (frame to frame) propuesto por Carmona [4]. El refinamiento cuadro a cuadro consiste en refinar solo hasta una cantidad mÃ¡xima de memoria (indicado por el usuario) por cada cuadro. Este proceso se ejecuta hasta que el volumen quede completamente refinado o no se pueda refinar mÃ¡s (ver Figura 3.9). Figura 3.9: Ejemplo de refinamiento cuadro a cuadro (frame to frame) al 10% de un volumen. 3.5.2 Proceso de refinamiento y colapso de bloques El proceso de refinamiento y colapso de bloques es el que se encarga de controlar la resoluciÃ³n que debe tener cada bloque que va a ser desplegado tomando en cuenta el Ã¡rea de interÃ©s y la capacidad de la memoria. Este proceso consta de dos (2) subprocesos, refinar y colapsar. El subproceso de refinar tiene como funciÃ³n cambiar el nivel de detalle CapÃ­tulo III 57 de los bloques a uno superior e insertarlos en la textura atlas siempre y cuando Ã©sta tenga espacio disponible. El subproceso de colapsar hace lo contrario, cambia la resoluciÃ³n de los bloques a una menor. Idealmente hay que colapsar el bloque que menos reduzca la calidad en base a la mÃ©trica de error utilizada (ver Figura 3.10). Los subprocesos refinar y colapsar son dependientes cuando no existe memoria suficiente para seguir refinando bloques, es decir, si se quiere refinar un bloque pero no hay memoria suficiente para realizarlo, el subproceso de colapsar debe reducir la resoluciÃ³n de algÃºn o algunos bloques de manera que el refinamiento puede llevarse a cabo (ver Figura 3.10). Para esto se ha utilizado la mÃ©trica de distancia mencionada en la secciÃ³n 3.5.1 ecuaciÃ³n Ec.3.1 con el objetivo de determinar si el proceso de refinar y colapsar de bloques contribuye a mejorar la calidad de la imagen o no. Cuando no existe espacio suficiente para seguir refinando bloques y el proceso de refinar y colapsar de bloques no mejora la calidad de la imagen el algoritmo se detiene. Figura 3.10: RepresentaciÃ³n de los subprocesos refinar (1) y colapsar (2). La figura (3) es una representaciÃ³n grÃ¡fica cuando los subprocesos son dependientes, cuando la memoria estÃ¡ llena y se quiere refinar un bloque (figura 3.10.a) se deben colapsar uno o mÃ¡s bloques (figura 3.10.c) para crear espacio y asÃ­ poder insertar el bloque refinado (figura 3.10.b). 3.6 Despliegue del volumen Para visualizar el volumen es necesario pasar por un proceso de despliegue. Los datos deben ordenarse y almacenarse en la textura atlas y luego recorrerse aplicando la tÃ©cnica de Ray Casting en GPU de una pasada para obtener el volumen final. El despliegue se realizarÃ¡ cuadro a cuadro, procesando un porcentaje de bloques por cada cuadro. CapÃ­tulo III 58 3.7 Textura atlas Se utilizÃ³ una textura atlas para insertar los bloques en memoria de textura. Las dimensiones de esta textura deben ser potencia de 2 en cada una de sus coordenadas (ğ‘¥, ğ‘¦) para un espacio bidimensional, donde ğ‘¥ es el largo de la textura y ğ‘¦ es la altura de la textura. Se usÃ³ un filtro de textura GL_NEAREST para evitar los artefactos generados por la interpolaciÃ³n entre las fronteras de los bloques. Se implementÃ³ una segunda textura mÃ¡s pequeÃ±a para indexar la textura atlas (ver SecciÃ³n 2.10.5). Cuando se insertan bloques en la textura atlas se puede dar el caso en que genere fragmentaciÃ³n o espacios inutilizados. Esto puede causar que no alcance el espacio para insertar bloques refinados y se tenga que realizar un proceso de desfragmentaciÃ³n de la textura atlas, dando como desventaja la transferencia de datos redundantes hacia la GPU. Para minimizar la fragmentaciÃ³n del atlas se explican diferentes algoritmos propuestos en la subsecciÃ³n siguiente. 3.8 Algoritmos propuestos para minimizar la fragmentaciÃ³n de la textura atlas. En el presente trabajo se desarrollaron distintos algoritmos para el almacenamiento de bloques en la textura atlas. Cabe destacar que el Ãºltimo algoritmo propuesto es el usado en la soluciÃ³n de la tesis y es el que va a ser explicado con mayor Ã©nfasis. Todos los algoritmos fueron explicados en un ambiente de dos dimensiones, con motivo de facilitar al lector una mayor legibilidad de las propuestas. 3.8.1 Bin Packing recursivo En esta soluciÃ³n se usÃ³ la textura atlas como Ãºnico contenedor de bloques, a diferencia del problema de Bin Packing convencional, que crea un nuevo contendor cuando no hay espacio en ningÃºn otro. Para esto, se divide el atlas en particiones (ver Figura 3.11) donde cada particiÃ³n es creada dinÃ¡micamente a medida en que se van insertando los bloques. CapÃ­tulo III 59 Figura 3.11: RepresentaciÃ³n de la textura atlas usando la tÃ©cnica de Bin Packing. Para la creaciÃ³n de particiones, se utiliza un Ã¡rbol de particionamiento binario BSP donde se inserta a travÃ©s de un algoritmo de recorrido Pre-Orden en el primer lugar que encaje (First Fit). Como se puede ver en la Figura 3.12 el algoritmo reserva el Ã¡rea de tamaÃ±o del bloque a insertar, creando el nodo izquierdo como la nueva particiÃ³n, y el Ã¡rea restante como el nodo derecho. Figura 3.12: Proceso de particionamiento usando Bin Packing. Cuando se trabaja con una gran cantidad de bloques, el algoritmo tiende a ser poco eficiente, esto es debido a que debe buscar desde la raÃ­z a los nodos hojas el siguiente nodo con el suficiente espacio para insertar. Para optimizar el algoritmo, se cambiÃ³ la recursividad por ciclos iterativos a travÃ©s de una pila, el cual guarda solamente los nodos hoja con espacio disponible a insertar. CapÃ­tulo III 60 Para aprovechar mejor el espacio de la textura atlas, se implementÃ³ un algoritmo que va redimensionando de forma lÃ³gica el tamaÃ±o del atlas hasta alcanzar el lÃ­mite ğ‘  y ğ‘¡ (dimensiones) del mismo. Se comenzÃ³ en un tamaÃ±o estÃ¡ndar (bloque con mayor nivel de detalle) y se fue redimensionando a travÃ©s de sub particiones a lo largo de la textura (ver Figura 3.13). Figura 3.13: Redimensionamiento de la textura atlas, donde R es el espacio inicial (a), cuando caben mÃ¡s bloques se procede a generar una particiÃ³n en la parte superior del contenedor (b), si se llena, genera una nueva particiÃ³n en la parte derecha (c). Esta primera propuesta tiene como desventaja el alto costo al hacer reinserciÃ³n de bloques, debido a que el algoritmo genera particiones de tamaÃ±o fija segÃºn el tamaÃ±o del bloque que debÃ­a ser insertado, si el siguiente bloque a ser insertado era de mayor tamaÃ±o que el anterior, debÃ­a crearse una nueva particiÃ³n para insertarlo, dejando la particiÃ³n anterior como un espacio libre de memoria inutilizado. En caso contrario, si el bloque a ser insertado era de menor tamaÃ±o, la particiÃ³n generada debÃ­a ser de ese tamaÃ±o y cuando se debÃ­a refinar un bloque no podÃ­a ser insertado en esa Ã¡rea, generando gran pÃ©rdida de espacio. Para resolver este problema, se tenÃ­a que eliminar las particiones, generar nuevas, y reinsertar una gran cantidad de bloques en el atlas, sin garantÃ­a de que todos pudieran ser insertados. 3.8.1.1 Extreme Points Se presentÃ³ una propuesta basada en Extreme Points, donde cada bloque puede generar nuevos puntos de inserciÃ³n para los siguientes bloques (ver Figura 3.14). Estos puntos CapÃ­tulo III 61 tienen un orden especÃ­fico Bottom â€“ Left (de abajo hacia la izquierda) y son insertados en una lista de puntos. Para calcular estos puntos se toma en cuenta los bloques ya insertados, ya que se debe evaluar si no hay intersecciÃ³n de bloques en fronteras, si las consigue, entonces genera el punto en esa intersecciÃ³n. Figura 3.14: GeneraciÃ³n de Extreme Points. Existen dos heurÃ­sticas para inserciÃ³n de bloques: First Fit, en donde se trata la lista de puntos como una cola ordenada de abajo hacia arriba, y Best Fit, que divide los espacios vacÃ­os en sub â€“ Ã¡rea a travÃ©s de una funciÃ³n de mÃ©rito. Una vez obtenidos estos espacios, se elige la sub â€“ Ã¡rea que pueda genera la menor pÃ©rdida de espacio y se inserta. Cabe destacar que para obtener un resultado Ã³ptimo, se debe ordenar de forma decreciente con respecto al tamaÃ±o del bloque, en caso contrario, puede generar pequeÃ±os espacios y el costo de evaluar el solapamiento de bloques es muy alto. 3.8.2 Strips and Pointers La siguiente propuesta se denominÃ³ Strips and Pointer (Estantes y Apuntadores). Se crea una abstracciÃ³n lÃ³gica de la textura atlas en un espacio unidimensional, representando su Ã¡rea en forma de un estante (Strip) de gran longitud, tomando como altura el tamaÃ±o del bloque en su resoluciÃ³n mÃ¡s fina. Los bloques serÃ¡n insertados en este Strip bajo la regla de que siempre deben estar en orden decreciente segÃºn su tamaÃ±o. Se puede visualizar la representaciÃ³n de un Strip en la Figura 3.15, donde se pueden ver los bloques ordenados de mayor a menor segÃºn su nivel de detalle. CapÃ­tulo III 62 Figura 3.15: RepresentaciÃ³n de la textura atlas en un Strip (a). La figura (b) es la textura atlas correspondiente al Strip (a) en un espacio 2D. Para pasar de las coordenadas del Strip a las coordenadas del atlas, se desarrollÃ³ la Ec. 3.3, ğ‘¥ğ‘ğ‘¡ğ‘™ğ‘ğ‘  = ğ‘¥ğ‘ ğ‘¡ğ‘Ÿğ‘–ğ‘ ğ‘šğ‘œğ‘‘ ğ‘‘ğ‘–ğ‘šğ‘ğ‘¡ğ‘™ğ‘ğ‘  ğ‘¦ğ‘ğ‘¡ğ‘™ğ‘ğ‘  = ( ğ‘¥ğ‘ ğ‘¡ğ‘Ÿğ‘–ğ‘ ğ‘‘ğ‘–ğ‘šğ‘ğ‘¡ğ‘™ğ‘ğ‘  ) ğ‘šğ‘œğ‘‘ ( ğ‘‘ğ‘–ğ‘šğ‘ğ‘¡ğ‘™ğ‘ğ‘  ğ¿ğ‘‚ğ·ğ‘šğ‘ğ‘¥ ) + ğ‘¦ğ‘ ğ‘¡ğ‘Ÿğ‘–ğ‘ [Ec. 3.3] donde ğ‘¥ğ‘ğ‘¡ğ‘™ğ‘ğ‘  y ğ‘¦ğ‘ğ‘¡ğ‘™ğ‘ğ‘  son las coordenadas en la textura atlas, ğ‘¥ğ‘ ğ‘¡ğ‘Ÿğ‘–ğ‘ y ğ‘¦ğ‘ ğ‘¡ğ‘Ÿğ‘–ğ‘ son las coordenadas en el estante, ğ‘‘ğ‘–ğ‘šğ‘ğ‘¡ğ‘™ğ‘ğ‘  es la dimensiÃ³n del atlas y ğ¿ğ‘‚ğ·ğ‘šğ‘ğ‘¥ es el tamaÃ±o del bloque en su representaciÃ³n mÃ¡s fina. Con Ã©sta ecuaciÃ³n, podemos calcular las coordenadas finales del bloque en el atlas. Para calcular las coordenadas del bloque en el Strip, se usan unas coordenadas base llamadas Pointers. Estas son pre-calculadas tomando en cuenta el Ã¡rea ocupada por los bloques en cada nivel de detalle y los anteriores, y se ubican al principio de cada nivel de detalle. Esto genera diferentes sub-Ã¡reas entre cada nivel de detalle delimitados por estos Pointers, ordenadas desde el nivel mÃ¡s fino al mÃ¡s bajo para validar el orden de los bloques. CapÃ­tulo III 63 Figura 3.16: RepresentaciÃ³n de los Pointers (puntos rojos) en la tÃ©cnica Strip and Pointers. Estos apuntadores solo se mueven solo en la coordenada ğ’™. Para insertar los bloques en el Strip, se deben enumerar los bloques por cada nivel de detalle. Esta indexaciÃ³n ordena los bloques en forma lineal y calcula su espacio en el Strip a travÃ©s de su Pointer. Para calcular su posiciÃ³n, se presenta la Ec. 3.4, ğ‘¥ğ‘ ğ‘¡ğ‘Ÿğ‘–ğ‘ = ğ‘ƒğ‘œğ‘–ğ‘›ğ‘¡ğ‘’ğ‘Ÿğ‘¥ + ğ¼ğ‘›ğ‘‘ğ‘’ğ‘¥ğ‘ğ‘™ğ‘œğ‘ğ‘˜ ğ‘‘ğ‘–ğ‘šğ‘Œğ‘ ğ‘¡ğ‘Ÿğ‘–ğ‘ ğ‘¦ğ‘ ğ‘¡ğ‘Ÿğ‘–ğ‘ = ğ‘ƒğ‘œğ‘–ğ‘›ğ‘¡ğ‘’ğ‘Ÿğ‘¦ + (ğ¼ğ‘›ğ‘‘ğ‘’ğ‘¥ğ‘ğ‘™ğ‘œğ‘ğ‘˜ ğ‘šğ‘œğ‘‘ ğ‘‘ğ‘–ğ‘šğ‘Œğ‘ ğ‘¡ğ‘Ÿğ‘–ğ‘) [Ec. 3.4] Donde ğ‘¥ğ‘ ğ‘¡ğ‘Ÿğ‘–ğ‘ y ğ‘¦ğ‘ ğ‘¡ğ‘Ÿğ‘–ğ‘ representa la coordenada del bloque en el Strip, ğ‘ƒğ‘œğ‘–ğ‘›ğ‘¡ğ‘’ğ‘Ÿğ‘¥ y ğ‘ƒğ‘œğ‘–ğ‘›ğ‘¡ğ‘’ğ‘Ÿğ‘¦ el Pointer del nivel de detalle del bloque, ğ¼ğ‘›ğ‘‘ğ‘’ğ‘¥ğ‘ğ‘™ğ‘œğ‘ğ‘˜ el Ã­ndice del bloque en la estructura de datos y ğ‘‘ğ‘–ğ‘šğ‘Œğ‘ ğ‘¡ğ‘Ÿğ‘–ğ‘ la dimensiÃ³n del Strip en ğ‘¦. Los bloques estÃ¡n clasificados en listas independientes por niveles de detalles, como se pude visualizar en la Figura 3.17, donde cada lista empieza desde la posiciÃ³n 0. Figura 3.17: Lista de bloques por niveles de detalles. Cada lista tiene la coordenada del Pointer (puntos rojos) asociado a su nivel de detalle. CapÃ­tulo III 64 Cuando una sub-Ã¡rea de un nivel de detalle se encuentra llena, los Pointers deben realizar un proceso de traslaciÃ³n en el eje ğ‘¥ para que el bloque pueda ser insertado en el Strip. Esta traslaciÃ³n debe ser de tamaÃ±o del bloque nuevo a insertar para que encaje en la sub-Ã¡rea. La traslaciÃ³n se puede hacer hacia la derecha o hacia la izquierda. Primero se realiza un cÃ¡lculo de validaciÃ³n de traslaciÃ³n para determinar hacia quÃ© lado debe hacerse. Cuando se realiza la traslaciÃ³n a la derecha (ver Figura 3.18) se seleccionan todos los bloques que puedan solaparse y se reinsertan en su sub-Ã¡rea si la misma tiene el espacio suficiente, en caso contrario, debe realizar el mismo proceso de traslaciÃ³n en el siguiente nivel de detalle menor hasta que puedan ser insertados todos los bloques. Si no hay espacio suficiente para trasladar y reinsertar a la derecha, se hace un proceso de inserciÃ³n a la izquierda, siempre y cuando exista el espacio suficiente para insertar todos los bloques, de ser asÃ­, se reinsertan los bloques a la izquierda con sus nuevos Ã­ndices y se traslada el Pointer. Figura 3.18: TranslaciÃ³n de un Pointer hacia la derecha. Se deben mover 8 bloques para que se pueda insertar el bloque refinado. El algoritmo genera mejores resultados que los algoritmos planteados anteriormente, debido a que la particiÃ³n es representada por cada una de las sub-Ã¡reas por niveles de detalles, delimitadas entre los Pointers. Por otro lado, es costoso calcular si existen bloques que requieren ser removidos y reinsertados a las sub-Ã¡reas correspondientes, ya que la traslaciÃ³n se realiza en el eje ğ‘¥, y como consecuencia de no poder insertar un bloque de ese nivel de detalle, podrÃ­a generar un gran movimiento de bloques, y lo que se quiere es trasladar el Pointer minimizando la cantidad de bloques a mover. 3.8.3 3D Z-order Strip Basado en el algoritmo anterior, se desarrollÃ³ una propuesta donde se utiliza un Strip para insertar los bloques y un Pointer por cada nivel de detalle para delimitar los mismos. CapÃ­tulo III 65 Este algoritmo utiliza una indexaciÃ³n de bloques tomando en cuenta su tamaÃ±o y la cantidad de bloques existentes por cada nivel de detalle, el ordenamiento de los bloques en forma decreciente y las traslaciones de puntos en un Strip unidimensional, donde cada bloque en el Strip tendrÃ¡ una posiciÃ³n correspondiente en la textura atlas, la cual es calculada con una fÃ³rmula de correspondencia. Se ha implementado una estructura de ordenamiento de bloques la cual no es mÃ¡s que una lista de bloques para cada nivel detalle, donde cada bloque estÃ¡ indexado por el Ã­ndice lÃ³gico del bloque en cada nivel de detalle multiplicado por el espacio que ocupa este, mÃ¡s la cantidad de bloques en los niveles de detalles anteriores y por el tamaÃ±o del bloque correspondiente a cada nivel, como se explica en la ecuaciÃ³n Ec.3.5. El Ãºltimo bloque de cada lista apunta al bloque inicial de la lista del nivel detalle siguiente, en caso de que Ã©sta exista. La estructura de ordenamiento estÃ¡ representada en la Figura 3.19. Este ordenamiento e indexaciÃ³n tiene como ventaja organizar y almacenar la mayor cantidad de bloques en el Strip de forma eficiente. ğ‘ğ‘– ğ‘™ğ‘œğ‘‘0 = ğ‘– âˆ— ğ‘¡ğ‘ğ‘šğµğ‘™ğ‘œğ‘ğ‘¢ğ‘’ğ‘™ğ‘œğ‘‘0 3 , ğ‘ğ‘œğ‘› 0 â‰¤ ğ‘– < ğ‘› ğ‘ğ‘— ğ‘™ğ‘œğ‘‘1 = ğ‘› âˆ— ğ‘¡ğ‘ğ‘šğµğ‘™ğ‘œğ‘ğ‘¢ğ‘’ğ‘™ğ‘œğ‘‘0 3 + ğ‘— âˆ— ğ‘¡ğ‘ğ‘šğµğ‘™ğ‘œğ‘ğ‘¢ğ‘’ğ‘™ğ‘œğ‘‘1 3 , ğ‘ğ‘œğ‘› 0 â‰¤ ğ‘— < ğ‘š ğ‘¦ ğ‘› â‰¥ 0 ğ‘ğ‘˜ ğ‘™ğ‘œğ‘‘2 = ğ‘› âˆ— ğ‘¡ğ‘ğ‘šğµğ‘™ğ‘œğ‘ğ‘¢ğ‘’ğ‘™ğ‘œğ‘‘0 3 + ğ‘š âˆ— ğ‘¡ğ‘ğ‘šğµğ‘™ğ‘œğ‘ğ‘¢ğ‘’ğ‘™ğ‘œğ‘‘1 3 + ğ‘˜ âˆ— ğ‘¡ğ‘ğ‘šğµğ‘™ğ‘œğ‘ğ‘¢ğ‘’ğ‘™ğ‘œğ‘‘2 3 , ğ‘›, ğ‘š â‰¥ 0 ğ‘¦ 0 â‰¤ ğ‘˜ < ğ‘ [Ec. 3.5] Donde ğ‘ğ‘– ğ‘™ğ‘œğ‘‘ğ‘¥ representa el Ã­ndice del bloque con Ã­ndice lÃ³gico ğ‘– del nivel de detalle ğ‘™ğ‘œğ‘‘ğ‘¥ con ğ‘–, ğ‘¥ â‰¥ 0 y ğ‘›, ğ‘š y ğ‘ representan la cantidad de bloques existentes por cada nivel de detalle y ğ‘¡ğ‘ğ‘šğµğ‘™ğ‘œğ‘ğ‘¢ğ‘’ğ‘™ğ‘œğ‘‘ğ‘¥ 3 es el tamaÃ±o del bloque del nivel de detalle ğ‘¥ elevado al cubo para un ambiente tridimensional (ğ‘¡ğ‘ğ‘šğµğ‘™ğ‘œğ‘ğ‘¢ğ‘’ğ‘™ğ‘œğ‘‘ğ‘¥ 2 para un ambiente bidimensional). CapÃ­tulo III 66 Figura 3.19: DescripciÃ³n grÃ¡fica de las listas de bloques para su ordenamiento. La notaciÃ³n ğ’ƒğ’Š ğ’ğ’ğ’…ğ’™ representa el Ã­ndice de cada bloque previamente calculado con la ecuaciÃ³n [Ec. 3.5]. Una vez ordenados todos los bloques y calculado sus Ã­ndices se procede a insertarlos en el Strip unidimensional respetando un orden especÃ­fico. Este orden propuesto se denomina Z-Order, que consiste en ordenar los bloques indexados (ver Figura 3.20) en forma de una letra Z, donde se realiza una correspondencia de los Ã­ndices de la estructura ordenada de bloques al Strip unidimensional. Para calcular el orden ğ‘ de los bloques, se sub-divide el Strip en tiras de tamaÃ±o del nivel de detalle mÃ¡s fino, una vez que se ubique la tira correspondiente, se procede a generar una sub-divisiÃ³n en forma de Quad-Tree, donde cada sub-Ã¡rea es representada en un rango especÃ­fico, el cual determinarÃ¡ en quÃ© posiciÃ³n debe ir el bloque en el Strip respetando el patrÃ³n del Z-Order (ver Figura 3.21). SegÃºn el sub-Ã¡rea que genere el algoritmo, se generan una cantidad movimientos en las coordenadas de la tira hasta llegar al nivel de detalle del bloque (ver Algoritmo 3.1). El valor de la sub-Ã¡rea dada por la sub- divisiÃ³n indica el movimiento a realizar, como podemos ver en Ec. 3.6, ğ‘¥ = ğ‘¥ + ğ‘œğ‘“ğ‘“ğ‘ ğ‘’ğ‘¡ ğ‘ ğ‘– (ğ‘¡ğ‘–ğ‘™ğ‘’ ğ‘šğ‘œğ‘‘ 2 == 1) ğ‘¦ = ğ‘¦ + ğ‘œğ‘“ğ‘“ğ‘ ğ‘’ğ‘¡ ğ‘ ğ‘– (ğ‘¡ğ‘–ğ‘™ğ‘’ >= 2) [Ec. 3.6] CapÃ­tulo III 67 donde se mueve en la coordenada ğ‘¥ si la sub-Ã¡rea es impar y movemos en ğ‘¦ si es mayor o igual que dos. Este algoritmo se realiza recursivamente hasta llegar a la coordenada requerida. Se pudo desarrollar una soluciÃ³n iterativa (ver Algoritmo 3.1) del algoritmo generando las sub-divisiones cuando se recorren los niveles de detalle. Figura 3.20: RepresentaciÃ³n del Z-Order en una tira en el Strip. Funcion z-order(entero indice, entero lod, entero s=maxTamLOD) : retorna vector2 { //Valores x,y con la posiciÃ³n del bloque en coordenadas de Strip entero x, y; //Calculo de la posicion de la tira entero tira = indice /(s*s); //Se inicializan las coordenadas x,y x = tira * s; y = 0; //Se resta el Ã¡rea sobrante para simular el Quad-Tree indice -= tira*s*s; //Bucle para realizar los movimientos necesarios Para LOD maximo hasta LOD actual Hacer { //Se genera el nuevo LOD s >>= 1; //Se actualiza el valor de la tira tira = indice /(s*s); //Si la tira es mayor que 2, mueve en coordenada y Si tira >= 2 Entonces y += s; //Si la tira es impar, mueve en coordenada x Si tira % 2 == 1 Entonces x += s; //Se resta el Ã¡rea sobrante para simular el Quad-Tree indice -= tira*s*s; } retorna vector2(x, y); } Algoritmo 3.1: Algoritmo pseudo formal para el cÃ¡lculo de las coordenadas bidimensionales de un bloque para la inserciÃ³n en un Strip. CapÃ­tulo III 68 El resultado de ordenar los bloques a travÃ©s de Ã©sta tÃ©cnica lo podemos visualizar en la Figura 3.21. Dicho orden se genera de forma eficiente y de tal forma de mover la mÃ­nima cantidad de bloques al momento de trasladar Pointers. Figura 3.21: Los bloques ordenados por el algoritmo de Z-Order, se puede ver que los bloques estÃ¡n indexados por Ã¡reas para no depender del Pointer en cada nivel de detalle. Por ejemplo, si se quiere hallar la coordenada del bloque en el Ã­ndice 1008 de la Figura 3.21, con nivel de detalle 2, podemos hacer una corrida del algoritmo en la Tabla 3.1, Ãndice 1008 TamaÃ±o 16 TamaÃ±o 8 TamaÃ±o 4 Coordenadas (x,y) (48,0) (56,8) (64,12) Nivel de detalle 0 1 2 Tira 3 3 3 Espacio disponible 240 48 0 Tabla 3.1: Corrida en frio del Algoritmo 3.1. Donde la coordenada inicial se encuentra en (48,0) y al evaluar la nueva sub-Ã¡rea, da como resultado que es impar y mayor que dos, por lo que se hacen movimientos de coordenadas en ğ’™ y ğ’š en ocho (8) posiciones. Se recalcula la tira en base al espacio que nos hemos quitado y volvemos a evaluar en el siguiente nivel de detalle. Como la sub-Ã¡rea dio nuevamente tres (3), se vuelven a mover las coordenadas en los dos ejes en cuatro (4) posiciones por ser de nivel de detalle 2 para tamaÃ±o de bloque 16. Cuando no sobra mÃ¡s espacio entre Pointers para insertar nuevos bloques, se debe hacer un proceso de traslaciÃ³n de Pointers. Con el Z-Order, a diferencia de la propuesta anterior que genera las coordenadas a travÃ©s de estos Pointers, se pueden trasladar tanto en CapÃ­tulo III 69 el eje ğ‘¥ como en el eje ğ‘¦, esto se debe a que este algoritmo ordena los bloques en el Strip de tal forma que se pueden mover solamente los bloques que ocupen el Ã¡rea necesaria para insertar el nuevo bloque refinado sin perder el orden en la estructura de datos. Existen dos formas de trasladar Pointers, a la derecha y a la izquierda, en la lista unidimensional que contiene todos los bloques ordenados. La traslaciÃ³n hacia la derecha se da si no hay mÃ¡s espacio en la sub-Ã¡rea del nivel de detalle al que se desea refinar (ver Figura 3.22). Para realizar este proceso, se toman todos los bloques desde la primera posiciÃ³n que puedan ocupar el Ã¡rea del bloque a refinar. Una vez que se tienen todos los bloques que se deben mover, se inserta el bloque a refinar y se reinsertan los bloques en las sub-Ã¡reas restantes. Cabe destacar que se puede dar el caso en el que se deban mover mÃ¡s de un Pointer para que encajen todos los bloques, para esto se hace un proceso iterativo que recorre el Strip hasta el nivel mÃ¡s bajo de ser necesario, recalculando los espacios necesarios. Figura 3.22: RepresentaciÃ³n grÃ¡fica de la traslaciÃ³n a la derecha, se quiere refinar el bloque con Ã­ndice 912 (a) por lo que se mueven los 4 primeros bloques del nivel anterior y se inserta el bloque refinado cuyo Ã­ndice pasa a ser 768 (b), los 4 bloques que fueron movidos se a los espacios libres correspondientes a su nivel de detalle. El bloque 768 de la figura (a) pasa a ser el 848 en la figura (b) ya que ocupa el espacio libre que dejÃ³ el bloque que se refinÃ³, los bloques 784, 800 y 816 de la figura (a) ahora son los bloques 1008, 1024 y 1040 respectivamente, en la figura (b). Para un mejor entendimiento de la traslaciÃ³n, se presenta el Algoritmo 3.2, donde se puede detallar como se realizÃ³ el proceso de traslaciÃ³n de una forma eficiente. Funcion Traslado_der(bloque b) : retorna Booleano { //Lista de bloques a insertar ordenados por nivel de detalle bloque lista_bloques_reinsertar [Cantidad_LOD][â€¦]; CapÃ­tulo III 70 //Variable que indica el espacio necesario para insertar bloques del nivel actual entero mb = 0, numero_bloques= 1; //Validar si hay espacio suficiente a la derecha para hacer las traslaciones necesarias Si No validar_espacio_derecha() Entonces retorna falso; //Bucle para realizar los movimientos necesarios Para LOD refinado hasta LOD minimo Hacer { //Calculamos Ã¡rea del nivel de detalle actual y del mas pequeÃ±o area_lod = pointers_LOD[LOD].area; area_lod_ant = pointers_LOD[LOD + 1].area; //Calculamos Ã¡rea del nivel de detalle actual y del mas pequeÃ±o pointers_LOD[LOD].pointer += mb + (area_lod* numero_bloques); //Se calcula Ã¡rea del nivel de detalle actual y del mas pequeÃ±o mb += area_lod * numero_bloques; //cantidad de bloques que se deben quitar del siguiente nivel de detalle entero cantidad_bloques = mb / area_lod_ant; //bucle que remueve los bloques de la lista para ser reinsertados posteriormente Mientras cantidad_bloques <> 0 || mb <> 0 Hacer { lista_bloques_reinsertar [LOD + 1][i] = lista_bloques [LOD + 1][0]; remover(lista_bloques [LOD + 1][0]); } //Insertamos los bloques del nivel de detalle actual Insertar_bloques(lista_bloques_reinsertar [LOD][â€¦]); //Insertamos los bloques del anterior nivel de detalle Insertar_bloques(lista_bloques_reinsertar [LOD+1][â€¦]); //Si el tamaÃ±o de la lista del ant. LOD no es cero, quiere decir que no encajaron todos los bloques y se debe realizar una nueva movida de apuntador del anterior nivel de detalle Si lista_bloques_reinsertar [LOD+1][â€¦].tamaÃ±o == 0 Entonces Break; Sino numero_bloques = lista_bloques_reinsertar [LOD+1][â€¦].tamaÃ±o; } retorna verdadero; } Algoritmo 3.2: Algoritmo pseudo formal para el traslado de bloques a la derecha. Si la validaciÃ³n del espacio en el Algoritmo 3.2 no se cumple, la funciÃ³n retorna falso porque no se tiene el suficiente espacio hacia la derecha para mover los bloques necesarios para insertar el bloque refinado. Si no se puede trasladar a la derecha, el algoritmo busca espacio a la izquierda (ver Figura 3.23) del nivel de detalle a refinar para insertar el bloque refinado. El proceso consiste en tomar el Ãºltimo espacio del nivel de detalle mayor al que se quiere refinar. Si el espacio es ocupado por un bloque, se debe mover este bloque a un espacio libre. Este proceso se ejecuta iterativamente, al igual que la traslaciÃ³n a la derecha, debido a que se puede mover mÃ¡s de un Pointer a la izquierda por falta de espacio, aunque se debe validar previamente que tenga el espacio suficiente para trasladar. CapÃ­tulo III 71 Figura 3.23: RepresentaciÃ³n grÃ¡fica de la traslaciÃ³n a la izquierda, se quiere refinar el bloque con Ã­ndice 944 (a) por lo que se mueve el Ãºltimo bloque del nivel mayor y se inserta el bloque refinado (b) al final se insertan el bloque que fue movido a un espacio libre correspondiente a su nivel de detalle. El Algoritmo 3.3 se asemeja al planteado anteriormente con traslaciÃ³n a la derecha. Con diferencia que saca el Ãºltimo bloque de la lista nada mÃ¡s si en el espacio existe un bloque. Si la funciÃ³n retorna falso, no se puede realizar traslaciÃ³n a la izquierda y se requiere de un proceso de Colapso de bloques para que exista el espacio necesario en el Strip. Por cada colapso de bloque, se valida nuevamente el espacio requerido por la derecha y por la izquierda, dando como prioridad el Ã¡rea de la derecha. Funcion Traslado_izq(bloque b) : retorna Booleano { //Lista de bloques a insertar ordenados por nivel de detalle bloque lista_bloques_reinsertar [Cantidad_LOD][â€¦]; //Variable que indica el espacio necesario para insertar bloques del nivel actual entero mb = 0, numero_bloques= 1; //Validar si hay espacio suficiente a la derecha para hacer las traslaciones necesarias Si No validar_espacio_izquierda() Entonces retorna falso; //Bucle para realizar los movimientos necesarios Para LOD refinado hasta LOD maximo Hacer { //Calculamos Ã¡rea del nivel de detalle actual y del mas pequeÃ±o area_lod = pointers_LOD[LOD].area; area_lod_sig = pointers_LOD[LOD-1].area //Calculamos Ã¡rea del nivel de detalle actual y del mas pequeÃ±o pointers_LOD[LOD].pointer -= mb + (area_lod_sig* numero_bloques); //Se calcula Ã¡rea del nivel de detalle actual y del mas pequeÃ±o mb += area_lod * numero_bloques; //Si existe un bloque en el espacio, quitarlo para reinsertarlo posteriormente Si mover_bloque_izquierda() Entonces { lista_bloques_reinsertar [LOD-1][i] = lista_bloques [LOD-1][ultimo]; CapÃ­tulo III 72 remover(lista_bloques [LOD-1][ultimo]); } //Insertamos los bloques del nivel de detalle actual Insertar_bloques(lista_bloques_reinsertar [LOD][â€¦]); //Insertamos los bloques del siguiente nivel de detalle Insertar_bloques(lista_bloques_reinsertar [LOD-1][â€¦]); //Si el tamaÃ±o de la lista del sig. LOD no es cero, quiere decir que no encajo el bloque que se quitÃ³ y se debe realizar una nueva movida de apuntador del siguiente nivel de detalle Si lista_bloques_reinsertar [LOD-1][â€¦].tamaÃ±o == 0 Entonces Break; Sino numero_bloques = lista_bloques_reinsertar [LOD+1][â€¦].tamaÃ±o; } retorna verdadero; } Algoritmo 3.3: Algoritmo pseudo formal para el traslado de bloques a la izquierda. Esta Ãºltima propuesta fue la elegida para la implementaciÃ³n de la inserciÃ³n y reajuste de los bloques en la textura atlas. Se puede evaluar en primera instancia que el algoritmo aprovecha la mayor cantidad de espacio por estar ordenado de forma decreciente, ademÃ¡s de poder minimizar la cantidad de bloques a mover en caso de ser necesario y permite determinar la posiciÃ³n exacta de cada bloque en el atlas sin la necesidad de hacer un recorrido por cada bloque existente, obteniendo asÃ­ una inserciÃ³n de bloques eficiente. En el capÃ­tulo siguiente se desglosan los ambientes de pruebas con sus respectivos volÃºmenes y resultados obtenidos. CapÃ­tulo IV 73 CapÃ­tulo IV Pruebas y resultados En este capÃ­tulo se presentan los ambientes de prueba, las pruebas realizadas y los resultados obtenidos del algoritmo implementado para el manejo eficiente de la segmentaciÃ³n de la textura atlas. 4.1 Ambiente de pruebas El sistema de despliegue de volÃºmenes multi-resoluciÃ³n fue probado en 2 computadores con diferentes caracterÃ­sticas de hardware para medir los tiempos de respuestas y niveles de fragmentaciÃ³n del sistema cargando diferentes volÃºmenes. A continuaciÃ³n se describen las especificaciones de hardware y software de ambos computadores. 4.2 Especificaciones de hardware El Algoritmo de volÃºmenes multi-resoluciÃ³n requiere de una gran capacidad de Hardware para poder generar mejores resultados, por eso se eligieron dos equipos para hacer la comparaciÃ³n entre los tiempos de respuestas. Cabe acotar que se trabajÃ³ con dispositivos NVIDIA para la tarjeta grÃ¡fica y dispositivos Intel para Procesamiento. ï‚· PC Intel i5 de 2.5 Ghz, con 16 Gb de RAM DDR3 y una tarjeta GrÃ¡fica Nvidia Gerforce 680GTX de 2Gb de RAM. Esta configuraciÃ³n serÃ¡ llamada â€œEquipo 1â€. CapÃ­tulo IV 74 ï‚· PC Procesador Intel Quad Core modelo 8400 de 2.4Ghz, con 8 Gb de RAM DDR3 y una tarjeta grÃ¡fica Nvidia Geforce 550 GTX de 1.0Gb de RAM. Esta configuraciÃ³n serÃ¡ llamada â€œEquipo 2â€. 4.3 Especificaciones de software ï‚· Sistema Operativo: Windows 8.1 64 Bit para cargar volÃºmenes de gran tamaÃ±o ï‚· Lenguaje de ProgramaciÃ³n: C++, lenguaje nativo del sistema para correr de forma eficiente el motor grÃ¡fico. ï‚· IDE de desarrollo: Visual Studio 2013 para compilar y desarrollar la propuesta de tesis. ï‚· Motor grÃ¡fico: OpenGL versiÃ³n 4 con soporte para programar en el procesador de vÃ©rtices y fragmentos a travÃ©s de GLSL, con manejador de ventanas GLUT e interfaz grÃ¡fica AntTweakBar 1.15 [60]. Se utilizÃ³ Glew 1.5.8 para usar las extensiones del API de OpenGL. ï‚· Repositorio remoto: GIT para almacenar en la web las versiones de la aplicaciÃ³n y poder obtener la Ãºltima versiÃ³n en cualquier PC. 4.4 Datasets Para las pruebas se usaron 3 volÃºmenes diferentes, el primero es la mujer visible redimensionada, el segundo volumen serÃ¡ una muestra de una flor de nueces y el tercer volumen es una fruta haitiana. Todos los volÃºmenes desplegados serÃ¡n generados con la tÃ©cnica de Ray Casting de una pasada. 4.4.1 Volumen 1 Del proyecto Humano Visible se tienen los cortes fotografiados en RGB de la mujer visible convertidos a escala de grises (ver Figura 4.1). Por limitaciones de este trabajo, se utilizÃ³ Ãºnicamente una muestra de 867 MB que corresponde a una tomografÃ­a. Existe una muestra del volumen de 12 GB que son una colecciÃ³n de fotos convertidas a escala de grises. La dimensiÃ³n de este sub volumen es de 512x512x1734 donde cada vÃ³xel tiene 16 bits. De ahora en adelante se referirÃ¡ a este como â€œVolumen 1â€. CapÃ­tulo IV 75 Figura 4.1: Muestra de la mujer visible redimensionada. 4.4.2 Volumen 2 Para la prueba nÃºmero 2 se utilizÃ³ el volumen de una flor (leucadendron rubrum) seca (ver Figura 4.2) de 1 GB, tomado de una micro tomografÃ­a computarizada. Sus dimensiones son 1024x1024x1024 y cada vÃ³xel tiene 8 bits. A este volumen se le llamarÃ¡ â€œVolumen 2â€. Figura 4.2: Volumen de flor seca. CapÃ­tulo IV 76 4.4.3 Volumen 3 El tercer y Ãºltimo volumen de prueba serÃ¡ una fruta haitiana (ver Figura 4.3) de dimensiÃ³n 1024x1024x1536 de 3.01GB con 16 bits por cada vÃ³xel. Este volumen tambiÃ©n fue generado por una micro tomografÃ­a computarizada y se identificarÃ¡ como â€œVolumen 3â€. Figura 4.3: Volumen de fruta haitiana de 3.01GB 4.5 Resultados Cuantitativos En esta secciÃ³n se mostrarÃ¡n los resultados cuantitativos, como mediciones de tiempo de carga, procesamiento y consumo de memoria obtenidos al desplegar cada volumen. Para estas pruebas se utilizÃ³ jerarquÃ­a en bloques con mÃ¡ximo seis niveles de detalle y la textura atlas con tres tamaÃ±os distintos. 4.5.1 Etapa de pre-procesamiento En esta secciÃ³n se mostrarÃ¡ una tabla donde se refleja la cantidad total de bloques que se generan, la memoria requerida para almacenar todo el volumen multi-resoluciÃ³n y el tiempo utilizado para la generaciÃ³n de los niveles de detalle (ver Tabla 4.1). CapÃ­tulo IV 77 Volumen 1 Volumen 2 Volumen 3 ğŸğŸ”ğŸ‘ ğŸ‘ğŸğŸ‘ ğŸğŸ”ğŸ‘ ğŸ‘ğŸğŸ‘ ğŸğŸ”ğŸ‘ ğŸ‘ğŸğŸ‘ Bloques Generados 110.976 13.872 262.144 32.768 393.216 49.152 Memoria necesaria (MB) 990,82 990,85 1.170,25 1.170,28 3.510,75 3.510,84 Tiempo para generar los niveles de detalle (ms.) Equipo 1 1.277,00 680,00 1.298,33 1.627,66 4.883,85 2.669,25 Equipo 2 1.959,37 1.828,12 3.267,73 2.531,66 N/P N/P Tabla 4.1: Tabla descriptiva de los tiempos y memoria utilizada en la generaciÃ³n de los niveles de detalle. Se puede notar que la cantidad de bloques generados para un tamaÃ±o de bloque igual a 32 es significativamente menor a la de 16, esto es asÃ­ porque aunque se tiene un nivel de detalle adicional (uno para cada tamaÃ±o de bloque (32, 16, 8, 4, 2, 1)), cada bloque contiene mayor cantidad de vÃ³xeles y esto es inversamente proporcional a la cantidad de bloques. Al tener menor cantidad de bloques el proceso para generar los niveles de detalle es mÃ¡s rÃ¡pido. 4.5.2 Refinamiento La siguiente tabla refleja la memoria utilizada y memoria desperdiciada al momento cuando de realizar el proceso de refinamiento y cuÃ¡nto tiempo toma para refinar todos los bloques posibles (ver Tabla 4.2, Tabla 4.3 y Tabla 4.4). Volumen 1 Volumen 1 Volumen 1 TamaÃ±o atlas 256x256x256 (16 MB) 512x512x512 (128 MB) 1024x1024x1024 (1GB) TamaÃ±o de Bloques ğŸğŸ”ğŸ‘ ğŸ‘ğŸğŸ‘ ğŸğŸ”ğŸ‘ ğŸ‘ğŸğŸ‘ ğŸğŸ”ğŸ‘ ğŸ‘ğŸğŸ‘ Tiempo de carga (ms) 440 440 440 440 440 440 Memoria utilizada (MB) 15,999576 15,99512 127,998047 127,96094 212,914063 228,593750 Memoria libre (MB) 0,000424 0,00488 0,001953 0,03906 811,085937 795,40625 % de memoria utilizada 99,997350 99,969500 99,998474 99,969484 20,792389 22,323608 Tiempo de refinamiento (ms.) Equipo 1 461,825 181,8525 550,675 242,2725 696,965 365,3425 Equipo 2 979,11 501,42 1.259,28 661,64 1.733,31 803,77 Tabla 4.2: Tabla descriptiva de los tiempos y memoria utilizada del volumen 1 en el proceso de refinamiento de bloques con atlas de tamaÃ±o diferentes. CapÃ­tulo IV 78 Volumen 2 Volumen 2 Volumen 2 TamaÃ±o atlas 256x256x256 (16 MB) 512x512x512 (128 MB) 1024x1024x1024 (1GB) TamaÃ±o de Bloques ğŸğŸ”ğŸ‘ ğŸ‘ğŸğŸ‘ ğŸğŸ”ğŸ‘ ğŸ‘ğŸğŸ‘ ğŸğŸ”ğŸ‘ ğŸ‘ğŸğŸ‘ Tiempo de carga (ms) 510 510 510 510 510 510 Memoria utilizada (MB) 16 15,997070 121,929688 127,976563 121,929688 130,218750 Memoria libre (MB) 0 0,00293 6,070312 0,023437 902,070312 893,78125 % de memoria utilizada 100,00 99,981688 95,257569 99,981690 11,907196 12,716675 Tiempo de refinamiento (ms.) Equipo 1 256,8675 177,8825 302,8975 206,765 361,525 198,605 Equipo 2 766,465 657,155 766,6975 690,3725 1021,855 613,7625 Tabla 4.3: Tabla descriptiva de los tiempos y memoria utilizada del volumen 2 en el proceso de refinamiento de bloques con atlas de tamaÃ±o diferentes. Volumen 3 Volumen 3 Volumen 3 TamaÃ±o atlas 256x256x256 (16 MB) 512x512x512 (128 MB) 1024x1024x1024 (1GB) TamaÃ±o de Bloques ğŸğŸ”ğŸ‘ ğŸ‘ğŸğŸ‘ ğŸğŸ”ğŸ‘ ğŸ‘ğŸğŸ‘ ğŸğŸ”ğŸ‘ ğŸ‘ğŸğŸ‘ Tiempo de carga (ms) 15.624,93 15.624,93 15.624,93 15.624,93 15.624,93 15.624,93 Memoria utilizada (MB) 15,08941 16 127,999878 127,999512 1.023,99902 1.023,99609 Memoria libre (MB) 0,91059 0 0,000122 0,000488 0,00098 0,00391 % de memoria utilizada 94,308813 100,00 99,999905 99,999619 99,999904 99,999618 Tiempo de refinamiento (ms.) Equipo 1 2.294,9575 368,39 2.584,425 590,7225 5.566,2775 1.471,2125 Equipo 2 N/P N/P N/P N/P N/P N/P Tabla 4.4: Tabla descriptiva de los tiempos y memoria utilizada del volumen 3 en el proceso de refinamiento de bloques con atlas de tamaÃ±o diferentes. El volumen 3 no pudo ser probado (N/P=No Probado) en el equipo 2 por no tener la capacidad de memoria RAM necesaria para cargar 3.01GB de datos. Se puede observar que el algoritmo Z-Order almacena los bloques eficientemente para usar el mÃ¡ximo espacio posible en la textura atlas. La textura atlas es usada casi en totalidad cuando su tamaÃ±o es significativamente menor al tamaÃ±o de volumen, ocupando entre el 99% y 100% de la memoria y en el peor de los casos es cercano al 94% de su espacio. Cuando el tamaÃ±o del volumen es menor que la textura atlas, el volumen necesita menos espacio para refinarse completamente, utilizando solo entre un 11% y 23% del tamaÃ±o disponible. La siguiente tabla indica los tiempos que tarda la actualizaciÃ³n de las prioridades de cada bloque cuando se mueve el punto de interÃ©s para volumen, asÃ­ como el tiempo de rendering, inserciÃ³n de bloques en la estructura de ordenamiento Z-Order y el tiempo de actualizaciÃ³n de la textura atlas en GPU. Los tiempos son calculados en milisegundos y son el promedio de los tiempos tomados por cada 10 frames del render. CapÃ­tulo IV 79 Volumen 1 Volumen 1 Volumen 1 TamaÃ±o atlas 256x256x256 (16 MB) 512x512x512 (128 MB) 1024x1024x1024 (1GB) TamaÃ±o de Bloques ğŸğŸ”ğŸ‘ ğŸ‘ğŸğŸ‘ ğŸğŸ”ğŸ‘ ğŸ‘ğŸğŸ‘ ğŸğŸ”ğŸ‘ ğŸ‘ğŸğŸ‘ Tiempo de cÃ¡lculo de prioridades (ms.) Equipo 1 0,01 0,01 0,01 0,01 0,01 0,01 Equipo 2 0,02 0,00 0,02 0,00 0,02 0,00 Tiempo de rendering (ms.) Equipo 1 49,08 4,81 33,34 5,40 61,13 9,04 Equipo 2 71,65 12,40 72,38 12,60 117,15 23,00 Tiempo de inserciÃ³n en estructura Z- Order (ms.) Equipo 1 16,02 1,21 11,78 1,51 11,78 1,33 Equipo 2 18,96 2,23 20,28 2,26 20,29 2,29 Tiempo de actualizaciÃ³n de textura atlas en GPU (ms.) Equipo 1 7,39 4,81 5,04 0,70 5,18 0,52 Equipo 2 5,9 1,19 5,84 1,23 5,52 1,12 Tabla 4.5: Tabla descriptiva de los tiempos de cÃ¡lculo en el volumen 1 de prioridades cuando se mueve el punto de interÃ©s, tiempo de rendering, inserciÃ³n de bloques en la estructura de ordenamiento Z-Order y el tiempo de actualizaciÃ³n de la textura atlas en GPU para el volumen de la mujer visible. Volumen 2 Volumen 2 Volumen 2 TamaÃ±o atlas 256x256x256 (16 MB) 512x512x512 (128 MB) 1024x1024x1024 (1GB) TamaÃ±o de Bloques ğŸğŸ”ğŸ‘ ğŸ‘ğŸğŸ‘ ğŸğŸ”ğŸ‘ ğŸ‘ğŸğŸ‘ ğŸğŸ”ğŸ‘ ğŸ‘ğŸğŸ‘ Tiempo de cÃ¡lculo de prioridades (ms.) Equipo 1 0,01 0,00 0,01 0,00 0,01 0,00 Equipo 2 0,01 0,00 0,01 0,00 0,01 0,00 Tiempo de rendering (ms.) Equipo 1 45,17 2,68 17,90 3,35 34,66 5,14 Equipo 2 120,08 11,96 50,46 7,09 34,02 12,98 Tiempo de inserciÃ³n en estructura Z- Order (ms.) Equipo 1 25,22 0,71 6,44 0,71 6,55 0,75 Equipo 2 43,85 2,15 10,68 1,25 10,32 1,33 Tiempo de actualizaciÃ³n de textura atlas en GPU (ms.) Equipo 1 5,78 0,30 2,35 0,25 2,29 0,25 Equipo 2 10,63 1,19 4,29 0,52 3,46 0,51 Tabla 4.6: Tabla descriptiva de los tiempos de cÃ¡lculo en el volumen 2 de prioridades cuando se mueve el punto de interÃ©s, tiempo de rendering, inserciÃ³n de bloques en la estructura de ordenamiento Z-Order y el tiempo de actualizaciÃ³n de la textura atlas en GPU para el volumen de la flor seca. Volumen 3 Volumen 3 Volumen 3 TamaÃ±o atlas 256x256x256 (16 MB) 512x512x512 (128 MB) 1024x1024x1024 (1GB) CapÃ­tulo IV 80 TamaÃ±o de Bloques ğŸğŸ”ğŸ‘ ğŸ‘ğŸğŸ‘ ğŸğŸ”ğŸ‘ ğŸ‘ğŸğŸ‘ ğŸğŸ”ğŸ‘ ğŸ‘ğŸğŸ‘ Tiempo de cÃ¡lculo de prioridades (ms.) Equipo 1 0,15 0,01 0,16 0,01 0,14 0,01 Equipo 2 N/P N/P N/P N/P N/P N/P Tiempo de rendering (ms.) Equipo 1 183,22 42,76 183,93 30,58 283,84 57,09 Equipo 2 N/P N/P N/P N/P N/P N/P Tiempo de inserciÃ³n en estructura Z- Order (ms.) Equipo 1 142,45 14,16 141,71 10,80 140,89 11,03 Equipo 2 N/P N/P N/P N/P N/P N/P Tiempo de actualizaciÃ³n de textura atlas en GPU (ms.) Equipo 1 33,06 7,12 33,02 4,48 34,33 4,97 Equipo 2 N/P N/P N/P N/P N/P N/P Tabla 4.7: Tabla descriptiva de los tiempos de cÃ¡lculo en el volumen 3 de prioridades cuando se mueve el punto de interÃ©s, tiempo de rendering, inserciÃ³n de bloques en la estructura de ordenamiento Z-Order y el tiempo de actualizaciÃ³n de la textura atlas en GPU para el volumen de la fruta haitiana de 3.01GB. Se puede observar que la cantidad de bloques generados para cada volumen influye significativamente en los tiempos calculados, a menor cantidad de bloques menor tiempo de procesamiento. Los tiempos de cÃ¡lculos de prioridad de los bloques son significativamente pequeÃ±os, debido a que la prioridad es calculada al principio de cada refinamiento y es O(1) ya que solo se requiere una fÃ³rmula para generar el error de cada bloque. El tiempo d actualizaciÃ³n del atlas es mucho menor al tiempo de la actualizaciÃ³n de la estructura de Z-Order debido a que el motor grÃ¡fico OpenGL genera un hilo de procesamiento para subir los bloques a la textura atlas y asÃ­ no afectar el tiempo de rendering. Al utilizar la instrucciÃ³n glFlush(), se pudo detallar que los tiempos de rendering son mÃ¡s elevados debido a que el motor grÃ¡fico espera a que los bloques se desplacen a la textura atlas para generar un cuadro de imagen. Por Ãºltimo, La estructura unidimensional de Z-Order es eficiente debido a que se guardan los apuntadores de los bloques en vez de una copia del mismo, y como el cÃ¡lculo de la posiciÃ³n es en O(1), los bloques son insertados de forma muy rÃ¡pida. Se puede ver que el tiempo para reacomodar los bloques en la estructura de datos Z-Order no genera mayor costo de tiempo. 4.6 Resultados cualitativos Al compactar y organizar los bloques de manera eficaz y eficiente, el algoritmo implementado permite que se inserte una mayor cantidad de bloques de los mejores niveles CapÃ­tulo IV 81 de detalle tratando siempre de no comprometer mucho la perdida de datos, con el fin de tener la mejor calidad de imagen posible con la memoria disponible. En la Figura 4.4 y Figura 4.5 se puede observar como varÃ­a la imagen al tener diferentes tamaÃ±os de memoria de textura atlas, generando mayores resoluciones con el atlas de 512x512x512 de tamaÃ±o porque se tiene mayor espacio para realizar el proceso de refinamiento . Figura 4.4: Muestra del volumen 1, con dos tamaÃ±os de atlas. En la figura se puede apreciar que el volumen con el atlas de 512x512x512 tiene una mejor resoluciÃ³n que el volumen con el atlas de 256x256x256. CapÃ­tulo IV 82 Figura 4.5: Muestra del volumen utilizando 3 tamaÃ±os de atlas diferentes. (a) Atlas de dimensiones 256x256x256. (b) Atlas de dimensiones 512x512x512 y atlas de dimensiones 1024x1024x1024. El punto rojo de la imagen representa el punto de interÃ©s. En la Figura 4.6 se tienen dos tamaÃ±os de bloques distintos para la generaciÃ³n de los niveles de detalles, de 163 y de 323 respectivamente. Se tiene que el volumen generado a 323 genera artefactos visuales tales como huecos en el volumen o picos en las fronteras del mismo. Se generan estos artefactos debido a que los bloques de mayor tamaÃ±o producen mÃ¡s perdida de datos cuando se crean los niveles de detalles menores. (a) (b) Volumen en atlas de 256x256x256 Volumen en atlas de 1024x1024x1024 Volumen en atlas de 512x512x512 Volumen en atlas de 1024x1024x1024 CapÃ­tulo IV 83 Figura 4.6: Muestra del volumen utilizando 2 tamaÃ±os de bloques diferentes. La figura de la izquierda tiene bloques de tamaÃ±o 16. La figura de la derecha tiene bloques de tamaÃ±o 32. Se puede observar como el volumen con bloques de 32 posee mayor cantidad de artefactos visuales. Con respecto a los cambios de nivel de detalle, en la Figura 4.7 se pueden visualizar los cambios de niveles de detalles por cada tamaÃ±o de bloques utilizados. En el tamaÃ±o de 323 los cambios de nivel de detalles son mÃ¡s toscos por el aumento de tamaÃ±o de nivel de detalle y la cantidad de bloques refinados al mayor nivel son menores. En el de 163 se puede ver un cambio mÃ¡s suavizado, porque el bloque mÃ¡s fino es de menor tamaÃ±o y se generan menos niveles de detalles. Figura 4.7: Volumen de fruta haitiana almacenada en un atlas de 128MB con dos tamaÃ±os de bloques, 16 y 32 respectivamente. CapÃ­tulo IV 84 En las vistas de los resultados visuales se pueden distinguir que los volÃºmenes generan un pixelado entre cada una de las muestras. Esto se debe a que no se genera interpolaciÃ³n de muestras debido a que pueden generar artefactos entre frontera de bloques (ver Figura 4.8). Para solucionar esto, se debe realizar una interpolaciÃ³n entre bloques vecinos [16] para eliminar estos artefactos. Figura 4.8: Muestra del volumen 3 en un atlas de 1024x1024x1024. Se puede observar que aunque el volumen tiene buena resoluciÃ³n, posee artefactos visuales por la falta de interpolaciÃ³n entre los bloques. 4.7 ComparaciÃ³n con trabajos previos Para las comparaciones utilizamos el trabajo realizado por K. LÃ³pez [28]. Como se mencionÃ³ anteriormente, LÃ³pez utilizÃ³ una jerarquÃ­a basada en bloques usando un pÃ­xel de holgura entre las fronteras de cada bloque por lo que necesitaba 27% de memoria adicional (ver SecciÃ³n 2.10.1.2), necesaria para insertar mÃ¡s bloques. Para la inserciÃ³n de bloques en la textura atlas se particiona la textura segÃºn el tamaÃ±o del bloque que era insertado, como consecuencia, si se necesitaba insertar un bloque de mayor tamaÃ±o que el insertado anteriormente no era posible. Este particionamiento genera mucha fragmentaciÃ³n de CapÃ­tulo IV 85 memoria, por lo que se debe pasar por un proceso de desfragmentaciÃ³n para borrar e insertar todos los bloques ordenados en forma decreciente. En este trabajo no se usÃ³ el pÃ­xel de holgura y la memoria restante se usÃ³ para insertar mayor cantidad de bloques. Para para la textura atlas se usÃ³ el algoritmo de 3D Z-Order Strip, donde los bloques se reordenan en la textura atlas sin la necesidad de borrar todo y volver a insertar. Este algoritmo permite que los bloques se procesen en menos tiempo y haya mayor cantidad de bloques para un mejor despliegue del volumen. (a) (b) Figura 4.9: ComparaciÃ³n entre el proceso de refinado de la textura atlas en el trabajo implementado por K. LÃ³pez (a) y el proceso de refinado de la textura atlas en este trabajo especial de grado (b). CapÃ­tulo IV 86 Conclusiones y trabajos futuros 87 Conclusiones y Trabajos Futuros En este trabajo especial de grado se desarrollÃ³ una aplicaciÃ³n para la visualizaciÃ³n de volÃºmenes multi-resoluciÃ³n usando una jerarquÃ­a basada en bloques con diversos niveles de detalle aplicando la tÃ©cnica de Ray Casting en GPU de una pasada, utilizando una textura atlas para la inserciÃ³n de bloques de manera eficiente. La textura atlas es una estructura utilizada para ordenar otras texturas mÃ¡s pequeÃ±as en un espacio limitado. El tamaÃ±o de los bloques en la textura atlas afecta considerablemente el tiempo de procesamiento, ya que mientras el tamaÃ±o de los bloques es mayor implica una menor cantidad de los mismos. Al tener menos bloques el proceso de refinamiento es mÃ¡s rÃ¡pido, por el contrario, cuando se tienen bloques mÃ¡s pequeÃ±os el tiempo de refinamiento aumenta debido a que la cantidad de bloques es mayor. En conclusiÃ³n, se puede decir que el tiempo de refinamiento es proporcional a la cantidad de bloques y a su vez la cantidad de bloques es inversamente proporcional al tamaÃ±o del bloque. El algoritmo implementado, 3D Z-Order Strip, permite hacer la inserciÃ³n de bloques de forma eficiente, ya que su orden de complejidad es O(1), tambiÃ©n, no requiere de un proceso de desfragmentaciÃ³n de memoria, ya que el algoritmo mantiene un orden de los bloques y los espacios disponibles dentro de la textura atlas. Como consecuencia, se tiene un control total sobre la posiciÃ³n de los bloques, y de esta manera se puede aprovechar el mÃ¡ximo espacio posible de la textura atlas para insertar la mayor cantidad de bloques posible segÃºn el punto de interÃ©s indicado por el usuario. Muchos autores han propuestos diversas tÃ©cnicas para el despliegue de volÃºmenes multi-resoluciÃ³n, ya sea para mejorar los artefactos visuales o para optimizar los tiempos de respuesta. A continuaciÃ³n se presentan algunas propuestas para mejorar el sistema de despliegue realizado en este trabajo especial de grado: ï‚· Realizar un algoritmo de interpolaciÃ³n entre bloques para mejorar la calidad visual de la imagen y eliminar los artefactos visuales [16]. Conclusiones y trabajos futuros 88 ï‚· Implementar un algoritmo para insertar mÃ¡s de un bloque a la vez de forma contigua en la memoria de textura, para minimizar las operaciones de subida de bloques y aprovechar el ancho de banda del GPU. ï‚· Aplicar muestreo adaptativo en el despliegue del volumen [61] y aplicar clasificaciÃ³n pre-integrada para la mejora visual del volumen [4]. Referencias 89 Referencias [1] T. Elvins, â€œA Survey Of Algorithms For Volume Visualizationâ€, Advanced Scientific Visualization Laboratory, San Diego Supercomputer Center, vol. 26, 1992. [2] E. Coto, â€œVolume Renderingâ€, PresentaciÃ³n de Power Point, Centro de ComputaciÃ³n GrÃ¡fica, Universidad Central de Venezuela, Facultad de Ciencias, Caracas, Venezuela, 2010. [3] J.L. Bernadas Saragoza, â€œTetraedrizaciÃ³n De Intervalos De Volumen Mediante ModificaciÃ³n De Cubos Marchantesâ€, Trabajo Especial de Grado, Biblioteca Alonso Gamero, Universidad Central de Venezuela, Facultad de Ciencias, 2009. [4] R. Carmona, â€œVisualizaciÃ³n Multi-ResoluciÃ³n de VolÃºmenes de Gran TamaÃ±oâ€, Tesis Doctoral, Biblioteca Alonso Gamero, Universidad Central de Venezuela, Facultad de Ciencias, Caracas, Venezuela, 2008. [5] K. Engel, M. Kraus, T. Ertl, â€œHigh-Quality Pre-Integrated Volume Rendering Using Hardware-Accelerated PÃ­xel Shadingâ€, Visualization and Interactive Systems Group, University of Stuttgart, Germany, 2001. [6] J. Kruger, R. Westermann, â€œAcceleration Techniques for GPU-based Volume Renderingâ€, in Computer Graphics and Visualization Group, Technical University Munich, 2003. [7] M. Levoy, â€œDisplay Of Surfaces From Volume Dataâ€, Computer Science Department, University of North Carolina, 1988. [8] D. Ruijters, A. Vilanova, â€œOptimizing GPU Volume Rendering,â€ en WSCG - Winter School of Computer Graphics, vol. 14, pp. 9-16, 2006. [9] P. Lacroute, M. Levoy, â€œFast Volume Rendering Using Shear-Warp Factorization of the Viewing Transformationâ€, Proc. SIGGRAPH '94, pp. 451-458, Orlando, Florida, 1994. [10] The National Library of Medicine's. â€œVisible Human ProjectÂ®â€.1987. [En LÃ­nea]. Disponible en: http://www.nlm.nih.gov/research/visible/visible_human.html [11] A. A. Mirin et al., â€œVery High Resolution Simulation of Compressible Turbulence on the IBM-SP Systemâ€, Proc. of the 1999 ACM/IEEE conference on Supercomputing, artÃ­culo No.70, 1999. [12] P. Bhaniramka, Y. Demange, â€œOpenGL Volumizer: A Toolkit for High Quality Volume Rendering of Large Data setsâ€, Proc. IEEE Symposium on Volume Visualization and Graphics, pp. 45-54, 2002. http://www.nlm.nih.gov/research/visible/visible_human.html Referencias 90 [13] E. LaMar, M. Duchaineau, B. Hamann, K. Joy, â€œMulti-resolution Techniques for Interactive Texture-based Rendering of Arbitrarily Oriented Cutting Planesâ€, en Data Visualization 2000, The Joint Eurographics and IEEE TVCG conference on Visualization, pp. 105-114, 2000,. [14] E. LaMar, M. Duchaineau, B. Hamann, K. Joy, â€œMulti-resolution Techniques for Interactive Texture-based Volume Visualizationâ€, en Visualization '99, California-USA, pp. 355-361, 1999. [15] I. Boada, I.Navazo, R. Sopigno, â€œA 3D Texture-Based Octree Volume Visualization Algorithmâ€, en The Visual Computer, vol. 17, pp. 185-197, 2000. [16] P. Ljung, C. LundstrÃ¶m, A. Ynnerman, â€œMulti-resolution Interblock Interpolation in Direct Volume Renderingâ€, en Eurographics/IEEE-VGTC Symposium on Visualization, pp. 259-266, 2006. [17] X. Li, H. Shen, â€œTime-Critical Multiresolution Volume Rendering Using 3D Texture Mapping Hardwareâ€, en IEEE Volume Visualization and Graphics Symposium '02, Boston-USA, 2002. [18] B. Chamberlain, T. DeRose, D. Lischinski, David Salesin, and John Snyder, "Fast rendering of complex environments using a spatial hierarchy", pp. 132-141, 1996,. [19] E. LaMar, M. Duchaineau, B. Hamann, K. Joy, â€œMulti-resolution Techniques for Interactive Texture-based Volume Visualizationâ€, en Visualization '99, California-USA, pp. 355-361, 1999. [20] I. Boada, I. Navazo, R. Sopigno, â€œA 3D Texture-Based Octree Volume Visualization Algorithmâ€, en The Visual Computer, vol. 17, pp. 185-197, 2000. [21] S. Guthe, M. Wand, J. Gonser, and W. Strasser, â€œInteractive Rendering of Large Volume Data Setsâ€, en IEEE Visualization â€™02, pp. 53-60, 2002. [22] J. Plate, M. Tirsana, R. Carmona, B. Froehlich, â€œOctreemizer: A Hierarchical Approach for Interactive Roaming Through Very Large Volumesâ€, en Joint Eurographics - IEEE TCVG Symposium on Visualization '02, pp. 53-60, 2002. [23] D. Laur, P. Hanrahan, â€œHierarchical Splatting: A Progressive Refinement Algorithm For Volume Renderingâ€, en SIGGRAPH Comput. Graph., pp. 285-288, 1991. [24] I. Boada, I. Navazo, R. Sopigno, â€œMulti-resolution Volume Visualization With A Texture-Based Octreeâ€, en The Visual Computer, pp. 185-197, 2001. [25] J. GaoGao, C. Wang, and Han-Wei Shen, â€œParallel Multi-resolution Volume Rendering of Large Data Sets with Error-Guided Load Balancingâ€, en Parallel Comput, pp. 185-204., 2005. Referencias 91 [26] P. Ljung, C. Lundstrom, A. Ynnerman, K. Museth, â€œTransfer Function Based Adaptive Decompression for Volume Rendering of Large Medical Data Sets,â€ en IEEE Symposium on Volume Visualization and Graphics, pp. 25-32, 2004. [27] C. Wang, A. Garcia, H. WeiShen, â€œInteractive Level-of-Detail Selection Using Image- Based Quality Metric For Large Volume Visualization,â€ IEEE Transactions on Visualization. [28] K. LÃ³pez, â€œDespliegue de VolÃºmenes Multi-resoluciÃ³n Basado en Ray Casting de una Pasadaâ€, Universidad Central de Venezuela, Tesis de Pregrado, 2011. [29] Gabriel RodrÃ­guez, â€œDespliegue Multi-resoluciÃ³n de VolÃºmenes con ReducciÃ³n de Artefactos entre Sub-VolÃºmenes Adyacentesâ€, Universidad Central de Venezuela, Tesis de Pregrado, 2008. [30] Kurt Zimmermann, R. Westermann, T. Ertl, C. Hansen, M. Weiler, â€œLevel-of-Detail Volume Rendering via 3D Texturesâ€, en Volume Visualization and Graphics, IEEE Symposium on, Los Alamitos, CA, USA, pp. 7-13, 2000. [31] M. Guthe, J. Wand, Gonser, W. Strasser, â€œInteractive Rendering of Large Volume Data Setsâ€, en IEEE Visualization â€™02, pp. 53-60, 2002. [32] C. Lux, B. Frohlich, â€œGPU-Based Ray Casting of Multiple Multi-resolution Volume Datasetsâ€, e ISVC '09 Proceedings of the 5th International Symposium on Advances in Visual Computing: Part II, pp. 104-116, 2009. [33] OpenMPÂ®. The OpenMPÂ® API Specification For Parallel Programming. 2010. [En LÃ­nea]. Disponible en: http://openmp.org/ [34] B. Hapman, G. Jost, R. Van Der Pas, â€œUsing OpenMP Portable Shared Memory Parallel Programmingâ€, The MIT Press, 2008. [35] NVidiaCorporation. CUDA. 2012. [En LÃ­nea]. Disponible en: http://www.nvidia.com/object/cuda_home_new.html [36] NVidia. NVIDIA Â® CUDAâ„¢ Architecture. 2010 [En LÃ­nea]. Disponible en: http://developer.download.nvidia.com/compute/cuda/docs/CUDA_Architecture_Overview. pdf [37] NVidiaÂ®, NVIDIA CUDA C Programming Guide V4.0.: NVIDIA CUDAâ„¢, 2011. [38] P. Ljung, C. Lundstrom, A. Ynnerman, K. Museth, â€œTransfer Function Based Adaptive Decompression for Volume Rendering of Large Medical Data Setsâ€, en IEEE Symposium on Volume Visualization and Graphics, pp. 25-32, 2004. http://openmp.org/ http://www.nvidia.com/object/cuda_home_new.html http://developer.download.nvidia.com/compute/cuda/docs/CUDA_Architecture_Overview.pdf http://developer.download.nvidia.com/compute/cuda/docs/CUDA_Architecture_Overview.pdf Referencias 92 [39] C. Lux, B. Frohlich, â€œGPU-Based Ray Casting of Multiple Multi-Resolution Volume Datasets,â€ in ISVC '09 Proceedings of the 5th International Symposium on Advances in Visual Computing: Part II, pp. 104-116, 2009. [40] P. B. Galvin, G. Gagne, A. Silberschats, â€œFundamentos de Sistemas Operativosâ€, Septima EdiciÃ³n, Editorial Mc Graw Hill, 2006. [41] W. Stallings, â€œSistemas Operativosâ€, Segunda EdiciÃ³n, Editorial Pretice Hall, Inc., 2000 [42] J. Carretero PÃ©rez, P. M. Anasagasti, Sistemas Operativos â€œUna visiÃ³n aplicadaâ€, Editorial Mc Graw Hill, 2001. [43] J. MartÃ­n SÃ¡ez, M. HernÃ¡ndez Huerta, J. GonzÃ¡lez LÃ³pez, â€œUnidades de Acceso a Memoria de Texturas Estructura y Aplicaciones Dentro De Las UAMTâ€, Universidad Rey Juan Carlos. [44] D. Shreiner, â€œOpenGL Programing Guide SÃ©ptima EdiciÃ³nâ€, Editorial Addison- Wesley, 2010. [45] J. MartÃ­nez Bayona â€œSpace-Optimized Texture Atlasesâ€ Universitat PolitÃ¨cnica De Catalunya Master Thesis, 2009. [46] E. G. Corman, Jr., M. R. Garey, D. S. Johnson, R. E. Tarjan. â€œPerformance Bounds For Level-Oriented Two-Dimensional Packing Algorithmsâ€. SIAM Journal on Computing, 9:801-826, 1980. [47] F. K. R. Chung, M. R. Garey, D. S. Johnson. â€œOn Packing Two-Dimensional Bins. SIAM Journal of Algebraic and Discrete Methodsâ€, 3:66-76, 1982. [48] J. O. Berkey, P. Y. Wang. â€œTwo Dimensional Finite Bin Packing Algorithms. Journal Of The Operational Research Societyâ€, 38:423-429, 1987. [49] A. Lodi, S. Martello, D. Vigo. â€œHeuristic And Metaheuristic Approaches For A Class Of Two-Dimensional Bin Packing Problemsâ€. INFORMS Journal on Computing, 11:345- 357, 1999. [50] B. S. Baker, E. G. CoÂ®man, Jr., and R. L. Rivest. â€œOrthogonal packing in two dimensionsâ€. SIAM Journal on Computing, 9:846-855, 1980. [51] J. Gordon, â€œBinary Tree Bin Packing Algorithmâ€, 2011, [En LÃ­nea]. Disponible en: http://codeincomplete.com/posts/2011/5/7/bin_packing/ [52] K. Dowsland, â€œSome Experiments With Simulated Annealing Techniques For Packing Problemsâ€, European Journal of Operational Research, 68:389â€“399. 1993 Referencias 93 [53] S. Martello, P. Toth, â€œLower Bounds and Reduction Procedures for the Bin Packing Problem. Discrete Applied Mathematicsâ€, 28(1), 59â€“70. 1990 [54] S. Jacobs, â€œOn Genetic Algorithms For The Packing Of Polygons, European Journal Of Operational Researchâ€, 88:165â€“181. 1996. [55] L. Cruz-Reyes, M. Quiroz C., A. C. F. Alvim, H. J. Fraire Huacuja, C. GÃ³mez S. , J. Torres-JimÃ©nez, â€œHeurÃ­sticas De AgrupaciÃ³n HÃ­bridas Eficientes Para El Problema De Empacado De Objetos En Contenedoresâ€, Centro de InvestigaciÃ³n y de Estudios Avanzados del Instituto PolitÃ©cnico Nacional, MÃ©xico ComputaciÃ³n y Sistemas Vol. 16 No.3, pp 349-360, 2012. [56] F. Torres, D. Mauricio, L. Rivera, â€œUn modelo de CompactaciÃ³n de Objetos Irregulares UPG-FISIâ€, Universidad Nacional Mayor de San Marcos (UNMSM) LCMAT- CCT, Universidade Estadual do Norte Fluminense (UENF) 2000. [57] J. Sol Roo, J. P. Dâ€™Amato, E. Ferrante, â€œOptimizaciÃ³n de Atlas de Textura Utilizando CompactaciÃ³n de PolÃ­gonos por SimulaciÃ³n FÃ­sicaâ€, Facultad de Ciencias Exactas, Universidad Nacional del Centro de la Provincia de Buenos Aires, Tandil, Argentina, Consejo Nacional de Investigaciones CientÃ­ficas y TÃ©cnicas CONICET, Bs. As., Argentina Ã‰cole Centrale de Paris, Paris, Francia. [58] K. E. Kendall, J. E. Kendall, â€œAnÃ¡lisis Y DiseÃ±o De Sistemasâ€, Editorial Pearson, 2005. [59] GestiÃ³n Operativa De La Calidad Del Software â€œExtreme Programingâ€ [En LÃ­nea]. Disponible En: http://maestria-modulo7.blogspot.com/2012/04/procesos-de-desarrollo- ligeros-vs.html [60] AntTweakBar Library [En LÃ­nea]. Disponible En: http://anttweakbar.sourceforge.net/doc/ [61] R. Carmona, B. Froehlich, â€œError-Controlled Real-Time Cut Updates For Multi- Resolution Volume Renderingâ€, Universidad Central de Venezuela, Facultad de Ciencias, Centro de ComputaciÃ³n GrÃ¡fica, Caracas, Venezuela, 2011. [62] Deane B. Judd, â€œHue saturation and lightness of surface colors with chromatic illuminationâ€ Journal of the Optical Society of America, vol. 3, no. 1, p. 2, 1949. [63] MPI [En LÃ­nea]. Disponible En: http://www.mcs.anl.gov/research/projects/mpi/ [64] OpenMP [En LÃ­nea]. Disponible En: http://openmp.org/wp/ [65] OpenCL [En LÃ­nea]. Disponible En: http://www.khronos.org/opencl/ [66] CUDA [En LÃ­nea]. Disponible En: http://maestria-modulo7.blogspot.com/2012/04/procesos-de-desarrollo-ligeros-vs.html http://maestria-modulo7.blogspot.com/2012/04/procesos-de-desarrollo-ligeros-vs.html http://maestria-modulo7.blogspot.com/2012/04/procesos-de-desarrollo-ligeros-vs.html http://anttweakbar.sourceforge.net/doc/ http://www.mcs.anl.gov/research/projects/mpi/ http://openmp.org/wp/ http://www.khronos.org/opencl/ Referencias 94 http://la.nvidia.com/object/cuda_home_new_la.html [67] OpenGL [En LÃ­nea]. Disponible En: http://www.khronos.org/opengl [68] E.Purcel, D. Varberg y E. Rigdon â€œCalculo Octava EdiciÃ³nâ€, Pearson EducaciÃ³n, p. 234, 2001. [69] T. Crainic, G. Perboli, R. Tadei, â€œExtreme Point-Based Heuristic for Three Dimensional Bin Packingâ€, UniversitÃ© de MontrÃ©al, QuebÃ©c, Canada, 2007. [70] Z-order curve [En LÃ­nea]. Disponible En: http://en.wikipedia.org/wiki/Z-order_curve [71] Schwaber, K., & Sutherland, J. (2010). Scrum guide. [En LÃ­nea]. Disponible En: http://www.scrumguides.org/ [72] Cohn, M. User stories applied: For agile software development. Addison Wesley. 2004. http://la.nvidia.com/object/cuda_home_new_la.html http://www.khronos.org/opengl http://en.wikipedia.org/wiki/Z-order_curve http://www.scrumguides.org/