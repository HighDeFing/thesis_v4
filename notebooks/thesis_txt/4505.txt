Universidad Central de Venezuela Facultad de Ciencias Escuela de Computaci√≥n Centro de Computaci√≥n Distribuida y Paralela Desarrollo de una interfaz gr√°fica en R para la ejecuci√≥n de m√©todos de miner√≠a de datos sobre plataformas Hadoop para Big Data. Trabajo Especial de Grado presentado ante la ilustre Universidad Central de Venezuela por el Br. Pascual Madrid Tutor: Prof. Jes√∫s Lares Prof. Jos√© Sosa Caracas, Octubre de 2015 ii ACTA Quienes suscriben, Miembros del Jurado designado por el Consejo de la Escuela de Computaci√≥n para examinar el Trabajo Especial de Grado, presentado por el Bachiller Pascual Madrid C.I.: 20.604.893, con el t√≠tulo: ‚ÄúDesarrollo de una interfaz gr√°fica en R para la ejecuci√≥n de m√©todos de miner√≠a de datos sobre plataformas Hadoop para Big Data‚Äù, a los fines de cumplir con el requisito legal para optar al t√≠tulo de Licenciado en Computaci√≥n, dejan constancia de lo siguiente: Le√≠do el trabajo por cada uno de los Miembros del Jurado, se fij√≥ el d√≠a 27 de octubre de 2015, a las 09:00am, para que su autor lo defendiera en forma p√∫blica, en la Sala III Postgrado de la Escuela de Computaci√≥n, Facultad de Ciencias de la Universidad Central de Venezuela, lo cual realiz√≥ mediante una exposici√≥n oral de su contenido, y luego respondi√≥ a las preguntas que le fueron formuladas por el Jurado, todo ello conforme a lo dispuesto en la Ley de Universidades y dem√°s normativas vigentes de la Universidad Central de Venezuela. Finalizada la defensa p√∫blica del Trabajo Especial de Grado, el jurado decidi√≥ aprobarlo con la nota de _________ puntos. En fe de lo cual se levanta la presente acta, en Caracas el 27 de octubre de 2015. _________________ _________________ Prof. Jos√© Sosa Prof. Jes√∫s Lares Tutor Tutor _________________ _________________ Prof. H√©ctor Navarro Prof. Fernando Crema Jurado Jurado iii Resumen El an√°lisis de grandes vol√∫menes de datos representa un gran reto para los cient√≠ficos de datos, ya sea desde un punto de vista intelectual y uno de recursos. No es sencillo realizar an√°lisis en plataformas de Big Data debido a que los scripts deben seguir un paradigma de programaci√≥n llamado MapReduce el cual resulta todo un reto hasta para las personas con mucha experiencia en la programaci√≥n sin contar lo costoso que es implementar toda una infraestructura que de soporte a la cantidad masiva de datos. La intenci√≥n de este trabajo de grado es la realizaci√≥n de una aplicaci√≥n que provea una interfaz gr√°fica para la ejecuci√≥n de m√©todos de miner√≠a de datos sobre una plataforma Hadoop de una manera remota sin tener que implementar m√©todos MapReduce ni tener que preparar una infraestructura Hadoop, s√≥lo utilizar una ya preparada previamente. La aplicaci√≥n fue programada utilizando el lenguaje de programaci√≥n estad√≠stico R utilizando una gran gama de paquetes para el desarrollo de la interfaz y de los c√°lculos. La comunicaci√≥n con la plataforma Hadoop se hace mediante el protocolo SSH (Secure Shell) permitiendo un tr√°fico de informaci√≥n de manera segura en todo momento. Se realizaron pruebas sencillas que englobaron todas las funcionalidades de la aplicaci√≥n. Este trabajo dej√≥ como fruto final una interfaz gr√°fica programada en R capaz de ejecutar m√©todos de miner√≠a de datos de manera local y remota sobre un cl√∫ster Hadoop y tambi√©n la posibilidad de ejecutar funciones Map y Reduce en un cl√∫ster Hadoop utilizando la funcionalidad llamada Hadoop Streaming. iv Agradecimientos Agradezco principalmente a Dios por permitirme hoy estar cumpliendo un sue√±o y por no dejarme s√≥lo en ning√∫n momento. A mi madre por todo el apoyo humano tan particular que me ha dado en toda mi vida. A mis hermanas Lucila Madrid, Carmen Ca√±as y a m√≠ cu√±ado Xavier Capelo por todo el apoyo que me han dado durante toda la carrera. A mis t√≠os Jaime Madrid, Hern√°n Valera y Antonio Valera, por sus orientaciones y todas las experiencias que han compartido conmigo toda mi vida. A Laura Gonz√°lez por brindarme todo su apoyo y cari√±o desde siempre. A Vicente Ordo√±ez, Juan Morantes y Gustavo Morantes por todo el apoyo que me han brindado y por compartir conmigo sus conocimientos y experiencias en el √°mbito acad√©mico y laboral. A Emily Corro, Daniel Hern√°ndez, Rafael Machado, √Ålvaro Marciales, Eduardo S√°nchez, Carlos Pereira y Claudio Torrez, por la amistad y hermandad que me han brindado por a√±os. Son pilares y s√≠mbolos de motivaci√≥n en muchos sentidos de mi vida. A todas aquellas personas que de una u otra manera me ayudaron durante el desarrollo de este Trabajo Especial de Grado. A mis tutores Jes√∫s Lares y Jos√© Sosa por el apoyo y confianza que han tenido en mi trabajo y por haberme guiado en el desarrollo de este Trabajo Especial de Grado. Igualmente al profesor Fernando Crema y al profesor H√©ctor Navarro por haberme ayudado a corregir los errores del TEG y haber sido un ejemplo de excelencia. Este trabajo especial de Grado est√° dedicado a Pascual Madrid Manzanilla, Pascual Madrid Araujo, Carmen Ver√≥nica Blanco y Pablo Padr√≥n v Tabla de contenidos ACTA ............................................................................................................... ii Resumen ........................................................................................................ iii Agradecimientos ............................................................................................. iv √çndice de figuras .............................................................................................. x √çndice de tablas ............................................................................................. xiii Introducci√≥n .................................................................................................. xiv 1. El Problema ........................................................................................... 16 1.1. Planteamiento del Problema .............................................................. 16 1.2. Justificaci√≥n ........................................................................................ 17 1.2.1. ¬øPor qu√© es un problema? .......................................................... 17 1.2.2. ¬øPara qui√©n es un problema? ...................................................... 17 1.2.3. ¬øDesde cu√°ndo es un problema? ................................................ 17 1.3. Objetivos de la investigaci√≥n .............................................................. 18 1.3.1. Objetivo General .......................................................................... 18 1.3.2. Objetivos Espec√≠ficos ................................................................... 18 1.4. Antecedentes ..................................................................................... 18 1.5. Alcance ............................................................................................... 20 2. Marco Conceptual .................................................................................. 22 2.1. Ciencia de Datos ................................................................................ 22 2.1.1. Miner√≠a de Datos ......................................................................... 22 2.1.1.1. Clustering .............................................................................. 23 2.1.1.1.1. K-medias......................................................................... 23 2.1.1.1.2. Clustering Jer√°rquico ...................................................... 25 2.1.1.1.3. An√°lisis de Componentes Principales ............................. 26 2.1.1.2. Clasificaci√≥n .......................................................................... 27 2.1.1.2.1. K vecinos m√°s cercanos ................................................. 27 2.1.1.2.2. An√°lisis discriminante ..................................................... 29 2.1.1.2.3. Maquinas vectoriales de soporte .................................... 29 Tabla de Contenidos vi 2.1.1.2.4. √Årbol de Decisi√≥n ............................................................ 32 2.1.1.2.5. Bosques Aleatorios ......................................................... 35 2.1.1.2.6. Redes Bayesianas .......................................................... 37 2.1.1.2.7. Redes Neuronales .......................................................... 38 2.1.1.2.8. Regresi√≥n Log√≠stica ........................................................ 39 2.1.2. Grandes Vol√∫menes de Datos ..................................................... 39 2.1.2.1. Las 5 V‚Äôs de Grandes Vol√∫menes de Datos .......................... 39 2.2. Sistema Operativo .............................................................................. 41 2.2.1. Tipos de Sistema Operativo ......................................................... 41 2.2.2. Linux ............................................................................................ 43 2.2.2.1. GTK+ ..................................................................................... 43 2.2.2.2. Secure Shell .......................................................................... 43 2.3. Lenguajes de Programaci√≥n ............................................................... 44 2.3.1. R .................................................................................................. 44 2.3.1.1. gWidgets2 ............................................................................. 44 2.3.1.2. RHadoop ............................................................................... 49 2.3.1.2.1. rmr2 ................................................................................ 50 2.3.1.2.2. rhdfs ................................................................................ 50 2.3.2. Java ............................................................................................. 50 2.3.3. Python .......................................................................................... 51 2.3.3.1. SciPy ..................................................................................... 51 2.4. Apache Hadoop .................................................................................. 51 2.4.1. Common ...................................................................................... 53 2.4.2. Hadoop Distributed File System (HDFS) ..................................... 53 2.4.2.1. Conceptos ............................................................................. 55 2.4.3. MapReduce ................................................................................. 57 2.4.3.1. Hadoop Streaming ................................................................ 60 2.4.4. YARN ........................................................................................... 62 2.4.5. Herramientas del Ecosistema Hadoop ......................................... 65 2.4.5.1. Hive ....................................................................................... 65 Tabla de Contenidos vii 2.4.5.2. Pig ......................................................................................... 66 2.4.5.3. HCatalog ............................................................................... 68 2.4.5.4. Apache Spark ........................................................................ 69 2.4.5.5. Apache Flume ....................................................................... 70 2.4.5.6. Hue ........................................................................................ 71 2.4.5.7. Apache ZooKeeper ............................................................... 72 2.4.5.8. Shark ..................................................................................... 75 2.4.5.9. Apache Sqoop ....................................................................... 76 2.4.6. Distribuciones Hadoop ................................................................. 77 2.4.6.1. MapR ..................................................................................... 77 2.4.6.2. Cloudera ................................................................................ 77 2.4.6.3. Hortonworks .......................................................................... 78 2.4.6.4 Comparaci√≥n entre Hortonworks y Cloudera ......................... 78 2.4.6.4.1. Similitudes ...................................................................... 78 2.4.6.4.2. Diferencias ...................................................................... 79 2.4.6.5. Comparaci√≥n general ............................................................ 80 3. M√©todo de Desarrollo ............................................................................ 82 3.1. Manifiesto √Ågil .................................................................................... 82 3.1.1. Principios del Manifiesto √Ågil ....................................................... 83 3.2. M√©todos √Ågiles ................................................................................... 83 3.2.1. Metodolog√≠a Ad Hoc orientada a prototipos ................................. 84 4. Desarrollo de la Soluci√≥n ....................................................................... 87 4.1. Cl√∫ster ................................................................................................ 87 4.1.1. Instalaci√≥n de R ........................................................................... 87 4.1.1.1. Instalaci√≥n de rmr .................................................................. 87 4.1.1.2. Instalaci√≥n de rhdfs ............................................................... 87 4.2. Ambiente de Desarrollo ...................................................................... 88 4.2.1. Instalaci√≥n de GTK+ .................................................................... 88 4.2.2. Instalaci√≥n de R ........................................................................... 88 4.2.2.1. Instalaci√≥n de R-Studio ......................................................... 88 Tabla de Contenidos viii 4.2.2.2. Instalaci√≥n y actualizaci√≥n de paquetes ................................ 88 4.2.3. Instalaci√≥n de Openssh y sshpass .............................................. 90 4.3. Aplicaci√≥n ........................................................................................... 90 4.3.1. Prototipo 0 ................................................................................... 91 4.3.1.1. Objetivos ............................................................................... 91 4.3.1.2. Resultados ............................................................................ 91 4.3.1.3. Conclusiones ......................................................................... 95 4.3.2. Prototipo 1 ................................................................................... 96 4.3.2.1. Objetivos ............................................................................... 96 4.3.2.2. Resultados ............................................................................ 96 4.3.2.3. Conclusiones ....................................................................... 103 4.3.3. Prototipo 2 ................................................................................. 104 4.3.3.1. Objetivos ............................................................................. 104 4.3.3.2. Resultados .......................................................................... 104 4.3.3.3. Conclusiones ....................................................................... 104 4.3.4. Prototipo 3 ................................................................................. 105 4.3.4.1. Objetivos ............................................................................. 105 4.3.4.2. Resultados .......................................................................... 105 4.3.4.3. Conclusiones ....................................................................... 113 4.3.5. Prototipo 4 ................................................................................. 113 4.3.5.1. Objetivos ............................................................................. 114 4.3.5.2. Resultados .......................................................................... 114 4.3.5.3. Conclusiones ....................................................................... 115 4.3.6. Prototipo 5 ................................................................................. 115 4.3.6.1. Objetivos ............................................................................. 116 4.3.6.2. Resultados .......................................................................... 116 4.3.6.3. Conclusiones ....................................................................... 118 4.3.7. Prototipo 6 ................................................................................. 119 4.3.7.1. Objetivos ............................................................................. 119 4.3.7.2. Resultados .......................................................................... 119 Tabla de Contenidos ix 4.3.7.3. Conclusiones ....................................................................... 128 5. Conclusiones y Resultados .................................................................. 129 5.1. Resultados ....................................................................................... 129 5.2. Conclusiones .................................................................................... 141 5.3. Recomendaciones ............................................................................ 142 5.4. Trabajos Futuros .............................................................................. 142 Anexos ........................................................................................................ 143 Gu√≠a de instalaci√≥n de R, rmr y rhdfs ...................................................... 143 Gu√≠a de instalaci√≥n de gtk+ ..................................................................... 145 Gu√≠a de instalaci√≥n de R ......................................................................... 146 Gu√≠a de instalaci√≥n de R-Studio .............................................................. 147 Gu√≠a de instalaci√≥n Openssh y sshpass ................................................. 148 Algoritmo de K-medias en MapReduce en R .......................................... 149 Algoritmo de Regresi√≥n Log√≠stica en MapReduce en R .......................... 151 Funci√≥n Map del algoritmo Wordcount en R ........................................... 152 Funci√≥n Reduce del algoritmo Wordcount en R ...................................... 153 Bibliograf√≠a .................................................................................................. 154 x √çndice de figuras Figura 1: Interfaz Gr√°fica de Weka (http://cs.calstatela.edu/wiki/index.php/Courses/CS_491ab/Winter_2009/Lala ntha_Sathkumara) ........................................................................................ 19 Figura 2: Interfaz gr√°fica Rcommander (http://uce.uniovi.es/CURSOICE/Informese2.html) ....................................... 19 Figura 3: Interfaz gr√°fica de Rattle ................................................................ 20 Figura 4: Ejemplo agrupaci√≥n K-medias ....................................................... 25 Figura 5: Ejemplo Agrupamiento jer√°rquico ascendente .............................. 26 Figura 6: Ejemplo K vecinos m√°s cercanos .................................................. 28 Figura 7: Ejemplo Maquinas vectoriales de Soporte ..................................... 30 Figura 8: Maquina vectorial de soporte de margen m√°ximo ......................... 31 Figura 9: Maquina vectorial de soporte de margen blando ........................... 31 Figura 10: Ejemplo √Årbol de Decisi√≥n ........................................................... 32 Figura 11: √Årbol Podado ............................................................................... 35 Figura 12: Ejemplo m√©todos de consenso .................................................... 35 Figura 13: Ejemplo Bosques Aleatorios ........................................................ 36 Figura 14: Ejemplo de ventana creada con el paquete gWidgets2 en R ...... 45 Figura 15: Arquitectura HDFS ....................................................................... 55 Figura 16: Ejemplo de MapReduce ............................................................... 57 Figura 17: Arquitectura YARN de Hortonworks............................................. 62 Figura 18: Proceso MapReduce YARN ........................................................ 64 Figura 19: Ciclo de la metodolog√≠a utilizada ................................................. 85 Figura 20: Ejemplo de widget utilizando R con el paquete gWidgets ............ 91 Figura 21: Secci√≥n K-medias del Prototipo 0 ................................................ 92 Figura 22: Secci√≥n de An√°lisis de Componentes Principales del Prototipo 0 92 Figura 23: Secci√≥n Cl√∫ster Jer√°rquico del Prototipo 0 .................................. 93 Figura 24: Resultado del m√©todo K medias del prototipo 0 .......................... 93 Figura 25: Resultado An√°lisis de componentes Principales del Prototipo 0 . 94 √çndice de Figuras xi Figura 26: Resultados gr√°ficos de An√°lisis de componentes principales del Prototipo 0 .................................................................................................... 94 Figura 27: Resultado Agrupamiento Jer√°rquico ............................................ 95 Figura 28: Vista principal del prototipo 1 ....................................................... 97 Figura 29: Secci√≥n de carga de datos del prototipo 1 ................................... 98 Figura 30: Secci√≥n de an√°lisis exploratorio de datos del prototipo 1 ............ 99 Figura 31: Secci√≥n para el agrupamiento de datos del prototipo 1 ............. 100 Figura 32: Secci√≥n de Big Data del prototipo 1 ........................................... 101 Figura 33: Resultados gr√°ficos de la secci√≥n de exploraci√≥n de datos del prototipo 1 ................................................................................................... 102 Figura 34: Resultados gr√°ficos del m√©todo K medias del prototipo 1 ......... 102 Figura 35: Resultados gr√°ficos del m√©todo agrupamiento jer√°rquico del prototipo 1 ................................................................................................... 103 Figura 36: Resultado K medias MapReduce del prototipo 2 ....................... 104 Figura 37: Secci√≥n modelo del prototipo 3 .................................................. 106 Figura 38: Secci√≥n para la creaci√≥n de conexiones del prototipo 3 ............ 107 Figura 39: Resultado de carga previa al almacenamiento de conexiones en el prototipo 3 ................................................................................................... 108 Figura 40: Datos de una conexi√≥n del prototipo 3 ....................................... 109 Figura 41: Secci√≥n d√≥nde se muestran todas las conexiones disponibles del prototipo 3 ................................................................................................... 110 Figura 42: M√©todos disponibles para las conexiones de tipo archivo csv del prototipo 3 ................................................................................................... 111 Figura 43: M√©todos disponibles para las conexiones de tipo archivo HDFS del prototipo 3 ............................................................................................. 112 Figura 44: Resultado de clasificaci√≥n por el m√©todo de agrupamiento jer√°rquico .................................................................................................... 113 Figura 45: Secci√≥n crear nueva conexi√≥n del prototipo 4 ........................... 115 Figura 46: Resultado del m√©todo K medias del prototipo 5 ........................ 116 Figura 47: Resultado del m√©todo Bosques Aleatorios del prototipo 5 ......... 117 Figura 48: Gr√°fico del codo de jambu ......................................................... 118 Figura 49: Jer√°rquia del proyecto ............................................................... 120 √çndice de Figuras xii Figura 50: Vista principal del prototipo 6 ..................................................... 121 Figura 51: Funcionalidad de Subir funci√≥n MAP del prototipo 6 ................. 122 Figura 52: Funcionalidad para crear conexi√≥n de tipo Archivo HDFS ......... 123 Figura 53: Secci√≥n para ejecutar funciones MAP y REDUCE sobre un cl√∫ster Hadoop ....................................................................................................... 124 Figura 54: Secci√≥n que muestra las conexiones almacenadas del prototipo 6 .................................................................................................................... 125 Figura 55: Ejemplo de tooltip en el prototipo 6 ............................................ 126 Figura 56: Ejecuci√≥n del m√©todo K medias MapReduce ............................ 127 Figura 57: Ejecuci√≥n del m√©todo Regresi√≥n Log√≠stica MapReduce ............ 128 Figura 58: Estad√≠sticas de la Conexi√≥n 1 .................................................... 129 Figura 59: Estadisticas de la Conexi√≥n 2 .................................................... 130 Figura 60: Resultado An√°lisis de Componentes Principales ....................... 131 Figura 61: Resultado An√°lisis de Componentes Principales (Individuos) ... 132 Figura 62: Resultados An√°lisis de Componentes Principales (Variables) ... 133 Figura 63: Resultados del m√©todo K medias .............................................. 134 Figura 64: Diagrama de datos del m√©todo K medias .................................. 135 Figura 65: Clasificaci√≥n despu√©s de aplicar el m√©todo K medias ............... 136 Figura 66: Resultado Agrupamiento Jer√°rquico .......................................... 137 Figura 67: Clasificaci√≥n del m√©todo Agrupamiento Jer√°rquico ................... 138 Figura 68: Clasificaci√≥n despu√©s de ejecutar el m√©todo Agrupamiento Jer√°rquico ................................................................................................... 139 Figura 69: Centros de grupos generados tras la ejecuci√≥n del m√©todo K medias MapReduce sobre un cl√∫ster Hadoop ............................................ 139 Figura 70: Resultado del m√©todo Bosques Aleatorios utilizando la conexi√≥n 2 .................................................................................................................... 140 Figura 71: Resultado del m√©todo Regresi√≥n Log√≠stica utilizando la conexi√≥n 3 .................................................................................................................... 140 xiii √çndice de tablas Tabla 1: Parametros de Hadoop Streaming .................................................. 62 Tabla 2: Comparaci√≥n de las principales distribuciones de Hadoop ............. 81 Tabla 3: Primeros siete resultados del Hadoop Streaming ......................... 141 xiv Introducci√≥n Actualmente vivimos en un mundo globalizado regido por la Internet y un sin fin de tecnolog√≠as basadas de igual manera en la Internet, sabemos que estamos en una √©poca en la que cada d√≠a se genera informaci√≥n, la cual muchas veces no nos enteramos que de verdad se haya generado. La mayor√≠a de esta informaci√≥n est√° no estructurada lo que implica que es indescifrable para el ojo com√∫n, debido a que oculta patrones que no se ven a simple vista, al descubrir estos patrones las empresas tendr√°n una gran ventaja en conocimiento sobre sus principales competidores. Todo lo planteado ha dado un gran impulso a una gran gama de oportunidades basadas en el conocimiento que se puede obtener a partir de todos esos datos generados diariamente. A ra√≠z de esto podr√≠an surgir una serie de interrogantes validas que describimos a continuaci√≥n: ÔÇ∑ ¬øC√≥mo hago para acceder de forma eficaz y eficiente a todos estos datos? ÔÇ∑ ¬øExiste alguna estructura o esquema de almacenamiento que permita mantener en el tiempo estos datos? ÔÇ∑ Una vez obtenido los datos ¬øC√≥mo los proceso eficientemente para obtener informaci√≥n relevante que permita optimizar el proceso de toma de decisiones dentro de la organizaci√≥n? La respuesta a todas estas interrogantes la tiene una tecnolog√≠a emergente llamada Big Data o Grandes Vol√∫menes de Datos, la cual se definir√° en el contenido de la investigaci√≥n. El trabajo de investigaci√≥n se divide en cinco cap√≠tulos. En el primer cap√≠tulo se describe el problema a solucionar. Se plantea el problema, su justificaci√≥n, los objetivos y el alcance de la misma. En el segundo cap√≠tulo se definen las bases te√≥ricas de la investigaci√≥n. Se define lo que es ciencia de datos, miner√≠a de datos, grandes vol√∫menes de datos la herramienta Apache Hadoop, el lenguaje de programaci√≥n estad√≠stico R, entre otras definiciones. En el tercer cap√≠tulo se define la metodolog√≠a de desarrollo utilizada para la aplicaci√≥n que da respuesta al problema de investigaci√≥n. Introducci√≥n xv En el cuarto cap√≠tulo se describe en detalle el proceso de desarrollo de la aplicaci√≥n y finalmente en el quinto cap√≠tulo se describen los resultados y las conclusiones obtenidas. 16 1. El Problema 1.1. Planteamiento del Problema En la Escuela de Computaci√≥n de la Universidad Central de Venezuela ha surgido la iniciativa de incursionar en el mundo de la ciencia de datos realizando investigaciones y proyectos relacionados con el an√°lisis de datos complejos y/o masivos. Para realizar estos proyectos se necesita un cl√∫ster de computadores, espec√≠ficamente un cl√∫ster basado en Apache Hadoop, tener acceso al mismo y escribir m√©todos para realizar los an√°lisis sobre el cl√∫ster. No siempre se tiene acceso a un cl√∫ster de manera directa pero para dar los primeros pasos las 3 grandes compa√±√≠as especializadas en el procesamiento de grandes vol√∫menes de datos (Cloudera, Hortonworks y MapR) ofrecen instalaciones de pruebas llamadas ‚ÄúSandBox‚Äù. Pero estas instalaciones no tienen la capacidad de hacer an√°lisis de envergadura debido a que se encuentran en la maquina local. Sin embargo se pueden hacer an√°lisis de envergadura sobre un cl√∫ster remoto si se encuentra en alg√∫n centro dedicado siempre y cuando se tenga acceso al mismo. La mejor manera para conectarse a un cl√∫ster remoto es utilizando el protocolo SSH (Secure Shell), pero no todos los interesados en utilizar el cl√∫ster conocen los pasos para realizar una conexi√≥n. Para realizar un an√°lisis en un cl√∫ster remoto se deben seguir los siguientes pasos: 1) Generar los scripts y los datos de entrada de manera local 2) Enviar los archivos generados al cl√∫ster 3) Establecer una conexi√≥n dedicada 4) Ejecutar los scripts 5) Visualizar el resultado. Cap√≠tulo 1. El Problema 17 Esos scripts deben seguir el paradigma de programaci√≥n MapReduce lo cual resulta muy complejo para cualquier analista debido a que deben cambiar cualquier soluci√≥n v√°lida a este paradigma para que pueda funcionar en el cl√∫ster. Por todo lo anterior ser√≠a de gran utilidad la creaci√≥n de una aplicaci√≥n que brinde una interfaz gr√°fica que provea la funcionalidad de conectarse a un cl√∫ster Apache Hadoop y realizar an√°lisis de datos complejos abstrayendo a los usuarios finales de los pasos de conexi√≥n remota y del desarrollo de complejos scripts MapReduce utilizando m√©todos previamente validados por otros analistas con mayores conocimientos en el paradigma MapReduce. 1.2. Justificaci√≥n 1.2.1. ¬øPor qu√© es un problema? Es un problema porque resulta muy engorroso realizar los pasos para la conexi√≥n remota a un cl√∫ster Apache Hadoop y la realizaci√≥n de scripts MapReduce v√°lidos. 1.2.2. ¬øPara qui√©n es un problema? Es un problema para cualquier persona que desee incursionar en el mundo de la ciencia de datos y no posea los conocimientos necesarios para la realizaci√≥n de los pasos previos para una conexi√≥n remota ni la pericia para desarrollar scripts en el paradigma MapReduce. 1.2.3. ¬øDesde cu√°ndo es un problema? A grandes rasgos es un problema desde que se desea realizar un an√°lisis de datos teniendo acceso a un cluster pero sin saber c√≥mo acceder al mismo ni como realizar scripts MapReduce. Cap√≠tulo 1. El Problema 18 1.3. Objetivos de la investigaci√≥n 1.3.1. Objetivo General Desarrollar una aplicaci√≥n capaz de ejecutar algoritmos de miner√≠a de datos en un cluster Apache Hadoop para hacer an√°lisis de datos accediendo al mismo de manera remota y mostrando los resultados de manera local. 1.3.2. Objetivos Espec√≠ficos a) Realizar las instalaciones necesarias en el ambiente de desarrollo local y en el cluster de prueba. b) Programar la aplicaci√≥n. c) Definir casos de estudio para las pruebas integradas de la aplicaci√≥n. d) Visualizar los resultados obtenidos. 1.4. Antecedentes No conocemos antecedentes de una aplicaci√≥n capaz de ejecutar algoritmos MapReduce de manera remota en un cl√∫ster Apache Hadoop pero si conocemos antecedentes de aplicaciones que ejecutan modelos de miner√≠a de datos, las cuales sirvieron de inspiraci√≥n para el desarrollo de esta investigaci√≥n. a) Weka: Weka es una colecci√≥n de algoritmos de aprendizaje autom√°tico para tareas de miner√≠a de datos [1]. Contiene tambi√©n una colecci√≥n de herramientas de visualizaci√≥n unidas a una interfaz gr√°fica de usuario para acceder f√°cilmente a sus funcionalidades. Las √∫ltimas versiones de Weka fueron implementadas en Java [2]. Cap√≠tulo 1. El Problema 19 Figura 1: Interfaz Gr√°fica de Weka (http://cs.calstatela.edu/wiki/index.php/Courses/CS_491ab/Winter_2009/Lalantha_Sathkumara) b) Rcommander: Rcommander es una interfaz gr√°fica para el uso de las funcionalidades que proporciona el lenguaje de programaci√≥n R. R proporciona un sistema potente para el an√°lisis de datos y cuando se utiliza con RCommander proporciona una interfaz gr√°fica que es f√°cil e intuitiva de usar [3]. Figura 2: Interfaz gr√°fica Rcommander (http://uce.uniovi.es/CURSOICE/Informese2.html) Cap√≠tulo 1. El Problema 20 c) Rattle: Rattle es una interfaz gr√°fica para la miner√≠a de datos utilizando el lenguaje de programaci√≥n R. Rattle proporciona funcionalidades de miner√≠a de datos exponiendo considerablemente el poder R a trav√©s de una interfaz gr√°fica de usuario. Rattle se puede utilizar para el an√°lisis estad√≠stico, o la generaci√≥n de modelos [4]. Figura 3: Interfaz gr√°fica de Rattle Rattle es la aplicaci√≥n que m√°s ha inspirado el desarrollo de esta investigaci√≥n debido a que se program√≥ utilizando las mismas herramientas de desarrollo. 1.5. Alcance Esta aplicaci√≥n va dirigida a todas las personas que est√©n interesadas en incursionar en el mundo de la ciencia de datos. La aplicaci√≥n cuenta con Cap√≠tulo 1. El Problema 21 una interfaz sencilla que contempla a grandes rasgos las siguientes funcionalidades: a) Crear conexiones de datos b) Verificar las conexiones creadas c) Realizar an√°lisis exploratorio a las conexiones creadas d) Realizar clustering de datos a las conexiones creadas de manera local y en un cluster Apache Hadoop e) Aplicaci√≥n de modelos de miner√≠a de datos a las conexiones creadas de manera local y en un cluster Apache Hadoop f) Ejecuci√≥n de funciones map y reduce en un cluster Apache Hadoop 22 2. Marco Conceptual 2.1. Ciencia de Datos La Ciencia de Datos (Data Science) es el estudio de la extracci√≥n de conocimiento generalizable a partir de datos. El t√©rmino ‚ÄúCiencia‚Äù implica conocimiento ganado a trav√©s de un estudio sistem√°tico. En una definici√≥n la Ciencia de Datos, es una empresa sistem√°tica que construye y organiza conocimiento en forma de explicaciones comprobables y predicciones [5]. La Ciencia de Datos solamente es √∫til cuando se utilizan los datos para responder una pregunta [6]. 2.1.1. Miner√≠a de Datos Es el proceso de extraer conocimiento √∫til y comprensible, previamente desconocido, desde grandes cantidades de datos almacenados en distintos formatos. Es decir, la tarea fundamental de la miner√≠a de datos es encontrar modelos inteligibles a partir de los datos. Para que este proceso sea efectivo deber√≠a ser autom√°tico o semi-autom√°tico (asistido) y el uso de los patrones descubiertos deber√≠a ayudar a tomar decisiones m√°s seguras que reporten, por tanto, alg√∫n beneficio a la organizaci√≥n [7]. Por lo tanto, dos son los retos de la miner√≠a de datos: por un lado, trabajar con grandes vol√∫menes de datos, procedentes mayoritariamente de sistemas de informaci√≥n, con los problemas que ello conlleva (ruido, datos ausentes, intratabilidad, volatilidad de los datos‚Ä¶), y por el otro usar t√©cnicas adecuadas para analizar los mismos y extraer conocimiento novedoso y √∫til [7]. Otro concepto: La Miner√≠a de Datos es un t√≥pico que involucra el aprendizaje en un sentido pr√°ctico. Se interesa en t√©cnicas para encontrar y describir patrones estructurales en los datos, como una herramienta para ayudar a explicar los datos y hacer predicciones a partir de los mismos. Aunque la salida de un proceso de miner√≠a de datos no siempre es una predicci√≥n, tambi√©n puede ser una descripci√≥n actual de una estructura la cual puede ser utilizada para clasificar ejemplos desconocidos [8]. Cap√≠tulo 2. Marco Conceptual 23 La miner√≠a de datos tiene como objetivo analizar los datos para extraer conocimiento. Este conocimiento puede ser en forma de relaciones, patrones o reglas inferidos de los datos y (previamente) desconocidos, o bien en forma de una descripci√≥n m√°s concisa (es decir, un resumen de los mismos). Estas relaciones o res√∫menes constituyen el modelo de los datos analizados. Existen muchas formas de representar los modelos y cada una de ellas determina el tipo de t√©cnica que puede usarse para inferirlos. En la pr√°ctica, los modelos pueden ser de dos tipos: predictivos o de clasificaci√≥n y descriptivos o de Clustering [7]. 2.1.1.1. Clustering Los modelos descriptivos o de Clustering identifican patrones que explican o resumen los datos, es decir, sirven para explorar las propiedades de los datos examinados, no para predecir nuevos datos. Por ejemplo una agencia de viaje desea identificar grupos de personas con unos mismos gustos, con el objeto de organizar diferentes ofertas para cada grupo y poder as√≠ remitirles esta informaci√≥n; para ello analiza los viajes que han realizado sus clientes e infiere un modelo descriptivo que caracteriza estos grupos [7]. 2.1.1.1.1. K-medias El algoritmo de K medias (del ingl√©s Kmeans) se trata de un m√©todo de agrupamiento por vecindad en el que se parte de un n√∫mero determinado de prototipos y de un conjunto de ejemplos a agrupar, sin etiquetar. Es el m√©todo m√°s popular de los m√©todos de agrupamiento denominados ‚Äúpor partici√≥n‚Äù, en contraposici√≥n de los m√©todos jer√°rquicos. La idea del K medias es situar a los prototipos o centros en el espacio, de forma que los datos pertenecientes al mismo prototipo tengan caracter√≠sticas similares [7]. Las regiones se definen minimizando la suma de las distancias cuadr√°ticas entre cada vector de entrada y el centro de su correspondiente clase, representado por el prototipo correspondiente. Cuando se inicia el algoritmo, se debe seleccionar arbitrariamente una partici√≥n inicial de forma que cada clase disponga de, al menos, un ejemplo. Como la totalidad de los datos est√°n disponibles, los centros de cada partici√≥n se calculan como la media de los ejemplos pertenecientes a esa clase. A medida que el algoritmo se va ejecutando, algunos ejemplos cambian de una clase a otra debiendo Cap√≠tulo 2. Marco Conceptual 24 recalcularse los centros a cada paso, o sea, desplazar convenientemente los prototipos. [7] El procedimiento es el siguiente: ÔÇ∑ Se calcula para cada ejemplo ùë•ùëò, el prototipo m√°s pr√≥ximo ùê¥ùëî y se incluye en la lista de ejemplos de dicho prototipo ÔÇ∑ Despu√©s de haber introducido todos los ejemplos, cada prototipo ùê¥ùëò tendr√° un conjunto de ejemplos a los que representa ÔÇ∑ Se desplaza el prototipo hacia el centro de masas de su conjunto de ejemplos ÔÇ∑ Se repite el procedimiento hasta que ya no se desplacen los prototipos. Mediante este algoritmo el espacio de ejemplos de entrada se divide en k clases o regiones, y el prototipo de cada clase estar√° en el centro de la misma. Dichos centros se determinan con el objetivo de minimizar las distancias cuadr√°ticas eucl√≠deas entre los patrones de entrada y el centro m√°s cercano. [7] Cap√≠tulo 2. Marco Conceptual 25 Figura 4: Ejemplo agrupaci√≥n K-medias 2.1.1.1.2. Clustering Jer√°rquico En miner√≠a de datos, el agrupamiento jer√°rquico es un m√©todo de an√°lisis de grupos el cual busca construir una jerarqu√≠a de grupos. Estrategias para agrupamiento jer√°rquico generalmente caen en dos tipos [10]: ÔÇ∑ Aglomerativas: Este es un agrupamiento ascendente. Cada observaci√≥n comienza en su propio grupo, y los pares de grupos son mezclados mientras uno sube en la jerarqu√≠a. ÔÇ∑ Divisivas: Este es un agrupamiento descendente. Todas las observaciones comienzan en un grupo, y se realizan divisiones mientras uno baja en la jerarqu√≠a. En general, las mezclas y divisiones son determinadas de forma golosa. Los resultados del agrupamiento jer√°rquico son usualmente presentados en un dendograma. [10] Cap√≠tulo 2. Marco Conceptual 26 En orden de decidir cuales grupos deber√≠an ser combinados (para aglomerativo), o cuando un grupo deber√≠a der dividido (para divisivo), una medida de disimilitud entre conjuntos de observaciones es requerida. En la mayor√≠a de los m√©todos de agrupamiento jer√°rquico, esto es logrado mediante el uso de una m√©trica apropiada (una medida de distancia entre pares de observaciones), y un criterio de enlace el cual especifica la disimilitud de conjuntos como una funci√≥n de las distancias dos a dos entre observaciones en los conjuntos. [10] Figura 5: Ejemplo Agrupamiento jer√°rquico ascendente 2.1.1.1.3. An√°lisis de Componentes Principales En estad√≠stica, el an√°lisis de componentes principales (en espa√±ol ACP, en ingl√©s, PCA) es una t√©cnica utilizada para reducir la dimensionalidad de un conjunto de datos. Intuitivamente la t√©cnica sirve para hallar las causas de la variabilidad de un conjunto de datos y ordenarlos por importancia. Cap√≠tulo 2. Marco Conceptual 27 T√©cnicamente, el ACP busca la proyecci√≥n seg√∫n la cual los datos queden mejor representados en t√©rminos de m√≠nimos cuadrados. El ACP se emplea sobre todo en el an√°lisis exploratorio de datos y para construir modelos predictivos. El ACP comporta el c√°lculo de la descomposici√≥n en autovalores de la matriz de covarianza, normalmente tras centrar los datos en la medida de cada atributo [9]. El ACP construye una transformaci√≥n lineal que escoge un nuevo sistema de coordenadas para el conjunto original de datos en el cual la varianza de mayor tama√±o del conjunto de datos es capturada en el primer eje (llamado el Primer Componente Principal), la segunda varianza m√°s grande es el segundo eje, y as√≠ sucesivamente. Para construir esta transformaci√≥n lineal debe construirse primero la matriz de covarianza o matriz de coeficientes de correlaci√≥n. Debido a la simetr√≠a de esta matriz existe una base completa de vectores propios de la misma. La transformaci√≥n que lleva de las antiguas coordenadas a las coordenadas de la nueva base es precisamente la transformaci√≥n lineal necesaria para reducir la dimensionalidad de datos. 2.1.1.2. Clasificaci√≥n Los modelos predictivos o de Clasificaci√≥n pretenden estimar valores futuros o desconocidos de variables de inter√©s, que se denominan como variables objetivo o dependientes, usando otras variables o campos de la base de datos (o cualquier otra fuente), a las que se refieren como variables independientes o predictivas. Por ejemplo, un modelo predictivo ser√≠a aquel que permite estimar la demanda de un nuevo producto en funci√≥n del gasto en publicidad [7]. 2.1.1.2.1. K vecinos m√°s cercanos Es un m√©todo de clasificaci√≥n supervisada que sirve para estimar la funci√≥n de densidad F(x/Cj) de las predictoras x por cada clase Cj.[23] En este m√©todo se determina para cada regi√≥n del espacio la probabilidad de que un elemento que est√© situado en ella pertenezca a cada una de las clases existentes. En este caso no hay reglas prefijadas, sino que la clasificaci√≥n se ir√° haciendo para cada caso nuevo en particular. Cuando Cap√≠tulo 2. Marco Conceptual 28 un caso nuevo aparece, se genera un c√≠rculo con centro en dicho punto y un radio prefijado como par√°metro del sistema en el cual se encuentran los k ejemplos m√°s cercanos al nuevo elemento. Se etiqueta al nuevo caso como perteneciente a la clase m√°s numerosa dentro del c√≠rculo.[7] En la Figura 6 se aprecia c√≥mo en un primer caso con k igual a cuatro, dentro del c√≠rculo hay tres ejemplos de la clase A y uno de la clase B, luego el nuevo dato se etiqueta como perteneciente a la clase A. En la Figura tambi√©n se aprecia que el k elegido influye en la clasificaci√≥n. Si se aumenta o disminuye el k, la predicci√≥n realizada puede variar. Por lo tanto, el k ser√° un par√°metro cr√≠tico a tener en cuenta. Tambi√©n las predicciones pueden variar si se var√≠a la funci√≥n de distancia. Figura 6: Ejemplo K vecinos m√°s cercanos El m√©todo espera hasta la aparici√≥n de un nuevo dato a clasificar para la utilizaci√≥n del conjunto de ejemplos. Cuando el dato est√° disponible se recurre a los ejemplos para realizar la clasificaci√≥n, se crea una regla local al dato que acaba de llegar, se realiza la clasificaci√≥n, y se abandona dicha regla. Si ahora hubiera que clasificar otro dato m√°s, los c√°lculos realizados para la clasificaci√≥n del dato anterior ser√≠an inservibles y habr√≠a que realizar de nuevo todo el proceso. Este es un t√≠pico ejemplo de aprendizaje retardado. En este caso hay que almacenar los ejemplos de entrenamiento siempre, ya que son utilizados una y otra vez. [7] Cap√≠tulo 2. Marco Conceptual 29 2.1.1.2.2. An√°lisis discriminante El objetivo del an√°lisis discriminante es encontrar reglas de asignaci√≥n de individuos a una de las clases de una clasificaci√≥n preestablecida. El t√©rmino an√°lisis discrim√≠nate es el nombre que se utiliza tradicionalmente en estad√≠stica para englobar las t√©cnicas de clasificaci√≥n supervisada. Para resolver este problema se dispone de una muestra de n individuos, de los cuales sabemos su clase de pertenencia y en los que tenemos medidas un conjunto de p variables que permiten diferenciar a las clases. [7] Geom√©tricamente, las p variables permiten situar a los individuos en un espacio ùëÖùëù eucl√≠deo. Por otro lado, se supone que estas variables permiten diferenciar los individuos seg√∫n su clase de pertenencia, es decir, se supone que cada clase viene definida por una distribuci√≥n de probabilidad distinta de las restantes clases. Naturalmente, las variables ùë•ùëó no tienen por qu√© ser las originales sino que puede ser transformaciones que optimicen la separaci√≥n entre las clases [7] 2.1.1.2.3. Maquinas vectoriales de soporte Las m√°quinas de vectores de soporte pertenecen a la familia de los clasificadores lineales puesto que inducen separadores lineales o hiperplanos en espacios de caracter√≠sticas de muy alta dimensionalidad (introducidos por funciones de n√∫cleo o kernel) con un sesgo inductivo muy particular (maximizaci√≥n del margen). [7] Cap√≠tulo 2. Marco Conceptual 30 Figura 7: Ejemplo Maquinas vectoriales de Soporte La idea b√°sica de las m√°quinas de vectores de soporte es: Dado un conjunto de puntos, en el que cada uno de ellos pertenece a una de dos posibles categor√≠as, un algoritmo basado en SVM construye un modelo capaz de predecir si un punto nuevo (cuya categor√≠a se desconoce) pertenece a una categor√≠a o a la otra. Como en la mayor√≠a de los m√©todos de clasificaci√≥n supervisada, los datos de entrada (los puntos) son vistos como un vector p-dimensional. Las SVM buscan un hiperplano que separe de forma √≥ptima a los puntos de una clase de la otra, que eventualmente han podido ser previamente proyectados a un espacio de dimensionalidad superior. En ese concepto de ‚Äúseparaci√≥n √≥ptima‚Äù es donde reside la carater√≠stica fundamental de las SVM: este tipo de algoritmos busca el hiperplano que tenga la m√°xima distancia (margen) con los puntos que est√°n m√°s cerca de √©l mismo. Por eso tambi√©n a veces se les conoce a las SVM como clasificadores de margen m√°ximo. De esta forma, los puntos del vector que son etiquetados con una categor√≠a estar√°n a un lado del hiperplano y los casos que se encuentren en la otra categor√≠a estar√°n al otro lado. Al vector formado por los puntos m√°s cercanos al hiperplano se le llama vector de soporte. [43] Cap√≠tulo 2. Marco Conceptual 31 La SVM lineal con margen m√°ximo es el modelo m√°s sencillo e intuitivo de SVM, aunque tambi√©n el que tiene condiciones de aplicabilidad m√°s restringidas, puesto que parte de la hip√≥tesis de que el conjunto de datos es linealmente separable en el espacio de entrada. [7] Figura 8: Maquina vectorial de soporte de margen m√°ximo Desgraciadamente, no siempre es posible encontrar una transformaci√≥n de los datos que permita separarlos linealmente, y si se logra, el resultado del modelo no puede ser generalizado para otros datos. Con el fin de permitir cierta flexibilidad, los SVM manejan un par√°metro C que controla la compensaci√≥n entre errores de entrenamiento y los m√°rgenes r√≠gidos, creando as√≠ un margen blando que permita algunos errores en la clasificaci√≥n a la vez que los penaliza. [43] Figura 9: Maquina vectorial de soporte de margen blando Cap√≠tulo 2. Marco Conceptual 32 2.1.1.2.4. √Årbol de Decisi√≥n De todos los m√©todos de aprendizaje, los sistemas de aprendizaje basados en arboles de decisi√≥n son quiz√°s el m√©todo m√°s f√°cil de utilizar y de entender. Un √°rbol de de decisi√≥n es un conjunto de condiciones organizadas en una estructura jer√°rquica, de tal manera que la decisi√≥n final a tomar se puede determinar siguiendo las condiciones que se cumplen desde la ra√≠z del √°rbol hasta alguna de sus hojas. Los √°rboles de decisi√≥n se utilizan desde hace siglos, y son especialmente apropiados para expresar procedimientos m√©dicos, legales, comerciales, estrat√©gicos, matem√°ticos, l√≥gicos, etc. [7] Figura 10: Ejemplo √Årbol de Decisi√≥n Una de las grandes ventajas de los √°rboles de decisi√≥n es que en su forma m√°s general, las opciones posibles a partir de una determinada condici√≥n son excluyentes. Esto permite analizar una situaci√≥n y, siguiendo el √°rbol de decisi√≥n apropiadamente, llegar a una sola acci√≥n o decisi√≥n a tomar. [7] La tarea de aprendizaje para la cual los √°rboles de decisi√≥n se adecuan mejor es la clasificaci√≥n. De hecho, clasificar es determinar entre varias clases a qu√© clase pertenece un objeto; la estructura de condici√≥n y ramificaci√≥n de un √°rbol de decisi√≥n es id√≥nea para este problema. La Cap√≠tulo 2. Marco Conceptual 33 caracter√≠stica m√°s importante del problema de la clasificaci√≥n es que se asume que las clases son disjuntas. Debido al hecho de que la clasificaci√≥n trata con clases o etiquetas disjuntas, un √°rbol de decisi√≥n conducir√° un ejemplo hasta una y s√≥lo una hoja, asignando, por tanto, una √∫nica clase al ejemplo. Para ello las particiones existentes en el √°rbol deben ser tambi√©n disjuntas. Es decir, cada instancia cumple o no cumple una condici√≥n. Esta propiedad dio lugar al esquema b√°sico de los primeros algoritmos de aprendizaje de √°rboles de decisi√≥n; el espacio de instancias se iba partiendo de arriba abajo, utilizando cada vez una partici√≥n, es decir, un conjunto de condiciones excluyentes y exhaustivas. Otra caracter√≠stica importante de los primeros algoritmos de aprendizaje de √°rboles de decisi√≥n es que una vez elegida la partici√≥n dicha partici√≥n no se pod√≠a cambiar, aunque m√°s tarde se pensara que hab√≠a sido una mala elecci√≥n. Por tanto, uno de los aspectos m√°s importantes en los sistemas de aprendizaje de √°rboles de decisi√≥n es el denominado criterio de partici√≥n, ya que una mala elecci√≥n de la partici√≥n (especialmente en las partes superiores del √°rbol) generar√° un peor √°rbol. Las particiones son, como se ha dicho, un conjunto de condiciones exhaustivas y excluyentes. L√≥gicamente, cuantos m√°s tipos de condiciones se permitan, m√°s posibilidades se tendr√°n de encontrar los patrones que hay detr√°s de los datos. Cuantas m√°s particiones se permitan m√°s expresivos podr√°n ser los √°rboles de decisi√≥n generados y probablemente, m√°s precisos. No obstante, cuantas m√°s particiones elijamos, la complejidad del algoritmo ser√° mayor. [7] Incluso con s√≥lo dos tipos de particiones sencillas, el n√∫mero de particiones posibles en cada caso puede dispararse (si existen n atributos y m valores posibles para cada atributo, el n√∫mero de particiones posibles es de n por m). Como se ha dicho anteriormente, los algoritmos cl√°sicos de aprendizaje de decisi√≥n son voraces, en el sentido de que una vez elegida la partici√≥n se contin√∫a hacia abajo la construcci√≥n del √°rbol y no vuelve a plantearse las particiones ya construidas. Estos dos aspectos tienen como consecuencia que se busque un criterio que permita realizar una buena elecci√≥n de la partici√≥n que parece m√°s prometedora y que esto se haga sin demasiado esfuerzo computacional. Esto obliga a que calcular la optimalidad de cada partici√≥n no sea muy costoso. [7] Cap√≠tulo 2. Marco Conceptual 34 La mayor√≠a de criterios se basan por tanto en obtener medidas derivadas de las frecuencias relativas de las clases en cada uno de los hijos de la partici√≥n respecto a las frecuencias relativas de las clases en el padre. Por ejemplo, si en un nodo tenemos cincuenta por ciento de ejemplos de clase a y un cincuenta por ciento de ejemplos de clase b, una partici√≥n que d√© como resultado dos nodos n1 y n2, donde todos los ejemplos de n1 sean de la clase a y todos los ejemplos de n2 sean de la clase b, ser√° una buena partici√≥n, porque los nodos resultantes son m√°s puros que el padre. Por el contrario, si ambos nodos n1 y n2 siguen teniendo proporciones cercanas al cincuenta por ciento no habremos discriminado nada y no avanzaremos hacia un √°rbol que nos clasifique correctamente la evidencia. [7] Bas√°ndose en la idea de buscar particiones que discrimen o que consigan nodos m√°s puros, se han presentado en las √∫ltimas dos d√©cadas numerosos criterios de partici√≥n, tales como el criterio del error esperado, el criterio de Gini, los criterios de Gain, entre otros. [7] Los algoritmos de aprendizaje de √°rboles de decisi√≥n y conjuntos de reglas mencionados previamente obtienen un modelo que es completo y consistente con respecto a la evidencia. Es decir, el modelo cubre todos los ejemplos vistos y los cubre todos de manera correcta. Esto puede parecer √≥ptimo a primera vista, pero se vuelve demasiado ingenuo en la realidad. En primer lugar, ajustarse demasiado a la evidencia suele tener como consecuencia que el modelo se comporte mal para nuevos ejemplos, ya que, en la mayor√≠a de los casos, el modelo es solamente una aproximaci√≥n del concepto objetivo del aprendizaje. Por tanto, intentar aproximar demasiado hace que el modelo sea demasiado espec√≠fico, poco general y, por tanto, malo con otros datos no vistos. En segundo lugar, esto es especialmente patente cuando la evidencia puede contener ruido (errores en los atributos o incluso en las clases), ya que el modelo intentar√° ajustarse a los errores y esto perjudicar√° el comportamiento global del modelo aprendido. Esto es lo que se conoce como sobreajuste (overfitting). [7] La manera m√°s frecuente de limitar este problema es modificar los algoritmos de aprendizaje de tal manera que obtengan modelos m√°s generales. En el contexto de los √°rboles de decisi√≥n y conjuntos de reglas, generalizar significa eliminar condiciones de las ramas del √°rbol o de algunas reglas. En el caso de los √°rboles de decisi√≥n dicho procedimiento se puede ver gr√°ficamente como un proceso de poda, como se ilustra en la Figura 11. Cap√≠tulo 2. Marco Conceptual 35 Figura 11: √Årbol Podado 2.1.1.2.5. Bosques Aleatorios Antes de hablar de los Bosques Aleatorios es conveniente mencionar la definici√≥n de los m√©todos de consenso o Bagging. La idea fundamental de estos m√©todos es tomar m muestras aleatorias con reemplazo de los datos originales y luego aplicar a cada una de ellas un m√©todo predictivo para luego con alg√∫n criterio establecer un consenso de todos los resultados. El consenso podr√≠a ser un promedio, un promedio ponderado basado en cu√°l m√©todo obtuvo los mejores resultados o el que obtenga la mayor cantidad de votos.[44] Figura 12: Ejemplo m√©todos de consenso Bosques Aleatorios o Random forest es una combinaci√≥n de √°rboles de decisi√≥n tal que cada √°rbol depende de los valores de un vector aleatorio probado independientemente y con la misma distribuci√≥n para cada uno de estos. Cap√≠tulo 2. Marco Conceptual 36 Figura 13: Ejemplo Bosques Aleatorios Es una modificaci√≥n sustancial de los m√©todos de consenso que construye una larga correlaci√≥n de √°rboles no correlacionados y luego los promedia. [45] Las ventajas de los Bosques aleatorios son [45]: ÔÇ∑ Es uno de los algoritmos de aprendizaje m√°s certeros que hay disponible. Para un conjunto de datos lo suficientemente grande produce un clasificador muy certero ÔÇ∑ Corre eficientemente en bases de datos grandes ÔÇ∑ Puede manejar cientos de variables de entrada sin excluir ninguna ÔÇ∑ Da estimados de qu√© variables son importantes en la clasificaci√≥n ÔÇ∑ Tiene un m√©todo eficaz para estimar datos perdidos y mantener la exactitud cuando una gran proporci√≥n de los datos est√° perdida ÔÇ∑ Computa los prototipos que dan informaci√≥n sobre la relaci√≥n entre las variables y la clasificaci√≥n ÔÇ∑ Computa las proximidades entre los pares de casos que pueden usarse en los grupos, localizando valores at√≠picos, o (ascendiendo) dando vistas interesantes de los datos ÔÇ∑ Ofrece un m√©todo experimental para detectar las interacciones de las variables Cap√≠tulo 2. Marco Conceptual 37 Las desventajas son [45]: ÔÇ∑ Se ha observado que los Bosques aleatorios sobreajusta en ciertos grupos de datos con tareas de clasificaci√≥n ruidosas ÔÇ∑ A diferencia de los √°rboles de decisi√≥n, la clasificaci√≥n hecha por Bosques aleatorios es dif√≠cil de interpretar por el hombre ÔÇ∑ Para los datos que incluyen variables categ√≥ricas con diferente n√∫mero de niveles, el random forests se parcializa a favor de esos atributos con m√°s niveles. Por consiguiente, la posici√≥n que marca la variable no es fiable para este tipo de datos Si los datos contienen grupos de atributos correlacionado con similar relevancia para el rendimiento, entonces los grupos m√°s peque√±os est√°n favorecidos sobre los grupos m√°s grandes 2.1.1.2.6. Redes Bayesianas Antes de hablar de Na√Øve Bayes se debe hablar del Teorema de Bayes. En teor√≠a de la probabilidad, el teorema de Bayes es la regla b√°sica para realizar inferencias. As√≠, el teorema de Bayes nos permite actualizar la creencia que tenemos en un suceso o conjunto de sucesos a la luz de nuevos datos u observaciones. Es decir, nos permite pasar de la probabilidad a priori P(suceso) a la probabilidad a posteriori P(suceso|observaciones). La probabilidad a priori puede verse como la probabilidad inicial, la que fijamos sin saber nada m√°s. La probabilidad a posteriori es la que obtendr√≠amos tras conocer cierta informaci√≥n, por tanto, puede verse como un refinamiento de nuestro conocimiento.[7] Teniendo en cuenta estos conceptos, el teorema de Bayes viene representado por la siguiente expresi√≥n: ùëÉ(‚Ñé|ùëÇ) = ùëÉ(ùëÇ|‚Ñé). ùëÉ(‚Ñé) ùëÉ(ùëÇ) Donde, se puede observar, lo que aparecen son la probabilidad a priori de la hip√≥tesis (‚Ñé) y de las observaciones (ùëÇ) y las probabilidades condicionadas ùëÉ(‚Ñé|ùëÇ) y ùëÉ(ùëÇ|‚Ñé). Centr√°ndose en el problema de la clasificaci√≥n, con una variable clase (C) y un conjunto de variables predictoras o atributos {ùê¥1, ‚Ä¶ , ùê¥ùëõ}, el teorema de Bayes tendr√≠a la siguiente forma: Cap√≠tulo 2. Marco Conceptual 38 ùëÉ(ùê∂|ùê¥1 ‚Ä¶ ùê¥ùëõ) = ùëÉ(ùê¥1 ‚Ä¶ ùê¥ùëõ|ùê∂). ùëÉ(ùê∂) ùëÉ(ùê¥1 ‚Ä¶ ùê¥ùëõ) Evidentemente, si C tiene k posibles valores {ùëê1, ‚Ä¶ , ùëêùëò}, lo que interesa es identificar el m√°s plausible y devolverlo como resultado de la clasificaci√≥n. En el marco bayesiano, la hip√≥tesis m√°s plausible no es otra que aquella que tiene m√°xima probabilidad a posteriori dados los atributos, y es conocida como la hip√≥tesis m√°xima a posteriori. Por tanto, el teorema de Bayes facilita un m√©todo sencillo y con una sem√°ntica clara para resolver esta tarea. Sin embargo, este m√©todo tiene un problema, y es su alt√≠sima complejidad computacional, debido a que se necesita trabajar con distribuciones de probabilidad que involucran muchas variables, haci√©ndolas en la mayor√≠a de los casos inmanejables.[7] 2.1.1.2.7. Redes Neuronales Las redes neuronales artificiales son un m√©todo de aprendizaje cuya finalidad inicial era la de emular los procesadores biol√≥gicos de informaci√≥n. Las RNA parten de la presunci√≥n de que la capacidad humana de procesar informaci√≥n se debe a la naturaleza biol√≥gica del cerebro. Por tanto, para imitar esta caracter√≠stica se debe estudiar y basarse en el uso de soportes artificiales semejantes a los existentes en el cerebro.[7] Una red neuronal se compone de unidades llamadas neuronas. Cada neurona recibe una serie de entradas a trav√©s de interconexiones y emite una salida. Esta salida viene dada por tres funciones [46]: 1. Una funci√≥n de propagaci√≥n (tambi√©n conocida como funci√≥n de excitaci√≥n), que por lo general consiste en el sumatorio de cada entrada multiplicada por el peso de su interconexi√≥n (valor neto). Si el peso es positivo, la conexi√≥n se denomina excitatoria; si es negativo, denomina inhibitoria. 2. Una funci√≥n de activaci√≥n, que modifica a la anterior. Puede no existir, siendo en este caso la salida la misma funci√≥n de propagaci√≥n. 3. Una funci√≥n de transferencia, que se aplica al valor devuelto por la funci√≥n de activaci√≥n. Se utiliza para acotar la salida de la neurona y generalmente viene dada por la interpretaci√≥n que queramos darle a dichas salidas. Algunas de las m√°s utilizadas Cap√≠tulo 2. Marco Conceptual 39 son la funci√≥n sigmoidea (para obtener valores en el intervalo [0, 1]) y la tangente hiperb√≥lica (para obtener valores en el intervalo [-1, 1]). 2.1.1.2.8. Regresi√≥n Log√≠stica Antes de hablar de lo que es el modelo de regresi√≥n log√≠stica se debe saber qu√© es un modelo de regresi√≥n. Un modelo de regresi√≥n es cuando la variable de respuesta y las variables explicativas son todas ellas cuantitativas [7]. Si s√≥lo se dispone de una variable explicativa hablamos de regresi√≥n simple, mientras que si se dispone de varias variables explicativas se trata de una regresi√≥n m√∫ltiple. La regresi√≥n log√≠stica es un tipo especial de regresi√≥n que se utiliza para predecir el resultado de una variable categ√≥rica en funci√≥n de las variables explicativas [11]. 2.1.2. Grandes Vol√∫menes de Datos Una parte fundamental de la Ciencia de Datos es Grandes Vol√∫menes de datos o en ingl√©s Big Data el cual es un t√©rmino global para cualquier colecci√≥n de conjuntos de datos tan grandes y complejos que complican el procesamiento de los mismos inhabilitando el uso de herramientas de gesti√≥n de datos y las aplicaciones tradicionales de tratamiento de datos.[24] 2.1.2.1. Las 5 V‚Äôs de Grandes Vol√∫menes de Datos Se sabe que los datos se est√°n convirtiendo en la base de cara a obtener ventajas competitivas con el af√°n de desmarcarnos del resto de compa√±√≠as. Sin embargo, el gran inconveniente del Big Data y del tratamiento de datos es la ausencia de un diccionario, gu√≠a o ‚Äòlibrillo‚Äô que dicte la praxis para exprimir todo el potencial que posee. No obstante, en el a√±o 2001, el experto analista de datos Doug Laney defini√≥ los tres vectores de los vol√∫menes de datos. Desde entonces, numerosos autores han aparecido con otras definiciones y descripciones que enriquecen la teor√≠a de Laney.[37] Cap√≠tulo 2. Marco Conceptual 40 Finalmente, la comunidad tecnol√≥gica que rodea al Big Data y el Business Intelligence se ha puesto de acuerdo y ha establecido cinco directrices que describen. I. V de Volumen: El primer aspecto que se nos viene a la cabeza cuando pensamos en el Big Data es un torrente de datos desestructurados que guardan un inmenso potencial en s√≠ mismos. Dicho esto, no es de extra√±ar que las empresas ya sepan con los vol√∫menes que tienen ante s√≠. Y es que el panorama tecnol√≥gico referente ha sufrido variaciones considerables. Lo que antes se consideraba grande, ahora ya no lo es tanto, sino basta con echar un vistazo al Gigabyte, que al parecer ya se ha convertido en la unidad ‚Äúb√°sica‚Äù de almacenamiento, frente a los Petabytes que engloba el Big Data. [37] II. V de Velocidad: Para un gran volumen de datos que no sufre variaciones muy a menudo, el an√°lisis lleva horas e incluso d√≠as. No obstante, en el √°mbito del Big Data el montaje de informaci√≥n crece por Terabytes, de ah√≠ que el tiempo de procesamiento de la informaci√≥n sea un factor fundamental para que dicho tratamiento aporte ventajas que marquen la diferencia. [37] III. V de Variedad: De sobra se sabe que el Big Data no versa en la mayor√≠a de las ocasiones sobre datos estructurados y que no siempre es sencillo incorporar grandes vol√∫menes a una base de datos relacional. Infinidad de tipos de datos se aglutinan dispuestos a ser tratados y es por ello que frente a esa variedad aumenta el grado de complejidad tanto en el almacenamiento como en su an√°lisis. [37] IV. V de Veracidad: Con un alto volumen de informaci√≥n que crece a tal velocidad y es de tama√±a variedad, en ocasiones es inevitable dudar del grado de veracidad que √©stos poseen. Para ello, se incide en ejercer una limpieza en los datos para as√≠ asegurar el mayor aprovechamiento de los mismos. No obstante, supone un gran esfuerzo que a grosso modo no reflejar√° variaciones esenciales de los resultados finales Cap√≠tulo 2. Marco Conceptual 41 relativos al tratamiento de la informaci√≥n. Por lo tanto, dependiendo de la aplicaci√≥n que se les d√©, su veracidad y su verificaci√≥n puede ser imprescindible o simplemente un acto secundario sin llegar a ser vital. [37] V. V de Valor: Sin duda el aspecto m√°s relevante del Big Data. Es muy costoso poner en pr√°ctica las infraestructuras inform√°ticas para almacenar estos vol√∫menes de datos, y por ende, las empresas van a necesitar gran cantidad de dinero para rentabilizar su gasto. Si no se consigue extraer todo el valor de ellos, no habr√° lugar para almacenar ni administrar. [37] 2.2. Sistema Operativo Un sistema operativo (SO) es el software de sistema que gestiona los recursos de hardware y software del ordenador y proporciona servicios comunes para los programas del mismo. El sistema operativo es un componente esencial del software del sistema en un sistema inform√°tico. Los programas de aplicaci√≥n por lo general requieren un sistema operativo para funcionar [12]. Para las funciones de hardware como las entrada y salida y la asignaci√≥n de memoria, el sistema operativo act√∫a como intermediario entre los programas y el hardware del ordenador, aunque el c√≥digo de la aplicaci√≥n se suele ejecutarse directamente por el hardware y con frecuencia hace que el sistema llama a una funci√≥n del Sistema Operativo o ser interrumpido por ella. Los sistemas operativos se encuentran en muchos dispositivos que contienen un ordenador desde tel√©fonos celulares y consolas de videojuegos a los servidores web y supercomputadoras [12]. 2.2.1. Tipos de Sistema Operativo i. Single- and Multi-Tasking: Un sistema Single-Tasking s√≥lo puede ejecutar un programa a la vez, mientras que un sistema operativo Multi-Tasking permite que m√°s de un programa que se ejecuta de manera concurrente. Esto se logra por un tiempo Cap√≠tulo 2. Marco Conceptual 42 compartido, dividiendo el tiempo de procesador disponible entre m√∫ltiples procesos que son cada uno interrumpidos repetidamente por un subsistema de programaci√≥n de tareas del sistema operativo [12]. ii. Single- and Muti-User: Los sistemas operativos de un solo usuario no tienen instalaciones para distinguir a los usuarios, pero puede permitir que varios programas se ejecuten en paralelo. Un sistema operativo multiusuario extiende el concepto b√°sico de la multitarea con instalaciones que identifican los procesos y recursos, tales como el disco espacio, que pertenece a varios usuarios, y el sistema permite que varios usuarios interact√∫en con el sistema al mismo tiempo [12]. iii. Distribuido: Un sistema operativo distribuido gestiona un grupo de equipos distintos y los hace parecer como un solo equipo. El desarrollo de ordenadores conectados en red que podr√≠an estar vinculados y se comunican entre s√≠ dio lugar a la computaci√≥n distribuida. [12] iv. Templated: El t√©rmino se refiere a la creaci√≥n de una √∫nica imagen de m√°quina virtual como un sistema operativo invitado. La t√©cnica se utiliza tanto en la virtualizaci√≥n y la gesti√≥n de la computaci√≥n en la nube, y es com√∫n en grandes almacenes de un servidor. [12] v. Embebidos: Los sistemas operativos embebidos est√°n dise√±ados para ser utilizados en sistemas inform√°ticos integrados. Est√°n dise√±ados para operar en peque√±as m√°quinas como PDAs con menos autonom√≠a. Ellos son capaces de operar con un n√∫mero limitado de recursos. [12] vi. Real-time: Un sistema operativo de tiempo real es un sistema operativo que garantiza procesar los eventos o datos dentro de una corta cantidad de tiempo. Un sistema operativo de tiempo real puede ser de una o varias tareas a la vez. [12] Cap√≠tulo 2. Marco Conceptual 43 2.2.2. Linux Linux es un sistema operativo de software libre, compatible Unix. El sistema lo forman el n√∫cleo del sistema (kernel) m√°s un gran n√∫mero de programas / bibliotecas que hacen posible su utilizaci√≥n. Muchos de estos programas y bibliotecas han sido posibles gracias al proyecto GNU, por esto mismo, muchos llaman a Linux, GNU/Linux, para resaltar que el sistema lo forman tanto el n√∫cleo como gran parte del software producido por el proyecto GNU. Linux se distribuye bajo la GNU General Public License por lo tanto, el c√≥digo fuente tiene que estar siempre accesible y cualquier modificaci√≥n √≥ trabajo derivado tiene que tener esta licencia. [13] 2.2.2.1. GTK+ GTK+, o GIMP toolkit, es un kit de herramientas multiplataforma para crear interfaces gr√°ficas de usuario. Ofreciendo un conjunto completo de los widgets. GTK+ est√° escrito en C, pero ha sido dise√±ado desde cero para apoyar una amplia gama de lenguajes, no s√≥lo C/C++. El uso de GTK+ de lenguajes como Perl y Python proporciona un m√©todo eficaz para el desarrollo r√°pido de aplicaciones. GTK+ es software libre y parte del proyecto GNU. Sin embargo, los t√©rminos de licencia para GTK+, la licencia GNU LGPL, permiten que sea utilizado por todos los desarrolladores, incluyendo aquellos que desarrollan software propietario, sin ning√∫n tipo de derechos de licencia o regal√≠as. [14] 2.2.2.2. Secure Shell Secure Shell (SSH) es el nombre de un protocolo y del programa que lo implementa, y sirve para acceder a m√°quinas remotas a trav√©s de una red. Permite manejar por completo la computadora mediante un int√©rprete de comandos, y tambi√©n puede redirigir el tr√°fico de X para poder ejecutar programas gr√°ficos si tenemos ejecutando un Servidor X (en sistemas Unix y Windows). Adem√°s de la conexi√≥n a otros dispositivos, SSH nos permite copiar datos de forma segura (tanto archivos sueltos como simular sesiones FTP cifradas), gestionar claves RSA para no escribir claves Cap√≠tulo 2. Marco Conceptual 44 al conectar a los dispositivos y pasar los datos de cualquier otra aplicaci√≥n por un canal seguro tunelizado mediante SSH. [15] 2.3. Lenguajes de Programaci√≥n 2.3.1. R El proyecto R es a la vez un lenguaje especializado y un conjunto de herramientas de m√≥dulos dirigido a cualquier persona trabajando con las estad√≠sticas. Abarca todo, desde la carga de los datos a la ejecuci√≥n de an√°lisis sofisticados en √©l y luego ya sea de exportaci√≥n o la visualizaci√≥n de los resultados. La consola interactiva hace que sea f√°cil de experimentar con sus datos, ya que se puede probar un mont√≥n de diferentes enfoques muy r√°pidamente. La desventaja m√°s grande desde una perspectiva de proceso de datos es que est√° dise√±ado para trabajar con conjuntos de datos que se ajustan a la memoria de una sola m√°quina. Es posible utilizarlo dentro de Hadoop como otro lenguaje para streaming, pero una gran cantidad de las m√°s potentes funciones requieren acceso al conjunto completo de datos para ser eficaz. R hace una gran plataforma de creaci√≥n de prototipos para el dise√±o de soluciones que necesitan para funcionar con cantidades masivas de datos, sin embargo, o para dar sentido a los resultados de menor escala del procesamiento. [25] R se compone de una serie de paquetes programados por una comunidad activa de desarrolladores. A continuaci√≥n se describen los paquetes m√°s importantes utilizados en el marco del desarrollo de esta investigaci√≥n. 2.3.1.1. gWidgets2 El paquete gWidgets2 proporciona una interfaz de programaci√≥n para la fabricaci√≥n de interfaces gr√°ficas de usuario dentro de R. El paquete es una reescritura del paquete gWidgets. El paquete se basa en uno de los varios paquetes toolkit subyacentes que dan acceso a las bibliotecas de gr√°ficos. Estos incluyen RGtk2, tcltk, qtbase, y una colecci√≥n de widgets del navegador proporcionado por ExtJS. [16] El paquete proporciona constructores para desarrollar controles, widgets con los que un usuario interact√∫a, contenedores, objetos GUI Cap√≠tulo 2. Marco Conceptual 45 utilizados para organizar los controles dentro de una ventana y di√°logos simples. Estos objetos son manipulados a trav√©s de diversos m√©todos. El paquete proporciona algunas funcionalidades gen√©ricas y, en lo posible, aprovecha los m√©todos existentes para R. [16] Figura 14: Ejemplo de ventana creada con el paquete gWidgets2 en R Los constructores se pueden dividir en las siguientes categor√≠as: i) Constructores de control: 1. gbutton: Provee un bot√≥n b√°sico para iniciar una acci√≥n 2. gcalendar: Provee una entrada de texto con formato de fecha 3. gcheckbox: Provee un checkbox junto con su etiqueta para permitir a los usuario realizar selecciones 4. gcheckboxgroup: Igual que el gcheckbox pero permitiendo la selecci√≥n de cero o m√°s objetos 5. gcombobox: Provee una lista desplegable con una lista de opciones para una libre selecci√≥n 6. gdf: Provee un widget para la edici√≥n de un dataframe 7. gedit: Provee un entrada de texto 8. ggraphics: Provee la funci√≥n de mostrar gr√°ficos embebidos en un widget Cap√≠tulo 2. Marco Conceptual 46 9. gimage: Provee la funci√≥n para que un widget soporte im√°genes 10. glabel: Provee etiquetas 11. gmenu: Provee men√∫s en la parte superior de la ventana 12. gradio: Proporciona un medio para seleccionar uno de los muchos objetos 13. gseparator: Proporciona una l√≠nea visual para separar partes de una ventana 14. gslider: Proporciona un medio para seleccionar un valor de uno de continuo de valores 15. gspinbutton: Proporciona los medios para seleccionar un valor de una secuencia de valores 16. gstatusbar: Proporciona un widget para mostrar los mensajes de estado en una ventana de nivel superior 17. gtable: Proporciona un widget para mostrar datos tabulares para la selecci√≥n 18. gtext: Proporciona un widget de edici√≥n de texto de varias l√≠neas 19. gtimer: Proporciona un temporizador 20. gtoolbar: Proporciona barras de herramientas para ventanas de nivel superior 21. gtree: Proporciona una pantalla para los datos jer√°rquicos 22. gvarbrowser: Proporciona un widget que muestra una instant√°nea del espacio actual de trabajo 23. gaction: Proporciona un medio para encapsular las acciones para su uso con barras de men√∫, barras de herramientas y botones. 24. gexpandgroup: Proporciona un contenedor con una opci√≥n de revelar u ocultar sus hijos 25. gframe: Proporciona un contenedor cuadro enmarcado 26. ggroup: Proporciona un contenedor caja horizontal o vertical para el embalaje en componentes hijos 27. glayout: Proporciona un contenedor para organizar los datos por filas y columnas 28. gnotebook: Proporciona un contenedor port√°til 29. gpanedgroup: Proporciona un contenedor dividido con divisor ajustable 30. gstackwidget: Proporciona un recipiente como un bloc de notas, pero sin etiquetas pesta√±a Cap√≠tulo 2. Marco Conceptual 47 31. gwindow: Proporciona una ventana de nivel superior ii) Constructores de dialogo: 1. gmessage: Produce un di√°logo sencillo para mostrar un mensaje 2. gconfirm: Produce un cuadro de di√°logo para un usuario para confirmar una acci√≥n 3. ginput: Proporciona un cuadro de di√°logo para recoger la entrada del usuario 4. gbasicdialog: Proporciona un medio para producir cuadros de di√°logo modales generales 5. galert: Proporciona un di√°logo de mensaje transitoria corta 6. gfile: Proporciona un cuadro de di√°logo para seleccionar un nombre de archivo o directorio iii) M√©todos 1. svalue: Esto se utiliza para recuperar o establecer la propiedad principal asociado con un widget 2. enabled: Un widget est√° activado si es sensible a la entrada del usuario. Los widgets no activados normalmente se presentan en un estado en gris. 3. visible: La idea gen√©rica de un widget visible es uno que se dibuja. Sin embargo, varias clases anulan esto como parte del widget es visible o no visible. 4. focus: Un widget con focus recibe cualquier entrada de teclado. 5. editable: Un widget es editable si puede recibir la entrada de teclado. 6. font: La fuente para un objeto se especifica a trav√©s de este m√©todo que utiliza una convenci√≥n se ilustra en la p√°gina de ayuda. 7. size: El tama√±o de un widget se recupera o se da a trav√©s de estos m√©todos 8. tooltip: Una tooltip ofrece informaci√≥n contextual cuando un rat√≥n pasa sobre un objeto 9. undo, redo: Algunos widgets apoyan las funciones deshacer y rehacer 10. isExtant: Un m√©todo para comprobar si todav√≠a existe una parte de un widget. Cap√≠tulo 2. Marco Conceptual 48 11. tag: Un m√©todo utilizado para establecer los atributos de un objeto que se almacenan en un entorno de modo que se pasan por referencia, no por copia. Esto permite a los controladores de eventos manipular atributos de un objeto fuera del √°mbito del callback. 12. getToolkitWidget: Devuelve el conjunto de herramientas del objeto que subyacen empaquetados en un objeto gWidgets2 13. add: M√©todo utilizado para a√±adir un componente secundario de un contenedor primario 14. delete: M√©todo utilizado para eliminar un componente de su contenedor 15. dispose: M√©todo utilizado para eliminar un componente 16. dim: Se utiliza para volver fila y tama√±o de la columna de informaci√≥n seg√∫n corresponda. 17. names: Se utiliza para definir los nombres asociados a un objeto. Estos pueden ser nombres de columna en el widget table, o nombres de ficha en el contenedor port√°til. 18. dimnames: Se utiliza para definir nombres de fila y columna, seg√∫n corresponda. 19. update: Llamada para actualizar el estado de un widget. iv) Manejadores de eventos 1. addHandlerChanged: Asigna un handler y lo ejecuta cuando el objeto cambia 2. addHandlerClicked: Asigna un handler y lo ejecuta cuando se le hace click al objeto 3. addHandlerDoubleclick: Asigna un handler y lo ejecuta cuando se le hace doble click al objeto 4. addHandlerRightclick: Asigna un handler y lo ejecuta cuando se le hace click derecho al objeto 5. addHandlerColumnclicked: Asigna un handler y lo ejecuta cuando se le hace click a una columna del objeto 6. addHandlerColumnDoubleclicked: Asigna un handler y lo ejecuta cuando se le hace doble click a una columna del objeto 7. addHandlerColumnRightclicked: Asigna un handler y lo ejecuta cuando se le hace click derecho a una columna del objeto Cap√≠tulo 2. Marco Conceptual 49 8. addHandlerSelect: Asigna un handler y lo ejecuta cuando se selecciona el objeto 9. addHandlerFocus: Asigna un handler y lo ejecuta cuando se el objeto recibe un focus 10. addHandlerBlur: Asigna un handler y lo ejecuta cuando el objeto recibe un blur 11. addHandlerDestroy: Ejecuta un handler cuando el objeto es destruido 12. addHandlerUnrealize: Para un gwindow esta funci√≥n es llamada antes de la destrucci√≥n del objeto y puede prevenir que eso suceda 13. addHandlerExpose: Asigna un handler y lo ejecuta cuando el objeto es expuesto 14. addHandlerKeystroke: Asigna un handler y lo ejecuta cuando un evento sobre el identificador ocurre 15. addHandlerMouseMotion: Asigna un handler y lo ejecuta cuando el rat√≥n pasa sobre el objeto 16. addHandler: M√©todo base para asignar un handler 17. addHandlerIdle: M√©todo para asignar un handler por un determinado tiempo 18. addPopupMenu: Agrega un men√∫ popup 19. add3rdmousePopupMenu: Agrega un men√∫ popup para el rat√≥n derecho 20. addDropSource: Especificar un widget como una ruta para activar el drag and drop 21. addDropTarget: Especificar un widget como una destino para activar el drag and drop 22. addDragMotion: Ejecuta un handler cuando un evento drag ocurre en el objeto 23. blockHandlers, blockHandler: Bloquea el handler del objeto 24. unblockHandlers, unblockHandler: Desbloquea el handler del objeto 25. removeHandler: Remueva el handler del objeto 2.3.1.2. RHadoop RHadoop es una colecci√≥n de cinco paquetes del lenguaje R que permiten a los usuarios manipular y analizar datos con Hadoop [48]. Cap√≠tulo 2. Marco Conceptual 50 2.3.1.2.1. rmr2 Corre en la parte superior de Hadoop, este paquete permite definir y ejecutar trabajos de MapReduce, incluida la especificaci√≥n del mapper y el reducer como funciones de investigaci√≥n, y para mover datos entre R y Hadoop de una manera casi transparente. El objetivo es hacer que la escritura de los trabajos map y reduce sea muy similar y tan f√°cil como escribir un lapply y tapply. Las caracter√≠sticas adicionales proporcionan composici√≥n de trabajo f√°cil, gesti√≥n de resultado intermedio transparente, soporte para diferentes formatos de datos y mucho m√°s. [17] Especificando la siguiente configuraci√≥n se puede utilizar el paquete sin estar en una plataforma Hadoop rmr.options(backend=‚Äùlocal‚Äù) 2.3.1.2.2. rhdfs El paque rhdfs suministra las funciones para interactuar con un sistema de archivos distribuido Hadoop desde dentro R. Hay funciones para la gesti√≥n del sistema de archivos, as√≠ como funciones para leer, escribir, abrir, y cerrar archivos. [18] Sus principales funciones son: hdfs.copy, hdfs.move, hdfs.rename, hdfs.put, hdfs.get, hdfs.file, hdfs.write,hdfs.close, hdfs.flush, hdfs.read, hdfs.seek, hdfs.tell, hdfs.defaults, hdfs.ls, hdfslist.files, hdfs.delete, hdfs.rm, hdfs.del, hdfs.dircreate, hdfs.mkdir, hdfs.chmod, hdfs.chown, hdfs.file.info, hdfs.exists, hdfs.init, hdfs.line.reader, hdfs.read.text.file. 2.3.2. Java Java es un lenguaje de programaci√≥n de prop√≥sito general, concurrente, orientado a objetos y basado en objetos que fue dise√±ado espec√≠ficamente para tener tan pocas dependencias de implementaci√≥n como fuera posible. Su intenci√≥n es permitir que los desarrolladores de aplicaciones escriban el programa una vez y lo ejecuten en cualquier dispositivo (conocido en ingl√©s como WORA, o "write once, run anywhere"), lo que quiere decir que el c√≥digo que es ejecutado en una plataforma no tiene que ser recompilado para correr en otra. [32] Cap√≠tulo 2. Marco Conceptual 51 2.3.3. Python Python es un lenguaje de programaci√≥n orientado a objetos claro y potente, comparable a Perl, Ruby, Scheme o Java. [35] Python tiene un gran soporte para aplicaciones de Ciencias de Datos, especialmente con librer√≠as como NumPy/SciPy, Pandas, Scikit-learn, IPython para un an√°lisis exploratorio y Matplotlib para visualizaciones.[40] Python para el an√°lisis de de Big Data se enfoca en la manipulaci√≥n, procesamiento y limpieza de los datos. Se apoya en algunas librer√≠as como PyDoop y SciPy. [41] 2.3.3.1. SciPy Scipy es un software de c√≥digo abierto para matem√°ticas, ciencias e ingenier√≠a. Incluye m√≥dulos para estad√≠sticas, optimizaci√≥n, integraci√≥n, algebra lineal, transformaciones de Fourier, procesamiento de im√°genes, y m√°s [49]. A continuaci√≥n se listan algunos de sus m√≥dulos [50]: 1. NumPy: Provee una manipulaci√≥n r√°pida y conveniente de arreglos n-dimensionales 2. SciPy library: Librer√≠a fundamental para la computaci√≥n cient√≠fica 3. Matplotlib: Maneja gr√°ficos comprensibles de dos dimensiones 4. IPython: Consola interactiva 5. Sympy: Provee simbolog√≠a matem√°tica 6. Pandas: Provee rutinas para la estructuraci√≥n y an√°lisis de los datos 2.4. Apache Hadoop Antes de hablar de Apache Hadoop primero se debe mencionar que es Apache. Apache Software Foundation (ASF) es una organizaci√≥n no lucrativa creada para dar soporte a los proyectos de software bajo la denominaci√≥n Apache. Apache Software Foundation es una comunidad descentralizada de desarrolladores que trabajan cada uno en sus propios proyectos de c√≥digo abierto. [39] Cap√≠tulo 2. Marco Conceptual 52 Los proyectos Apache se caracterizan por un modelo de desarrollo basado en el consenso y la colaboraci√≥n y en una licencia de software abierta y pragm√°tica. Cada proyecto es gestionado por un grupo autoseleccionado de expertos t√©cnicos que son participantes activos en dicho proyecto. [39] Entre los objetivos de la ASF se encuentra el proporcionar protecci√≥n legal a los voluntarios que trabajan en proyectos Apache, y al propio nombre Apache de ser empleado por otras organizaciones. El proyecto Apache es el origen de la licencia Apache y de todas las licencias que siguen un esquema similar. [39] Apache Hadoop es un framework de software que soporta aplicaciones distribuidas bajo una licencia libre. Fue creado por Doug Cutting. Tiene sus or√≠genes en Apache Nutch, el cual es un motor de b√∫squeda en la web de c√≥digo abierto. [24] Nutch se inici√≥ en 2002. Sin embargo, se dieron cuenta de que su arquitectura no escalar√≠a a los miles de millones de p√°ginas en la Web. La ayuda estaba a la mano con la publicaci√≥n de un art√≠culo en 2003 que describe la arquitectura del sistema de archivos distribuido de Google, llamado GFS, que estaba siendo utilizado en producci√≥n en Google. GFS, o algo parecido, podr√≠a resolver las necesidades de almacenamiento para los archivos muy grandes que se generan como parte del proceso de indexaci√≥n y rastreo web. En particular, GFS liberar√≠a tiempo que se gasta en tareas administrativas, tales como la gesti√≥n de nodos de almacenamiento. En 2004, se empezo a escribir una implementaci√≥n de c√≥digo abierto, el Sistema de archivos distribuidos Nutch (NDFS). [24] En 2004, Google public√≥ el documento que present√≥ MapReduce para el mundo. Temprano en 2005, los desarrolladores de Nutch ten√≠an una implementaci√≥n de MapReduce trabajando en Nutch, y a mediados de ese a√±o. Todos los algoritmos principales Nutch hab√≠an sido adecuados para ejecutarse utilizando MapReduce y NDFS. [24] NDFS y la implementaci√≥n de MapReduce en Nutch eran aplicables m√°s all√° del √°mbito de b√∫squeda, y en febrero de 2006 los desarrolladores se mudaron de Nutch para formar un subproyecto independiente de Lucene llamado Hadoop. Casi al mismo tiempo, Doug Cutting se uni√≥ a Yahoo!, la que proporcion√≥ un equipo dedicado y los recursos para convertir a Hadoop en un sistema que corri√≥ a escala web. Este se demostr√≥ en febrero de 2008, Cap√≠tulo 2. Marco Conceptual 53 cuando Yahoo! anunci√≥ que su b√∫squeda de √≠ndices en producci√≥n fue generada por 10000 n√∫cleos de un cl√∫ster Hadoop. [24] En enero de 2008, Hadoop se hizo su propio proyecto de nivel superior en Apache, lo que confirma su √©xito y su diversa comunidad activa. En ese momento, Hadoop estaba siendo utilizado por muchas otras empresas, adem√°s de Yahoo!, como Last.fm, Facebook, y el New York Times. [24] En abril de 2008, Hadoop rompi√≥ un r√©cord mundial al convertirse en el sistema m√°s r√°pido para ordenar una terabyte de datos. Ejecut√°ndose en un cl√∫ster de 910 nodos, Hadoop orden√≥ un terabyte en 209 segundos, superando al ganador de 297 segundos del a√±o anterior. [24] Desde entonces, Hadoop ha visto una r√°pida adopci√≥n de las empresas dominantes. El papel de Hadoop como una plataforma de almacenamiento y an√°lisis de prop√≥sito general para grandes vol√∫menes de datos ha sido reconocido por la industria, y este hecho se refleja en el n√∫mero de productos que utilizan o incorporan Hadoop de alguna manera. Hay distribuciones de Hadoop de las grandes empresas establecida, incluyendo EMC, IBM, Microsoft y Oracle, as√≠ como de empresas especialistas como Cloudera Hadoop, Hortonworks y MapR. [24] El nombre Hadoop proviene del nombre que le dio su hijo a un elefante de juguete. [24] Permite a las aplicaciones trabajar con miles de nodos y petabytes de datos. Hadoop se inspir√≥ en los documentos de Google para MapReduce y Google File System (GFS). [24] 2.4.1. Common Son un conjunto de librerias que soportan varios subproyectos de Hadoop. [27] 2.4.2. Hadoop Distributed File System (HDFS) Hadoop viene con un sistema de archivos distribuidos llamados HDFS, siglas de Hadoop Distributed Filesystem o en espa√±ol como Sistema de Archivos Distribuidos de Hadoop. [24] Cap√≠tulo 2. Marco Conceptual 54 El Sistema de archivos distribuido Hadoop (HDFS) est√° dise√±ado para soportar aplicaciones como trabajos MapReduce que leen y escriben grandes cantidades de datos en lotes, en lugar de m√°s accesos aleatorios a un mont√≥n de archivos peque√±os. S√≥lo se puede escribir en un archivo una vez en el tiempo de la creaci√≥n, para que sea m√°s f√°cil de manejar problemas de coherencia cuando los datos se alojan en un cl√∫ster de m√°quinas, por lo que las copias del archivo en cach√© se pueden leer en cualquiera de las m√°quinas que tienen uno, sin tener para comprobar si el contenido ha cambiado. El software cliente almacena los datos escritos en un archivo local temporal, hasta que haya suficiente para llenar un bloque completo HDFS. Todos los archivos son almacenados en estos bloques, con un tama√±o predeterminado de 64 MB. Una vez que suficientes datos se hayan guardado, o la operaci√≥n de escritura este cerrada, los datos locales se env√≠an a trav√©s de la red y son escritos a varios servidores del cl√∫ster, para asegurar que no se pierde si hay una falla de hardware. Para simplificar la arquitectura, HDFS utiliza un √∫nico nodo maestro o namenode para tener un rastreo sobre que archivos son almacenados y en d√≥nde. Esto quiere decir que hay un √∫nico punto de fallo y el rendimiento potencial a un cuello de botella. La intervenci√≥n manual necesaria para un fallo de namenode puede ser un dolor de cabeza para el mantenimiento del sistema. [25] Cap√≠tulo 2. Marco Conceptual 55 Figura 15: Arquitectura HDFS 2.4.2.1. Conceptos Bloques: HDFS tiene el concepto de un bloque, que a diferencia de otros sistemas de archivos la unidad es mucho m√°s grande. De 64 MB son los bloques por defecto. Al igual que en un sistema de archivos de un solo disco, los archivos en HDFS se rompen en chunks del tama√±o de bloque, que se almacenan como unidades independientes. A diferencia de un sistema de archivos de un solo disco, un archivo en HDFS que es m√°s peque√±o que un solo bloque no ocupa el valor de un bloque completo lo cual hace que valga la pena el almacenamiento subyacente. Los bloques HDFS son m√°s grandes en comparaci√≥n con los bloques de disco, y la raz√≥n es para minimizar el costo de b√∫squeda. Al hacer un bloque lo suficientemente grande, el tiempo para transferir los datos desde el disco puede ser significativamente m√°s largo que el tiempo de b√∫squeda al principio del bloque. As√≠, el tiempo para transferir un archivo grande hecho de m√∫ltiples bloques opera a la velocidad de transferencia de disco. [24] Namenodes y datanodes: Un cl√∫ster HDFS tiene dos tipos de nodos que operan en un patr√≥n maestro esclavo: un namenode (el maestro) y un n√∫mero de datanodes (esclavos). El namenode gestiona el espacio de nombres del sistema de archivos. √âl mantiene el √°rbol de archivos y los metadatos de todos los archivos y directorios en el √°rbol. Esta informaci√≥n se Cap√≠tulo 2. Marco Conceptual 56 almacena persistentemente en el disco local en la forma de dos archivos: la imagen de espacio de nombres y el registro de ediciones. El namenode tambi√©n sabe de los datanodes que se encuentran todos los bloques de un archivo dado; sin embargo, no conoce la ubicaci√≥n de manera persistente, ya que esta informaci√≥n se reconstruye a partir los datanodes cuando el sistema se inicia. Un cliente tiene acceso al sistema de archivos en nombre del usuario mediante la comunicaci√≥n con el namenode y datanodes. El cliente presenta una interfaz de sistema de archivos similar a una Portable Operating System Interface (POSIX), por lo que el c√≥digo de usuario no necesita saber sobre el funcionamiento del namenode y del datanode. Los datanodes son los caballos de batalla del sistema de archivos. Ellos almacenan y recuperan bloques cuando se les dice que lo haga (los clientes o el namenode), y que informen a el namenode peri√≥dicamente con las listas de bloques que est√°n almacenando. Sin el namenode, el sistema de ficheros no se puede utilizar. De hecho, si la m√°quina est√° en marcha y el namenode fue borrado, todos los archivos en el sistema de archivos se perder√≠an ya que no habr√≠a manera de saber c√≥mo reconstruir los archivos de los bloques en los datanodes. Por esta raz√≥n, es importante hacer que el namenode sea resistente a fallas, y Hadoop proporciona dos mecanismos para ello. La primera manera es hacer una copia de seguridad de los archivos que componen el estado persistente de los metadatos del sistema de archivos. Hadoop se puede configurar de modo que el namenode escribe su estado persistente a m√∫ltiples sistemas de ficheros. Estas escrituras son sincr√≥nicas y at√≥micas. La opci√≥n de configuraci√≥n habitual es escribir en el disco local, as√≠ como un mando a distancia de montaje NFS. Tambi√©n es posible ejecutar un namenode secundario o sustituto, que a pesar de su nombre no act√∫a como un namenode. Su funci√≥n principal es la de integrar peri√≥dicamente la imagen de espacio de nombres con el registro de ediciones para prevenir que el registro de ediciones se haga demasiado grande. El namenode secundario generalmente se ejecuta en una m√°quina f√≠sica independiente, ya que requiere un mont√≥n de CPU y tanta memoria como el namenode principal para realizar la combinaci√≥n. Mantiene una copia de la imagen del espacio de nombres fusionada, que se puede utilizar en el caso de fallo del namenode. Sin embargo, el estado del Cap√≠tulo 2. Marco Conceptual 57 namenode secundario queda por detr√°s de la primaria, por lo que en caso de fallo total del principal, la p√©rdida de datos es casi seguro. El curso normal de la acci√≥n, en este caso es copiar los archivos de metadatos del namenode que est√°n en NFS al secundario y ejecutarlo como el nuevo principal. [24] 2.4.3. MapReduce Hadoop es el sistema p√∫blico m√°s conocido para el funcionamiento de los algoritmos de MapReduce, pero muchas bases de datos modernas, tales como MongoDB, tambi√©n apoyan este patr√≥n. Es muy eficaz incluso en un sistema bastante tradicional, ya que si se puede escribir su consulta en una forma MapReduce, ser√° capaz de ejecutar de manera eficiente en tantas m√°quinas como se tenga disponible. [7] Figura 16: Ejemplo de MapReduce Los trabajos Hadoop MapReduce se dividen en un conjunto de tareas map y tareas reduce las cuales se ejecutan de una manera distribuida en un cl√∫ster de ordenadores. Cada tarea trabaja en un peque√±o subconjunto de los datos que ha sido asignado de manera que la carga se distribuye a trav√©s del cl√∫ster. Las tareas map generalmente cargan, analizan, transforman, y filtran los datos. Cada tarea reduce es responsable de la manipulaci√≥n de un subconjunto de la salida de la tarea map. Los datos intermedios son copiados de las tareas map por las tareas reducer con el fin de agrupar y agregar los datos. Es incre√≠ble como una amplia gama de problemas se puede resolver con un paradigma tan directo, de agregaciones num√©ricas simples a complejas operaciones de combinaci√≥n y productos cartesianos. Cap√≠tulo 2. Marco Conceptual 58 La entrada a un trabajo MapReduce es un conjunto de archivos en el almac√©n de datos que se transmiten a lo largo del Sistema de Archivos Distribuidos de Hadoop o ‚ÄúHadoop Distributed File System‚Äù (HDFS). En Hadoop, estos archivos se dividen con una entrada formato, que define c√≥mo separar un archivo en divisiones de entrada. Una partici√≥n de la entrada es una vista orientada a byte de una parte del archivo a ser cargado por una tarea map. Cada tarea map en Hadoop se divide en las siguientes fases: record reader, mapper, combiner, y partitioner. La salida de las tareas map, son llamadas claves intermedias y valores, las cuales se env√≠an a las tareas reducer. Las tareas reducer se dividen en las siguientes fases: shuffle, sort, reducer, y output format. Los nodos en los que las tareas map se ejecutan de manera √≥ptima son los nodos en los que los datos se apoyan. De esta manera, los datos normalmente no se tienen que mover por la red y se puede calcular en la m√°quina local. Record reader: El record reader traduce una partici√≥n de entrada generado por el formato de entrada en los registros. El prop√≥sito del lector de registro es para analizar los datos en los registros, pero no analiza el registro en s√≠. Se pasa los datos al mapper en la forma de un par clave/valor. Por lo general, la clave en este contexto es la informaci√≥n de posici√≥n y el valor es el fragmento o chunk de datos que compone un registro. [26] Map: En el mapper, el usuario proporciona un c√≥digo que se ejecuta en cada par clave/valor del record reader para producir cero o m√°s pares clave/valor, llamados pares intermedios. La decisi√≥n de cu√°l es la clave y el valor que aqu√≠ no es arbitraria y es muy importante lo que est√° logrando el trabajo MapReduce. La clave est√° dada de manera que los datos se agrupan en base a ella y el valor es la informaci√≥n pertinente para el an√°lisis en el reducer. [26] Combiner: El combiner, un reducer opcional localizado, pueden agrupar los datos en la fase map. El combiner toma las claves intermedias desde el mapper y aplica un m√©todo proporcionado por el usuario para agregar valores en el peque√±o √°mbito de un mapper. Por ejemplo, debido a que el recuento de una agregaci√≥n es la suma de los cargos de cada parte, se puede producir un recuento intermedio y luego sumar esos recuentos intermedios para el resultado final. En muchas situaciones, esto reduce significativamente la cantidad de datos que tienen que moverse m√°s en red. Cap√≠tulo 2. Marco Conceptual 59 Env√≠o (hola mundo, 3) requiere menos bytes que env√≠a (helloworld, 1) tres veces a lo largo de la red. Muchos de los nuevos desarrolladores de Hadoop ignoran la fase combiner, pero a menudo proporcionan mejoras de rendimiento extremas con ning√∫n inconveniente. Se puede se√±alar que los patrones se benefician del uso de combiner, y hay cu√°les en los que no se puede utilizar un combiner. Un combiner no est√° garantizado para ejecutarse, por lo que no puede ser un parte del algoritmo general. [26] Partitioner: El partitioner toma los pares clave/valor intermedios desde el mapper (o combiner si se utiliza) y los divide en fragmentos o shards, uno fragmento por reducer. De forma predeterminada, la herramienta partitioner interroga al objeto por su c√≥digo hash, que es t√≠picamente un md5sum. Entonces, el partitioner realiza una operaci√≥n de m√≥dulo por el n√∫mero de reducer: key.hashCode ()% (n√∫mero de reducers). Esto distribuye aleatoriamente el espacio de claves de manera uniforme sobre los reducers, pero a√∫n asegura que las claves con el mismo valor en diferentes mappers terminen en el mismo reducer. El comportamiento por defecto de la herramienta partitioner se puede personalizar, y estar√° en algunos patrones m√°s avanzados, tales como el sorting. Sin embargo, el cambio de la herramienta partitioner rara vez es necesario. Los datos particionados se escriben en el sistema de archivos local de cada tarea map y espera a ser pulled por su respectivo reducer. [26] Shuffle and sort: La tarea reduce comienza con la etapa shuffle and sort. Este paso toma los archivos de salida escrito por todos los partitioners y lo descarga en el equipo local en el que el reducer se est√° ejecutando. Estas piezas individuales de datos se ordenan por llave en una lista de datos m√°s grande. El prop√≥sito de este tipo es agrupar las llaves equivalentes juntas para que sus valores puedan iterarse m√°s f√°cilmente en la tarea reducer. Esta fase no es adaptable y el framework maneja todo autom√°ticamente. El √∫nico control que tiene un desarrollador es c√≥mo se clasifican y agrupan las claves especificando una costumbre Comparator object. [26] Reduce: El reducer toma los datos agrupados como entrada y ejecuta una funci√≥n reduce una vez por agrupaci√≥n clave. La funci√≥n se le pasa la clave y un iterador sobre todos los valores asociados a la clave pasada. Una amplia gama de procesamientos pueden ocurrir en esta funci√≥n. Los datos pueden ser agregados, filtrados, y combinados en un n√∫mero amplio de maneras. Una vez que la funci√≥n reduce se haga, se env√≠an cero o m√°s clave/valor par a la etapa final, el output format o formato de salida. Al igual Cap√≠tulo 2. Marco Conceptual 60 que la funci√≥n map, la funci√≥n reduce cambiar√° de un trabajo a otro, ya que es una pieza central de la l√≥gica en la soluci√≥n. [26] Output format: El formato de salida o output format traduce el par clave/valor final de la funci√≥n reduce y lo escribe en un archivo de un registro escritor. Por defecto, se separar√° la clave y el valor en una ficha de registros separados con un car√°cter de nueva l√≠nea. Esto puede ser t√≠picamente personalizado para ofrecer formatos de salida m√°s entendibles, pero al final, los datos se escriben en el HDFS, independientemente del formato.[26] 2.4.3.1. Hadoop Streaming Hadoop streaming es un componente que viene con las distribuciones de Hadoop. La utilidad le permite crear y ejecutar trabajos map / reduce con cualquier ejecutable o script. [19] Por ejemplo: $HADOOP_HOME/bin/hadoop jar $HADOOP_HOME/hadoop-streaming.jar \ -input myInputDirs \ -output myOutputDir \ -mapper /bin/cat \ -reducer /bin/wc En el ejemplo anterior, tanto el map como el reduce son ejecutables que leen la entrada por entrada est√°ndar (l√≠nea por l√≠nea) y emiten la salida a como salida est√°ndar. El componente crear√° un trabajo Map/Reduce, enviar√° la tarea a un cl√∫ster apropiado y monitorear√° el progreso del trabajo hasta que se complete. Parametro Requerido Descripci√≥n -input Requerido Localizaci√≥n de la entrada del mapper -output Requerido Localizaci√≥n de la salida del reducer -mapper Requerido Ejecutable Mapper -reducer Requerido Ejecutable Reducer Cap√≠tulo 2. Marco Conceptual 61 -file Opcional Ruta donde se encuentra el ejecutable mapper o reducer -inputformat Opcional Clase que especifica el tipo de entrada. Si no se especifica, TextInputFormat es usado por defecto -outputformat Opcional Clase que especifica el tipo de entrada. Si no se especifica, TextOutputFormat es usado por defecto -partitioner Opcional Clase que determina que clave reduce es enviada -combiner Opcional Ejecutable Combiner para la salida map -cmdenv Opcional Pasa variables de entorno para los commandos de streaming -inputreader Opcional Por compatibilidad con versiones anteriores: especifica una clase record reader (en lugar de una clase de formato de entrada) -verbose Opcional Mostrar log de salida -lazyOutput Opcional Crea una salida perezosa Cap√≠tulo 2. Marco Conceptual 62 -numReduceTasks Opcional Especifica el n√∫mero de reducers -mapdebug Opcional Script a ser llamado cuando una tarea map falle Tabla 1: Parametros de Hadoop Streaming 2.4.4. YARN Como parte de Hadoop 2.0, YARN toma las capacidades de gesti√≥n de los recursos que estaban en MapReduce y las empaqueta para que puedan ser utilizados por los nuevos motores. Esto tambi√©n simplifica MapReduce para hacer lo que mejor hace, procesar los datos. Con YARN, ahora puede ejecutar varias aplicaciones en Hadoop, todos compartiendo una gesti√≥n com√∫n de los recursos. Muchas organizaciones ya est√°n construyendo aplicaciones sobre YARN con el fin de traerlos a Hadoop. [28] Figura 17: Arquitectura YARN de Hortonworks YARN combina un administrador de recursos central que reconcilia la forma en que las aplicaciones utilizan los recursos del sistema de Hadoop con agentes gestores de nodos que controlan las operaciones de procesamiento de los nodos individuales del cl√∫ster. La separaci√≥n de HDFS Cap√≠tulo 2. Marco Conceptual 63 y MapReduce con YARN hace que el ambiente Hadoop sea m√°s adecuado para las aplicaciones operativas que no pueden esperar que terminen trabajos por lotes. [29] YARN aumenta el poder de un cl√∫ster de c√°lculo Hadoop de las siguientes maneras: a. Escalabilidad: El poder de procesamiento en los centros de datos contin√∫a creciendo r√°pidamente. Debido a que YARN ResourceManager se centra exclusivamente en la programaci√≥n, se puede administrar esos grandes grupos con mucha m√°s facilidad. [28] b. Compatibilidad con MapReduce: Aplicaciones MapReduce y usuarios existentes pueden ejecutar en la parte superior de YARN y sin interrupci√≥n a sus procesos existentes. [28] c. Utilizaci√≥n cl√∫ster mejorada: El ResourceManager es un programador puro que optimiza la utilizaci√≥n del cl√∫ster de acuerdo con criterios tales como garant√≠as de capacidad, equidad y SLAs. [28] d. Soporte para cargas de trabajo distintas de MapReduce: Modelos de programaci√≥n adicionales, tales como procesamiento gr√°fico y modelado iterativo ahora son posibles para el procesamiento de datos. [28] e. Agilidad: MapReduce se convierte en una biblioteca de espacio de usuario, que puede evolucionar de forma independiente de la capa de administrador de recursos subyacente y de una manera mucho m√°s √°gil. [28] ¬øC√≥mo trabaja YARN? La idea fundamental es la de dividir las dos principales funcionalidades del JobTracker/TaskTracker en varias entidades. La idea es tener un Manejador de Recursos global ResourceManager (RM), un ApplicationMaster (AM) por aplicaci√≥n Cap√≠tulo 2. Marco Conceptual 64 El ResourceManager y el esclavo por nodo, el NodeManager (NM), forman el marco de datos de c√°lculo. El ResourceManager es la √∫ltima autoridad que arbitra los recursos entre todas las aplicaciones en el sistema. El ApplicationMaster es, en efecto, un framework espec√≠fico de biblioteca y se encarga de la negociaci√≥n de los recursos del ResourceManager y trabajar con los NodeManager para ejecutar y supervisar las tareas que lo componen.[30] Figura 18: Proceso MapReduce YARN El ResourceManager tiene un planificador, que es responsable de la asignaci√≥n de recursos para las diversas aplicaciones en ejecuci√≥n, de acuerdo con las limitaciones como las capacidades de colas, los plazos de usuario, etc. El programador realiza su funci√≥n de programaci√≥n basado en las necesidades de recursos de las aplicaciones. El NodeManager es responsable del lanzamiento de los contenedores de las aplicaciones, el seguimiento de su uso de los recursos (CPU, memoria, disco, red) e informar del mismo al ResourceManager. Cada ApplicationMaster tiene la responsabilidad de negociar contenedores de recursos adecuados desde el planificador, el seguimiento de su estado, y el seguimiento de su progreso. Desde la perspectiva del sistema, el ApplicationMaster se ejecuta como un recipiente normal. Cap√≠tulo 2. Marco Conceptual 65 2.4.5. Herramientas del Ecosistema Hadoop 2.4.5.1. Hive Apache Hive es el est√°ndar de facto para las consultas SQL que tienen m√°s de petabytes de datos en Hadoop. Es un motor integral y compatible que ofrece la gama m√°s amplia de la sem√°ntica de SQL para Hadoop, proporcionando un potente conjunto de herramientas para los analistas y desarrolladores para acceder a los datos de Hadoop.[31] Con Hive, se pueden programar trabajos Hadoop utilizando SQL. Es una excelente interfaz para cualquier persona que viene del mundo de bases de datos relacionales, aunque los detalles de la implementaci√≥n subyacente no est√°n completamente ocultos. El usuario todav√≠a tiene que preocuparse acerca de algunas diferencias en cosas como la forma m√°s √≥ptima para especificar los joins para un mejor rendimiento y algunas caracter√≠sticas del lenguaje que faltan. Hive ofrece la posibilidad de conectar en c√≥digo personalizado para situaciones que no encajan en SQL, as√≠ como una gran cantidad de herramientas para el manejo de entrada y salida. Para usarlo, debe configurar las tablas estructuradas que describen su entrada y salida, los problemas en comandos de carga para ingerir archivos y, a continuaci√≥n, escribir sus consultas como lo har√≠a en cualquier otra base de datos relacional. No se debe tener en cuenta, sin embargo, que debido al enfoque de Hadoop de procesamientos en gran escala, la latencia puede significar que incluso los trabajos m√°s simples toman minutos para completarse, as√≠ que no es un sustituto de una base de datos transaccional en tiempo real.[7] Hive fue creado para hacer posible que los analistas con fuertes habilidades de SQL (pero con escaso conocimientos de programaci√≥n Java) puedan ejecutar consultas sobre los enormes vol√∫menes de datos que Facebook ha almacenado en HDFS. Hoy, Hive es un proyecto Apache exitoso utilizado por muchas organizaciones. [24] ¬øQu√© hace Hive? Hadoop fue construido para organizar y almacenar grandes cantidades de datos. Un cluster Hadoop es un dep√≥sito de datos heterog√©neos, provenientes de m√∫ltiples fuentes y en diferentes formatos. Hive permite al usuario explorar y estructura que los datos, analizarlos, y luego convertirlo en el conocimiento del negocio. [31] Cap√≠tulo 2. Marco Conceptual 66 ¬øC√≥mo funciona Hive? Las tablas en Hive son similares a las tablas en una base de datos relacional, y las unidades de datos est√°n organizadas en una taxonom√≠a m√°s grande que muchas unidades granulares. Las bases de datos se componen de tablas, que se componen de particiones. Los datos se pueden acceder a trav√©s de un lenguaje de consulta simple, llamado HiveQL, que es similar a SQL. Hive apoya sobrescribir o anexar datos, pero no las actualizaciones y eliminaciones. [31] Dentro de una base de datos particular, los datos de las tablas son serializados y cada tabla tiene un directorio en el sistema de archivos distribuido Hadoop correspondiente (HDFS). Cada tabla puede estar subdividida en particiones que determinan c√≥mo los datos se distribuyen dentro de los subdirectorios del directorio de la tabla. Los datos dentro de particiones se pueden desglosar en cubos. [31] Estas son algunas de las caracter√≠sticas ventajosas de Hive: a) Familiar: Cientos de usuarios √∫nicos pueden consultar simult√°neamente los datos utilizando un lenguaje familiar para los usuarios de SQL. [31] b) Velocidad: Los tiempos de respuesta son normalmente mucho m√°s r√°pido que otros tipos de consultas en el mismo tipo de conjuntos de datos enormes. [31] c) Escalable y extensible: Como la variedad de datos y el volumen crece, m√°s m√°quinas de las materias primas se pueden a√±adir a la agrupaci√≥n, sin una reducci√≥n correspondiente en el rendimiento. [31] d) Informativo: Controladores JDBC y ODBC familiares permiten muchas aplicaciones para extraer datos de Hive para la presentaci√≥n de informes sin fisuras. Hive permite a los usuarios leer los datos en formatos arbitrarios, usando SerDes y formatos de entrada/salida. [31] 2.4.5.2. Pig El proyecto Apache Pig es un lenguaje procedimental para el procesamiento de datos dise√±ado para Hadoop. En contraste con el enfoque de Hive, con Pig se especifican una serie de pasos a realizar en los datos. Est√° m√°s cerca de un lenguaje de programaci√≥n todos los d√≠as, pero con un Cap√≠tulo 2. Marco Conceptual 67 conjunto especializado de funciones que ayudan con problemas de procesamiento de datos comunes.[25] Pig eleva el nivel de abstracci√≥n para el procesamiento de grandes conjuntos de datos. MapReduce permite, como el programador especifica una funci√≥n de map seguida por una funci√≥n de reduce, pero trabajando fuera de c√≥mo encontrar la manera de adaptar su procesamiento de datos a este patr√≥n, que a menudo requiere m√∫ltiples etapas de MapReduce, por ende la adaptaci√≥n puede ser un desaf√≠o. Con Pig, las estructuras de datos son mucho m√°s ricas, suelen ser m√∫ltiples valores y anidados, y el conjunto de transformaciones que se le pueden aplicar los datos son mucho m√°s poderosas. Ellas incluyen joins.[32] Pig se compone de dos piezas: a) El lenguajes para expresar flujos de datos lladamo, Pig Latin. b) El entorno de ejecuci√≥n para ejecutar los programas de Pig Latin. Actualmente hay dos entornos de ejecuci√≥n: Una ejecuci√≥n local en una √∫nica JVM y una ejecuci√≥n distribuida en un cl√∫ster Hadoop. [32] ¬øQu√© hace Pig? Pig fue dise√±ado para llevar a cabo una larga serie de operaciones de datos, por lo que es ideal para tres categor√≠as de empleos Big Data: Extracci√≥n, transformaci√≥n y carga (ETL) de pipelines de datos, la investigaci√≥n sobre los datos en bruto, y el procesamiento de datos iterativo. [33] Cualquiera que sea el caso de uso, Pig ser√°: a) Extensible. Los usuarios Pig pueden crear funciones personalizadas para satisfacer sus necesidades de procesamiento particulares. b) F√°cil de programar. Las tareas complejas que implican transformaciones de datos relacionados entre s√≠ se pueden simplificar y codificar como secuencias de flujo de datos. Los programas Pig realizan tareas enormes, pero son f√°ciles de escribir y mantener. c) Auto-optimizaci√≥n. El sistema optimiza autom√°ticamente la ejecuci√≥n de trabajos Pig, por lo que el usuario puede centrarse en la sem√°ntica. [33] Cap√≠tulo 2. Marco Conceptual 68 ¬øC√≥mo funciona Pig? Pig se ejecuta en Hadoop y hace uso del sistema de archivos distribuido Hadoop (HDFS) y MapReduce. El idioma de la plataforma se llama Pig Latin, que abstrae del lenguaje Java MapReduce en una forma similar a SQL. Pig Latin es un lenguaje de flujo mientras que SQL es un lenguaje declarativo. SQL es ideal para hacer una pregunta de sus datos, mientras Pig Latin le permite escribir un flujo de datos que describe c√≥mo se transforman los datos. Los scripts Pig Latin pueden ser gr√°ficos (en lugar de requerir una sola salida) es posible construir flujos de datos compleja que involucren m√∫ltiples entradas, transformaciones y salidas. Los usuarios pueden ampliar Pig Latin escribiendo sus propias funciones, utilizando Java, Python, Ruby, u otros lenguajes de script. [33] El usuario puede ejecutar Pig en dos modos: 1. Modo Local. Con acceso a una sola m√°quina, todos los archivos se instalan y se ejecutan utilizando un sistema anfitri√≥n y el archivo local. [19] 2. Modo MapReduce. Este es el modo por defecto, lo que requiere el acceso a un cluster Hadoop. [33] El usuario puede ejecutar Pig en cualquiera de los modos mediante el comando "java" o el comando "pig". 2.4.5.3. HCatalog Apache HCatalog es una capa que gestiona el almacenamiento de datos en tablas que permite a los usuarios utilizando diferentes herramientas de procesamiento leer y escribir datos de manera m√°s f√°cil en la red. La abstracci√≥n que provee HCatalog en base a tablas presenta a los usuarios una visi√≥n relacional de los datos en el sistema de archivos distribuidos de Hadoop (HDFS) y adem√°s asegura a los usuarios que no deben preocuparse acerca de d√≥nde o en qu√© formato se almacenan los datos. Hcatalog muestra datos provenientes desde fuentes con varios formatos en una vista tabular. Tambi√©n proporciona medios para que los sistemas externos puedan acceder a los datos de las tablas.[34] ¬øQu√© hace HCatalog? Cap√≠tulo 2. Marco Conceptual 69 Apache HCatalog ofrece los siguientes beneficios a los administradores de la red: ÔÇ∑ Libera al usuario de tener que saber d√≥nde se almacenan los datos, con la abstracci√≥n en base a tablas [34] ÔÇ∑ Activa las notificaciones de la disponibilidad de datos [34] ÔÇ∑ Proporciona visibilidad para herramientas de limpieza y almacenamiento de datos [34] ¬øC√≥mo trabaja HCatalog? HCatalog apoya la lectura y la escritura de archivos en cualquier formato para el que Hive SerDe funcione. Por defecto HCatalog soporta los siguientes formatos: RCFile, CSV, JSON y SequenceFile. Para utilizar un formato personalizado se debe proporcionar el formato de entrada, el de salida y el SerDe. [34] HCatalog se construye en la parte superior de Hive e incorpora componentes DDL de Hive. HCatalog proporciona interfaces de lectura y escritura interfaces para Pig y MapReduce y usa la interfaz de l√≠nea de comandos de Hive para la emisi√≥n de comando para la definici√≥n y exploraci√≥n de datos. Tambi√©n presenta una interfaz REST para permitir a las herramientas externas el acceso a las operaciones DDL (Data Definition Language) de Hive, como "create table" y "describe table". [34] HCatalog presenta una vista relacional de datos. Los datos se almacenan en tablas y estas tablas se pueden colocar en las bases de datos. Las tablas tambi√©n se pueden dividir en una o m√°s claves. Para un valor dado de una clave (o conjunto de claves) habr√° una partici√≥n que contiene todas las filas con ese valor (o conjunto de valores). [34] 2.4.5.4. Apache Spark A medida que la relaci√≥n de la memoria a la potencia de procesamiento evoluciona r√°pidamente, muchos dentro de la comunidad Cap√≠tulo 2. Marco Conceptual 70 Hadoop est√°n gravitando hacia Apache Spark para procesamiento r√°pido de datos en memoria.[35] Apache Spark es un framework de c√≥digo abierto para an√°lisis de datos en cl√∫steres, desarrollado originalmente en el AMPLab en UC Berkeley. [36] Spark encaja en la comunidad de c√≥digo abierto Hadoop, sobre la parte superior del sistema de archivos distribuido Hadoop (HDFS). Sin embargo, Spark no est√° ligado al paradigma MapReduce de dos etapas, y promete un rendimiento de hasta 100 veces m√°s r√°pido que Hadoop MapReduce para ciertas aplicaciones.[36] Spark proporciona primitivas para la computaci√≥n de cl√∫steres en memoria que permite a los programas de usuario cargar datos en un la memoria de cl√∫steres y consultarla varias veces, por lo que es muy adecuado para los algoritmos de aprendizaje autom√°tico. [36] Apache Spark permite a los cient√≠ficos de datos implementar de manera efectiva y simple algoritmos iterativos para an√°lisis avanzados como la agrupaci√≥n y clasificaci√≥n de conjuntos de datos. Actualmente es un proyecto Apache nivel superior y se est√° convirtiendo en una alternativa atractiva para ejecutar algunas cargas discretas de trabajo de ciencia de datos. [35] 2.4.5.5. Apache Flume Apache Flume es un servicio disponible, distribuido y confiable para la recolecci√≥n, agregaci√≥n y el movimiento de manera eficiente de grandes cantidades de datos en el sistema de archivos distribuidos de Hadoop (HDFS). Cuenta con una arquitectura simple y flexible basada en la transmisi√≥n de flujos de datos; es robusto y tolerante a fallos con mecanismos de confiabilidad sintonizables para la conmutaci√≥n por error y recuperaci√≥n. [38] ¬øQu√© hace Flume? Flume permite a los usuarios de Hadoop sacar mayor provecho a los datos de registro con mayor valor. En concreto, Flume permite a los usuarios hacer: Cap√≠tulo 2. Marco Conceptual 71 1. Secuencias de datos a partir de m√∫ltiples fuentes en Hadoop para el an√°lisis. [38] 2. Recoger registros Web de alto volumen en tiempo real. [38] 3. Aislarse de picos transitorios cuando la tasa de datos entrantes excede la tasa a la que los datos se pueden escribir en el destino. [38] 4. Garant√≠a en la entrega de datos. [38] 5. Escala horizontal para manejar el volumen de datos adicional. [38] ¬øC√≥mo funciona Flume? La arquitectura de alto nivel de Flume se centra en la entrega de una base de c√≥digo optimizada que es f√°cil de usar y f√°cil de extender. El equipo del proyecto ha dise√±ado Flume con los siguientes componentes: a) Event - una unidad singular de los datos que se transporta por el canal de flujo (por lo general una sola entrada de registro). [38] b) Source - la entidad a trav√©s de la cual los datos de entrada en Flume. Source o bien sondea activamente para datos o pasivamente espera que los datos sean entregados a ellos. [38] c) Sink - la entidad que entrega los datos al destino. [38] d) Channel - el conducto entre el Source y el Sink. Source ingieren Events en el Channel y los Sinks drenan el Channel. [38] e) Agent - cualquier m√°quina virtual f√≠sica Java que ejecute Flume. Se trata de una colecci√≥n de Source, Sink y Channel. [38] f) Client - produce y transmite el Event a Source que opera dentro del Agent. [38] Un flujo de Flume se inicia desde el Client. El Client transmite el Event a una Source que opera dentro del Agent. La Source de recibir este Event lo entrega a uno o m√°s Channels. Estos Channels son drenados por uno o m√°s Sinks que operan dentro del mismo Agent. [38] 2.4.5.6. Hue Hue es una interfaz Web para analizar datos con Apache Hadoop. Es compatible con un explorador de archivos y trabajos, Hive, Pig, Impala, Cap√≠tulo 2. Marco Conceptual 72 Spark, editores oozie, Solr Search cuadros de mando, HBase, Sqoop2, y m√°s.[39] Hue cuenta con: ÔÇ∑ Explorador de archivos para acceder a HDFS ÔÇ∑ Editor Hive para desarrollar y ejecutar consultas Hive ÔÇ∑ Search App para consultar, explorar, visualizar datos y cuadros de mando con Solr ÔÇ∑ Impala App para ejecutar consultas SQL interactivas ÔÇ∑ Spark Editor y Dashboard ÔÇ∑ Editor Pig para la presentaci√≥n de scripts Pig ÔÇ∑ Editor Oozie y Dashboard para la presentaci√≥n y seguimiento de flujos de trabajo, de coordinadores y de los paquetes ÔÇ∑ HBase Browser para visualizar, consultar y modificar tablas HBase ÔÇ∑ MetaStore Browser para acceder a los metadatos de Hive y HCatalog ÔÇ∑ Navegador de empleo para acceder a puestos de trabajo de MapReduce (MR1/MR2-YARN) ÔÇ∑ Dise√±ador de trabajos para la creaci√≥n de trabajos MapReduce/Streaming/Java ÔÇ∑ Un editor y dashboard para Sqoop 2 ÔÇ∑ Un navegador y editor ZooKeeper ÔÇ∑ Un editor de consultas DB para MySql, Postgres, SQLite y Oracle 2.4.5.7. Apache ZooKeeper Escribir aplicaciones distribuidas es dif√≠cil. Es complicado principalmente debido a las fallas parciales. Cuando es enviado un mensaje a trav√©s de la red entre dos nodos y la red falla, el remitente no sabe si el receptor recibi√≥ el mensaje. La √∫nica manera de que el emisor pueda saber si se recibi√≥ el mensaje o no es reconectarse con el receptor y preguntarle. Este es el fracaso parcial, cuando no se sabe si una operaci√≥n ha fallado. [40] Apache ZooKeeper es un servidor de c√≥digo abierto que coordina de forma fiable procesos distribuidos. [40] Apache ZooKeeper ofrece servicios operativos para un cl√∫ster Hadoop. ZooKeeper ofrece un servicio de configuraci√≥n distribuida, un Cap√≠tulo 2. Marco Conceptual 73 servicio de sincronizaci√≥n y un registro de denominaci√≥n para los sistemas distribuidos. Las aplicaciones distribuidas utilizan Zookeeper para almacenar y mediar cambios a la informaci√≥n de configuraci√≥n importante. [40] ZooKeeper no puede hacer que las fallas parciales se vayan, ya que son intr√≠nsecos al sistema distribuido. Ciertamente tampoco esconde los fracasos parciales. Pero lo que hace ZooKeeper es proporcionar un conjunto de herramientas para construir aplicaciones distribuidas que puedan manejar de forma segura los fracasos parciales. [40] ZooKeeper tambi√©n tiene las siguientes caracter√≠sticas: ZooKeeper es simple. ZooKeeper es, en su esencia, un sistema de archivos que expone algunas simples operaciones, y algunas abstracciones adicionales, tales como ordenaciones y notificaciones. [40] ZooKeeper es expresivo. Las primitivas ZooKeeper son un rico conjunto de bloques de construcci√≥n que se puede utilizar para construir una gran clase de estructuras de datos y protocolos de coordinaci√≥n. Los ejemplos incluyen: colas distribuidas, cerraduras distribuidas y elecci√≥n de un l√≠der entre un grupo de compa√±eros. [40] ZooKeeper es altamente disponible. ZooKeeper se ejecuta en una colecci√≥n de m√°quinas y est√° dise√±ado para ser altamente disponible, por lo que las aplicaciones pueden depender de √©l. [40] ZooKeeper facilita las interacciones d√©bilmente acopladas. Las interacciones de ZooKeeper apoyan a los participantes que no necesitan saber acerca de otros. Por ejemplo, ZooKeeper se puede utilizar como un mecanismo de encuentro de manera que los procesos que no saben de la existencia de otros (o detalles de la red) puedan descubrir e interactuar con los dem√°s. Las partes de coordinaci√≥n pueden incluso no ser contempor√°neas, ya que un proceso puede dejar un mensaje en ZooKeeper el cual puese ser le√≠do por otro despu√©s de que el primero se haya apagado. [40] ZooKeeper es una biblioteca. ZooKeeper proporciona un repositorio compartido de implementaciones y recetas de patrones de coordinaci√≥n comunes, de c√≥digo abierto. Los programadores individuales se esparcen la carga de la escritura protocolos comunes entre ellos mismos (que a menudo son dif√≠ciles de conseguir de manera correcta). Con el tiempo, la comunidad Cap√≠tulo 2. Marco Conceptual 74 puede aumentar y mejorar las bibliotecas, que es para beneficio de todos. [40] ZooKeeper es de gran rendimiento tambi√©n. En Yahoo!, donde fue creado, el rendimiento para un cl√∫ster ZooKeeper se ha evaluado en m√°s de 10.000 operaciones por segundo para cargas de trabajo de escritura dominante generados por cientos de clientes. Para cargas de trabajo donde la lectura domina, que es la norma, el rendimiento es varias veces alto.[40] ¬øQu√© hace ZooKeeper? ZooKeeper proporciona una interfaz muy simple y servicios. ZooKeeper trae los siguientes beneficios clave: a) R√°pido. ZooKeeper es especialmente r√°pido con cargas de trabajo donde la lectura de los datos es m√°s com√∫n que la escritura. La proporci√≥n ideal de lectura/escritura es de aproximadamente 10: 1. [40] b) Fiable. ZooKeeper se replica a trav√©s de una serie de hosts (llamado un conjunto) y los servidores son conscientes unos de otros. Mientras una masa cr√≠tica de servidores est√° disponible, el servicio ZooKeeper tambi√©n estar√° disponible. No hay ning√∫n punto √∫nico de fallo. [40] c) Sencillo. ZooKeeper mantiene un espacio de nombres jer√°rquico est√°ndar, similar a los archivos y directorios. d) Ordenado. El servicio mantiene un registro de todas las transacciones, que se pueden utilizar para abstracciones de nivel superior, como primitivas de sincronizaci√≥n. ¬øC√≥mo trabaja ZooKeeper? ZooKeeper permite procesos distribuidos para coordinar entre s√≠ a trav√©s de un espacio de nombres jer√°rquico compartido de registros de datos, conocidos como znodes. Cada znode se identifica por un camino, con elementos de ruta separados por una barra ("/"). Aparte de la ra√≠z, cada znode tiene un padre y un znode no puede ser eliminado si tiene hijos. [40] Esto es muy similar a un sistema de archivos normal, pero ZooKeeper ofrece una fiabilidad superior a trav√©s de servicios redundantes. Un servicio Cap√≠tulo 2. Marco Conceptual 75 se replica a trav√©s de una serie de m√°quinas y cada uno mantiene una imagen en memoria de los √°rboles de los datos y de transacciones. Los clientes se conectan a un √∫nico servidor ZooKeeper y mantienen una conexi√≥n TCP a trav√©s del cual env√≠an peticiones y reciben respuestas. [40] Esta arquitectura permite a ZooKeeper proporcionar un alto rendimiento y disponibilidad con baja latencia, pero el tama√±o de la base de datos que puede gestionar ZooKeeper est√° limitado por la memoria. [40] 2.4.5.8. Shark Shark es un sistema de almacenamiento de datos a gran escala para Spark dise√±ado para ser compatible con Apache Hive. Puede ejecutar consultas Hive QL hasta 100 veces m√°s r√°pido que Hive sin ninguna modificaci√≥n a los datos o consultas existentes. Shark soporta el lenguaje de consulta Hive, MetaStore, formatos de serializaci√≥n, y funciones definidas por el usuario, proporcionando una integraci√≥n perfecta con los despliegues Hive existentes y una opci√≥n familiar, m√°s potente para los nuevos. [41] Shark se construye en la parte superior de Spark, un motor de ejecuci√≥n de datos en paralelo que es r√°pido y de alta disponibilidad. Incluso si los datos est√°n en el disco, Shark puede ser notablemente m√°s r√°pido que Hive debido al motor de ejecuci√≥n r√°pida. Evita la tarea lanzamiento de alta sobrecarga de Hadoop MapReduce y no requiere la materializaci√≥n de datos intermedios entre las etapas en el disco. Gracias a este motor r√°pido, Shark puede responder a las consultas en menos de un segundo de latencia. [41] Las consultas anal√≠ticas por lo general se centran en un subgrupo en particular o en una ventana de tiempo, por ejemplo, los registros de HTTP desde el mes anterior, tocando solamente las tablas de dimensiones y una peque√±a porci√≥n de la tabla de hechos. Estas consultas tienen una fuerte localidad temporal, y en muchos casos, es plausible para encajar el conjunto de trabajo en la memoria de un cl√∫ster. Shark permite a los usuarios explotar esta localidad temporal mediante el almacenamiento de su conjunto de trabajo de datos a trav√©s de la memoria de un grupo, o en t√©rminos de base de datos, para crear en memoria vistas materializadas.[41] Cap√≠tulo 2. Marco Conceptual 76 2.4.5.9. Apache Sqoop Apache Sqoop es una herramienta dise√±ada para transferir datos de manera eficiente a granel entre Hadoop y almacenes de datos estructurados como bases de datos relacionales. Sqoop importa datos de almacenes estructurados externos dentro de los sistemas HDFS o cualquier medio de almacenamiento que se utilice, como Hive y HBase. Sqoop tambi√©n se puede utilizar para extraer datos de Hadoop y exportarlo a almacenes estructurados externos tales como bases de datos relacionales y almacenes de datos empresariales. Sqoop trabaja con bases de datos relacionales, tales como: Teradata, Netezza, Oracle, MySQL, Postgres, y HSQLDB. [42] ¬øQu√© hace Sqoop? Est√° dise√±ado para transferir datos de manera eficiente a granel entre Hadoop y almacenes estructurados como bases de datos relacionales, Apache Sqoop: ÔÇ∑ Permite la importaci√≥n de datos de almacenes externos y almacenes de datos empresariales en Hadoop [42] ÔÇ∑ Paraleliza la transferencia de datos para un rendimiento r√°pido y la utilizaci√≥n √≥ptima del sistema [42] ÔÇ∑ Copia datos r√°pidamente de sistemas externos a Hadoop [42] ÔÇ∑ Hace un an√°lisis de datos m√°s eficiente [42] ÔÇ∑ Mitiga cargas excesivas a sistemas externos. [42] ¬øC√≥mo trabaja Sqoop? Sqoop proporciona un mecanismo conector enchufable para una √≥ptima conectividad a sistemas externos. La API de extensi√≥n de Sqoop proporciona un marco conveniente para la construcci√≥n de nuevos conectores que pueden ser ignorados en las instalaciones de Sqoop para proporcionar conectividad a varios sistemas. Sqoop s√≠ viene incluido con varios conectores que pueden ser utilizados para los sistemas de base de datos y almacenes de datos populares. [42] Cap√≠tulo 2. Marco Conceptual 77 2.4.6. Distribuciones Hadoop La arquitectura flexible y modular de hadoop permite a√±adir nuevas funcionalidades para la realizaci√≥n de diversas tareas de Big Data. Un n√∫mero de vendedores han aprovechado el framework de composici√≥n abierta de Hadoop ajustando sus c√≥digos para cambiar o mejorar sus funcionalidades. En el proceso han sido capaces de solucionar algunos de los inconvenientes inherentes de Hadoop. En lo que se refiere a las distribuciones de Hadoop, las tres empresas que realmente se destacan en la terminaci√≥n son: Cloudera, MapR y Hortonworks. [20] Cloudera ha estado presente por mucho m√°s tiempo, desde la creaci√≥n de Hadoop. Hortonworks vino despu√©s. Mientras Cloudera y Hortonworks son 100 por ciento de c√≥digo abierto, la mayor√≠a de las versiones de MapR vienen con m√≥dulos propietarios. [20] 2.4.6.1. MapR MapR reemplaza el componente HDFS y en su lugar utiliza su propio sistema de archivo propietario, llamado MapRFS. MapRFS ayuda a incorporar caracter√≠sticas de nivel empresarial en Hadoop, lo que permite una gesti√≥n m√°s eficiente de los datos, fiabilidad y lo m√°s importante, la facilidad de uso. [20] A trav√©s de una alianza con Canonical, el creador del sistema operativo Ubuntu, MapR est√° ofreciendo Hadoop como un componente predeterminado del sistema operativo Ubuntu. Bajo los t√©rminos de la alianza, la edici√≥n M3 de MapR para Hadoop se integrar√° en el sistema operativo Ubuntu. [20] 2.4.6.2. Cloudera Cloudera Inc. fue fundada por los genios de Big Data de Facebook, Google, Oracle y Yahoo en 2008. Fue la primera empresa en desarrollar y distribuir software basado en Apache Hadoop y todav√≠a tiene la mayor base de usuarios con mayor n√∫mero de clientes. Aunque el n√∫cleo de la distribuci√≥n est√° basado en Hadoop, tambi√©n proporciona una Suite de Cap√≠tulo 2. Marco Conceptual 78 gesti√≥n propietaria llamada Management Suite Cloudera para automatizar el proceso de instalaci√≥n y proporcionar otros servicios para mejorar la comodidad de los usuarios, que incluyen la reducci√≥n de tiempo de implementaci√≥n, mostrando recuento nodos en tiempo real, etc. [20] 2.4.6.3. Hortonworks Hortonworks, fundada en 2011, se ha convertido r√°pidamente en uno de los principales proveedores de Hadoop. La distribuci√≥n proporciona la plataforma de c√≥digo abierto basado en Hadoop para analizar, almacenar y gestionar grandes vol√∫menes de datos. Hortonworks es el √∫nico proveedor comercial para distribuir c√≥digo abierto completamente Hadoop sin software propietario adicional. La distribuci√≥n 2.0 de Hadoop Data Platform (HDP2.0) de Hortonworks se puede descargar directamente desde su p√°gina web de forma gratuita y es f√°cil de instalar. Los ingenieros de Hortonworks est√°n detr√°s de la mayor√≠a de las innovaciones recientes de Hadoop incluido YARN, que es mejor que MapReduce en el sentido de que permitir√° inclusi√≥n de m√°s frameworks para el procesamiento de datos. [20] 2.4.6.4 Comparaci√≥n entre Hortonworks y Cloudera 2.4.6.4.1. Similitudes ÔÇ∑ Ofrecen distribuciones de Hadoop listas para la empresa. Las distribuciones han resistido la prueba del tiempo, as√≠ como los consumidores, garantizando la seguridad y la estabilidad. Adem√°s, proporcionan servicios de capacitaci√≥n y familiarizaci√≥n pagos a los reci√©n llegados que pisan el camino de Big Data. ÔÇ∑ Han establecido comunidades que participan de forma activa y ayudan con los problemas que enfrentan. ÔÇ∑ Ambas distribuciones tienen una arquitectura maestro-esclavo. ÔÇ∑ Soportan y dan apoyo a MapReduce as√≠ como a YARN. Cap√≠tulo 2. Marco Conceptual 79 2.4.6.4.2. Diferencias ÔÇ∑ Cloudera ha anunciado que su objetivo a largo plazo es convertirse en un "centro de datos empresariales", disminuyendo as√≠ la necesidad de almacenamiento de datos. Hortonworks, por el contrario, sigue siendo firmemente un proveedor de Hadoop, y se ha asociado con la compa√±√≠a de almacenamiento de datos Teradata. ÔÇ∑ Mientras Cloudera CDH se puede ejecutar en un servidor de Windows, HDP est√° disponible como un componente nativo en un servidor de Windows. Un cluster Hadoop basado en Windows se puede implementar en Windows Azure a trav√©s del Servicio HDInsight. ÔÇ∑ Cloudera tiene un software de gesti√≥n propietario llamado Cloudera Manager, una interfaz de manejo de consulta SQL llamada Impala y Cloudera Search qu√© es un acceso f√°cil y en tiempo real de los productos. Hortonworks no tiene software propietario, utiliza Ambari para la gesti√≥n y Stinger para el manejo de consultas y Apache Solr para b√∫squedas de datos. ÔÇ∑ Cloudera tiene uso comercial, mientras Hortonworks tiene licencia de c√≥digo abierto. ÔÇ∑ Cloudera tambi√©n permite el uso de sus proyectos de c√≥digo abierto de manera gratuita, pero el paquete no incluye la suite de gesti√≥n de Cloudera Manager o cualquier otro software propietario. ÔÇ∑ Cloudera tiene una prueba gratuita de 60 d√≠as, Hortonworks es totalmente gratuito. Cap√≠tulo 2. Marco Conceptual 80 2.4.6.5. Comparaci√≥n general Hortonworks Cloudera MapR Rendimiento Ingreso de datos Por lotes Por lotes Por lotes y escritura de tipo streaming Arquitectura de los metadatos Centralizada Centralizada Distribuida Rendimiento de HBase Picos en latencia Picos en latencia Consistente de baja latencia Aplicaciones NoSQL Principalmente aplicaciones con datos por lotes Principalmente aplicaciones con datos por lotes Aplicaciones con datos por lotes y de tiempo real Dependencia Alta disponibilidad Recuperaci√≥n de fallas simples Recuperaci√≥n de fallas simples Auto recuperaci√≥n a trav√©s de m√∫ltiples fallas Replicaci√≥n Datos Datos Datos y meta- datos Recuperaci√≥n tras cat√°strofe No Planificaci√≥n de copia de archivos (BDR) Mirroring Manejabilidad Herramientas de manejo Ambari Cloudera Manager MapR Control System Integraci√≥n con API¬¥s REST S√≠ S√≠ S√≠ Acceso a los Datos Acceso al HDFS, s√≥lo HDFS, s√≥lo HDFS, lectura y Cap√≠tulo 2. Marco Conceptual 81 Sistema de Archivos lectura NFS lectura NFS escritura NFS Entrada y Salida de Archivos S√≥lo Append S√≥lo Append Lectura y escritura Autenticaci√≥n Kerberos Kerberos Kerberos y Nativa Tabla 2: Comparaci√≥n de las principales distribuciones de Hadoop 82 3. M√©todo de Desarrollo Para el desarrollo de software de manera eficiente se emplean m√©todos de desarrollo acorde a los requerimientos que amerite el software. Dentro del conjunto de m√©todos de desarrollo de Software, existen unos para el desarrollo √°gil, estos tienen como objetivo fundamental minimizar las actividades que no se considera relevantes, aumentar la productividad del equipo de desarrollo y elevar la adaptabilidad del resultado. En este cap√≠tulo se describen algunos t√≥picos requeridos para el desarrollo del Trabajo Especial de Grado. Entre estos t√≥picos se encuentran el Manifiesto √Ågil y m√©todos √°giles Ad Hoc. 3.1. Manifiesto √Ågil El 17 de febrero de 2001 diecisiete cr√≠ticos de los modelos de mejora del desarrollo de software basados en procesos, convocados por Kent Beck, quien hab√≠a publicado un par de a√±os antes Extreme Programming Explained, libro en el que expon√≠a una nueva metodolog√≠a denominada Extreme Programming, se reunieron en Snowbird, Utah para tratar sobre t√©cnicas y procesos para desarrollar software. En la reuni√≥n se acu√±√≥ el t√©rmino ‚ÄúM√©todos √Ågiles‚Äù para definir a los m√©todos que estaban surgiendo como alternativa a las metodolog√≠as formales (CMMI, SPICE) a las que consideraban excesivamente ‚Äúpesadas‚Äù y r√≠gidas por su car√°cter normativo y fuerte dependencia de planificaciones detalladas previas al desarrollo. Los integrantes de la reuni√≥n resumieron los principios sobre los que se basan los m√©todos alternativos en cuatro postulados, lo que ha quedado denominado como Manifiesto √Ågil. [21] Cap√≠tulo 3. M√©todo de Desarrollo 83 3.1.1. Principios del Manifiesto √Ågil ÔÇ∑ Nuestra mayor prioridad es satisfacer al cliente mediante la entrega temprana y continua de software con valor. ÔÇ∑ Aceptamos que los requisitos cambien, incluso en etapas tard√≠as del desarrollo. Los procesos √Ågiles aprovechan el cambio para proporcionar ventaja competitiva al cliente. ÔÇ∑ Entregamos software funcional frecuentemente, entre dos semanas y dos meses, con preferencia al periodo de tiempo m√°s corto posible. ÔÇ∑ Los responsables de negocio y los desarrolladores trabajamos juntos de forma cotidiana durante todo el proyecto. ÔÇ∑ Los proyectos se desarrollan en torno a individuos motivados. Hay que darles el entorno y el apoyo que necesitan, y confiarles la ejecuci√≥n del trabajo. ÔÇ∑ El m√©todo m√°s eficiente y efectivo de comunicar informaci√≥n al equipo de desarrollo y entre sus miembros es la conversaci√≥n cara a cara. ÔÇ∑ El software funcionando es la medida principal de progreso. ÔÇ∑ Los procesos √Ågiles promueven el desarrollo sostenible. Los promotores, desarrolladores y usuarios debemos ser capaces de mantener un ritmo constante de forma indefinida. ÔÇ∑ La atenci√≥n continua a la excelencia t√©cnica y al buen dise√±o mejora la Agilidad. ÔÇ∑ La simplicidad, o el arte de maximizar la cantidad de trabajo no realizado, es esencial. ÔÇ∑ Las mejores arquitecturas, requisitos y dise√±os emergen de equipos auto-organizados. ÔÇ∑ A intervalos regulares el equipo reflexiona sobre c√≥mo ser m√°s efectivo para a continuaci√≥n ajustar y perfeccionar su comportamiento en consecuencia. 3.2. M√©todos √Ågiles El desarrollo √°gil de software refiere a m√©todos de ingenier√≠a del software basados en el desarrollo iterativo e incremental, donde los requisitos y soluciones evolucionan mediante la colaboraci√≥n de grupos auto Cap√≠tulo 3. M√©todo de Desarrollo 84 organizados y multidisciplinarios. Existen muchos m√©todos de desarrollo √°gil; la mayor√≠a minimiza riesgos desarrollando software en lapsos cortos. El software desarrollado en una unidad de tiempo es llamado una iteraci√≥n, la cual debe durar de una a cuatro semanas. Cada iteraci√≥n del ciclo de vida incluye: planificaci√≥n, an√°lisis de requisitos, dise√±o, codificaci√≥n, revisi√≥n y documentaci√≥n. Una iteraci√≥n no debe agregar demasiada funcionalidad para justificar el lanzamiento del producto al mercado, sino que la meta es tener una ‚Äúdemo‚Äù (sin errores) al final de cada iteraci√≥n. Al final de cada iteraci√≥n el equipo vuelve a evaluar las prioridades del proyecto. Los m√©todos √°giles enfatizan las comunicaciones cara a cara en vez de la documentaci√≥n. La mayor√≠a de los equipos √°giles est√°n localizados en una simple oficina abierta, a veces llamadas "plataformas de lanzamiento" (bullpen en ingl√©s). La oficina debe incluir revisores, escritores de documentaci√≥n y ayuda, dise√±adores de iteraci√≥n y directores de proyecto. Los m√©todos √°giles tambi√©n enfatizan que el software funcional es la primera medida del progreso. Combinado con la preferencia por las comunicaciones cara a cara, generalmente los m√©todos √°giles son criticados y tratados como "indisciplinados" por la falta de documentaci√≥n t√©cnica. [22] 3.2.1. Metodolog√≠a Ad Hoc orientada a prototipos Antes de hablar de una metodolog√≠a Ad hoc se debe explicar que significa ad hoc. Ad hoc es una locuci√≥n latina que significa literalmente ‚Äúpara esto‚Äù. [23] Generalmente se refiere a una soluci√≥n espec√≠ficamente elaborada para un problema o fin preciso y, por tanto, no generalizable ni utilizable para otros prop√≥sitos. Se usa pues para referirse a algo que es adecuado s√≥lo para un determinado fin o en una determinada situaci√≥n. Cuando hablamos de una metodolog√≠a de desarrollo de software Ad hoc se refiere a una metodolog√≠a particular para un determinado problema tomando en cuenta aspectos como el n√∫mero de desarrolladores, el objetivo a cumplir, entre otros. https://en.wikipedia.org/wiki/bullpen Cap√≠tulo 3. M√©todo de Desarrollo 85 Para el desarrollo particular de esta aplicaci√≥n se adecuo de manera tal que no se necesitar√≠a ning√∫n artefacto entregable y se manejar√≠a en base a prototipos funcionales o no cumpliendo los distintos objetivos plasmados para esa entrega. Dependiendo de los resultados obtenidos por cada prototipo se generar√°n nuevos objetivos o se eliminaran anteriores para el siguiente prototipo. Se manejan dos roles para este desarrollo. El rol de l√≠der, el cual se encarga de liderizar el desarrollo. Sus actividades principales son las de definir los objetivos, verificar los resultados de cada prototipo y estimar el tiempo de desarrollo de cada prototipo. El segundo rol es el de desarrollador, el cual se encarga de desarrollar valga la redundancia. Su actividad principal es la de completar los objetivos plasmados por el l√≠der. En la entrega de cada prototipo ambos roles pueden discutir sobre los objetivos siguientes o los anteriores, tomando en cuenta la opini√≥n de cada ente. En la siguiente figura se ejemplifica el ciclo de desarrollo de cada prototipo. Figura 19: Ciclo de la metodolog√≠a utilizada Analisis de Objetivos para el prototipo Preparaci√≥n de soluci√≥n Verificaci√≥n de resultados Despliegue del Prototipo Cap√≠tulo 3. M√©todo de Desarrollo 86 En la fase de an√°lisis los dos roles involucrados discuten sobre los objetivos a cumplir para el prototipo. En la siguiente fase el desarrollador ejecuta los objetivos planteados en la fase anterior, luego se verifican los resultados y se hace el despliegue del mismo. Las conclusiones obtenidas sirven para la fase de an√°lisis del siguiente prototipo. 87 4. Desarrollo de la Soluci√≥n Para el desarrollo de la aplicaci√≥n son necesarios dos ambientes, el primero es el cl√∫ster basado en Hadoop d√≥nde se ejecutaran los algoritmos MapReduce y el segundo es el ambiente de desarrollo como tal en el cual se ejecutar√° la aplicaci√≥n. En ambos es necesaria la instalaci√≥n de R debido a que en ese lenguaje se desarroll√≥ la aplicaci√≥n. En estos dos ambientes se tienen que configurar con las librer√≠as, herramientas y paquetes necesarios para el funcionamiento correcto de la aplicaci√≥n. A continuaci√≥n se listan en detalle las configuraciones necesarias que se realizaron para el desarrollo de la aplicaci√≥n. 4.1. Cl√∫ster En lo que se refiere al cl√∫ster basado en Hadoop s√≥lo se necesita la instalaci√≥n de R en cada nodo. 4.1.1. Instalaci√≥n de R Para la instalaci√≥n de R en cada nodo se siguen los siguientes pasos (ver anexo 1). Junto con R son necesarios dos paquetes junto con sus dependencias los cuales se listan a continuaci√≥n: 4.1.1.1. Instalaci√≥n de rmr Para la instalaci√≥n del paquete rmr en cada nodo primero se deben instalar sus dependencias y luego seguir los pasos que se reflejan en el anexo 1. 4.1.1.2. Instalaci√≥n de rhdfs Para la instalaci√≥n del paquete rhdfs en cada nodo primero se deben instalar sus dependencias y luego seguir los pasos que se reflejan en el anexo 1. Cap√≠tulo 4. Desarrollo de la Soluci√≥n 88 4.2. Ambiente de Desarrollo En lo que se refiere al ambiente de desarrollo de la aplicaci√≥n si son necesarias m√°s instalaciones en comparaci√≥n con el cl√∫ster. A continuaci√≥n se listan y se describen las mismas. 4.2.1. Instalaci√≥n de GTK+ Para poder crear widgets es necesaria la herramienta GTK+. Para ver el proceso de instalaci√≥n por favor v√©ase el anexo 2. Cabe resaltar que esta especificaci√≥n solamente aplica para sistemas operativos Linux, en sistemas operativos Windows no es necesaria debido a que se instala autom√°ticamente al instalar el paquete gWidgets2 en R. 4.2.2. Instalaci√≥n de R La instalaci√≥n de R es necesaria en el ambiente local en el anexo 3 se especifican los pasos a seguir para instalar el mismo. 4.2.2.1. Instalaci√≥n de R-Studio R-Studio es la interfaz gr√°fica para el desarrollo de proyectos en R. Su instalaci√≥n se especifica en el anexo 4. 4.2.2.2. Instalaci√≥n y actualizaci√≥n de paquetes A diferencia del cl√∫ster que s√≥lo necesita dos paquetes, en el ambiente de desarrollo se necesitan muchos m√°s. A continuaci√≥n se listan los paquetes necesarios instalados, la forma en la que se instal√≥ y la funci√≥n de cada uno: ÔÇ∑ gWidgets2: Se instala ejecutando el siguiente comando en una consola de R: install.packages('gWidgets2', dependencies = TRUE). V√©ase el capitulo dos para m√°s detalles del paquete. ÔÇ∑ RGtk2: Es un paquete en el lenguaje R para el desarrollo de interfaces gr√°ficas utilizando GTK. Se instala ejecutando el Cap√≠tulo 4. Desarrollo de la Soluci√≥n 89 siguiente comando en una consola de R: install.packages('RGtk2', dependencies = TRUE). ÔÇ∑ gWidgets2RGtk2: Es el puerto de conexi√≥n entre el API gWidgets2 hacia RGtk2. Se instala ejecutando el siguiente comando en una consola de R: install.packages('gWidgets2RGtk2', dependencies = TRUE). ÔÇ∑ FactoMineR: Es un paquete que contiene m√©todos para el an√°lisis exploratorio de datos, tales como los m√©todos de componentes principales y de clustering. Se instala ejecutando el siguiente comando en una consola de R: install.packages('FactoMineR', dependencies = TRUE). ÔÇ∑ kknn: Paquete que contiene el m√©todo k vecinos m√°s cercanos. Se instala ejecutando el siguiente comando en una consola de R: install.packages('kknn', dependencies = TRUE). ÔÇ∑ e1071: Paquete que contiene funciones para el an√°lisis de datos tales como: transformada de Fourier, fuzzy clustering, m√°quinas de vectores soporte, c√°lculo de camino m√°s corto, bagged clustering, clasificador naive Bayes, entre otros. Se instala ejecutando el siguiente comando en una consola de R: install.packages('e1071', dependencies = TRUE). ÔÇ∑ MASS: Contiene funciones y conjuntos de datos para su posterior an√°lisis. Se instala ejecutando el siguiente comando en una consola de R: install.packages('MASS', dependencies = TRUE). ÔÇ∑ class: Contiene varias funciones para la clasificaci√≥n. Se instala ejecutando el siguiente comando en una consola de R: install.packages('class', dependencies = TRUE). ÔÇ∑ rpart: Provee particionamiento recursivo para √°rboles de clasificaci√≥n, regresi√≥n y supervivencia .Se instala ejecutando el Cap√≠tulo 4. Desarrollo de la Soluci√≥n 90 siguiente comando en una consola de R: install.packages('rpart', dependencies = TRUE). ÔÇ∑ rpart.plot: Paquete para gr√°ficar los modelos generados con rpart. Se instala ejecutando el siguiente comando en una consola de R: install.packages('rpart.plot', dependencies = TRUE). ÔÇ∑ randomForest: Provee bosques aleatorios para la clasificaci√≥n y regresi√≥n. Se instala ejecutando el siguiente comando en una consola de R: install.packages('randomForest', dependencies = TRUE). ÔÇ∑ nnet: Software para redes neuronales con una sola capa oculta, y para los modelos multinomiales. Se instala ejecutando el siguiente comando en una consola de R: install.packages('nnet', dependencies = TRUE). 4.2.3. Instalaci√≥n de Openssh y sshpass Para la comunicaci√≥n entre el ambiente de desarrollo y el cl√∫ster es necesario utilizar el protocolo Secure Shell (SSH) el cual se obtiene instalando la aplicaci√≥n Openssh y sshpass como se ve en el anexo 5. Esta instalaci√≥n s√≥lo es v√°lida para los sistemas operativos basados en Linux debido a que estos programas son netos de estos sistemas. 4.3. Aplicaci√≥n Despu√©s de tener ambos ambientes completamente configurados se empez√≥ con el desarrollo de la aplicaci√≥n utilizando la metodolog√≠a previamente definida. Como se dijo anteriormente esta metodolog√≠a consist√≠a de la realizaci√≥n de prototipos funcionales o no utilizando el lenguaje de programaci√≥n R. A continuaci√≥n se listan todos los prototipos desarrollados con sus objetivos, resultados y conclusiones: Cap√≠tulo 4. Desarrollo de la Soluci√≥n 91 4.3.1. Prototipo 0 Este prototipo se bas√≥ en la exploraci√≥n de las herramientas que provee R y sus paquetes para la realizaci√≥n de widgets, por esto previo a trazar objetivos se realiz√≥ una exploraci√≥n a fondo del paquete gWidgets. Figura 20: Ejemplo de widget utilizando R con el paquete gWidgets Luego de realizar esta exploraci√≥n se procedi√≥ a la primera reuni√≥n con el fin de establecer los objetivos para el primer prototipo. 4.3.1.1. Objetivos 1. Crear una interfaz gr√°fica utilizando R y el paquete gWidgets 2. Ejecutar el m√©todo K medias sobre un conjunto de datos provenientes de un archivo con valores separados por coma. 3. Ejecutar el m√©todo An√°lisis de componentes principales sobre un conjunto de datos provenientes de un archivo con valores separados por coma. 4. Ejecutar el m√©todo de cl√∫ster jer√°rquico sobre un conjunto de datos provenientes de un archivo con valores separados por coma. 4.3.1.2. Resultados Para el primer objetivo se logro crear una interfaz sencilla con una barra de herramientas, un toolbar y tres secciones, una para cada m√©todo. En cada secci√≥n se requieren los par√°metros necesarios para cada m√©todo V√©anse las Figuras 21, 22 y 23. Cap√≠tulo 4. Desarrollo de la Soluci√≥n 92 Figura 21: Secci√≥n K-medias del Prototipo 0 Figura 22: Secci√≥n de An√°lisis de Componentes Principales del Prototipo 0 Cap√≠tulo 4. Desarrollo de la Soluci√≥n 93 Figura 23: Secci√≥n Cl√∫ster Jer√°rquico del Prototipo 0 Para el segundo objetivo se utilizaron funciones de R para realizar el an√°lisis. El resultado de la ejecuci√≥n del m√©todo se muestra por una consola de R como se ve en la Figura 24. Figura 24: Resultado del m√©todo K medias del prototipo 0 Cap√≠tulo 4. Desarrollo de la Soluci√≥n 94 Para el tercer objetivo al igual que en el objetivo anterior se imprime el resultado del modelo por una consola de R, v√©ase la figura 25, pero tambi√©n se muestra a trav√©s de otro widget el circulo de correlaciones y las distancias entre cada individuo, v√©ase la figura 26. Figura 25: Resultado An√°lisis de componentes Principales del Prototipo 0 Figura 26: Resultados gr√°ficos de An√°lisis de componentes principales del Prototipo 0 Para el cuarto y √∫ltimo objetivo solamente se imprime el dendograma resultante en un nuevo widget, v√©ase la figura 27. Cap√≠tulo 4. Desarrollo de la Soluci√≥n 95 Figura 27: Resultado Agrupamiento Jer√°rquico 4.3.1.3. Conclusiones Luego de entregar este prototipo se llegaron a las siguientes conclusiones: ÔÇ∑ Se deben mejorar las interfaces de usuario debido a que existieron muchos descontroles en los elementos. ÔÇ∑ Los resultados se deben ver en alg√∫n widget generado por la aplicaci√≥n. ÔÇ∑ El agrupamiento jer√°rquico no agrupa, s√≥lo muestra el dendograma. ÔÇ∑ Ser√≠a mejor tener una secci√≥n para la carga de datos solamente. Cap√≠tulo 4. Desarrollo de la Soluci√≥n 96 ÔÇ∑ No se hace referencia a la teor√≠a de grandes vol√∫menes de datos. 4.3.2. Prototipo 1 Tomando como premisa los resultados y las conclusiones del prototipo 0 se procedi√≥ a establecer los objetivos para a siguiente entrega bajo el nombre de Prototipo 1. 4.3.2.1. Objetivos 1. Mejorar la interfaz de usuario colocando iconos a los botones acorde a sus funcionalidades 2. Crear secci√≥n √∫nica para la carga de datos de entrada 3. Crear secci√≥n √∫nica para el an√°lisis exploratorio de datos 4. Crear secci√≥n √∫nica para el agrupamiento de datos 5. Crear secci√≥n √∫nica para los algoritmos de Big Data 6. Mostrar resultados de los m√©todos de manera gr√°fica 7. Ejecutar m√©todo K medias bajo el paradigma MapReduce 8. Establecer funcionalidad para determinar el K √≥ptimo para el m√©todo K medias 4.3.2.2. Resultados El primer objetivo se cumpli√≥ mejorando el marco de la aplicaci√≥n, v√©ase la figura 28. Cap√≠tulo 4. Desarrollo de la Soluci√≥n 97 Figura 28: Vista principal del prototipo 1 Los objetivos dos, tres, cuatro y cinco se ven representados en las siguientes im√°genes: Cap√≠tulo 4. Desarrollo de la Soluci√≥n 98 Figura 29: Secci√≥n de carga de datos del prototipo 1 Cap√≠tulo 4. Desarrollo de la Soluci√≥n 99 Figura 30: Secci√≥n de an√°lisis exploratorio de datos del prototipo 1 Cap√≠tulo 4. Desarrollo de la Soluci√≥n 100 Figura 31: Secci√≥n para el agrupamiento de datos del prototipo 1 Cap√≠tulo 4. Desarrollo de la Soluci√≥n 101 Figura 32: Secci√≥n de Big Data del prototipo 1 El objetivo seis se cumpli√≥ para todas las secciones como se muestra en las siguientes im√°genes: Cap√≠tulo 4. Desarrollo de la Soluci√≥n 102 Figura 33: Resultados gr√°ficos de la secci√≥n de exploraci√≥n de datos del prototipo 1 Figura 34: Resultados gr√°ficos del m√©todo K medias del prototipo 1 Cap√≠tulo 4. Desarrollo de la Soluci√≥n 103 Figura 35: Resultados gr√°ficos del m√©todo agrupamiento jer√°rquico del prototipo 1 Los objetivos siete y ocho no pudieron ser cumplidos por limitaciones de tiempo. 4.3.2.3. Conclusiones Luego de la entrega de este prototipo se lleg√≥ a estas conclusiones: ÔÇ∑ Es necesaria la ejecuci√≥n del algoritmo K medias MapReduce ÔÇ∑ Se debe mostrar gr√°fico con la agrupaci√≥n del m√©todo de agrupaci√≥n jer√°rquico Cap√≠tulo 4. Desarrollo de la Soluci√≥n 104 4.3.3. Prototipo 2 El prototipo 2 no tuvo muchos cambios con respecto al prototipo 1. A continuaci√≥n se listan los objetivos 4.3.3.1. Objetivos 1. Ejecutar el m√©todo K medias MapReduce a un conjunto de datos en el ambiente local. 4.3.3.2. Resultados El √∫nico objetivo que se traz√≥ se cumpli√≥ perfectamente c√≥mo se muestra en la siguiente figura que muestra los resultados obtenidos. Figura 36: Resultado K medias MapReduce del prototipo 2 El m√©todo K medias MapReduce utilizado se encuentra en el anexo 6. 4.3.3.3. Conclusiones Las conclusiones m√°s importantes tras el despliegue del prototipo 2 son: Cap√≠tulo 4. Desarrollo de la Soluci√≥n 105 ÔÇ∑ El prototipo tiene muy pocos m√©todos disponibles ÔÇ∑ Resulta engorroso tener que cambiar entre conjuntos de datos ÔÇ∑ No existe una visualizaci√≥n de datos previos a la carga 4.3.4. Prototipo 3 Tras las conclusiones obtenidas en el prototipo dos se empez√≥ a utilizar el paquete gWidgets2 en vez de gWidgets y tambi√©n se procedi√≥ a la generaci√≥n de los nuevos objetivos para el siguiente prototipo. 4.3.4.1. Objetivos Los objetivos principales fueron: 1. Incluir m√©todos de clasificaci√≥n en una nueva secci√≥n 2. Capacidad de crear conexiones de datos y acceder a ellas siempre 3. Crear los siguientes tipos de conexiones de datos: Archivos de tipo csv, archivos de tipo HDFS y muestra de archivos de tipo HDFS 4. Ver la estad√≠stica de los archivos de tipo csv antes de ser almacenados 5. Ver los datos antes de ser almacenados 6. Decidir que variable ser√° la variable destino para los m√©todos de clasificaci√≥n 7. Mostrar la lista de todas las conexiones creadas 8. Poder editar la lista de todas las conexiones creadas 9. Mostrar los m√©todos disponibles dependiendo que tipo de conexi√≥n se haya escogido 10. Poder mostrar la clasificaci√≥n del m√©todo agrupamiento jer√°rquico 4.3.4.2. Resultados El primer objetivo se ve reflejado en la siguiente figura en la cual se listan todos los m√©todos disponibles para la conexi√≥n seleccionada. Cap√≠tulo 4. Desarrollo de la Soluci√≥n 106 Figura 37: Secci√≥n modelo del prototipo 3 El objetivo n√∫mero dos se logr√≥ pero no de manera completa, se crean las conexiones y se pueden acceder a ellas siempre y cuando no se haya reiniciado la aplicaci√≥n, es decir, si la aplicaci√≥n se cierra con algunas conexiones las mismas no se podr√°n acceder cuando se inicie otra vez, se deben volver a crear. El objetivo n√∫mero tres se logr√≥ aunque los archivos de tipo HDFS y muestra HDFS son iguales a los archivos csv, esto debido s√≥lo para ilustrar Cap√≠tulo 4. Desarrollo de la Soluci√≥n 107 que la selecci√≥n de m√©todos disponibles dependiendo del tipo de conexi√≥n funciona. Figura 38: Secci√≥n para la creaci√≥n de conexiones del prototipo 3 Los objetivos cuatro, cinco y seis se ven en las siguientes figuras: Cap√≠tulo 4. Desarrollo de la Soluci√≥n 108 Figura 39: Resultado de carga previa al almacenamiento de conexiones en el prototipo 3 Cap√≠tulo 4. Desarrollo de la Soluci√≥n 109 Figura 40: Datos de una conexi√≥n del prototipo 3 El resultado de la realizaci√≥n del objetivo siete se muestra a continuaci√≥n: Cap√≠tulo 4. Desarrollo de la Soluci√≥n 110 Figura 41: Secci√≥n d√≥nde se muestran todas las conexiones disponibles del prototipo 3 El objetivo ocho no se cumpli√≥ y quedo rezagado para la siguiente entrega, mientras el objetivo nueve s√≠ como se muestra a continuaci√≥n: Cap√≠tulo 4. Desarrollo de la Soluci√≥n 111 Figura 42: M√©todos disponibles para las conexiones de tipo archivo csv del prototipo 3 Cap√≠tulo 4. Desarrollo de la Soluci√≥n 112 Figura 43: M√©todos disponibles para las conexiones de tipo archivo HDFS del prototipo 3 El objetivo diez se cumpli√≥ a cabalidad y se ve representado en la siguiente figura: Cap√≠tulo 4. Desarrollo de la Soluci√≥n 113 Figura 44: Resultado de clasificaci√≥n por el m√©todo de agrupamiento jer√°rquico 4.3.4.3. Conclusiones Las principales conclusiones son que para cada m√©todo sigue sin imprimir el resultado en la aplicaci√≥n, s√≥lo lo imprime en una consola de R. Adem√°s de esta tambi√©n se concluy√≥ lo siguiente: ÔÇ∑ La clasificaci√≥n y los modelos generados s√≥lo se tienen de manera visual, ser√≠a ideal poder descargarlos. 4.3.5. Prototipo 4 Cap√≠tulo 4. Desarrollo de la Soluci√≥n 114 El prototipo cuatro no tuvo muchas diferencias con respecto al tres. S√≥lo se incluy√≥ un nuevo tipo de conexi√≥n llamada datos de R el cual provee algunos conjuntos de datos para la utilizaci√≥n de la aplicaci√≥n. 4.3.5.1. Objetivos El √∫nico objetivo fue el de crear el nuevo tipo de conexi√≥n. 4.3.5.2. Resultados El √∫nico objetivo fue cumplido como se muestra en la siguiente imagen: Cap√≠tulo 4. Desarrollo de la Soluci√≥n 115 Figura 45: Secci√≥n crear nueva conexi√≥n del prototipo 4 4.3.5.3. Conclusiones Las conclusiones de este prototipo son las de terminar los objetivos que ha quedado pendiente. 4.3.6. Prototipo 5 En este prototipo se cumplieron varios de los objetivos anteriores que no se lograron los cuales se listan a continuaci√≥n: Cap√≠tulo 4. Desarrollo de la Soluci√≥n 116 4.3.6.1. Objetivos 1. Imprimir resultado de las clasificaciones y de los modelos en la aplicaci√≥n 2. Mostrar funcionalidad que grafique el n√∫mero √≥ptimo de grupos para el m√©todo K medias 3. Posibilidad de descargar los resultados obtenidos de cualquier m√©todo ya sea la clasificaci√≥n o el modelo predictivo generado. 4.3.6.2. Resultados El cumplimiento del objetivo uno se muestra en las siguientes figuras: Figura 46: Resultado del m√©todo K medias del prototipo 5 Cap√≠tulo 4. Desarrollo de la Soluci√≥n 117 Figura 47: Resultado del m√©todo Bosques Aleatorios del prototipo 5 El gr√°fico que muestra el n√∫mero de grupos √≥ptimos en cumplimiento con el objetivo dos se muestra a continuaci√≥n: Cap√≠tulo 4. Desarrollo de la Soluci√≥n 118 Figura 48: Gr√°fico del codo de jambu Por √∫ltimo en cumplimiento con el objetivo tres se cumple que por los m√©todos de clasificaci√≥n se descargue un archivo csv con la clasificaci√≥n obtenida y por los m√©todos predictivos el modelo generado para poder utilizarlo en otro conjunto de datos desde R. 4.3.6.3. Conclusiones Las conclusiones principales fueron: ÔÇ∑ Es necesario para la investigaci√≥n poder utilizar un cl√∫ster Hadoop por eso se debe programar el tipo de conexiones de archivos HDFS para ejecutar algoritmos en un cl√∫ster. Cap√≠tulo 4. Desarrollo de la Soluci√≥n 119 ÔÇ∑ Es indispensable poder tener conexiones constantes escribi√©ndolas en un archivo o en alg√∫n lugar de almacenamiento. ÔÇ∑ Tener s√≥lo un algoritmo MapReduce es muy poco 4.3.7. Prototipo 6 Todos los prototipos anteriores solamente eran un archivo, aunque seg√∫n las buenas pr√°cticas de programaci√≥n en R dicen que es mejor tener todo en un solo archivo a la hora de codificar resultaba muy engorroso por ende se decidi√≥ cambiar la estructura del proyecto en base a una jerarqu√≠a de archivos y otros cambios que se listan a continuaci√≥n: 4.3.7.1. Objetivos 1. Cambiar la estructura de archivos de la aplicaci√≥n de un archivo a varios m√≥dulos 2. Remover botones de m√°s 3. Crear un nuevo tipos de conexi√≥n, para Subir funciones MAP y funciones REDUCE 4. Guardar tipo de conexi√≥n en la cual se guarden las credenciales de acceso para conectarse a un cl√∫ster Hadoop 5. Crear secci√≥n para la ejecuci√≥n de las funciones MAP y REDUCE sobre un cl√∫ster Hadoop utilizando la funcionalidad del Hadoop Streaming 6. Mejorar secci√≥n donde se muestran las conexiones con la posibilidad de ver el detalle y eliminarlas 7. Colocar tooltips a algunas secciones de la aplicaci√≥n 8. Ejecutar el algoritmo K medias MapReduce sobre un cl√∫ster Hadoop 9. Colocar el algoritmo regresi√≥n log√≠stica MapReduce para ejecutarlo en un cl√∫ster Hadoop 4.3.7.2. Resultados Como se mencion√≥ de manera previo el proyecto de la aplicaci√≥n pas√≥ de ser un solo archivo a la siguiente estructura de archivos: Cap√≠tulo 4. Desarrollo de la Soluci√≥n 120 Figura 49: Jer√°rquia del proyecto ÔÇ∑ vars: Almacena un script que contiene la definici√≥n de todas las variables a utilizar ÔÇ∑ templates: Contiene los scripts necesarios para el dise√±o de las secciones de la aplicaci√≥n ÔÇ∑ scripts: Almacena de manera din√°mica los scripts que ser√°n enviados para la ejecuci√≥n en el cl√∫ster ÔÇ∑ handlers: Contiene los scripts que realizan la l√≥gica de negocio ÔÇ∑ functions: Contiene las funciones MAP y REDUCE que ser√°n ejecutadas en el cl√∫ster ÔÇ∑ conections: Contiene el archivo que funciona como almacenamiento de las conexiones de datos. La aplicaci√≥n se inicia ejecutando solamente el archivo main.R desde una consola de R. Los objetivos dos, tres, cuatro, cinco, seis y siete se cumplieron a cabalidad como se muestra en las figuras 50, 51, 52, 53, 54 y 55. Cap√≠tulo 4. Desarrollo de la Soluci√≥n 121 Figura 50: Vista principal del prototipo 6 Cap√≠tulo 4. Desarrollo de la Soluci√≥n 122 Figura 51: Funcionalidad de Subir funciones MAP y REDUCE del prototipo 6 Cap√≠tulo 4. Desarrollo de la Soluci√≥n 123 Figura 52: Funcionalidad para crear conexi√≥n de tipo Archivo HDFS Cap√≠tulo 4. Desarrollo de la Soluci√≥n 124 Figura 53: Secci√≥n para ejecutar funciones MAP y REDUCE sobre un cl√∫ster Hadoop Cap√≠tulo 4. Desarrollo de la Soluci√≥n 125 Figura 54: Secci√≥n que muestra las conexiones almacenadas del prototipo 6 Cap√≠tulo 4. Desarrollo de la Soluci√≥n 126 Figura 55: Ejemplo de tooltip en el prototipo 6 El resultado del objetivo ocho se muestra a continuaci√≥n: Cap√≠tulo 4. Desarrollo de la Soluci√≥n 127 Figura 56: Ejecuci√≥n del m√©todo K medias MapReduce Se incorpor√≥ el algoritmo Regresi√≥n Log√≠stica bajo el marco MapReduce como se muestra en la siguiente imagen. El m√©todo se encuentra en el anexo siete. Cap√≠tulo 4. Desarrollo de la Soluci√≥n 128 Figura 57: Ejecuci√≥n del m√©todo Regresi√≥n Log√≠stica MapReduce 4.3.7.3. Conclusiones Las conclusiones para este prototipo se especificaran el pr√≥ximo cap√≠tulo luego de verificar los resultados. 129 5. Conclusiones y Resultados 5.1. Resultados Se realizaron las siguientes pruebas con el fin de obtener los resultados pertinentes para as√≠ concluir la investigaci√≥n. Para realizar las pruebas se definieron las siguientes conexiones: 1) Conexi√≥n 1: a. Nombre: mtcars b. Tipo: Archivo csv c. Variable a predecir: Ninguna d. Variables a ignorar: Ninguna e. Estad√≠sticas por Variable: Figura 58: Estad√≠sticas de la Conexi√≥n 1 2) Conexi√≥n 2: a. Nombre: iris b. Tipo: Datos de R c. Variable a predecir: Species d. Variables a ignorar: Ninguna e. Porcentaje de muestreo: 70 f. Porcentaje de prueba: 30 g. Estad√≠sticas por Variable: Cap√≠tulo 5. Conclusiones y Resultados 130 Figura 59: Estad√≠sticas de la Conexi√≥n 2 3) Conexi√≥n 3: a. Nombre: hadoop b. Tipo: Archivo HDFS c. Usuario: pascual d. Contrase√±a: hadoop e. Dominio: 192.168.0.107 f. Puerto: 2222 g. Hadoop_cmd: /usr/lib/hadoop/bin/hadoop h. Hadoop_streaming: /usr/lib/hadoop-mapreduce/hadoop- streaming-2.4.0.2.1.1.0-385.jar i. Archivo: El mismo que se utiliz√≥ en la conexi√≥n 1 ya almacenado en HDFS 4) Conexi√≥n 4: a. Nombre: wordcount b. Funci√≥n MAP: La funci√≥n que se utiliz√≥ se puede ver en el anexo 8 c. Funci√≥n REDUCE: La funci√≥n que se utilizo se puede ver en el anexo 9 Luego de tener definidas las conexiones se procedi√≥ a probar las funcionalidades m√°s relevantes de la aplicaci√≥n. I. Componentes principales: Utilizando como entrada la Conexi√≥n 1, generando cinco componentes y graficando las componentes uno y dos se tuvieron los siguientes resultados: Cap√≠tulo 5. Conclusiones y Resultados 131 Figura 60: Resultado An√°lisis de Componentes Principales Cap√≠tulo 5. Conclusiones y Resultados 132 Figura 61: Resultado An√°lisis de Componentes Principales (Individuos) Cap√≠tulo 5. Conclusiones y Resultados 133 Figura 62: Resultados An√°lisis de Componentes Principales (Variables) II. K medias Utilizando la Conexi√≥n 1 con un n√∫mero de grupos igual a cuatro y un n√∫mero de iteraciones igual a diez se obtuvieron los siguientes resultados en el m√©todo de K medias disponible para las conexiones locales: Cap√≠tulo 5. Conclusiones y Resultados 134 Figura 63: Resultados del m√©todo K medias Cap√≠tulo 5. Conclusiones y Resultados 135 Figura 64: Diagrama de datos del m√©todo K medias Cap√≠tulo 5. Conclusiones y Resultados 136 Figura 65: Clasificaci√≥n despu√©s de aplicar el m√©todo K medias III. Agrupamiento Jer√°rquico Utilizando la Conexi√≥n 1 con un par√°metro de distancia igual a Euclidean y un par√°metro de aglomeraci√≥n igual a Ward.D se obtuvieron los siguientes resultados en el m√©todo de Agrupamiento Jer√°rquico: Cap√≠tulo 5. Conclusiones y Resultados 137 Figura 66: Resultado Agrupamiento Jer√°rquico Tomando un n√∫mero de grupos igual a cuatro se obtuvieron los siguientes resultados: Cap√≠tulo 5. Conclusiones y Resultados 138 Figura 67: Clasificaci√≥n del m√©todo Agrupamiento Jer√°rquico Cap√≠tulo 5. Conclusiones y Resultados 139 Figura 68: Clasificaci√≥n despu√©s de ejecutar el m√©todo Agrupamiento Jer√°rquico IV. K medias MapReduce Utilizando la Conexi√≥n 3 con un n√∫mero de grupos igual a cuatro y un n√∫mero de iteraciones igual a diez se obtuvieron los siguientes resultados en el m√©todo de K medias disponible para las conexiones que corren sobre un cl√∫ster Hadoop: Figura 69: Centros de grupos generados tras la ejecuci√≥n del m√©todo K medias MapReduce sobre un cl√∫ster Hadoop Cabe resaltar que el m√©todo tardo alrededor de sesenta minutos en dar el resultado. Cap√≠tulo 5. Conclusiones y Resultados 140 V. Bosques Aleatorios Utilizando la Conexi√≥n 2 como entrada al m√©todo de Bosques Aleatorios se obtuvieron los siguientes resultados: Figura 70: Resultado del m√©todo Bosques Aleatorios utilizando la conexi√≥n 2 VI. Regresi√≥n Log√≠stica MapReduce Utilizando la Conexi√≥n 3 con un n√∫mero de iteraciones igual a dos, un n√∫mero de dimensiones igual a diez y un par√°metro alpha igual a 0.05 se obtuvieron los siguientes resultados en el m√©todo de regresi√≥n log√≠stica disponible para las conexiones que corren sobre un cl√∫ster Hadoop: Figura 71: Resultado del m√©todo Regresi√≥n Log√≠stica utilizando la conexi√≥n 3 VII. Streaming Utilizando la conexi√≥n 3 junto con la conexi√≥n 4 como funciones map y reduce respectivamente y como par√°metro de entrada un archivo de texto se obtuvo el siguiente resultado: Palabra Repeticiones ¬°Ah 1 Cap√≠tulo 5. Conclusiones y Resultados 141 ¬°Feliz 1 ¬°Oh! 2 ¬øEres 1 ¬øPorqu√© 2 a 23 abandon√©. 1 Tabla 3: Primeros siete resultados del Hadoop Streaming S√≥lo se muestran los primeros siete resultados, esto debido a que la salida arrojo quinientas palabras. 5.2. Conclusiones Se logr√≥ desarrollar todos los objetivos planeados para el √∫ltimo prototipo junto con los objetivos espec√≠ficos de la investigaci√≥n. Se instal√≥ R en el cl√∫ster junto con los paquetes rmr2 y rhdfs. En el ambiente local tambi√©n se instal√≥ R junto con R Studio, GTK+, SSH y todos los paquetes necesarios que se definieron de manera previa. La aplicaci√≥n se program√≥ utilizando una metodolog√≠a propia basada en la entrega de prototipos con ning√∫n otro artefacto entregable m√°s que el prototipo como tal, esto debido a qu√© s√≥lo existi√≥ un desarrollador por lo cual ser√≠a muy engorroso generar artefactos de sincronizaci√≥n cuando no hab√≠a con quien sincronizarse. Se definieron siete casos de estudios para as√≠ probar las funcionalidades principales de la aplicaci√≥n. Los resultados fueron lo esperado aunque hubo ciertos problemas de rendimiento esto debido a que la aplicaci√≥n es muy propensa a la funcionalidad del cl√∫ster, es decir si el cl√∫ster es de bajo rendimiento la aplicaci√≥n se comportar√° de igual manera. El desarrollo de esta aplicaci√≥n fue todo un reto personal debido a que la programaci√≥n en R es orientada a scripts que resuelvan un solo problema no al desarrollo de aplicaciones, pero pese a esto se obtuvo una aplicaci√≥n Cap√≠tulo 5. Conclusiones y Resultados 142 potente que puede hacer an√°lisis de datos de manera local y remota incentivando as√≠ al desarrollo de nuevas investigaciones. Este trabajo de investigaci√≥n contribuye principalmente con la Escuela de Computaci√≥n de la Facultad de Ciencias de la Universidad Central de Venezuela, ya que esta aplicaci√≥n fue creada inicialmente para ser utilizada por los docentes y alumnos de la escuela. M√°s all√° de la UCV, esta aplicaci√≥n puede ser √∫til para todo aquel que desee explorar en el an√°lisis de grandes vol√∫menes de datos tambi√©n queda abierta para cualquier contribuci√≥n futura ya sea un nuevo trabajo de grado o simplemente alguna mejora. 5.3. Recomendaciones Tras las conclusiones obtenidas las recomendaciones basadas en esas conclusiones son las siguientes: ÔÇ∑ Incentivar m√°s las ciencias de datos con la apertura de m√°s materias en la Facultad de Ciencias ÔÇ∑ La programaci√≥n de interfaces en R son algo complicadas, por ende ser√≠a muy √∫til utilizar un lenguaje distinto para la realizaci√≥n de las interfaces y los c√°lculos en R ÔÇ∑ Investigar m√°s m√©todos de an√°lisis de datos basados en el marco MapReduce 5.4. Trabajos Futuros El principal trabajo de investigaci√≥n que puede desencadenar desde el presente es la mejora de las interfaces utilizando tecnolog√≠as como html, css y javascript junto con un lenguaje del lado del servidor que pueda conectarse con R como java o php. Tambi√©n se podr√≠an incluir m√°s m√©todos y/o m√≥dulos a este trabajo de investigaci√≥n. 143 Anexos Gu√≠a de instalaci√≥n de R, rmr y rhdfs Pasos para distribuciones de Linux basadas en Red Hat. 1. Actualizar los repositorios epel Se actualizan estos repositorios para futuras instalaciones de paquetes. Se utiliza el siguiente comando: sudo rpm -Uvh http://dl.fedoraproject.org/pub/epel/6/x86_64/epel- release-6-8.noarch.rpm 2. Instalar R Se instala R con el siguiente comando: sudo yum -y install git wget R 3. Instalar Rstudio Server Se descarga he instala con los siguientes comandos: wget http://download2.rstudio.org/rstudio-server-0.97.332-x86_64.rpm sudo yum install --nogpgcheck rstudio-server-0.97.332-x86_64.rpm 4. Instalar rmr2 Primero se descargan las dependencias con el siguiente comando install.packages( c('RJSONIO', 'itertools', 'digest', 'Rcpp', 'functional', 'plyr', 'stringr'), repos='http://cran.revolutionanalytics.com') install.packages( c('reshape2'), repos='http://cran.revolutionanalytics.com') Anexos 144 Se descarga e instala con los siguientes comandos: wget --no-check-certificate https://github.com/RevolutionAnalytics/rmr2/releases/download/3.3.1/r mr2_3.3.1.tar.gz sudo R CMD INSTALL rmr2_3.3.1.tar.gz 5. Instalar rhdfs Primero se deben resolver las dependencias que se listan a continuaci√≥n: a. export JAVA_HOME=/usr/lib/java/jdk-version b. export PATH=$PATH:$JAVA_HOME/bin c. export HADOOP_CMD=/usr/lib/hadoop/bin/hadoop d. En una consola de R instalar el paquete 'rJava' Luego ejecutar los siguientes comandos wget --no-check-certificate https://github.com/RevolutionAnalytics/rhdfs/blob/master/build/rhdfs_1. 0.8.tar.gz?raw=true sudo R CMD INSTALL rhdfs_1.0.8.tar.gz?raw=true Anexos 145 Gu√≠a de instalaci√≥n de gtk+ Se deben ejecutar las dos siguientes l√≠neas en distribuciones de Linux basadas en Red Hat: 1. yum groupinstall "Development Tools" 2. yum install gtk+-devel gtk2-devel Anexos 146 Gu√≠a de instalaci√≥n de R En distribuciones de Linux basadas en Red Hat: 1. sudo yum -y install git wget R Anexos 147 Gu√≠a de instalaci√≥n de R-Studio En distribuciones de Linux basadas en Red Hat: 1. wget http://download2.rstudio.org/rstudio-server-0.97.332- x86_64.rpm 2. sudo yum install --nogpgcheck rstudio-server-0.97.332-x86_64.rpm Anexos 148 Gu√≠a de instalaci√≥n Openssh y sshpass En distribuciones de Linux basadas en Red Hat: 1. yum ‚Äìy install openssh-server openssh-clients 2. yum install sshpass Anexos 149 Algoritmo de K-medias en MapReduce en R Sys.setenv(HADOOP_CMD="/usr/lib/hadoop/bin/hadoop") Sys.setenv(HADOOP_STREAMING="/usr/lib/hadoop-mapreduce/hadoop- streaming-2.4.0.2.1.1.0-385.jar") library(rhdfs) hdfs.init() library(rmr2) rmr.options(backend="hadoop") ## @knitr kmeans-signature kmeans.mr = function( P, num.clusters, num.iter, combine, in.memory.combine) { ## @knitr kmeans-dist.fun dist.fun = function(C, P) { apply( C, 1, function(x) colSums((t(P) - x)^2))} ## @knitr kmeans.map kmeans.map = function(., P) { nearest = { if(is.null(C)) sample( 1:num.clusters, nrow(P), replace = TRUE) else { D = dist.fun(C, P) nearest = max.col(-D)}} if(!(combine || in.memory.combine)) keyval(nearest, P) else keyval(nearest, cbind(1, P))} ## @knitr kmeans.reduce kmeans.reduce = { if (!(combine || in.memory.combine) ) function(., P) t(as.matrix(apply(P, 2, mean))) else function(k, P) keyval( k, t(as.matrix(apply(P, 2, sum))))} ## @knitr kmeans-main-1 Anexos 150 C = NULL for(i in 1:num.iter ) { C = values( from.dfs( mapreduce( P, map = kmeans.map, reduce = kmeans.reduce))) if(combine || in.memory.combine) C = C[, -1]/C[, 1] ## @knitr end # points(C, col = i + 1, pch = 19) ## @knitr kmeans-main-2 if(nrow(C) < num.clusters) { C = rbind( C, matrix( rnorm( (num.clusters - nrow(C)) * nrow(C)), ncol = nrow(C)) %*% C) }} C} testdata = data kmeans.mr(testdata, num.clusters = 3, num.iter = 10, combine = FALSE, in.memory.combine = FALSE) Disponible en [51] Anexos 151 Algoritmo de Regresi√≥n Log√≠stica en MapReduce en R Sys.setenv(HADOOP_CMD="/usr/lib/hadoop/bin/hadoop") Sys.setenv(HADOOP_STREAMING="/usr/lib/hadoop-mapreduce/hadoop- streaming-2.4.0.2.1.1.0-385.jar") library(rhdfs) hdfs.init() library(rmr2) rmr.options(backend="hadoop") logistic.regression = function(input, iterations, dims, alpha){ lr.map = function(., M) { Y = M[,1] X = M[,-1] keyval( 1, Y * X * g(-Y * as.numeric(X %*% t(plane)))) } lr.reduce = function(k, Z) keyval(k, t(as.matrix(apply(Z,2,sum)))) plane = t(rep(0, dims)) g = function(z) 1/(1 + exp(-z)) for (i in 1:iterations) { gradient = values( from.dfs( mapreduce( input, map = lr.map, reduce = lr.reduce, combine = T))) plane = plane + alpha * gradient } plane } testdata = data logistic.regression(testdata, 10, 10, 0.05) Disponible en [51] Anexos 152 Funci√≥n Map del algoritmo Wordcount en R #! /usr/bin/env Rscript # mapper.R - Wordcount program in R # script for Mapper (R-Hadoop integration) trimWhiteSpace <- function(line) gsub("(^ +)|( +$)", "", line) splitIntoWords <- function(line) unlist(strsplit(line, "[[:space:]]+")) ## **** could wo with a single readLines or in blocks con <- file("stdin", open = "r") while (length(line <- readLines(con, n = 1, warn = FALSE)) > 0) { line <- trimWhiteSpace(line) words <- splitIntoWords(line) ## **** can be done as cat(paste(words, "\t1\n", sep=""), sep="") for (w in words) cat(w, "\t1\n", sep="") } close(con) Anexos 153 Funci√≥n Reduce del algoritmo Wordcount en R #! /usr/bin/env Rscript # reducer.R - Wordcount program in R # script for Reducer (R-Hadoop integration) trimWhiteSpace <- function(line) gsub("(^ +)|( +$)", "", line) splitLine <- function(line) { val <- unlist(strsplit(line, "\t")) list(word = val[1], count = as.integer(val[2])) } env <- new.env(hash = TRUE) con <- file("stdin", open = "r") while (length(line <- readLines(con, n = 1, warn = FALSE)) > 0) { line <- trimWhiteSpace(line) split <- splitLine(line) word <- split$word count <- split$count if (exists(word, envir = env, inherits = FALSE)) { oldcount <- get(word, envir = env) assign(word, oldcount + count, envir = env) } else assign(word, count, envir = env) } close(con) for (w in ls(env, all = TRUE)) cat(w, "\t", get(w, envir = env), "\n", sep = "") 154 Bibliograf√≠a [1] Weka 3: Data Mining Software in Java [en l√≠nea]: documenting electronic sources on the Internet. s.f. [Fecha de consulta: 4 de septiembre 2015, 10:11 am] Disponible en < http://www.cs.waikato.ac.nz/ml/weka/ > [2] Weka (aprendizaje autom√°tico) [en √≠nea]: documenting electronic sources on the Internet. s.f. [Fecha de consulta: 4 de septiembre 2015, 10:15 am] Disponible en < https://es.wikipedia.org/wiki/Weka_(aprendizaje_autom%C3%A1tico) > [3] Rcommander a graphical interface for R [en l√≠nea]: documenting electronic sources on the Internet. 2013. [Fecha de consulta: 4 de septiembre 2015, 10:18 am] Disponible en < http://www.rcommander.com/ > [4] Rattle GUI [en l√≠nea]: documenting electronic sources on the Internet. 2015. [Fecha de consulta: 4 de septiembre 2015, 10:21 am] Disponible en < https://en.wikipedia.org/wiki/Rattle_GUI > [5] DHAR, V. Data Science and Prediction [en l√≠nea]: documenting electronic sources on the Internet. 2013 [Fecha de consulta: 5 de octubre 2014, 8:06 pm] Disponible en <http://cacm.acm.org/magazines/2013/12/169933-data-science-and- prediction/fulltext/ > [6] LEAK, J. The keyword in ‚ÄúData Science‚Äù is not Data, It is Science [en l√≠nea]: documenting electronic sources on the Internet. 2013 [Fecha de consulta: 5 de octubre de 2014, 8:06 pm] Disponible en <http://simplystatistics.org/2013/12/12/the-key-word-in-data-science-is-not- data-it-is-science/> [7] HERNANDEZ, J. Introducci√≥n a la Miner√≠a de Datos. Pearson Prentice Hall 2004. [8] WITTEN, I. Data Mining, Third Edition. Morgan Kauffman 2011. http://www.cs.waikato.ac.nz/ml/weka/ https://es.wikipedia.org/wiki/Weka_(aprendizaje_autom%C3%A1tico) http://www.rcommander.com/ https://en.wikipedia.org/wiki/Rattle_GUI http://cacm.acm.org/magazines/2013/12/169933-data-science-and-prediction/fulltext/ http://cacm.acm.org/magazines/2013/12/169933-data-science-and-prediction/fulltext/ http://simplystatistics.org/2013/12/12/the-key-word-in-data-science-is-not-data-it-is-science/ http://simplystatistics.org/2013/12/12/the-key-word-in-data-science-is-not-data-it-is-science/ Bibliograf√≠a 155 [9] An√°lisis de componentes principales [en l√≠nea]: documenting electronic sources on the Internet. s.f [Fecha de consulta: 17 de febrero de 2015, 8:05 pm] Disponible en < http://es.wikipedia.org/wiki/An%C3%A1lisis_de_componentes_principales> [10] Agrupamiento jer√°rquico [en l√≠nea]: documenting electronic sources on the Internet. s.f [Fecha de consulta: 17 de febrero de 2015, 8:52 pm] Disponible en < http://es.wikipedia.org/wiki/Agrupamiento_jer%C3%A1rquico> [11] Regresi√≥n Log√≠stica [en l√≠nea]: documenting electronic sources on the Internet. 2014 [Fecha de consulta: 4 de septiembre de 2015, 10:24 am] Disponible en < https://es.wikipedia.org/wiki/Regresi%C3%B3n_log%C3%ADstica > [12] Operating System [en l√≠nea]: documenting electronic sources on the Internet. 2015 [Fecha de consulta: 4 de septiembre de 2015, 10:27 am] Disponible en < https://en.wikipedia.org/wiki/Operating_system > [13] MARTINEZ, R. Sobre Linux [en l√≠nea]: documenting electronic sources on the Internet. 2014. [Fecha de consulta: 4 de septiembre de 2015, 10: 29 am] Disponible en < http://www.linux-es.org/sobre_linux > [14] The GTK+ Project [en l√≠nea]: documenting electronic sources on the Internet. 2015. [Fecha de consulta: 4 de septiembre de 2015, 10:32 am] Disponible en < http://www.gtk.org/ > [15] Secure Shell [en l√≠nea]: documenting electronic sources on the Internet. 2015. [Fecha de consulta: 4 de septiembre de 2015, 10:34 am] Disponible en < https://es.wikipedia.org/wiki/Secure_Shell > [16] VERZANI, J. gWidgets2-package [en l√≠nea]: documenting electronic sources on the Internet. s.f [Fecha de consulta: 4 de septiembre de 2015, 10:37 am] Disponible en < http://www.rdocumentation.org/packages/gWidgets2/functions/gWidgets2- package > http://es.wikipedia.org/wiki/An%C3%A1lisis_de_componentes_principales http://es.wikipedia.org/wiki/Agrupamiento_jer%C3%A1rquico https://es.wikipedia.org/wiki/Regresi%C3%B3n_log%C3%ADstica https://en.wikipedia.org/wiki/Operating_system http://www.linux-es.org/sobre_linux http://www.gtk.org/ https://es.wikipedia.org/wiki/Secure_Shell http://www.rdocumentation.org/packages/gWidgets2/functions/gWidgets2-package http://www.rdocumentation.org/packages/gWidgets2/functions/gWidgets2-package Bibliograf√≠a 156 [17] rmr-package [en l√≠nea]: documenting sources on the Internet. s.f [Fecha de consulta: 4 de septiembre de 2015, 10:39 am] Disponible en < http://www.rdocumentation.org/packages/rmr2/functions/rmr-package > [18] rhdfs [en l√≠nea]: documenting electronic sources on the Internet. s.f [Fecha de consulta: 4 de septiembre de 2015, 10:41 am] Disponible en < http://www.rdocumentation.org/packages/rhdfs/functions/rhdfs > [19] Hadoop Streaming [en l√≠nea]: documenting electronic sources on the Internet. 2013 [Fecha de consulta: 4 de septiembre de 2015, 10:43 am] Disponible en < http://hadoop.apache.org/docs/r1.2.1/streaming.html > [20] Cloudera vs Hortonworks vs MapR: Comparing Hadoop Distributions [en l√≠nea]: documenting electronic sources on the Internet. 2014 [Fecha de consulta: 4 de septiembre de 2015, 10:47 am] Disponible en: < http://www.experfy.com/blog/cloudera-vs-hortonworks-comparing-hadoop- distributions/ > [21] Manfiesto √Ågil [en l√≠nea]: documenting electronic sources on the Internet. 2015 [Fecha de consulta: 4 de septiembre de 2015, 10:50 am] Disponible en < https://es.wikipedia.org/wiki/Manifiesto_%C3%A1gil > [22] Desarrollo √°gil de software [en l√≠nea]: documenting electronic sources on the Internet. 2015 [Fecha de consulta: 4 de septiembre de 2015, 10:52 am] Disponible en < https://es.wikipedia.org/wiki/Desarrollo_%C3%A1gil_de_software > [23] Knn [en l√≠nea]: documenting electronic sources on the Internet. s.f [Fecha de consulta: 17 de febrero de 2015, 1:33 pm] Disponible en < http://es.wikipedia.org/wiki/Knn> [24] WHITE, T. Hadoop: The Definitive Guide, Third Edition. O‚ÄôReilly Media 2012 . [25] WARDEN, P. Big Data Glossary. O‚ÄôReilly Media 2011. [26] MINER, D. MapReduce Design Patterns. O‚ÄôReilly Media 2013. http://www.rdocumentation.org/packages/rmr2/functions/rmr-package http://www.rdocumentation.org/packages/rhdfs/functions/rhdfs http://hadoop.apache.org/docs/r1.2.1/streaming.html http://www.experfy.com/blog/cloudera-vs-hortonworks-comparing-hadoop-distributions/ http://www.experfy.com/blog/cloudera-vs-hortonworks-comparing-hadoop-distributions/ https://es.wikipedia.org/wiki/Manifiesto_%C3%A1gil https://es.wikipedia.org/wiki/Desarrollo_%C3%A1gil_de_software http://es.wikipedia.org/wiki/Knn Bibliograf√≠a 157 [27] ¬øQu√© es Big Data? [en l√≠nea]: documenting electronic sources on the Internet. 2012 [Fecha de consulta: 5 de octubre de 2014, 8:08 pm] Disponible en <http://www.ibm.com/developerworks/ssa/local/im/que-es-big-data/> [28] Hadoop YARN [en l√≠nea]: documenting electronic sources on the Internet. s.f [Fecha de consulta: 5 de octubre de 2014, 8:11 pm] Disponible en <http://hortonworks.com/hadoop/yarn/> [29] ROUSE, Margaret. Apache Hadoop YARN (Yet Another Resource Negotiator) [en l√≠nea]: documenting electronic sources on the Internet. s.f [Fecha de consulta: 5 de octubre de 2014, 8:12 pm] Disponible en <http://searchdatamanagement.techtarget.com/definition/Apache-Hadoop- YARN-Yet-Another-Resource-Negotiator> [30] Apache Hadoop NextGen MapReduce (YARN) [en l√≠nea]: documenting electronic sources on the Internet. 2014 [Fecha de consulta: 5 de octubre de 2014, 8:13 pm] Disponible en <http://hadoop.apache.org/docs/r2.3.0/hadoop-yarn/hadoop-yarn- site/YARN.html> [31] Apache Hive [en l√≠nea]: documenting electronic sources on the Internet. s.f [Fecha de consulta: 5 de octubre de 2014, 8:14 pm] Disponible en <http://hortonworks.com/hadoop/hive/> [32] amplab/shark [en l√≠nea]: documenting electronic sources on the Internet. s.f [Fecha de consulta: 5 de octubre de 2014, 8:19 pm] Disponible en <https://github.com/amplab/shark/wiki> [33] Apache Pig [en l√≠nea]: documenting electronic sources on the Internet. s.f [Fecha de consulta: 5 de octubre de 2014, 8:15 pm] Disponible en <http://hortonworks.com/hadoop/pig/> [34] Apache HCatalog [en l√≠nea]: documenting electronic sources on the Internet. s.f [Fecha de consulta: 16 de febrero de 2015, 9:34 pm] Disponible en <http://hortonworks.com/hadoop/hcatalog/> http://www.ibm.com/developerworks/ssa/local/im/que-es-big-data/ http://hortonworks.com/hadoop/yarn/ http://searchdatamanagement.techtarget.com/definition/Apache-Hadoop-YARN-Yet-Another-Resource-Negotiator http://searchdatamanagement.techtarget.com/definition/Apache-Hadoop-YARN-Yet-Another-Resource-Negotiator http://hadoop.apache.org/docs/r2.3.0/hadoop-yarn/hadoop-yarn-site/YARN.html http://hadoop.apache.org/docs/r2.3.0/hadoop-yarn/hadoop-yarn-site/YARN.html http://hortonworks.com/hadoop/hive/ https://github.com/amplab/shark/wiki http://hortonworks.com/hadoop/pig/ http://hortonworks.com/hadoop/hcatalog/ Bibliograf√≠a 158 [35] Apache Spark [en l√≠nea]: documenting electronic sources on the Internet. s.f [Fecha de consulta: 5 de octubre de 2014, 8:16 pm] Disponible en <http://hortonworks.com/hadoop/spark/> [36] METZ, C. (2013). Spark: Open Source Superstar Rewrites Future of Big Data [en l√≠nea]: documenting electronic sources on the Internet. 2013 [Fecha de consulta: 5 de octubre de 2014, 8:17 pm] Disponible en <http://www.wired.com/2013/06/yahoo-amazon-amplab-spark/all/> [37] Las 5 V¬¥s del Big Data [en l√≠nea]: documenting electronic sources on the Internet. 2014 [Fecha de consulta: 13 de noviembre de 2014, 10:38 pm] Disponible en <http://www.quanticsolutions.es/big-data/las-5-v-big-data/> [38] Apache Flume [en l√≠nea]: documenting electronic sources on the Internet. s.f [Fecha de consulta: 5 de octubre de 2014, 8:18 pm] Disponible en <http://hortonworks.com/hadoop/flume/> [39] cloudera/hue [en l√≠nea]: documenting electronic sources on the Internet. s.f [Fecha de consulta: 5 de octubre de 2014, 8:20 pm] Disponible en <https://github.com/cloudera/hue> [40] Apache ZooKeeper [en l√≠nea]: documenting electronic sources on the Internet. s.f [Fecha de consulta: 5 de octubre de 2014, 8:18 pm] Disponible en <http://hortonworks.com/hadoop/zookeeper/> [41] amplab/shark [en l√≠nea]: documenting electronic sources on the Internet. s.f [Fecha de consulta: 5 de octubre de 2014, 8:19 pm] Disponible en <https://github.com/amplab/shark/wiki> [42] Apache Sqoop [en l√≠nea]: documenting electronic sources on the Internet. s.f [Fecha de consulta: 16 de febrero de 2015, 10:06 pm] Disponible en <http://hortonworks.com/hadoop/hcatalog/> [43] M√°quinas de vectores de soporte [en l√≠nea]: documenting electronic sources on the Internet. s.f [Fecha de consulta: 17 de febrero de 2015, 2:35 pm] Disponible en <http://es.wikipedia.org/wiki/M%C3%A1quinas_de_vectores_de_soporte> [44] RODRIGUEZ, Oldemar. Aprendizaje Supervisado. Redes Neuronales, M√©todos de Consenso y Potenciaci√≥n [en l√≠nea]: documenting electronic sources on the Internet. s.f [Fecha de consulta: 17 de febrero de 2015, 7:15 pm] Disponible en http://hortonworks.com/hadoop/spark/ http://www.wired.com/2013/06/yahoo-amazon-amplab-spark/all/ http://www.quanticsolutions.es/big-data/las-5-v-big-data/ http://hortonworks.com/hadoop/flume/ https://github.com/cloudera/hue http://hortonworks.com/hadoop/zookeeper/ https://github.com/amplab/shark/wiki http://hortonworks.com/hadoop/hcatalog/ http://es.wikipedia.org/wiki/M%C3%A1quinas_de_vectores_de_soporte Bibliograf√≠a 159 <http://www.oldemarrodriguez.com/yahoo_site_admin/assets/docs/Presentaci %C3%B3n_-_Redes_-_Consenso_-_Potenciacion.293124147.pdf> [45] Random forest [en l√≠nea]: documenting electronic sources on the Internet. s.f [Fecha de consulta: 17 de febrero de 2015, 7:31 pm] Disponible en < http://es.wikipedia.org/wiki/Random_forest> [46] Red neuronal artificial [en l√≠nea]: documenting electronic sources on the Internet. s.f [Fecha de consulta: 17 de febrero de 2015, 7:53 pm] Disponible en < http://es.wikipedia.org/wiki/Red_neuronal_artificial> [47] An√°lisis de componentes principales [en l√≠nea]: documenting electronic sources on the Internet. s.f [Fecha de consulta: 17 de febrero de 2015, 8:05 pm] Disponible en < http://es.wikipedia.org/wiki/An%C3%A1lisis_de_componentes_principales> [48] RevolutionAnalytics/RHadoop [en l√≠nea]: documenting electronic sources on the Internet. s.f [Fecha de consulta: 21 de febrero de 2015, 5:58 pm] Disponible en < https://github.com/RevolutionAnalytics/RHadoop/wiki> [49] Scipy/Scipy [en l√≠nea]: documenting electronic sources on the Internet. s.f [Fecha de consulta: 21 de febrero de 2015, 6:15 pm] Disponible en <https://github.com/scipy/scipy> [50] Scipy/.org [en l√≠nea]: documenting electronic sources on the Internet. s.f [Fecha de consulta: 21 de febrero de 2015, 6:16 pm] Disponible en <http://www.scipy.org> [51] DEVLIN, H. Mapreduce in R [en l√≠nea]: documenting electronic sources on the Internet. 2014 [Fecha de consulta: 4 de septiembre de 2015, 10:59 am] Disponible en < https://github.com/RevolutionAnalytics/rmr2/blob/master/docs/tutorial.md > http://www.oldemarrodriguez.com/yahoo_site_admin/assets/docs/Presentaci%C3%B3n_-_Redes_-_Consenso_-_Potenciacion.293124147.pdf http://www.oldemarrodriguez.com/yahoo_site_admin/assets/docs/Presentaci%C3%B3n_-_Redes_-_Consenso_-_Potenciacion.293124147.pdf http://es.wikipedia.org/wiki/Random_forest http://es.wikipedia.org/wiki/Red_neuronal_artificial http://es.wikipedia.org/wiki/An%C3%A1lisis_de_componentes_principales https://github.com/RevolutionAnalytics/RHadoop/wiki https://github.com/scipy/scipy https://github.com/RevolutionAnalytics/rmr2/blob/master/docs/tutorial.mdUniversidad Central de Venezuela Facultad de Ciencias Escuela de Computaci√≥n Centro de Computaci√≥n Distribuida y Paralela Desarrollo de una interfaz gr√°fica en R para la ejecuci√≥n de m√©todos de miner√≠a de datos sobre plataformas Hadoop para Big Data. Trabajo Especial de Grado presentado ante la ilustre Universidad Central de Venezuela por el Br. Pascual Madrid Tutor: Prof. Jes√∫s Lares Prof. Jos√© Sosa Caracas, Octubre de 2015 ii ACTA Quienes suscriben, Miembros del Jurado designado por el Consejo de la Escuela de Computaci√≥n para examinar el Trabajo Especial de Grado, presentado por el Bachiller Pascual Madrid C.I.: 20.604.893, con el t√≠tulo: ‚ÄúDesarrollo de una interfaz gr√°fica en R para la ejecuci√≥n de m√©todos de miner√≠a de datos sobre plataformas Hadoop para Big Data‚Äù, a los fines de cumplir con el requisito legal para optar al t√≠tulo de Licenciado en Computaci√≥n, dejan constancia de lo siguiente: Le√≠do el trabajo por cada uno de los Miembros del Jurado, se fij√≥ el d√≠a 27 de octubre de 2015, a las 09:00am, para que su autor lo defendiera en forma p√∫blica, en la Sala III Postgrado de la Escuela de Computaci√≥n, Facultad de Ciencias de la Universidad Central de Venezuela, lo cual realiz√≥ mediante una exposici√≥n oral de su contenido, y luego respondi√≥ a las preguntas que le fueron formuladas por el Jurado, todo ello conforme a lo dispuesto en la Ley de Universidades y dem√°s normativas vigentes de la Universidad Central de Venezuela. Finalizada la defensa p√∫blica del Trabajo Especial de Grado, el jurado decidi√≥ aprobarlo con la nota de _________ puntos. En fe de lo cual se levanta la presente acta, en Caracas el 27 de octubre de 2015. _________________ _________________ Prof. Jos√© Sosa Prof. Jes√∫s Lares Tutor Tutor _________________ _________________ Prof. H√©ctor Navarro Prof. Fernando Crema Jurado Jurado iii Resumen El an√°lisis de grandes vol√∫menes de datos representa un gran reto para los cient√≠ficos de datos, ya sea desde un punto de vista intelectual y uno de recursos. No es sencillo realizar an√°lisis en plataformas de Big Data debido a que los scripts deben seguir un paradigma de programaci√≥n llamado MapReduce el cual resulta todo un reto hasta para las personas con mucha experiencia en la programaci√≥n sin contar lo costoso que es implementar toda una infraestructura que de soporte a la cantidad masiva de datos. La intenci√≥n de este trabajo de grado es la realizaci√≥n de una aplicaci√≥n que provea una interfaz gr√°fica para la ejecuci√≥n de m√©todos de miner√≠a de datos sobre una plataforma Hadoop de una manera remota sin tener que implementar m√©todos MapReduce ni tener que preparar una infraestructura Hadoop, s√≥lo utilizar una ya preparada previamente. La aplicaci√≥n fue programada utilizando el lenguaje de programaci√≥n estad√≠stico R utilizando una gran gama de paquetes para el desarrollo de la interfaz y de los c√°lculos. La comunicaci√≥n con la plataforma Hadoop se hace mediante el protocolo SSH (Secure Shell) permitiendo un tr√°fico de informaci√≥n de manera segura en todo momento. Se realizaron pruebas sencillas que englobaron todas las funcionalidades de la aplicaci√≥n. Este trabajo dej√≥ como fruto final una interfaz gr√°fica programada en R capaz de ejecutar m√©todos de miner√≠a de datos de manera local y remota sobre un cl√∫ster Hadoop y tambi√©n la posibilidad de ejecutar funciones Map y Reduce en un cl√∫ster Hadoop utilizando la funcionalidad llamada Hadoop Streaming. iv Agradecimientos Agradezco principalmente a Dios por permitirme hoy estar cumpliendo un sue√±o y por no dejarme s√≥lo en ning√∫n momento. A mi madre por todo el apoyo humano tan particular que me ha dado en toda mi vida. A mis hermanas Lucila Madrid, Carmen Ca√±as y a m√≠ cu√±ado Xavier Capelo por todo el apoyo que me han dado durante toda la carrera. A mis t√≠os Jaime Madrid, Hern√°n Valera y Antonio Valera, por sus orientaciones y todas las experiencias que han compartido conmigo toda mi vida. A Laura Gonz√°lez por brindarme todo su apoyo y cari√±o desde siempre. A Vicente Ordo√±ez, Juan Morantes y Gustavo Morantes por todo el apoyo que me han brindado y por compartir conmigo sus conocimientos y experiencias en el √°mbito acad√©mico y laboral. A Emily Corro, Daniel Hern√°ndez, Rafael Machado, √Ålvaro Marciales, Eduardo S√°nchez, Carlos Pereira y Claudio Torrez, por la amistad y hermandad que me han brindado por a√±os. Son pilares y s√≠mbolos de motivaci√≥n en muchos sentidos de mi vida. A todas aquellas personas que de una u otra manera me ayudaron durante el desarrollo de este Trabajo Especial de Grado. A mis tutores Jes√∫s Lares y Jos√© Sosa por el apoyo y confianza que han tenido en mi trabajo y por haberme guiado en el desarrollo de este Trabajo Especial de Grado. Igualmente al profesor Fernando Crema y al profesor H√©ctor Navarro por haberme ayudado a corregir los errores del TEG y haber sido un ejemplo de excelencia. Este trabajo especial de Grado est√° dedicado a Pascual Madrid Manzanilla, Pascual Madrid Araujo, Carmen Ver√≥nica Blanco y Pablo Padr√≥n v Tabla de contenidos ACTA ............................................................................................................... ii Resumen ........................................................................................................ iii Agradecimientos ............................................................................................. iv √çndice de figuras .............................................................................................. x √çndice de tablas ............................................................................................. xiii Introducci√≥n .................................................................................................. xiv 1. El Problema ........................................................................................... 16 1.1. Planteamiento del Problema .............................................................. 16 1.2. Justificaci√≥n ........................................................................................ 17 1.2.1. ¬øPor qu√© es un problema? .......................................................... 17 1.2.2. ¬øPara qui√©n es un problema? ...................................................... 17 1.2.3. ¬øDesde cu√°ndo es un problema? ................................................ 17 1.3. Objetivos de la investigaci√≥n .............................................................. 18 1.3.1. Objetivo General .......................................................................... 18 1.3.2. Objetivos Espec√≠ficos ................................................................... 18 1.4. Antecedentes ..................................................................................... 18 1.5. Alcance ............................................................................................... 20 2. Marco Conceptual .................................................................................. 22 2.1. Ciencia de Datos ................................................................................ 22 2.1.1. Miner√≠a de Datos ......................................................................... 22 2.1.1.1. Clustering .............................................................................. 23 2.1.1.1.1. K-medias......................................................................... 23 2.1.1.1.2. Clustering Jer√°rquico ...................................................... 25 2.1.1.1.3. An√°lisis de Componentes Principales ............................. 26 2.1.1.2. Clasificaci√≥n .......................................................................... 27 2.1.1.2.1. K vecinos m√°s cercanos ................................................. 27 2.1.1.2.2. An√°lisis discriminante ..................................................... 29 2.1.1.2.3. Maquinas vectoriales de soporte .................................... 29 Tabla de Contenidos vi 2.1.1.2.4. √Årbol de Decisi√≥n ............................................................ 32 2.1.1.2.5. Bosques Aleatorios ......................................................... 35 2.1.1.2.6. Redes Bayesianas .......................................................... 37 2.1.1.2.7. Redes Neuronales .......................................................... 38 2.1.1.2.8. Regresi√≥n Log√≠stica ........................................................ 39 2.1.2. Grandes Vol√∫menes de Datos ..................................................... 39 2.1.2.1. Las 5 V‚Äôs de Grandes Vol√∫menes de Datos .......................... 39 2.2. Sistema Operativo .............................................................................. 41 2.2.1. Tipos de Sistema Operativo ......................................................... 41 2.2.2. Linux ............................................................................................ 43 2.2.2.1. GTK+ ..................................................................................... 43 2.2.2.2. Secure Shell .......................................................................... 43 2.3. Lenguajes de Programaci√≥n ............................................................... 44 2.3.1. R .................................................................................................. 44 2.3.1.1. gWidgets2 ............................................................................. 44 2.3.1.2. RHadoop ............................................................................... 49 2.3.1.2.1. rmr2 ................................................................................ 50 2.3.1.2.2. rhdfs ................................................................................ 50 2.3.2. Java ............................................................................................. 50 2.3.3. Python .......................................................................................... 51 2.3.3.1. SciPy ..................................................................................... 51 2.4. Apache Hadoop .................................................................................. 51 2.4.1. Common ...................................................................................... 53 2.4.2. Hadoop Distributed File System (HDFS) ..................................... 53 2.4.2.1. Conceptos ............................................................................. 55 2.4.3. MapReduce ................................................................................. 57 2.4.3.1. Hadoop Streaming ................................................................ 60 2.4.4. YARN ........................................................................................... 62 2.4.5. Herramientas del Ecosistema Hadoop ......................................... 65 2.4.5.1. Hive ....................................................................................... 65 Tabla de Contenidos vii 2.4.5.2. Pig ......................................................................................... 66 2.4.5.3. HCatalog ............................................................................... 68 2.4.5.4. Apache Spark ........................................................................ 69 2.4.5.5. Apache Flume ....................................................................... 70 2.4.5.6. Hue ........................................................................................ 71 2.4.5.7. Apache ZooKeeper ............................................................... 72 2.4.5.8. Shark ..................................................................................... 75 2.4.5.9. Apache Sqoop ....................................................................... 76 2.4.6. Distribuciones Hadoop ................................................................. 77 2.4.6.1. MapR ..................................................................................... 77 2.4.6.2. Cloudera ................................................................................ 77 2.4.6.3. Hortonworks .......................................................................... 78 2.4.6.4 Comparaci√≥n entre Hortonworks y Cloudera ......................... 78 2.4.6.4.1. Similitudes ...................................................................... 78 2.4.6.4.2. Diferencias ...................................................................... 79 2.4.6.5. Comparaci√≥n general ............................................................ 80 3. M√©todo de Desarrollo ............................................................................ 82 3.1. Manifiesto √Ågil .................................................................................... 82 3.1.1. Principios del Manifiesto √Ågil ....................................................... 83 3.2. M√©todos √Ågiles ................................................................................... 83 3.2.1. Metodolog√≠a Ad Hoc orientada a prototipos ................................. 84 4. Desarrollo de la Soluci√≥n ....................................................................... 87 4.1. Cl√∫ster ................................................................................................ 87 4.1.1. Instalaci√≥n de R ........................................................................... 87 4.1.1.1. Instalaci√≥n de rmr .................................................................. 87 4.1.1.2. Instalaci√≥n de rhdfs ............................................................... 87 4.2. Ambiente de Desarrollo ...................................................................... 88 4.2.1. Instalaci√≥n de GTK+ .................................................................... 88 4.2.2. Instalaci√≥n de R ........................................................................... 88 4.2.2.1. Instalaci√≥n de R-Studio ......................................................... 88 Tabla de Contenidos viii 4.2.2.2. Instalaci√≥n y actualizaci√≥n de paquetes ................................ 88 4.2.3. Instalaci√≥n de Openssh y sshpass .............................................. 90 4.3. Aplicaci√≥n ........................................................................................... 90 4.3.1. Prototipo 0 ................................................................................... 91 4.3.1.1. Objetivos ............................................................................... 91 4.3.1.2. Resultados ............................................................................ 91 4.3.1.3. Conclusiones ......................................................................... 95 4.3.2. Prototipo 1 ................................................................................... 96 4.3.2.1. Objetivos ............................................................................... 96 4.3.2.2. Resultados ............................................................................ 96 4.3.2.3. Conclusiones ....................................................................... 103 4.3.3. Prototipo 2 ................................................................................. 104 4.3.3.1. Objetivos ............................................................................. 104 4.3.3.2. Resultados .......................................................................... 104 4.3.3.3. Conclusiones ....................................................................... 104 4.3.4. Prototipo 3 ................................................................................. 105 4.3.4.1. Objetivos ............................................................................. 105 4.3.4.2. Resultados .......................................................................... 105 4.3.4.3. Conclusiones ....................................................................... 113 4.3.5. Prototipo 4 ................................................................................. 113 4.3.5.1. Objetivos ............................................................................. 114 4.3.5.2. Resultados .......................................................................... 114 4.3.5.3. Conclusiones ....................................................................... 115 4.3.6. Prototipo 5 ................................................................................. 115 4.3.6.1. Objetivos ............................................................................. 116 4.3.6.2. Resultados .......................................................................... 116 4.3.6.3. Conclusiones ....................................................................... 118 4.3.7. Prototipo 6 ................................................................................. 119 4.3.7.1. Objetivos ............................................................................. 119 4.3.7.2. Resultados .......................................................................... 119 Tabla de Contenidos ix 4.3.7.3. Conclusiones ....................................................................... 128 5. Conclusiones y Resultados .................................................................. 129 5.1. Resultados ....................................................................................... 129 5.2. Conclusiones .................................................................................... 141 5.3. Recomendaciones ............................................................................ 142 5.4. Trabajos Futuros .............................................................................. 142 Anexos ........................................................................................................ 143 Gu√≠a de instalaci√≥n de R, rmr y rhdfs ...................................................... 143 Gu√≠a de instalaci√≥n de gtk+ ..................................................................... 145 Gu√≠a de instalaci√≥n de R ......................................................................... 146 Gu√≠a de instalaci√≥n de R-Studio .............................................................. 147 Gu√≠a de instalaci√≥n Openssh y sshpass ................................................. 148 Algoritmo de K-medias en MapReduce en R .......................................... 149 Algoritmo de Regresi√≥n Log√≠stica en MapReduce en R .......................... 151 Funci√≥n Map del algoritmo Wordcount en R ........................................... 152 Funci√≥n Reduce del algoritmo Wordcount en R ...................................... 153 Bibliograf√≠a .................................................................................................. 154 x √çndice de figuras Figura 1: Interfaz Gr√°fica de Weka (http://cs.calstatela.edu/wiki/index.php/Courses/CS_491ab/Winter_2009/Lala ntha_Sathkumara) ........................................................................................ 19 Figura 2: Interfaz gr√°fica Rcommander (http://uce.uniovi.es/CURSOICE/Informese2.html) ....................................... 19 Figura 3: Interfaz gr√°fica de Rattle ................................................................ 20 Figura 4: Ejemplo agrupaci√≥n K-medias ....................................................... 25 Figura 5: Ejemplo Agrupamiento jer√°rquico ascendente .............................. 26 Figura 6: Ejemplo K vecinos m√°s cercanos .................................................. 28 Figura 7: Ejemplo Maquinas vectoriales de Soporte ..................................... 30 Figura 8: Maquina vectorial de soporte de margen m√°ximo ......................... 31 Figura 9: Maquina vectorial de soporte de margen blando ........................... 31 Figura 10: Ejemplo √Årbol de Decisi√≥n ........................................................... 32 Figura 11: √Årbol Podado ............................................................................... 35 Figura 12: Ejemplo m√©todos de consenso .................................................... 35 Figura 13: Ejemplo Bosques Aleatorios ........................................................ 36 Figura 14: Ejemplo de ventana creada con el paquete gWidgets2 en R ...... 45 Figura 15: Arquitectura HDFS ....................................................................... 55 Figura 16: Ejemplo de MapReduce ............................................................... 57 Figura 17: Arquitectura YARN de Hortonworks............................................. 62 Figura 18: Proceso MapReduce YARN ........................................................ 64 Figura 19: Ciclo de la metodolog√≠a utilizada ................................................. 85 Figura 20: Ejemplo de widget utilizando R con el paquete gWidgets ............ 91 Figura 21: Secci√≥n K-medias del Prototipo 0 ................................................ 92 Figura 22: Secci√≥n de An√°lisis de Componentes Principales del Prototipo 0 92 Figura 23: Secci√≥n Cl√∫ster Jer√°rquico del Prototipo 0 .................................. 93 Figura 24: Resultado del m√©todo K medias del prototipo 0 .......................... 93 Figura 25: Resultado An√°lisis de componentes Principales del Prototipo 0 . 94 √çndice de Figuras xi Figura 26: Resultados gr√°ficos de An√°lisis de componentes principales del Prototipo 0 .................................................................................................... 94 Figura 27: Resultado Agrupamiento Jer√°rquico ............................................ 95 Figura 28: Vista principal del prototipo 1 ....................................................... 97 Figura 29: Secci√≥n de carga de datos del prototipo 1 ................................... 98 Figura 30: Secci√≥n de an√°lisis exploratorio de datos del prototipo 1 ............ 99 Figura 31: Secci√≥n para el agrupamiento de datos del prototipo 1 ............. 100 Figura 32: Secci√≥n de Big Data del prototipo 1 ........................................... 101 Figura 33: Resultados gr√°ficos de la secci√≥n de exploraci√≥n de datos del prototipo 1 ................................................................................................... 102 Figura 34: Resultados gr√°ficos del m√©todo K medias del prototipo 1 ......... 102 Figura 35: Resultados gr√°ficos del m√©todo agrupamiento jer√°rquico del prototipo 1 ................................................................................................... 103 Figura 36: Resultado K medias MapReduce del prototipo 2 ....................... 104 Figura 37: Secci√≥n modelo del prototipo 3 .................................................. 106 Figura 38: Secci√≥n para la creaci√≥n de conexiones del prototipo 3 ............ 107 Figura 39: Resultado de carga previa al almacenamiento de conexiones en el prototipo 3 ................................................................................................... 108 Figura 40: Datos de una conexi√≥n del prototipo 3 ....................................... 109 Figura 41: Secci√≥n d√≥nde se muestran todas las conexiones disponibles del prototipo 3 ................................................................................................... 110 Figura 42: M√©todos disponibles para las conexiones de tipo archivo csv del prototipo 3 ................................................................................................... 111 Figura 43: M√©todos disponibles para las conexiones de tipo archivo HDFS del prototipo 3 ............................................................................................. 112 Figura 44: Resultado de clasificaci√≥n por el m√©todo de agrupamiento jer√°rquico .................................................................................................... 113 Figura 45: Secci√≥n crear nueva conexi√≥n del prototipo 4 ........................... 115 Figura 46: Resultado del m√©todo K medias del prototipo 5 ........................ 116 Figura 47: Resultado del m√©todo Bosques Aleatorios del prototipo 5 ......... 117 Figura 48: Gr√°fico del codo de jambu ......................................................... 118 Figura 49: Jer√°rquia del proyecto ............................................................... 120 √çndice de Figuras xii Figura 50: Vista principal del prototipo 6 ..................................................... 121 Figura 51: Funcionalidad de Subir funci√≥n MAP del prototipo 6 ................. 122 Figura 52: Funcionalidad para crear conexi√≥n de tipo Archivo HDFS ......... 123 Figura 53: Secci√≥n para ejecutar funciones MAP y REDUCE sobre un cl√∫ster Hadoop ....................................................................................................... 124 Figura 54: Secci√≥n que muestra las conexiones almacenadas del prototipo 6 .................................................................................................................... 125 Figura 55: Ejemplo de tooltip en el prototipo 6 ............................................ 126 Figura 56: Ejecuci√≥n del m√©todo K medias MapReduce ............................ 127 Figura 57: Ejecuci√≥n del m√©todo Regresi√≥n Log√≠stica MapReduce ............ 128 Figura 58: Estad√≠sticas de la Conexi√≥n 1 .................................................... 129 Figura 59: Estadisticas de la Conexi√≥n 2 .................................................... 130 Figura 60: Resultado An√°lisis de Componentes Principales ....................... 131 Figura 61: Resultado An√°lisis de Componentes Principales (Individuos) ... 132 Figura 62: Resultados An√°lisis de Componentes Principales (Variables) ... 133 Figura 63: Resultados del m√©todo K medias .............................................. 134 Figura 64: Diagrama de datos del m√©todo K medias .................................. 135 Figura 65: Clasificaci√≥n despu√©s de aplicar el m√©todo K medias ............... 136 Figura 66: Resultado Agrupamiento Jer√°rquico .......................................... 137 Figura 67: Clasificaci√≥n del m√©todo Agrupamiento Jer√°rquico ................... 138 Figura 68: Clasificaci√≥n despu√©s de ejecutar el m√©todo Agrupamiento Jer√°rquico ................................................................................................... 139 Figura 69: Centros de grupos generados tras la ejecuci√≥n del m√©todo K medias MapReduce sobre un cl√∫ster Hadoop ............................................ 139 Figura 70: Resultado del m√©todo Bosques Aleatorios utilizando la conexi√≥n 2 .................................................................................................................... 140 Figura 71: Resultado del m√©todo Regresi√≥n Log√≠stica utilizando la conexi√≥n 3 .................................................................................................................... 140 xiii √çndice de tablas Tabla 1: Parametros de Hadoop Streaming .................................................. 62 Tabla 2: Comparaci√≥n de las principales distribuciones de Hadoop ............. 81 Tabla 3: Primeros siete resultados del Hadoop Streaming ......................... 141 xiv Introducci√≥n Actualmente vivimos en un mundo globalizado regido por la Internet y un sin fin de tecnolog√≠as basadas de igual manera en la Internet, sabemos que estamos en una √©poca en la que cada d√≠a se genera informaci√≥n, la cual muchas veces no nos enteramos que de verdad se haya generado. La mayor√≠a de esta informaci√≥n est√° no estructurada lo que implica que es indescifrable para el ojo com√∫n, debido a que oculta patrones que no se ven a simple vista, al descubrir estos patrones las empresas tendr√°n una gran ventaja en conocimiento sobre sus principales competidores. Todo lo planteado ha dado un gran impulso a una gran gama de oportunidades basadas en el conocimiento que se puede obtener a partir de todos esos datos generados diariamente. A ra√≠z de esto podr√≠an surgir una serie de interrogantes validas que describimos a continuaci√≥n: ÔÇ∑ ¬øC√≥mo hago para acceder de forma eficaz y eficiente a todos estos datos? ÔÇ∑ ¬øExiste alguna estructura o esquema de almacenamiento que permita mantener en el tiempo estos datos? ÔÇ∑ Una vez obtenido los datos ¬øC√≥mo los proceso eficientemente para obtener informaci√≥n relevante que permita optimizar el proceso de toma de decisiones dentro de la organizaci√≥n? La respuesta a todas estas interrogantes la tiene una tecnolog√≠a emergente llamada Big Data o Grandes Vol√∫menes de Datos, la cual se definir√° en el contenido de la investigaci√≥n. El trabajo de investigaci√≥n se divide en cinco cap√≠tulos. En el primer cap√≠tulo se describe el problema a solucionar. Se plantea el problema, su justificaci√≥n, los objetivos y el alcance de la misma. En el segundo cap√≠tulo se definen las bases te√≥ricas de la investigaci√≥n. Se define lo que es ciencia de datos, miner√≠a de datos, grandes vol√∫menes de datos la herramienta Apache Hadoop, el lenguaje de programaci√≥n estad√≠stico R, entre otras definiciones. En el tercer cap√≠tulo se define la metodolog√≠a de desarrollo utilizada para la aplicaci√≥n que da respuesta al problema de investigaci√≥n. Introducci√≥n xv En el cuarto cap√≠tulo se describe en detalle el proceso de desarrollo de la aplicaci√≥n y finalmente en el quinto cap√≠tulo se describen los resultados y las conclusiones obtenidas. 16 1. El Problema 1.1. Planteamiento del Problema En la Escuela de Computaci√≥n de la Universidad Central de Venezuela ha surgido la iniciativa de incursionar en el mundo de la ciencia de datos realizando investigaciones y proyectos relacionados con el an√°lisis de datos complejos y/o masivos. Para realizar estos proyectos se necesita un cl√∫ster de computadores, espec√≠ficamente un cl√∫ster basado en Apache Hadoop, tener acceso al mismo y escribir m√©todos para realizar los an√°lisis sobre el cl√∫ster. No siempre se tiene acceso a un cl√∫ster de manera directa pero para dar los primeros pasos las 3 grandes compa√±√≠as especializadas en el procesamiento de grandes vol√∫menes de datos (Cloudera, Hortonworks y MapR) ofrecen instalaciones de pruebas llamadas ‚ÄúSandBox‚Äù. Pero estas instalaciones no tienen la capacidad de hacer an√°lisis de envergadura debido a que se encuentran en la maquina local. Sin embargo se pueden hacer an√°lisis de envergadura sobre un cl√∫ster remoto si se encuentra en alg√∫n centro dedicado siempre y cuando se tenga acceso al mismo. La mejor manera para conectarse a un cl√∫ster remoto es utilizando el protocolo SSH (Secure Shell), pero no todos los interesados en utilizar el cl√∫ster conocen los pasos para realizar una conexi√≥n. Para realizar un an√°lisis en un cl√∫ster remoto se deben seguir los siguientes pasos: 1) Generar los scripts y los datos de entrada de manera local 2) Enviar los archivos generados al cl√∫ster 3) Establecer una conexi√≥n dedicada 4) Ejecutar los scripts 5) Visualizar el resultado. Cap√≠tulo 1. El Problema 17 Esos scripts deben seguir el paradigma de programaci√≥n MapReduce lo cual resulta muy complejo para cualquier analista debido a que deben cambiar cualquier soluci√≥n v√°lida a este paradigma para que pueda funcionar en el cl√∫ster. Por todo lo anterior ser√≠a de gran utilidad la creaci√≥n de una aplicaci√≥n que brinde una interfaz gr√°fica que provea la funcionalidad de conectarse a un cl√∫ster Apache Hadoop y realizar an√°lisis de datos complejos abstrayendo a los usuarios finales de los pasos de conexi√≥n remota y del desarrollo de complejos scripts MapReduce utilizando m√©todos previamente validados por otros analistas con mayores conocimientos en el paradigma MapReduce. 1.2. Justificaci√≥n 1.2.1. ¬øPor qu√© es un problema? Es un problema porque resulta muy engorroso realizar los pasos para la conexi√≥n remota a un cl√∫ster Apache Hadoop y la realizaci√≥n de scripts MapReduce v√°lidos. 1.2.2. ¬øPara qui√©n es un problema? Es un problema para cualquier persona que desee incursionar en el mundo de la ciencia de datos y no posea los conocimientos necesarios para la realizaci√≥n de los pasos previos para una conexi√≥n remota ni la pericia para desarrollar scripts en el paradigma MapReduce. 1.2.3. ¬øDesde cu√°ndo es un problema? A grandes rasgos es un problema desde que se desea realizar un an√°lisis de datos teniendo acceso a un cluster pero sin saber c√≥mo acceder al mismo ni como realizar scripts MapReduce. Cap√≠tulo 1. El Problema 18 1.3. Objetivos de la investigaci√≥n 1.3.1. Objetivo General Desarrollar una aplicaci√≥n capaz de ejecutar algoritmos de miner√≠a de datos en un cluster Apache Hadoop para hacer an√°lisis de datos accediendo al mismo de manera remota y mostrando los resultados de manera local. 1.3.2. Objetivos Espec√≠ficos a) Realizar las instalaciones necesarias en el ambiente de desarrollo local y en el cluster de prueba. b) Programar la aplicaci√≥n. c) Definir casos de estudio para las pruebas integradas de la aplicaci√≥n. d) Visualizar los resultados obtenidos. 1.4. Antecedentes No conocemos antecedentes de una aplicaci√≥n capaz de ejecutar algoritmos MapReduce de manera remota en un cl√∫ster Apache Hadoop pero si conocemos antecedentes de aplicaciones que ejecutan modelos de miner√≠a de datos, las cuales sirvieron de inspiraci√≥n para el desarrollo de esta investigaci√≥n. a) Weka: Weka es una colecci√≥n de algoritmos de aprendizaje autom√°tico para tareas de miner√≠a de datos [1]. Contiene tambi√©n una colecci√≥n de herramientas de visualizaci√≥n unidas a una interfaz gr√°fica de usuario para acceder f√°cilmente a sus funcionalidades. Las √∫ltimas versiones de Weka fueron implementadas en Java [2]. Cap√≠tulo 1. El Problema 19 Figura 1: Interfaz Gr√°fica de Weka (http://cs.calstatela.edu/wiki/index.php/Courses/CS_491ab/Winter_2009/Lalantha_Sathkumara) b) Rcommander: Rcommander es una interfaz gr√°fica para el uso de las funcionalidades que proporciona el lenguaje de programaci√≥n R. R proporciona un sistema potente para el an√°lisis de datos y cuando se utiliza con RCommander proporciona una interfaz gr√°fica que es f√°cil e intuitiva de usar [3]. Figura 2: Interfaz gr√°fica Rcommander (http://uce.uniovi.es/CURSOICE/Informese2.html) Cap√≠tulo 1. El Problema 20 c) Rattle: Rattle es una interfaz gr√°fica para la miner√≠a de datos utilizando el lenguaje de programaci√≥n R. Rattle proporciona funcionalidades de miner√≠a de datos exponiendo considerablemente el poder R a trav√©s de una interfaz gr√°fica de usuario. Rattle se puede utilizar para el an√°lisis estad√≠stico, o la generaci√≥n de modelos [4]. Figura 3: Interfaz gr√°fica de Rattle Rattle es la aplicaci√≥n que m√°s ha inspirado el desarrollo de esta investigaci√≥n debido a que se program√≥ utilizando las mismas herramientas de desarrollo. 1.5. Alcance Esta aplicaci√≥n va dirigida a todas las personas que est√©n interesadas en incursionar en el mundo de la ciencia de datos. La aplicaci√≥n cuenta con Cap√≠tulo 1. El Problema 21 una interfaz sencilla que contempla a grandes rasgos las siguientes funcionalidades: a) Crear conexiones de datos b) Verificar las conexiones creadas c) Realizar an√°lisis exploratorio a las conexiones creadas d) Realizar clustering de datos a las conexiones creadas de manera local y en un cluster Apache Hadoop e) Aplicaci√≥n de modelos de miner√≠a de datos a las conexiones creadas de manera local y en un cluster Apache Hadoop f) Ejecuci√≥n de funciones map y reduce en un cluster Apache Hadoop 22 2. Marco Conceptual 2.1. Ciencia de Datos La Ciencia de Datos (Data Science) es el estudio de la extracci√≥n de conocimiento generalizable a partir de datos. El t√©rmino ‚ÄúCiencia‚Äù implica conocimiento ganado a trav√©s de un estudio sistem√°tico. En una definici√≥n la Ciencia de Datos, es una empresa sistem√°tica que construye y organiza conocimiento en forma de explicaciones comprobables y predicciones [5]. La Ciencia de Datos solamente es √∫til cuando se utilizan los datos para responder una pregunta [6]. 2.1.1. Miner√≠a de Datos Es el proceso de extraer conocimiento √∫til y comprensible, previamente desconocido, desde grandes cantidades de datos almacenados en distintos formatos. Es decir, la tarea fundamental de la miner√≠a de datos es encontrar modelos inteligibles a partir de los datos. Para que este proceso sea efectivo deber√≠a ser autom√°tico o semi-autom√°tico (asistido) y el uso de los patrones descubiertos deber√≠a ayudar a tomar decisiones m√°s seguras que reporten, por tanto, alg√∫n beneficio a la organizaci√≥n [7]. Por lo tanto, dos son los retos de la miner√≠a de datos: por un lado, trabajar con grandes vol√∫menes de datos, procedentes mayoritariamente de sistemas de informaci√≥n, con los problemas que ello conlleva (ruido, datos ausentes, intratabilidad, volatilidad de los datos‚Ä¶), y por el otro usar t√©cnicas adecuadas para analizar los mismos y extraer conocimiento novedoso y √∫til [7]. Otro concepto: La Miner√≠a de Datos es un t√≥pico que involucra el aprendizaje en un sentido pr√°ctico. Se interesa en t√©cnicas para encontrar y describir patrones estructurales en los datos, como una herramienta para ayudar a explicar los datos y hacer predicciones a partir de los mismos. Aunque la salida de un proceso de miner√≠a de datos no siempre es una predicci√≥n, tambi√©n puede ser una descripci√≥n actual de una estructura la cual puede ser utilizada para clasificar ejemplos desconocidos [8]. Cap√≠tulo 2. Marco Conceptual 23 La miner√≠a de datos tiene como objetivo analizar los datos para extraer conocimiento. Este conocimiento puede ser en forma de relaciones, patrones o reglas inferidos de los datos y (previamente) desconocidos, o bien en forma de una descripci√≥n m√°s concisa (es decir, un resumen de los mismos). Estas relaciones o res√∫menes constituyen el modelo de los datos analizados. Existen muchas formas de representar los modelos y cada una de ellas determina el tipo de t√©cnica que puede usarse para inferirlos. En la pr√°ctica, los modelos pueden ser de dos tipos: predictivos o de clasificaci√≥n y descriptivos o de Clustering [7]. 2.1.1.1. Clustering Los modelos descriptivos o de Clustering identifican patrones que explican o resumen los datos, es decir, sirven para explorar las propiedades de los datos examinados, no para predecir nuevos datos. Por ejemplo una agencia de viaje desea identificar grupos de personas con unos mismos gustos, con el objeto de organizar diferentes ofertas para cada grupo y poder as√≠ remitirles esta informaci√≥n; para ello analiza los viajes que han realizado sus clientes e infiere un modelo descriptivo que caracteriza estos grupos [7]. 2.1.1.1.1. K-medias El algoritmo de K medias (del ingl√©s Kmeans) se trata de un m√©todo de agrupamiento por vecindad en el que se parte de un n√∫mero determinado de prototipos y de un conjunto de ejemplos a agrupar, sin etiquetar. Es el m√©todo m√°s popular de los m√©todos de agrupamiento denominados ‚Äúpor partici√≥n‚Äù, en contraposici√≥n de los m√©todos jer√°rquicos. La idea del K medias es situar a los prototipos o centros en el espacio, de forma que los datos pertenecientes al mismo prototipo tengan caracter√≠sticas similares [7]. Las regiones se definen minimizando la suma de las distancias cuadr√°ticas entre cada vector de entrada y el centro de su correspondiente clase, representado por el prototipo correspondiente. Cuando se inicia el algoritmo, se debe seleccionar arbitrariamente una partici√≥n inicial de forma que cada clase disponga de, al menos, un ejemplo. Como la totalidad de los datos est√°n disponibles, los centros de cada partici√≥n se calculan como la media de los ejemplos pertenecientes a esa clase. A medida que el algoritmo se va ejecutando, algunos ejemplos cambian de una clase a otra debiendo Cap√≠tulo 2. Marco Conceptual 24 recalcularse los centros a cada paso, o sea, desplazar convenientemente los prototipos. [7] El procedimiento es el siguiente: ÔÇ∑ Se calcula para cada ejemplo ùë•ùëò, el prototipo m√°s pr√≥ximo ùê¥ùëî y se incluye en la lista de ejemplos de dicho prototipo ÔÇ∑ Despu√©s de haber introducido todos los ejemplos, cada prototipo ùê¥ùëò tendr√° un conjunto de ejemplos a los que representa ÔÇ∑ Se desplaza el prototipo hacia el centro de masas de su conjunto de ejemplos ÔÇ∑ Se repite el procedimiento hasta que ya no se desplacen los prototipos. Mediante este algoritmo el espacio de ejemplos de entrada se divide en k clases o regiones, y el prototipo de cada clase estar√° en el centro de la misma. Dichos centros se determinan con el objetivo de minimizar las distancias cuadr√°ticas eucl√≠deas entre los patrones de entrada y el centro m√°s cercano. [7] Cap√≠tulo 2. Marco Conceptual 25 Figura 4: Ejemplo agrupaci√≥n K-medias 2.1.1.1.2. Clustering Jer√°rquico En miner√≠a de datos, el agrupamiento jer√°rquico es un m√©todo de an√°lisis de grupos el cual busca construir una jerarqu√≠a de grupos. Estrategias para agrupamiento jer√°rquico generalmente caen en dos tipos [10]: ÔÇ∑ Aglomerativas: Este es un agrupamiento ascendente. Cada observaci√≥n comienza en su propio grupo, y los pares de grupos son mezclados mientras uno sube en la jerarqu√≠a. ÔÇ∑ Divisivas: Este es un agrupamiento descendente. Todas las observaciones comienzan en un grupo, y se realizan divisiones mientras uno baja en la jerarqu√≠a. En general, las mezclas y divisiones son determinadas de forma golosa. Los resultados del agrupamiento jer√°rquico son usualmente presentados en un dendograma. [10] Cap√≠tulo 2. Marco Conceptual 26 En orden de decidir cuales grupos deber√≠an ser combinados (para aglomerativo), o cuando un grupo deber√≠a der dividido (para divisivo), una medida de disimilitud entre conjuntos de observaciones es requerida. En la mayor√≠a de los m√©todos de agrupamiento jer√°rquico, esto es logrado mediante el uso de una m√©trica apropiada (una medida de distancia entre pares de observaciones), y un criterio de enlace el cual especifica la disimilitud de conjuntos como una funci√≥n de las distancias dos a dos entre observaciones en los conjuntos. [10] Figura 5: Ejemplo Agrupamiento jer√°rquico ascendente 2.1.1.1.3. An√°lisis de Componentes Principales En estad√≠stica, el an√°lisis de componentes principales (en espa√±ol ACP, en ingl√©s, PCA) es una t√©cnica utilizada para reducir la dimensionalidad de un conjunto de datos. Intuitivamente la t√©cnica sirve para hallar las causas de la variabilidad de un conjunto de datos y ordenarlos por importancia. Cap√≠tulo 2. Marco Conceptual 27 T√©cnicamente, el ACP busca la proyecci√≥n seg√∫n la cual los datos queden mejor representados en t√©rminos de m√≠nimos cuadrados. El ACP se emplea sobre todo en el an√°lisis exploratorio de datos y para construir modelos predictivos. El ACP comporta el c√°lculo de la descomposici√≥n en autovalores de la matriz de covarianza, normalmente tras centrar los datos en la medida de cada atributo [9]. El ACP construye una transformaci√≥n lineal que escoge un nuevo sistema de coordenadas para el conjunto original de datos en el cual la varianza de mayor tama√±o del conjunto de datos es capturada en el primer eje (llamado el Primer Componente Principal), la segunda varianza m√°s grande es el segundo eje, y as√≠ sucesivamente. Para construir esta transformaci√≥n lineal debe construirse primero la matriz de covarianza o matriz de coeficientes de correlaci√≥n. Debido a la simetr√≠a de esta matriz existe una base completa de vectores propios de la misma. La transformaci√≥n que lleva de las antiguas coordenadas a las coordenadas de la nueva base es precisamente la transformaci√≥n lineal necesaria para reducir la dimensionalidad de datos. 2.1.1.2. Clasificaci√≥n Los modelos predictivos o de Clasificaci√≥n pretenden estimar valores futuros o desconocidos de variables de inter√©s, que se denominan como variables objetivo o dependientes, usando otras variables o campos de la base de datos (o cualquier otra fuente), a las que se refieren como variables independientes o predictivas. Por ejemplo, un modelo predictivo ser√≠a aquel que permite estimar la demanda de un nuevo producto en funci√≥n del gasto en publicidad [7]. 2.1.1.2.1. K vecinos m√°s cercanos Es un m√©todo de clasificaci√≥n supervisada que sirve para estimar la funci√≥n de densidad F(x/Cj) de las predictoras x por cada clase Cj.[23] En este m√©todo se determina para cada regi√≥n del espacio la probabilidad de que un elemento que est√© situado en ella pertenezca a cada una de las clases existentes. En este caso no hay reglas prefijadas, sino que la clasificaci√≥n se ir√° haciendo para cada caso nuevo en particular. Cuando Cap√≠tulo 2. Marco Conceptual 28 un caso nuevo aparece, se genera un c√≠rculo con centro en dicho punto y un radio prefijado como par√°metro del sistema en el cual se encuentran los k ejemplos m√°s cercanos al nuevo elemento. Se etiqueta al nuevo caso como perteneciente a la clase m√°s numerosa dentro del c√≠rculo.[7] En la Figura 6 se aprecia c√≥mo en un primer caso con k igual a cuatro, dentro del c√≠rculo hay tres ejemplos de la clase A y uno de la clase B, luego el nuevo dato se etiqueta como perteneciente a la clase A. En la Figura tambi√©n se aprecia que el k elegido influye en la clasificaci√≥n. Si se aumenta o disminuye el k, la predicci√≥n realizada puede variar. Por lo tanto, el k ser√° un par√°metro cr√≠tico a tener en cuenta. Tambi√©n las predicciones pueden variar si se var√≠a la funci√≥n de distancia. Figura 6: Ejemplo K vecinos m√°s cercanos El m√©todo espera hasta la aparici√≥n de un nuevo dato a clasificar para la utilizaci√≥n del conjunto de ejemplos. Cuando el dato est√° disponible se recurre a los ejemplos para realizar la clasificaci√≥n, se crea una regla local al dato que acaba de llegar, se realiza la clasificaci√≥n, y se abandona dicha regla. Si ahora hubiera que clasificar otro dato m√°s, los c√°lculos realizados para la clasificaci√≥n del dato anterior ser√≠an inservibles y habr√≠a que realizar de nuevo todo el proceso. Este es un t√≠pico ejemplo de aprendizaje retardado. En este caso hay que almacenar los ejemplos de entrenamiento siempre, ya que son utilizados una y otra vez. [7] Cap√≠tulo 2. Marco Conceptual 29 2.1.1.2.2. An√°lisis discriminante El objetivo del an√°lisis discriminante es encontrar reglas de asignaci√≥n de individuos a una de las clases de una clasificaci√≥n preestablecida. El t√©rmino an√°lisis discrim√≠nate es el nombre que se utiliza tradicionalmente en estad√≠stica para englobar las t√©cnicas de clasificaci√≥n supervisada. Para resolver este problema se dispone de una muestra de n individuos, de los cuales sabemos su clase de pertenencia y en los que tenemos medidas un conjunto de p variables que permiten diferenciar a las clases. [7] Geom√©tricamente, las p variables permiten situar a los individuos en un espacio ùëÖùëù eucl√≠deo. Por otro lado, se supone que estas variables permiten diferenciar los individuos seg√∫n su clase de pertenencia, es decir, se supone que cada clase viene definida por una distribuci√≥n de probabilidad distinta de las restantes clases. Naturalmente, las variables ùë•ùëó no tienen por qu√© ser las originales sino que puede ser transformaciones que optimicen la separaci√≥n entre las clases [7] 2.1.1.2.3. Maquinas vectoriales de soporte Las m√°quinas de vectores de soporte pertenecen a la familia de los clasificadores lineales puesto que inducen separadores lineales o hiperplanos en espacios de caracter√≠sticas de muy alta dimensionalidad (introducidos por funciones de n√∫cleo o kernel) con un sesgo inductivo muy particular (maximizaci√≥n del margen). [7] Cap√≠tulo 2. Marco Conceptual 30 Figura 7: Ejemplo Maquinas vectoriales de Soporte La idea b√°sica de las m√°quinas de vectores de soporte es: Dado un conjunto de puntos, en el que cada uno de ellos pertenece a una de dos posibles categor√≠as, un algoritmo basado en SVM construye un modelo capaz de predecir si un punto nuevo (cuya categor√≠a se desconoce) pertenece a una categor√≠a o a la otra. Como en la mayor√≠a de los m√©todos de clasificaci√≥n supervisada, los datos de entrada (los puntos) son vistos como un vector p-dimensional. Las SVM buscan un hiperplano que separe de forma √≥ptima a los puntos de una clase de la otra, que eventualmente han podido ser previamente proyectados a un espacio de dimensionalidad superior. En ese concepto de ‚Äúseparaci√≥n √≥ptima‚Äù es donde reside la carater√≠stica fundamental de las SVM: este tipo de algoritmos busca el hiperplano que tenga la m√°xima distancia (margen) con los puntos que est√°n m√°s cerca de √©l mismo. Por eso tambi√©n a veces se les conoce a las SVM como clasificadores de margen m√°ximo. De esta forma, los puntos del vector que son etiquetados con una categor√≠a estar√°n a un lado del hiperplano y los casos que se encuentren en la otra categor√≠a estar√°n al otro lado. Al vector formado por los puntos m√°s cercanos al hiperplano se le llama vector de soporte. [43] Cap√≠tulo 2. Marco Conceptual 31 La SVM lineal con margen m√°ximo es el modelo m√°s sencillo e intuitivo de SVM, aunque tambi√©n el que tiene condiciones de aplicabilidad m√°s restringidas, puesto que parte de la hip√≥tesis de que el conjunto de datos es linealmente separable en el espacio de entrada. [7] Figura 8: Maquina vectorial de soporte de margen m√°ximo Desgraciadamente, no siempre es posible encontrar una transformaci√≥n de los datos que permita separarlos linealmente, y si se logra, el resultado del modelo no puede ser generalizado para otros datos. Con el fin de permitir cierta flexibilidad, los SVM manejan un par√°metro C que controla la compensaci√≥n entre errores de entrenamiento y los m√°rgenes r√≠gidos, creando as√≠ un margen blando que permita algunos errores en la clasificaci√≥n a la vez que los penaliza. [43] Figura 9: Maquina vectorial de soporte de margen blando Cap√≠tulo 2. Marco Conceptual 32 2.1.1.2.4. √Årbol de Decisi√≥n De todos los m√©todos de aprendizaje, los sistemas de aprendizaje basados en arboles de decisi√≥n son quiz√°s el m√©todo m√°s f√°cil de utilizar y de entender. Un √°rbol de de decisi√≥n es un conjunto de condiciones organizadas en una estructura jer√°rquica, de tal manera que la decisi√≥n final a tomar se puede determinar siguiendo las condiciones que se cumplen desde la ra√≠z del √°rbol hasta alguna de sus hojas. Los √°rboles de decisi√≥n se utilizan desde hace siglos, y son especialmente apropiados para expresar procedimientos m√©dicos, legales, comerciales, estrat√©gicos, matem√°ticos, l√≥gicos, etc. [7] Figura 10: Ejemplo √Årbol de Decisi√≥n Una de las grandes ventajas de los √°rboles de decisi√≥n es que en su forma m√°s general, las opciones posibles a partir de una determinada condici√≥n son excluyentes. Esto permite analizar una situaci√≥n y, siguiendo el √°rbol de decisi√≥n apropiadamente, llegar a una sola acci√≥n o decisi√≥n a tomar. [7] La tarea de aprendizaje para la cual los √°rboles de decisi√≥n se adecuan mejor es la clasificaci√≥n. De hecho, clasificar es determinar entre varias clases a qu√© clase pertenece un objeto; la estructura de condici√≥n y ramificaci√≥n de un √°rbol de decisi√≥n es id√≥nea para este problema. La Cap√≠tulo 2. Marco Conceptual 33 caracter√≠stica m√°s importante del problema de la clasificaci√≥n es que se asume que las clases son disjuntas. Debido al hecho de que la clasificaci√≥n trata con clases o etiquetas disjuntas, un √°rbol de decisi√≥n conducir√° un ejemplo hasta una y s√≥lo una hoja, asignando, por tanto, una √∫nica clase al ejemplo. Para ello las particiones existentes en el √°rbol deben ser tambi√©n disjuntas. Es decir, cada instancia cumple o no cumple una condici√≥n. Esta propiedad dio lugar al esquema b√°sico de los primeros algoritmos de aprendizaje de √°rboles de decisi√≥n; el espacio de instancias se iba partiendo de arriba abajo, utilizando cada vez una partici√≥n, es decir, un conjunto de condiciones excluyentes y exhaustivas. Otra caracter√≠stica importante de los primeros algoritmos de aprendizaje de √°rboles de decisi√≥n es que una vez elegida la partici√≥n dicha partici√≥n no se pod√≠a cambiar, aunque m√°s tarde se pensara que hab√≠a sido una mala elecci√≥n. Por tanto, uno de los aspectos m√°s importantes en los sistemas de aprendizaje de √°rboles de decisi√≥n es el denominado criterio de partici√≥n, ya que una mala elecci√≥n de la partici√≥n (especialmente en las partes superiores del √°rbol) generar√° un peor √°rbol. Las particiones son, como se ha dicho, un conjunto de condiciones exhaustivas y excluyentes. L√≥gicamente, cuantos m√°s tipos de condiciones se permitan, m√°s posibilidades se tendr√°n de encontrar los patrones que hay detr√°s de los datos. Cuantas m√°s particiones se permitan m√°s expresivos podr√°n ser los √°rboles de decisi√≥n generados y probablemente, m√°s precisos. No obstante, cuantas m√°s particiones elijamos, la complejidad del algoritmo ser√° mayor. [7] Incluso con s√≥lo dos tipos de particiones sencillas, el n√∫mero de particiones posibles en cada caso puede dispararse (si existen n atributos y m valores posibles para cada atributo, el n√∫mero de particiones posibles es de n por m). Como se ha dicho anteriormente, los algoritmos cl√°sicos de aprendizaje de decisi√≥n son voraces, en el sentido de que una vez elegida la partici√≥n se contin√∫a hacia abajo la construcci√≥n del √°rbol y no vuelve a plantearse las particiones ya construidas. Estos dos aspectos tienen como consecuencia que se busque un criterio que permita realizar una buena elecci√≥n de la partici√≥n que parece m√°s prometedora y que esto se haga sin demasiado esfuerzo computacional. Esto obliga a que calcular la optimalidad de cada partici√≥n no sea muy costoso. [7] Cap√≠tulo 2. Marco Conceptual 34 La mayor√≠a de criterios se basan por tanto en obtener medidas derivadas de las frecuencias relativas de las clases en cada uno de los hijos de la partici√≥n respecto a las frecuencias relativas de las clases en el padre. Por ejemplo, si en un nodo tenemos cincuenta por ciento de ejemplos de clase a y un cincuenta por ciento de ejemplos de clase b, una partici√≥n que d√© como resultado dos nodos n1 y n2, donde todos los ejemplos de n1 sean de la clase a y todos los ejemplos de n2 sean de la clase b, ser√° una buena partici√≥n, porque los nodos resultantes son m√°s puros que el padre. Por el contrario, si ambos nodos n1 y n2 siguen teniendo proporciones cercanas al cincuenta por ciento no habremos discriminado nada y no avanzaremos hacia un √°rbol que nos clasifique correctamente la evidencia. [7] Bas√°ndose en la idea de buscar particiones que discrimen o que consigan nodos m√°s puros, se han presentado en las √∫ltimas dos d√©cadas numerosos criterios de partici√≥n, tales como el criterio del error esperado, el criterio de Gini, los criterios de Gain, entre otros. [7] Los algoritmos de aprendizaje de √°rboles de decisi√≥n y conjuntos de reglas mencionados previamente obtienen un modelo que es completo y consistente con respecto a la evidencia. Es decir, el modelo cubre todos los ejemplos vistos y los cubre todos de manera correcta. Esto puede parecer √≥ptimo a primera vista, pero se vuelve demasiado ingenuo en la realidad. En primer lugar, ajustarse demasiado a la evidencia suele tener como consecuencia que el modelo se comporte mal para nuevos ejemplos, ya que, en la mayor√≠a de los casos, el modelo es solamente una aproximaci√≥n del concepto objetivo del aprendizaje. Por tanto, intentar aproximar demasiado hace que el modelo sea demasiado espec√≠fico, poco general y, por tanto, malo con otros datos no vistos. En segundo lugar, esto es especialmente patente cuando la evidencia puede contener ruido (errores en los atributos o incluso en las clases), ya que el modelo intentar√° ajustarse a los errores y esto perjudicar√° el comportamiento global del modelo aprendido. Esto es lo que se conoce como sobreajuste (overfitting). [7] La manera m√°s frecuente de limitar este problema es modificar los algoritmos de aprendizaje de tal manera que obtengan modelos m√°s generales. En el contexto de los √°rboles de decisi√≥n y conjuntos de reglas, generalizar significa eliminar condiciones de las ramas del √°rbol o de algunas reglas. En el caso de los √°rboles de decisi√≥n dicho procedimiento se puede ver gr√°ficamente como un proceso de poda, como se ilustra en la Figura 11. Cap√≠tulo 2. Marco Conceptual 35 Figura 11: √Årbol Podado 2.1.1.2.5. Bosques Aleatorios Antes de hablar de los Bosques Aleatorios es conveniente mencionar la definici√≥n de los m√©todos de consenso o Bagging. La idea fundamental de estos m√©todos es tomar m muestras aleatorias con reemplazo de los datos originales y luego aplicar a cada una de ellas un m√©todo predictivo para luego con alg√∫n criterio establecer un consenso de todos los resultados. El consenso podr√≠a ser un promedio, un promedio ponderado basado en cu√°l m√©todo obtuvo los mejores resultados o el que obtenga la mayor cantidad de votos.[44] Figura 12: Ejemplo m√©todos de consenso Bosques Aleatorios o Random forest es una combinaci√≥n de √°rboles de decisi√≥n tal que cada √°rbol depende de los valores de un vector aleatorio probado independientemente y con la misma distribuci√≥n para cada uno de estos. Cap√≠tulo 2. Marco Conceptual 36 Figura 13: Ejemplo Bosques Aleatorios Es una modificaci√≥n sustancial de los m√©todos de consenso que construye una larga correlaci√≥n de √°rboles no correlacionados y luego los promedia. [45] Las ventajas de los Bosques aleatorios son [45]: ÔÇ∑ Es uno de los algoritmos de aprendizaje m√°s certeros que hay disponible. Para un conjunto de datos lo suficientemente grande produce un clasificador muy certero ÔÇ∑ Corre eficientemente en bases de datos grandes ÔÇ∑ Puede manejar cientos de variables de entrada sin excluir ninguna ÔÇ∑ Da estimados de qu√© variables son importantes en la clasificaci√≥n ÔÇ∑ Tiene un m√©todo eficaz para estimar datos perdidos y mantener la exactitud cuando una gran proporci√≥n de los datos est√° perdida ÔÇ∑ Computa los prototipos que dan informaci√≥n sobre la relaci√≥n entre las variables y la clasificaci√≥n ÔÇ∑ Computa las proximidades entre los pares de casos que pueden usarse en los grupos, localizando valores at√≠picos, o (ascendiendo) dando vistas interesantes de los datos ÔÇ∑ Ofrece un m√©todo experimental para detectar las interacciones de las variables Cap√≠tulo 2. Marco Conceptual 37 Las desventajas son [45]: ÔÇ∑ Se ha observado que los Bosques aleatorios sobreajusta en ciertos grupos de datos con tareas de clasificaci√≥n ruidosas ÔÇ∑ A diferencia de los √°rboles de decisi√≥n, la clasificaci√≥n hecha por Bosques aleatorios es dif√≠cil de interpretar por el hombre ÔÇ∑ Para los datos que incluyen variables categ√≥ricas con diferente n√∫mero de niveles, el random forests se parcializa a favor de esos atributos con m√°s niveles. Por consiguiente, la posici√≥n que marca la variable no es fiable para este tipo de datos Si los datos contienen grupos de atributos correlacionado con similar relevancia para el rendimiento, entonces los grupos m√°s peque√±os est√°n favorecidos sobre los grupos m√°s grandes 2.1.1.2.6. Redes Bayesianas Antes de hablar de Na√Øve Bayes se debe hablar del Teorema de Bayes. En teor√≠a de la probabilidad, el teorema de Bayes es la regla b√°sica para realizar inferencias. As√≠, el teorema de Bayes nos permite actualizar la creencia que tenemos en un suceso o conjunto de sucesos a la luz de nuevos datos u observaciones. Es decir, nos permite pasar de la probabilidad a priori P(suceso) a la probabilidad a posteriori P(suceso|observaciones). La probabilidad a priori puede verse como la probabilidad inicial, la que fijamos sin saber nada m√°s. La probabilidad a posteriori es la que obtendr√≠amos tras conocer cierta informaci√≥n, por tanto, puede verse como un refinamiento de nuestro conocimiento.[7] Teniendo en cuenta estos conceptos, el teorema de Bayes viene representado por la siguiente expresi√≥n: ùëÉ(‚Ñé|ùëÇ) = ùëÉ(ùëÇ|‚Ñé). ùëÉ(‚Ñé) ùëÉ(ùëÇ) Donde, se puede observar, lo que aparecen son la probabilidad a priori de la hip√≥tesis (‚Ñé) y de las observaciones (ùëÇ) y las probabilidades condicionadas ùëÉ(‚Ñé|ùëÇ) y ùëÉ(ùëÇ|‚Ñé). Centr√°ndose en el problema de la clasificaci√≥n, con una variable clase (C) y un conjunto de variables predictoras o atributos {ùê¥1, ‚Ä¶ , ùê¥ùëõ}, el teorema de Bayes tendr√≠a la siguiente forma: Cap√≠tulo 2. Marco Conceptual 38 ùëÉ(ùê∂|ùê¥1 ‚Ä¶ ùê¥ùëõ) = ùëÉ(ùê¥1 ‚Ä¶ ùê¥ùëõ|ùê∂). ùëÉ(ùê∂) ùëÉ(ùê¥1 ‚Ä¶ ùê¥ùëõ) Evidentemente, si C tiene k posibles valores {ùëê1, ‚Ä¶ , ùëêùëò}, lo que interesa es identificar el m√°s plausible y devolverlo como resultado de la clasificaci√≥n. En el marco bayesiano, la hip√≥tesis m√°s plausible no es otra que aquella que tiene m√°xima probabilidad a posteriori dados los atributos, y es conocida como la hip√≥tesis m√°xima a posteriori. Por tanto, el teorema de Bayes facilita un m√©todo sencillo y con una sem√°ntica clara para resolver esta tarea. Sin embargo, este m√©todo tiene un problema, y es su alt√≠sima complejidad computacional, debido a que se necesita trabajar con distribuciones de probabilidad que involucran muchas variables, haci√©ndolas en la mayor√≠a de los casos inmanejables.[7] 2.1.1.2.7. Redes Neuronales Las redes neuronales artificiales son un m√©todo de aprendizaje cuya finalidad inicial era la de emular los procesadores biol√≥gicos de informaci√≥n. Las RNA parten de la presunci√≥n de que la capacidad humana de procesar informaci√≥n se debe a la naturaleza biol√≥gica del cerebro. Por tanto, para imitar esta caracter√≠stica se debe estudiar y basarse en el uso de soportes artificiales semejantes a los existentes en el cerebro.[7] Una red neuronal se compone de unidades llamadas neuronas. Cada neurona recibe una serie de entradas a trav√©s de interconexiones y emite una salida. Esta salida viene dada por tres funciones [46]: 1. Una funci√≥n de propagaci√≥n (tambi√©n conocida como funci√≥n de excitaci√≥n), que por lo general consiste en el sumatorio de cada entrada multiplicada por el peso de su interconexi√≥n (valor neto). Si el peso es positivo, la conexi√≥n se denomina excitatoria; si es negativo, denomina inhibitoria. 2. Una funci√≥n de activaci√≥n, que modifica a la anterior. Puede no existir, siendo en este caso la salida la misma funci√≥n de propagaci√≥n. 3. Una funci√≥n de transferencia, que se aplica al valor devuelto por la funci√≥n de activaci√≥n. Se utiliza para acotar la salida de la neurona y generalmente viene dada por la interpretaci√≥n que queramos darle a dichas salidas. Algunas de las m√°s utilizadas Cap√≠tulo 2. Marco Conceptual 39 son la funci√≥n sigmoidea (para obtener valores en el intervalo [0, 1]) y la tangente hiperb√≥lica (para obtener valores en el intervalo [-1, 1]). 2.1.1.2.8. Regresi√≥n Log√≠stica Antes de hablar de lo que es el modelo de regresi√≥n log√≠stica se debe saber qu√© es un modelo de regresi√≥n. Un modelo de regresi√≥n es cuando la variable de respuesta y las variables explicativas son todas ellas cuantitativas [7]. Si s√≥lo se dispone de una variable explicativa hablamos de regresi√≥n simple, mientras que si se dispone de varias variables explicativas se trata de una regresi√≥n m√∫ltiple. La regresi√≥n log√≠stica es un tipo especial de regresi√≥n que se utiliza para predecir el resultado de una variable categ√≥rica en funci√≥n de las variables explicativas [11]. 2.1.2. Grandes Vol√∫menes de Datos Una parte fundamental de la Ciencia de Datos es Grandes Vol√∫menes de datos o en ingl√©s Big Data el cual es un t√©rmino global para cualquier colecci√≥n de conjuntos de datos tan grandes y complejos que complican el procesamiento de los mismos inhabilitando el uso de herramientas de gesti√≥n de datos y las aplicaciones tradicionales de tratamiento de datos.[24] 2.1.2.1. Las 5 V‚Äôs de Grandes Vol√∫menes de Datos Se sabe que los datos se est√°n convirtiendo en la base de cara a obtener ventajas competitivas con el af√°n de desmarcarnos del resto de compa√±√≠as. Sin embargo, el gran inconveniente del Big Data y del tratamiento de datos es la ausencia de un diccionario, gu√≠a o ‚Äòlibrillo‚Äô que dicte la praxis para exprimir todo el potencial que posee. No obstante, en el a√±o 2001, el experto analista de datos Doug Laney defini√≥ los tres vectores de los vol√∫menes de datos. Desde entonces, numerosos autores han aparecido con otras definiciones y descripciones que enriquecen la teor√≠a de Laney.[37] Cap√≠tulo 2. Marco Conceptual 40 Finalmente, la comunidad tecnol√≥gica que rodea al Big Data y el Business Intelligence se ha puesto de acuerdo y ha establecido cinco directrices que describen. I. V de Volumen: El primer aspecto que se nos viene a la cabeza cuando pensamos en el Big Data es un torrente de datos desestructurados que guardan un inmenso potencial en s√≠ mismos. Dicho esto, no es de extra√±ar que las empresas ya sepan con los vol√∫menes que tienen ante s√≠. Y es que el panorama tecnol√≥gico referente ha sufrido variaciones considerables. Lo que antes se consideraba grande, ahora ya no lo es tanto, sino basta con echar un vistazo al Gigabyte, que al parecer ya se ha convertido en la unidad ‚Äúb√°sica‚Äù de almacenamiento, frente a los Petabytes que engloba el Big Data. [37] II. V de Velocidad: Para un gran volumen de datos que no sufre variaciones muy a menudo, el an√°lisis lleva horas e incluso d√≠as. No obstante, en el √°mbito del Big Data el montaje de informaci√≥n crece por Terabytes, de ah√≠ que el tiempo de procesamiento de la informaci√≥n sea un factor fundamental para que dicho tratamiento aporte ventajas que marquen la diferencia. [37] III. V de Variedad: De sobra se sabe que el Big Data no versa en la mayor√≠a de las ocasiones sobre datos estructurados y que no siempre es sencillo incorporar grandes vol√∫menes a una base de datos relacional. Infinidad de tipos de datos se aglutinan dispuestos a ser tratados y es por ello que frente a esa variedad aumenta el grado de complejidad tanto en el almacenamiento como en su an√°lisis. [37] IV. V de Veracidad: Con un alto volumen de informaci√≥n que crece a tal velocidad y es de tama√±a variedad, en ocasiones es inevitable dudar del grado de veracidad que √©stos poseen. Para ello, se incide en ejercer una limpieza en los datos para as√≠ asegurar el mayor aprovechamiento de los mismos. No obstante, supone un gran esfuerzo que a grosso modo no reflejar√° variaciones esenciales de los resultados finales Cap√≠tulo 2. Marco Conceptual 41 relativos al tratamiento de la informaci√≥n. Por lo tanto, dependiendo de la aplicaci√≥n que se les d√©, su veracidad y su verificaci√≥n puede ser imprescindible o simplemente un acto secundario sin llegar a ser vital. [37] V. V de Valor: Sin duda el aspecto m√°s relevante del Big Data. Es muy costoso poner en pr√°ctica las infraestructuras inform√°ticas para almacenar estos vol√∫menes de datos, y por ende, las empresas van a necesitar gran cantidad de dinero para rentabilizar su gasto. Si no se consigue extraer todo el valor de ellos, no habr√° lugar para almacenar ni administrar. [37] 2.2. Sistema Operativo Un sistema operativo (SO) es el software de sistema que gestiona los recursos de hardware y software del ordenador y proporciona servicios comunes para los programas del mismo. El sistema operativo es un componente esencial del software del sistema en un sistema inform√°tico. Los programas de aplicaci√≥n por lo general requieren un sistema operativo para funcionar [12]. Para las funciones de hardware como las entrada y salida y la asignaci√≥n de memoria, el sistema operativo act√∫a como intermediario entre los programas y el hardware del ordenador, aunque el c√≥digo de la aplicaci√≥n se suele ejecutarse directamente por el hardware y con frecuencia hace que el sistema llama a una funci√≥n del Sistema Operativo o ser interrumpido por ella. Los sistemas operativos se encuentran en muchos dispositivos que contienen un ordenador desde tel√©fonos celulares y consolas de videojuegos a los servidores web y supercomputadoras [12]. 2.2.1. Tipos de Sistema Operativo i. Single- and Multi-Tasking: Un sistema Single-Tasking s√≥lo puede ejecutar un programa a la vez, mientras que un sistema operativo Multi-Tasking permite que m√°s de un programa que se ejecuta de manera concurrente. Esto se logra por un tiempo Cap√≠tulo 2. Marco Conceptual 42 compartido, dividiendo el tiempo de procesador disponible entre m√∫ltiples procesos que son cada uno interrumpidos repetidamente por un subsistema de programaci√≥n de tareas del sistema operativo [12]. ii. Single- and Muti-User: Los sistemas operativos de un solo usuario no tienen instalaciones para distinguir a los usuarios, pero puede permitir que varios programas se ejecuten en paralelo. Un sistema operativo multiusuario extiende el concepto b√°sico de la multitarea con instalaciones que identifican los procesos y recursos, tales como el disco espacio, que pertenece a varios usuarios, y el sistema permite que varios usuarios interact√∫en con el sistema al mismo tiempo [12]. iii. Distribuido: Un sistema operativo distribuido gestiona un grupo de equipos distintos y los hace parecer como un solo equipo. El desarrollo de ordenadores conectados en red que podr√≠an estar vinculados y se comunican entre s√≠ dio lugar a la computaci√≥n distribuida. [12] iv. Templated: El t√©rmino se refiere a la creaci√≥n de una √∫nica imagen de m√°quina virtual como un sistema operativo invitado. La t√©cnica se utiliza tanto en la virtualizaci√≥n y la gesti√≥n de la computaci√≥n en la nube, y es com√∫n en grandes almacenes de un servidor. [12] v. Embebidos: Los sistemas operativos embebidos est√°n dise√±ados para ser utilizados en sistemas inform√°ticos integrados. Est√°n dise√±ados para operar en peque√±as m√°quinas como PDAs con menos autonom√≠a. Ellos son capaces de operar con un n√∫mero limitado de recursos. [12] vi. Real-time: Un sistema operativo de tiempo real es un sistema operativo que garantiza procesar los eventos o datos dentro de una corta cantidad de tiempo. Un sistema operativo de tiempo real puede ser de una o varias tareas a la vez. [12] Cap√≠tulo 2. Marco Conceptual 43 2.2.2. Linux Linux es un sistema operativo de software libre, compatible Unix. El sistema lo forman el n√∫cleo del sistema (kernel) m√°s un gran n√∫mero de programas / bibliotecas que hacen posible su utilizaci√≥n. Muchos de estos programas y bibliotecas han sido posibles gracias al proyecto GNU, por esto mismo, muchos llaman a Linux, GNU/Linux, para resaltar que el sistema lo forman tanto el n√∫cleo como gran parte del software producido por el proyecto GNU. Linux se distribuye bajo la GNU General Public License por lo tanto, el c√≥digo fuente tiene que estar siempre accesible y cualquier modificaci√≥n √≥ trabajo derivado tiene que tener esta licencia. [13] 2.2.2.1. GTK+ GTK+, o GIMP toolkit, es un kit de herramientas multiplataforma para crear interfaces gr√°ficas de usuario. Ofreciendo un conjunto completo de los widgets. GTK+ est√° escrito en C, pero ha sido dise√±ado desde cero para apoyar una amplia gama de lenguajes, no s√≥lo C/C++. El uso de GTK+ de lenguajes como Perl y Python proporciona un m√©todo eficaz para el desarrollo r√°pido de aplicaciones. GTK+ es software libre y parte del proyecto GNU. Sin embargo, los t√©rminos de licencia para GTK+, la licencia GNU LGPL, permiten que sea utilizado por todos los desarrolladores, incluyendo aquellos que desarrollan software propietario, sin ning√∫n tipo de derechos de licencia o regal√≠as. [14] 2.2.2.2. Secure Shell Secure Shell (SSH) es el nombre de un protocolo y del programa que lo implementa, y sirve para acceder a m√°quinas remotas a trav√©s de una red. Permite manejar por completo la computadora mediante un int√©rprete de comandos, y tambi√©n puede redirigir el tr√°fico de X para poder ejecutar programas gr√°ficos si tenemos ejecutando un Servidor X (en sistemas Unix y Windows). Adem√°s de la conexi√≥n a otros dispositivos, SSH nos permite copiar datos de forma segura (tanto archivos sueltos como simular sesiones FTP cifradas), gestionar claves RSA para no escribir claves Cap√≠tulo 2. Marco Conceptual 44 al conectar a los dispositivos y pasar los datos de cualquier otra aplicaci√≥n por un canal seguro tunelizado mediante SSH. [15] 2.3. Lenguajes de Programaci√≥n 2.3.1. R El proyecto R es a la vez un lenguaje especializado y un conjunto de herramientas de m√≥dulos dirigido a cualquier persona trabajando con las estad√≠sticas. Abarca todo, desde la carga de los datos a la ejecuci√≥n de an√°lisis sofisticados en √©l y luego ya sea de exportaci√≥n o la visualizaci√≥n de los resultados. La consola interactiva hace que sea f√°cil de experimentar con sus datos, ya que se puede probar un mont√≥n de diferentes enfoques muy r√°pidamente. La desventaja m√°s grande desde una perspectiva de proceso de datos es que est√° dise√±ado para trabajar con conjuntos de datos que se ajustan a la memoria de una sola m√°quina. Es posible utilizarlo dentro de Hadoop como otro lenguaje para streaming, pero una gran cantidad de las m√°s potentes funciones requieren acceso al conjunto completo de datos para ser eficaz. R hace una gran plataforma de creaci√≥n de prototipos para el dise√±o de soluciones que necesitan para funcionar con cantidades masivas de datos, sin embargo, o para dar sentido a los resultados de menor escala del procesamiento. [25] R se compone de una serie de paquetes programados por una comunidad activa de desarrolladores. A continuaci√≥n se describen los paquetes m√°s importantes utilizados en el marco del desarrollo de esta investigaci√≥n. 2.3.1.1. gWidgets2 El paquete gWidgets2 proporciona una interfaz de programaci√≥n para la fabricaci√≥n de interfaces gr√°ficas de usuario dentro de R. El paquete es una reescritura del paquete gWidgets. El paquete se basa en uno de los varios paquetes toolkit subyacentes que dan acceso a las bibliotecas de gr√°ficos. Estos incluyen RGtk2, tcltk, qtbase, y una colecci√≥n de widgets del navegador proporcionado por ExtJS. [16] El paquete proporciona constructores para desarrollar controles, widgets con los que un usuario interact√∫a, contenedores, objetos GUI Cap√≠tulo 2. Marco Conceptual 45 utilizados para organizar los controles dentro de una ventana y di√°logos simples. Estos objetos son manipulados a trav√©s de diversos m√©todos. El paquete proporciona algunas funcionalidades gen√©ricas y, en lo posible, aprovecha los m√©todos existentes para R. [16] Figura 14: Ejemplo de ventana creada con el paquete gWidgets2 en R Los constructores se pueden dividir en las siguientes categor√≠as: i) Constructores de control: 1. gbutton: Provee un bot√≥n b√°sico para iniciar una acci√≥n 2. gcalendar: Provee una entrada de texto con formato de fecha 3. gcheckbox: Provee un checkbox junto con su etiqueta para permitir a los usuario realizar selecciones 4. gcheckboxgroup: Igual que el gcheckbox pero permitiendo la selecci√≥n de cero o m√°s objetos 5. gcombobox: Provee una lista desplegable con una lista de opciones para una libre selecci√≥n 6. gdf: Provee un widget para la edici√≥n de un dataframe 7. gedit: Provee un entrada de texto 8. ggraphics: Provee la funci√≥n de mostrar gr√°ficos embebidos en un widget Cap√≠tulo 2. Marco Conceptual 46 9. gimage: Provee la funci√≥n para que un widget soporte im√°genes 10. glabel: Provee etiquetas 11. gmenu: Provee men√∫s en la parte superior de la ventana 12. gradio: Proporciona un medio para seleccionar uno de los muchos objetos 13. gseparator: Proporciona una l√≠nea visual para separar partes de una ventana 14. gslider: Proporciona un medio para seleccionar un valor de uno de continuo de valores 15. gspinbutton: Proporciona los medios para seleccionar un valor de una secuencia de valores 16. gstatusbar: Proporciona un widget para mostrar los mensajes de estado en una ventana de nivel superior 17. gtable: Proporciona un widget para mostrar datos tabulares para la selecci√≥n 18. gtext: Proporciona un widget de edici√≥n de texto de varias l√≠neas 19. gtimer: Proporciona un temporizador 20. gtoolbar: Proporciona barras de herramientas para ventanas de nivel superior 21. gtree: Proporciona una pantalla para los datos jer√°rquicos 22. gvarbrowser: Proporciona un widget que muestra una instant√°nea del espacio actual de trabajo 23. gaction: Proporciona un medio para encapsular las acciones para su uso con barras de men√∫, barras de herramientas y botones. 24. gexpandgroup: Proporciona un contenedor con una opci√≥n de revelar u ocultar sus hijos 25. gframe: Proporciona un contenedor cuadro enmarcado 26. ggroup: Proporciona un contenedor caja horizontal o vertical para el embalaje en componentes hijos 27. glayout: Proporciona un contenedor para organizar los datos por filas y columnas 28. gnotebook: Proporciona un contenedor port√°til 29. gpanedgroup: Proporciona un contenedor dividido con divisor ajustable 30. gstackwidget: Proporciona un recipiente como un bloc de notas, pero sin etiquetas pesta√±a Cap√≠tulo 2. Marco Conceptual 47 31. gwindow: Proporciona una ventana de nivel superior ii) Constructores de dialogo: 1. gmessage: Produce un di√°logo sencillo para mostrar un mensaje 2. gconfirm: Produce un cuadro de di√°logo para un usuario para confirmar una acci√≥n 3. ginput: Proporciona un cuadro de di√°logo para recoger la entrada del usuario 4. gbasicdialog: Proporciona un medio para producir cuadros de di√°logo modales generales 5. galert: Proporciona un di√°logo de mensaje transitoria corta 6. gfile: Proporciona un cuadro de di√°logo para seleccionar un nombre de archivo o directorio iii) M√©todos 1. svalue: Esto se utiliza para recuperar o establecer la propiedad principal asociado con un widget 2. enabled: Un widget est√° activado si es sensible a la entrada del usuario. Los widgets no activados normalmente se presentan en un estado en gris. 3. visible: La idea gen√©rica de un widget visible es uno que se dibuja. Sin embargo, varias clases anulan esto como parte del widget es visible o no visible. 4. focus: Un widget con focus recibe cualquier entrada de teclado. 5. editable: Un widget es editable si puede recibir la entrada de teclado. 6. font: La fuente para un objeto se especifica a trav√©s de este m√©todo que utiliza una convenci√≥n se ilustra en la p√°gina de ayuda. 7. size: El tama√±o de un widget se recupera o se da a trav√©s de estos m√©todos 8. tooltip: Una tooltip ofrece informaci√≥n contextual cuando un rat√≥n pasa sobre un objeto 9. undo, redo: Algunos widgets apoyan las funciones deshacer y rehacer 10. isExtant: Un m√©todo para comprobar si todav√≠a existe una parte de un widget. Cap√≠tulo 2. Marco Conceptual 48 11. tag: Un m√©todo utilizado para establecer los atributos de un objeto que se almacenan en un entorno de modo que se pasan por referencia, no por copia. Esto permite a los controladores de eventos manipular atributos de un objeto fuera del √°mbito del callback. 12. getToolkitWidget: Devuelve el conjunto de herramientas del objeto que subyacen empaquetados en un objeto gWidgets2 13. add: M√©todo utilizado para a√±adir un componente secundario de un contenedor primario 14. delete: M√©todo utilizado para eliminar un componente de su contenedor 15. dispose: M√©todo utilizado para eliminar un componente 16. dim: Se utiliza para volver fila y tama√±o de la columna de informaci√≥n seg√∫n corresponda. 17. names: Se utiliza para definir los nombres asociados a un objeto. Estos pueden ser nombres de columna en el widget table, o nombres de ficha en el contenedor port√°til. 18. dimnames: Se utiliza para definir nombres de fila y columna, seg√∫n corresponda. 19. update: Llamada para actualizar el estado de un widget. iv) Manejadores de eventos 1. addHandlerChanged: Asigna un handler y lo ejecuta cuando el objeto cambia 2. addHandlerClicked: Asigna un handler y lo ejecuta cuando se le hace click al objeto 3. addHandlerDoubleclick: Asigna un handler y lo ejecuta cuando se le hace doble click al objeto 4. addHandlerRightclick: Asigna un handler y lo ejecuta cuando se le hace click derecho al objeto 5. addHandlerColumnclicked: Asigna un handler y lo ejecuta cuando se le hace click a una columna del objeto 6. addHandlerColumnDoubleclicked: Asigna un handler y lo ejecuta cuando se le hace doble click a una columna del objeto 7. addHandlerColumnRightclicked: Asigna un handler y lo ejecuta cuando se le hace click derecho a una columna del objeto Cap√≠tulo 2. Marco Conceptual 49 8. addHandlerSelect: Asigna un handler y lo ejecuta cuando se selecciona el objeto 9. addHandlerFocus: Asigna un handler y lo ejecuta cuando se el objeto recibe un focus 10. addHandlerBlur: Asigna un handler y lo ejecuta cuando el objeto recibe un blur 11. addHandlerDestroy: Ejecuta un handler cuando el objeto es destruido 12. addHandlerUnrealize: Para un gwindow esta funci√≥n es llamada antes de la destrucci√≥n del objeto y puede prevenir que eso suceda 13. addHandlerExpose: Asigna un handler y lo ejecuta cuando el objeto es expuesto 14. addHandlerKeystroke: Asigna un handler y lo ejecuta cuando un evento sobre el identificador ocurre 15. addHandlerMouseMotion: Asigna un handler y lo ejecuta cuando el rat√≥n pasa sobre el objeto 16. addHandler: M√©todo base para asignar un handler 17. addHandlerIdle: M√©todo para asignar un handler por un determinado tiempo 18. addPopupMenu: Agrega un men√∫ popup 19. add3rdmousePopupMenu: Agrega un men√∫ popup para el rat√≥n derecho 20. addDropSource: Especificar un widget como una ruta para activar el drag and drop 21. addDropTarget: Especificar un widget como una destino para activar el drag and drop 22. addDragMotion: Ejecuta un handler cuando un evento drag ocurre en el objeto 23. blockHandlers, blockHandler: Bloquea el handler del objeto 24. unblockHandlers, unblockHandler: Desbloquea el handler del objeto 25. removeHandler: Remueva el handler del objeto 2.3.1.2. RHadoop RHadoop es una colecci√≥n de cinco paquetes del lenguaje R que permiten a los usuarios manipular y analizar datos con Hadoop [48]. Cap√≠tulo 2. Marco Conceptual 50 2.3.1.2.1. rmr2 Corre en la parte superior de Hadoop, este paquete permite definir y ejecutar trabajos de MapReduce, incluida la especificaci√≥n del mapper y el reducer como funciones de investigaci√≥n, y para mover datos entre R y Hadoop de una manera casi transparente. El objetivo es hacer que la escritura de los trabajos map y reduce sea muy similar y tan f√°cil como escribir un lapply y tapply. Las caracter√≠sticas adicionales proporcionan composici√≥n de trabajo f√°cil, gesti√≥n de resultado intermedio transparente, soporte para diferentes formatos de datos y mucho m√°s. [17] Especificando la siguiente configuraci√≥n se puede utilizar el paquete sin estar en una plataforma Hadoop rmr.options(backend=‚Äùlocal‚Äù) 2.3.1.2.2. rhdfs El paque rhdfs suministra las funciones para interactuar con un sistema de archivos distribuido Hadoop desde dentro R. Hay funciones para la gesti√≥n del sistema de archivos, as√≠ como funciones para leer, escribir, abrir, y cerrar archivos. [18] Sus principales funciones son: hdfs.copy, hdfs.move, hdfs.rename, hdfs.put, hdfs.get, hdfs.file, hdfs.write,hdfs.close, hdfs.flush, hdfs.read, hdfs.seek, hdfs.tell, hdfs.defaults, hdfs.ls, hdfslist.files, hdfs.delete, hdfs.rm, hdfs.del, hdfs.dircreate, hdfs.mkdir, hdfs.chmod, hdfs.chown, hdfs.file.info, hdfs.exists, hdfs.init, hdfs.line.reader, hdfs.read.text.file. 2.3.2. Java Java es un lenguaje de programaci√≥n de prop√≥sito general, concurrente, orientado a objetos y basado en objetos que fue dise√±ado espec√≠ficamente para tener tan pocas dependencias de implementaci√≥n como fuera posible. Su intenci√≥n es permitir que los desarrolladores de aplicaciones escriban el programa una vez y lo ejecuten en cualquier dispositivo (conocido en ingl√©s como WORA, o "write once, run anywhere"), lo que quiere decir que el c√≥digo que es ejecutado en una plataforma no tiene que ser recompilado para correr en otra. [32] Cap√≠tulo 2. Marco Conceptual 51 2.3.3. Python Python es un lenguaje de programaci√≥n orientado a objetos claro y potente, comparable a Perl, Ruby, Scheme o Java. [35] Python tiene un gran soporte para aplicaciones de Ciencias de Datos, especialmente con librer√≠as como NumPy/SciPy, Pandas, Scikit-learn, IPython para un an√°lisis exploratorio y Matplotlib para visualizaciones.[40] Python para el an√°lisis de de Big Data se enfoca en la manipulaci√≥n, procesamiento y limpieza de los datos. Se apoya en algunas librer√≠as como PyDoop y SciPy. [41] 2.3.3.1. SciPy Scipy es un software de c√≥digo abierto para matem√°ticas, ciencias e ingenier√≠a. Incluye m√≥dulos para estad√≠sticas, optimizaci√≥n, integraci√≥n, algebra lineal, transformaciones de Fourier, procesamiento de im√°genes, y m√°s [49]. A continuaci√≥n se listan algunos de sus m√≥dulos [50]: 1. NumPy: Provee una manipulaci√≥n r√°pida y conveniente de arreglos n-dimensionales 2. SciPy library: Librer√≠a fundamental para la computaci√≥n cient√≠fica 3. Matplotlib: Maneja gr√°ficos comprensibles de dos dimensiones 4. IPython: Consola interactiva 5. Sympy: Provee simbolog√≠a matem√°tica 6. Pandas: Provee rutinas para la estructuraci√≥n y an√°lisis de los datos 2.4. Apache Hadoop Antes de hablar de Apache Hadoop primero se debe mencionar que es Apache. Apache Software Foundation (ASF) es una organizaci√≥n no lucrativa creada para dar soporte a los proyectos de software bajo la denominaci√≥n Apache. Apache Software Foundation es una comunidad descentralizada de desarrolladores que trabajan cada uno en sus propios proyectos de c√≥digo abierto. [39] Cap√≠tulo 2. Marco Conceptual 52 Los proyectos Apache se caracterizan por un modelo de desarrollo basado en el consenso y la colaboraci√≥n y en una licencia de software abierta y pragm√°tica. Cada proyecto es gestionado por un grupo autoseleccionado de expertos t√©cnicos que son participantes activos en dicho proyecto. [39] Entre los objetivos de la ASF se encuentra el proporcionar protecci√≥n legal a los voluntarios que trabajan en proyectos Apache, y al propio nombre Apache de ser empleado por otras organizaciones. El proyecto Apache es el origen de la licencia Apache y de todas las licencias que siguen un esquema similar. [39] Apache Hadoop es un framework de software que soporta aplicaciones distribuidas bajo una licencia libre. Fue creado por Doug Cutting. Tiene sus or√≠genes en Apache Nutch, el cual es un motor de b√∫squeda en la web de c√≥digo abierto. [24] Nutch se inici√≥ en 2002. Sin embargo, se dieron cuenta de que su arquitectura no escalar√≠a a los miles de millones de p√°ginas en la Web. La ayuda estaba a la mano con la publicaci√≥n de un art√≠culo en 2003 que describe la arquitectura del sistema de archivos distribuido de Google, llamado GFS, que estaba siendo utilizado en producci√≥n en Google. GFS, o algo parecido, podr√≠a resolver las necesidades de almacenamiento para los archivos muy grandes que se generan como parte del proceso de indexaci√≥n y rastreo web. En particular, GFS liberar√≠a tiempo que se gasta en tareas administrativas, tales como la gesti√≥n de nodos de almacenamiento. En 2004, se empezo a escribir una implementaci√≥n de c√≥digo abierto, el Sistema de archivos distribuidos Nutch (NDFS). [24] En 2004, Google public√≥ el documento que present√≥ MapReduce para el mundo. Temprano en 2005, los desarrolladores de Nutch ten√≠an una implementaci√≥n de MapReduce trabajando en Nutch, y a mediados de ese a√±o. Todos los algoritmos principales Nutch hab√≠an sido adecuados para ejecutarse utilizando MapReduce y NDFS. [24] NDFS y la implementaci√≥n de MapReduce en Nutch eran aplicables m√°s all√° del √°mbito de b√∫squeda, y en febrero de 2006 los desarrolladores se mudaron de Nutch para formar un subproyecto independiente de Lucene llamado Hadoop. Casi al mismo tiempo, Doug Cutting se uni√≥ a Yahoo!, la que proporcion√≥ un equipo dedicado y los recursos para convertir a Hadoop en un sistema que corri√≥ a escala web. Este se demostr√≥ en febrero de 2008, Cap√≠tulo 2. Marco Conceptual 53 cuando Yahoo! anunci√≥ que su b√∫squeda de √≠ndices en producci√≥n fue generada por 10000 n√∫cleos de un cl√∫ster Hadoop. [24] En enero de 2008, Hadoop se hizo su propio proyecto de nivel superior en Apache, lo que confirma su √©xito y su diversa comunidad activa. En ese momento, Hadoop estaba siendo utilizado por muchas otras empresas, adem√°s de Yahoo!, como Last.fm, Facebook, y el New York Times. [24] En abril de 2008, Hadoop rompi√≥ un r√©cord mundial al convertirse en el sistema m√°s r√°pido para ordenar una terabyte de datos. Ejecut√°ndose en un cl√∫ster de 910 nodos, Hadoop orden√≥ un terabyte en 209 segundos, superando al ganador de 297 segundos del a√±o anterior. [24] Desde entonces, Hadoop ha visto una r√°pida adopci√≥n de las empresas dominantes. El papel de Hadoop como una plataforma de almacenamiento y an√°lisis de prop√≥sito general para grandes vol√∫menes de datos ha sido reconocido por la industria, y este hecho se refleja en el n√∫mero de productos que utilizan o incorporan Hadoop de alguna manera. Hay distribuciones de Hadoop de las grandes empresas establecida, incluyendo EMC, IBM, Microsoft y Oracle, as√≠ como de empresas especialistas como Cloudera Hadoop, Hortonworks y MapR. [24] El nombre Hadoop proviene del nombre que le dio su hijo a un elefante de juguete. [24] Permite a las aplicaciones trabajar con miles de nodos y petabytes de datos. Hadoop se inspir√≥ en los documentos de Google para MapReduce y Google File System (GFS). [24] 2.4.1. Common Son un conjunto de librerias que soportan varios subproyectos de Hadoop. [27] 2.4.2. Hadoop Distributed File System (HDFS) Hadoop viene con un sistema de archivos distribuidos llamados HDFS, siglas de Hadoop Distributed Filesystem o en espa√±ol como Sistema de Archivos Distribuidos de Hadoop. [24] Cap√≠tulo 2. Marco Conceptual 54 El Sistema de archivos distribuido Hadoop (HDFS) est√° dise√±ado para soportar aplicaciones como trabajos MapReduce que leen y escriben grandes cantidades de datos en lotes, en lugar de m√°s accesos aleatorios a un mont√≥n de archivos peque√±os. S√≥lo se puede escribir en un archivo una vez en el tiempo de la creaci√≥n, para que sea m√°s f√°cil de manejar problemas de coherencia cuando los datos se alojan en un cl√∫ster de m√°quinas, por lo que las copias del archivo en cach√© se pueden leer en cualquiera de las m√°quinas que tienen uno, sin tener para comprobar si el contenido ha cambiado. El software cliente almacena los datos escritos en un archivo local temporal, hasta que haya suficiente para llenar un bloque completo HDFS. Todos los archivos son almacenados en estos bloques, con un tama√±o predeterminado de 64 MB. Una vez que suficientes datos se hayan guardado, o la operaci√≥n de escritura este cerrada, los datos locales se env√≠an a trav√©s de la red y son escritos a varios servidores del cl√∫ster, para asegurar que no se pierde si hay una falla de hardware. Para simplificar la arquitectura, HDFS utiliza un √∫nico nodo maestro o namenode para tener un rastreo sobre que archivos son almacenados y en d√≥nde. Esto quiere decir que hay un √∫nico punto de fallo y el rendimiento potencial a un cuello de botella. La intervenci√≥n manual necesaria para un fallo de namenode puede ser un dolor de cabeza para el mantenimiento del sistema. [25] Cap√≠tulo 2. Marco Conceptual 55 Figura 15: Arquitectura HDFS 2.4.2.1. Conceptos Bloques: HDFS tiene el concepto de un bloque, que a diferencia de otros sistemas de archivos la unidad es mucho m√°s grande. De 64 MB son los bloques por defecto. Al igual que en un sistema de archivos de un solo disco, los archivos en HDFS se rompen en chunks del tama√±o de bloque, que se almacenan como unidades independientes. A diferencia de un sistema de archivos de un solo disco, un archivo en HDFS que es m√°s peque√±o que un solo bloque no ocupa el valor de un bloque completo lo cual hace que valga la pena el almacenamiento subyacente. Los bloques HDFS son m√°s grandes en comparaci√≥n con los bloques de disco, y la raz√≥n es para minimizar el costo de b√∫squeda. Al hacer un bloque lo suficientemente grande, el tiempo para transferir los datos desde el disco puede ser significativamente m√°s largo que el tiempo de b√∫squeda al principio del bloque. As√≠, el tiempo para transferir un archivo grande hecho de m√∫ltiples bloques opera a la velocidad de transferencia de disco. [24] Namenodes y datanodes: Un cl√∫ster HDFS tiene dos tipos de nodos que operan en un patr√≥n maestro esclavo: un namenode (el maestro) y un n√∫mero de datanodes (esclavos). El namenode gestiona el espacio de nombres del sistema de archivos. √âl mantiene el √°rbol de archivos y los metadatos de todos los archivos y directorios en el √°rbol. Esta informaci√≥n se Cap√≠tulo 2. Marco Conceptual 56 almacena persistentemente en el disco local en la forma de dos archivos: la imagen de espacio de nombres y el registro de ediciones. El namenode tambi√©n sabe de los datanodes que se encuentran todos los bloques de un archivo dado; sin embargo, no conoce la ubicaci√≥n de manera persistente, ya que esta informaci√≥n se reconstruye a partir los datanodes cuando el sistema se inicia. Un cliente tiene acceso al sistema de archivos en nombre del usuario mediante la comunicaci√≥n con el namenode y datanodes. El cliente presenta una interfaz de sistema de archivos similar a una Portable Operating System Interface (POSIX), por lo que el c√≥digo de usuario no necesita saber sobre el funcionamiento del namenode y del datanode. Los datanodes son los caballos de batalla del sistema de archivos. Ellos almacenan y recuperan bloques cuando se les dice que lo haga (los clientes o el namenode), y que informen a el namenode peri√≥dicamente con las listas de bloques que est√°n almacenando. Sin el namenode, el sistema de ficheros no se puede utilizar. De hecho, si la m√°quina est√° en marcha y el namenode fue borrado, todos los archivos en el sistema de archivos se perder√≠an ya que no habr√≠a manera de saber c√≥mo reconstruir los archivos de los bloques en los datanodes. Por esta raz√≥n, es importante hacer que el namenode sea resistente a fallas, y Hadoop proporciona dos mecanismos para ello. La primera manera es hacer una copia de seguridad de los archivos que componen el estado persistente de los metadatos del sistema de archivos. Hadoop se puede configurar de modo que el namenode escribe su estado persistente a m√∫ltiples sistemas de ficheros. Estas escrituras son sincr√≥nicas y at√≥micas. La opci√≥n de configuraci√≥n habitual es escribir en el disco local, as√≠ como un mando a distancia de montaje NFS. Tambi√©n es posible ejecutar un namenode secundario o sustituto, que a pesar de su nombre no act√∫a como un namenode. Su funci√≥n principal es la de integrar peri√≥dicamente la imagen de espacio de nombres con el registro de ediciones para prevenir que el registro de ediciones se haga demasiado grande. El namenode secundario generalmente se ejecuta en una m√°quina f√≠sica independiente, ya que requiere un mont√≥n de CPU y tanta memoria como el namenode principal para realizar la combinaci√≥n. Mantiene una copia de la imagen del espacio de nombres fusionada, que se puede utilizar en el caso de fallo del namenode. Sin embargo, el estado del Cap√≠tulo 2. Marco Conceptual 57 namenode secundario queda por detr√°s de la primaria, por lo que en caso de fallo total del principal, la p√©rdida de datos es casi seguro. El curso normal de la acci√≥n, en este caso es copiar los archivos de metadatos del namenode que est√°n en NFS al secundario y ejecutarlo como el nuevo principal. [24] 2.4.3. MapReduce Hadoop es el sistema p√∫blico m√°s conocido para el funcionamiento de los algoritmos de MapReduce, pero muchas bases de datos modernas, tales como MongoDB, tambi√©n apoyan este patr√≥n. Es muy eficaz incluso en un sistema bastante tradicional, ya que si se puede escribir su consulta en una forma MapReduce, ser√° capaz de ejecutar de manera eficiente en tantas m√°quinas como se tenga disponible. [7] Figura 16: Ejemplo de MapReduce Los trabajos Hadoop MapReduce se dividen en un conjunto de tareas map y tareas reduce las cuales se ejecutan de una manera distribuida en un cl√∫ster de ordenadores. Cada tarea trabaja en un peque√±o subconjunto de los datos que ha sido asignado de manera que la carga se distribuye a trav√©s del cl√∫ster. Las tareas map generalmente cargan, analizan, transforman, y filtran los datos. Cada tarea reduce es responsable de la manipulaci√≥n de un subconjunto de la salida de la tarea map. Los datos intermedios son copiados de las tareas map por las tareas reducer con el fin de agrupar y agregar los datos. Es incre√≠ble como una amplia gama de problemas se puede resolver con un paradigma tan directo, de agregaciones num√©ricas simples a complejas operaciones de combinaci√≥n y productos cartesianos. Cap√≠tulo 2. Marco Conceptual 58 La entrada a un trabajo MapReduce es un conjunto de archivos en el almac√©n de datos que se transmiten a lo largo del Sistema de Archivos Distribuidos de Hadoop o ‚ÄúHadoop Distributed File System‚Äù (HDFS). En Hadoop, estos archivos se dividen con una entrada formato, que define c√≥mo separar un archivo en divisiones de entrada. Una partici√≥n de la entrada es una vista orientada a byte de una parte del archivo a ser cargado por una tarea map. Cada tarea map en Hadoop se divide en las siguientes fases: record reader, mapper, combiner, y partitioner. La salida de las tareas map, son llamadas claves intermedias y valores, las cuales se env√≠an a las tareas reducer. Las tareas reducer se dividen en las siguientes fases: shuffle, sort, reducer, y output format. Los nodos en los que las tareas map se ejecutan de manera √≥ptima son los nodos en los que los datos se apoyan. De esta manera, los datos normalmente no se tienen que mover por la red y se puede calcular en la m√°quina local. Record reader: El record reader traduce una partici√≥n de entrada generado por el formato de entrada en los registros. El prop√≥sito del lector de registro es para analizar los datos en los registros, pero no analiza el registro en s√≠. Se pasa los datos al mapper en la forma de un par clave/valor. Por lo general, la clave en este contexto es la informaci√≥n de posici√≥n y el valor es el fragmento o chunk de datos que compone un registro. [26] Map: En el mapper, el usuario proporciona un c√≥digo que se ejecuta en cada par clave/valor del record reader para producir cero o m√°s pares clave/valor, llamados pares intermedios. La decisi√≥n de cu√°l es la clave y el valor que aqu√≠ no es arbitraria y es muy importante lo que est√° logrando el trabajo MapReduce. La clave est√° dada de manera que los datos se agrupan en base a ella y el valor es la informaci√≥n pertinente para el an√°lisis en el reducer. [26] Combiner: El combiner, un reducer opcional localizado, pueden agrupar los datos en la fase map. El combiner toma las claves intermedias desde el mapper y aplica un m√©todo proporcionado por el usuario para agregar valores en el peque√±o √°mbito de un mapper. Por ejemplo, debido a que el recuento de una agregaci√≥n es la suma de los cargos de cada parte, se puede producir un recuento intermedio y luego sumar esos recuentos intermedios para el resultado final. En muchas situaciones, esto reduce significativamente la cantidad de datos que tienen que moverse m√°s en red. Cap√≠tulo 2. Marco Conceptual 59 Env√≠o (hola mundo, 3) requiere menos bytes que env√≠a (helloworld, 1) tres veces a lo largo de la red. Muchos de los nuevos desarrolladores de Hadoop ignoran la fase combiner, pero a menudo proporcionan mejoras de rendimiento extremas con ning√∫n inconveniente. Se puede se√±alar que los patrones se benefician del uso de combiner, y hay cu√°les en los que no se puede utilizar un combiner. Un combiner no est√° garantizado para ejecutarse, por lo que no puede ser un parte del algoritmo general. [26] Partitioner: El partitioner toma los pares clave/valor intermedios desde el mapper (o combiner si se utiliza) y los divide en fragmentos o shards, uno fragmento por reducer. De forma predeterminada, la herramienta partitioner interroga al objeto por su c√≥digo hash, que es t√≠picamente un md5sum. Entonces, el partitioner realiza una operaci√≥n de m√≥dulo por el n√∫mero de reducer: key.hashCode ()% (n√∫mero de reducers). Esto distribuye aleatoriamente el espacio de claves de manera uniforme sobre los reducers, pero a√∫n asegura que las claves con el mismo valor en diferentes mappers terminen en el mismo reducer. El comportamiento por defecto de la herramienta partitioner se puede personalizar, y estar√° en algunos patrones m√°s avanzados, tales como el sorting. Sin embargo, el cambio de la herramienta partitioner rara vez es necesario. Los datos particionados se escriben en el sistema de archivos local de cada tarea map y espera a ser pulled por su respectivo reducer. [26] Shuffle and sort: La tarea reduce comienza con la etapa shuffle and sort. Este paso toma los archivos de salida escrito por todos los partitioners y lo descarga en el equipo local en el que el reducer se est√° ejecutando. Estas piezas individuales de datos se ordenan por llave en una lista de datos m√°s grande. El prop√≥sito de este tipo es agrupar las llaves equivalentes juntas para que sus valores puedan iterarse m√°s f√°cilmente en la tarea reducer. Esta fase no es adaptable y el framework maneja todo autom√°ticamente. El √∫nico control que tiene un desarrollador es c√≥mo se clasifican y agrupan las claves especificando una costumbre Comparator object. [26] Reduce: El reducer toma los datos agrupados como entrada y ejecuta una funci√≥n reduce una vez por agrupaci√≥n clave. La funci√≥n se le pasa la clave y un iterador sobre todos los valores asociados a la clave pasada. Una amplia gama de procesamientos pueden ocurrir en esta funci√≥n. Los datos pueden ser agregados, filtrados, y combinados en un n√∫mero amplio de maneras. Una vez que la funci√≥n reduce se haga, se env√≠an cero o m√°s clave/valor par a la etapa final, el output format o formato de salida. Al igual Cap√≠tulo 2. Marco Conceptual 60 que la funci√≥n map, la funci√≥n reduce cambiar√° de un trabajo a otro, ya que es una pieza central de la l√≥gica en la soluci√≥n. [26] Output format: El formato de salida o output format traduce el par clave/valor final de la funci√≥n reduce y lo escribe en un archivo de un registro escritor. Por defecto, se separar√° la clave y el valor en una ficha de registros separados con un car√°cter de nueva l√≠nea. Esto puede ser t√≠picamente personalizado para ofrecer formatos de salida m√°s entendibles, pero al final, los datos se escriben en el HDFS, independientemente del formato.[26] 2.4.3.1. Hadoop Streaming Hadoop streaming es un componente que viene con las distribuciones de Hadoop. La utilidad le permite crear y ejecutar trabajos map / reduce con cualquier ejecutable o script. [19] Por ejemplo: $HADOOP_HOME/bin/hadoop jar $HADOOP_HOME/hadoop-streaming.jar \ -input myInputDirs \ -output myOutputDir \ -mapper /bin/cat \ -reducer /bin/wc En el ejemplo anterior, tanto el map como el reduce son ejecutables que leen la entrada por entrada est√°ndar (l√≠nea por l√≠nea) y emiten la salida a como salida est√°ndar. El componente crear√° un trabajo Map/Reduce, enviar√° la tarea a un cl√∫ster apropiado y monitorear√° el progreso del trabajo hasta que se complete. Parametro Requerido Descripci√≥n -input Requerido Localizaci√≥n de la entrada del mapper -output Requerido Localizaci√≥n de la salida del reducer -mapper Requerido Ejecutable Mapper -reducer Requerido Ejecutable Reducer Cap√≠tulo 2. Marco Conceptual 61 -file Opcional Ruta donde se encuentra el ejecutable mapper o reducer -inputformat Opcional Clase que especifica el tipo de entrada. Si no se especifica, TextInputFormat es usado por defecto -outputformat Opcional Clase que especifica el tipo de entrada. Si no se especifica, TextOutputFormat es usado por defecto -partitioner Opcional Clase que determina que clave reduce es enviada -combiner Opcional Ejecutable Combiner para la salida map -cmdenv Opcional Pasa variables de entorno para los commandos de streaming -inputreader Opcional Por compatibilidad con versiones anteriores: especifica una clase record reader (en lugar de una clase de formato de entrada) -verbose Opcional Mostrar log de salida -lazyOutput Opcional Crea una salida perezosa Cap√≠tulo 2. Marco Conceptual 62 -numReduceTasks Opcional Especifica el n√∫mero de reducers -mapdebug Opcional Script a ser llamado cuando una tarea map falle Tabla 1: Parametros de Hadoop Streaming 2.4.4. YARN Como parte de Hadoop 2.0, YARN toma las capacidades de gesti√≥n de los recursos que estaban en MapReduce y las empaqueta para que puedan ser utilizados por los nuevos motores. Esto tambi√©n simplifica MapReduce para hacer lo que mejor hace, procesar los datos. Con YARN, ahora puede ejecutar varias aplicaciones en Hadoop, todos compartiendo una gesti√≥n com√∫n de los recursos. Muchas organizaciones ya est√°n construyendo aplicaciones sobre YARN con el fin de traerlos a Hadoop. [28] Figura 17: Arquitectura YARN de Hortonworks YARN combina un administrador de recursos central que reconcilia la forma en que las aplicaciones utilizan los recursos del sistema de Hadoop con agentes gestores de nodos que controlan las operaciones de procesamiento de los nodos individuales del cl√∫ster. La separaci√≥n de HDFS Cap√≠tulo 2. Marco Conceptual 63 y MapReduce con YARN hace que el ambiente Hadoop sea m√°s adecuado para las aplicaciones operativas que no pueden esperar que terminen trabajos por lotes. [29] YARN aumenta el poder de un cl√∫ster de c√°lculo Hadoop de las siguientes maneras: a. Escalabilidad: El poder de procesamiento en los centros de datos contin√∫a creciendo r√°pidamente. Debido a que YARN ResourceManager se centra exclusivamente en la programaci√≥n, se puede administrar esos grandes grupos con mucha m√°s facilidad. [28] b. Compatibilidad con MapReduce: Aplicaciones MapReduce y usuarios existentes pueden ejecutar en la parte superior de YARN y sin interrupci√≥n a sus procesos existentes. [28] c. Utilizaci√≥n cl√∫ster mejorada: El ResourceManager es un programador puro que optimiza la utilizaci√≥n del cl√∫ster de acuerdo con criterios tales como garant√≠as de capacidad, equidad y SLAs. [28] d. Soporte para cargas de trabajo distintas de MapReduce: Modelos de programaci√≥n adicionales, tales como procesamiento gr√°fico y modelado iterativo ahora son posibles para el procesamiento de datos. [28] e. Agilidad: MapReduce se convierte en una biblioteca de espacio de usuario, que puede evolucionar de forma independiente de la capa de administrador de recursos subyacente y de una manera mucho m√°s √°gil. [28] ¬øC√≥mo trabaja YARN? La idea fundamental es la de dividir las dos principales funcionalidades del JobTracker/TaskTracker en varias entidades. La idea es tener un Manejador de Recursos global ResourceManager (RM), un ApplicationMaster (AM) por aplicaci√≥n Cap√≠tulo 2. Marco Conceptual 64 El ResourceManager y el esclavo por nodo, el NodeManager (NM), forman el marco de datos de c√°lculo. El ResourceManager es la √∫ltima autoridad que arbitra los recursos entre todas las aplicaciones en el sistema. El ApplicationMaster es, en efecto, un framework espec√≠fico de biblioteca y se encarga de la negociaci√≥n de los recursos del ResourceManager y trabajar con los NodeManager para ejecutar y supervisar las tareas que lo componen.[30] Figura 18: Proceso MapReduce YARN El ResourceManager tiene un planificador, que es responsable de la asignaci√≥n de recursos para las diversas aplicaciones en ejecuci√≥n, de acuerdo con las limitaciones como las capacidades de colas, los plazos de usuario, etc. El programador realiza su funci√≥n de programaci√≥n basado en las necesidades de recursos de las aplicaciones. El NodeManager es responsable del lanzamiento de los contenedores de las aplicaciones, el seguimiento de su uso de los recursos (CPU, memoria, disco, red) e informar del mismo al ResourceManager. Cada ApplicationMaster tiene la responsabilidad de negociar contenedores de recursos adecuados desde el planificador, el seguimiento de su estado, y el seguimiento de su progreso. Desde la perspectiva del sistema, el ApplicationMaster se ejecuta como un recipiente normal. Cap√≠tulo 2. Marco Conceptual 65 2.4.5. Herramientas del Ecosistema Hadoop 2.4.5.1. Hive Apache Hive es el est√°ndar de facto para las consultas SQL que tienen m√°s de petabytes de datos en Hadoop. Es un motor integral y compatible que ofrece la gama m√°s amplia de la sem√°ntica de SQL para Hadoop, proporcionando un potente conjunto de herramientas para los analistas y desarrolladores para acceder a los datos de Hadoop.[31] Con Hive, se pueden programar trabajos Hadoop utilizando SQL. Es una excelente interfaz para cualquier persona que viene del mundo de bases de datos relacionales, aunque los detalles de la implementaci√≥n subyacente no est√°n completamente ocultos. El usuario todav√≠a tiene que preocuparse acerca de algunas diferencias en cosas como la forma m√°s √≥ptima para especificar los joins para un mejor rendimiento y algunas caracter√≠sticas del lenguaje que faltan. Hive ofrece la posibilidad de conectar en c√≥digo personalizado para situaciones que no encajan en SQL, as√≠ como una gran cantidad de herramientas para el manejo de entrada y salida. Para usarlo, debe configurar las tablas estructuradas que describen su entrada y salida, los problemas en comandos de carga para ingerir archivos y, a continuaci√≥n, escribir sus consultas como lo har√≠a en cualquier otra base de datos relacional. No se debe tener en cuenta, sin embargo, que debido al enfoque de Hadoop de procesamientos en gran escala, la latencia puede significar que incluso los trabajos m√°s simples toman minutos para completarse, as√≠ que no es un sustituto de una base de datos transaccional en tiempo real.[7] Hive fue creado para hacer posible que los analistas con fuertes habilidades de SQL (pero con escaso conocimientos de programaci√≥n Java) puedan ejecutar consultas sobre los enormes vol√∫menes de datos que Facebook ha almacenado en HDFS. Hoy, Hive es un proyecto Apache exitoso utilizado por muchas organizaciones. [24] ¬øQu√© hace Hive? Hadoop fue construido para organizar y almacenar grandes cantidades de datos. Un cluster Hadoop es un dep√≥sito de datos heterog√©neos, provenientes de m√∫ltiples fuentes y en diferentes formatos. Hive permite al usuario explorar y estructura que los datos, analizarlos, y luego convertirlo en el conocimiento del negocio. [31] Cap√≠tulo 2. Marco Conceptual 66 ¬øC√≥mo funciona Hive? Las tablas en Hive son similares a las tablas en una base de datos relacional, y las unidades de datos est√°n organizadas en una taxonom√≠a m√°s grande que muchas unidades granulares. Las bases de datos se componen de tablas, que se componen de particiones. Los datos se pueden acceder a trav√©s de un lenguaje de consulta simple, llamado HiveQL, que es similar a SQL. Hive apoya sobrescribir o anexar datos, pero no las actualizaciones y eliminaciones. [31] Dentro de una base de datos particular, los datos de las tablas son serializados y cada tabla tiene un directorio en el sistema de archivos distribuido Hadoop correspondiente (HDFS). Cada tabla puede estar subdividida en particiones que determinan c√≥mo los datos se distribuyen dentro de los subdirectorios del directorio de la tabla. Los datos dentro de particiones se pueden desglosar en cubos. [31] Estas son algunas de las caracter√≠sticas ventajosas de Hive: a) Familiar: Cientos de usuarios √∫nicos pueden consultar simult√°neamente los datos utilizando un lenguaje familiar para los usuarios de SQL. [31] b) Velocidad: Los tiempos de respuesta son normalmente mucho m√°s r√°pido que otros tipos de consultas en el mismo tipo de conjuntos de datos enormes. [31] c) Escalable y extensible: Como la variedad de datos y el volumen crece, m√°s m√°quinas de las materias primas se pueden a√±adir a la agrupaci√≥n, sin una reducci√≥n correspondiente en el rendimiento. [31] d) Informativo: Controladores JDBC y ODBC familiares permiten muchas aplicaciones para extraer datos de Hive para la presentaci√≥n de informes sin fisuras. Hive permite a los usuarios leer los datos en formatos arbitrarios, usando SerDes y formatos de entrada/salida. [31] 2.4.5.2. Pig El proyecto Apache Pig es un lenguaje procedimental para el procesamiento de datos dise√±ado para Hadoop. En contraste con el enfoque de Hive, con Pig se especifican una serie de pasos a realizar en los datos. Est√° m√°s cerca de un lenguaje de programaci√≥n todos los d√≠as, pero con un Cap√≠tulo 2. Marco Conceptual 67 conjunto especializado de funciones que ayudan con problemas de procesamiento de datos comunes.[25] Pig eleva el nivel de abstracci√≥n para el procesamiento de grandes conjuntos de datos. MapReduce permite, como el programador especifica una funci√≥n de map seguida por una funci√≥n de reduce, pero trabajando fuera de c√≥mo encontrar la manera de adaptar su procesamiento de datos a este patr√≥n, que a menudo requiere m√∫ltiples etapas de MapReduce, por ende la adaptaci√≥n puede ser un desaf√≠o. Con Pig, las estructuras de datos son mucho m√°s ricas, suelen ser m√∫ltiples valores y anidados, y el conjunto de transformaciones que se le pueden aplicar los datos son mucho m√°s poderosas. Ellas incluyen joins.[32] Pig se compone de dos piezas: a) El lenguajes para expresar flujos de datos lladamo, Pig Latin. b) El entorno de ejecuci√≥n para ejecutar los programas de Pig Latin. Actualmente hay dos entornos de ejecuci√≥n: Una ejecuci√≥n local en una √∫nica JVM y una ejecuci√≥n distribuida en un cl√∫ster Hadoop. [32] ¬øQu√© hace Pig? Pig fue dise√±ado para llevar a cabo una larga serie de operaciones de datos, por lo que es ideal para tres categor√≠as de empleos Big Data: Extracci√≥n, transformaci√≥n y carga (ETL) de pipelines de datos, la investigaci√≥n sobre los datos en bruto, y el procesamiento de datos iterativo. [33] Cualquiera que sea el caso de uso, Pig ser√°: a) Extensible. Los usuarios Pig pueden crear funciones personalizadas para satisfacer sus necesidades de procesamiento particulares. b) F√°cil de programar. Las tareas complejas que implican transformaciones de datos relacionados entre s√≠ se pueden simplificar y codificar como secuencias de flujo de datos. Los programas Pig realizan tareas enormes, pero son f√°ciles de escribir y mantener. c) Auto-optimizaci√≥n. El sistema optimiza autom√°ticamente la ejecuci√≥n de trabajos Pig, por lo que el usuario puede centrarse en la sem√°ntica. [33] Cap√≠tulo 2. Marco Conceptual 68 ¬øC√≥mo funciona Pig? Pig se ejecuta en Hadoop y hace uso del sistema de archivos distribuido Hadoop (HDFS) y MapReduce. El idioma de la plataforma se llama Pig Latin, que abstrae del lenguaje Java MapReduce en una forma similar a SQL. Pig Latin es un lenguaje de flujo mientras que SQL es un lenguaje declarativo. SQL es ideal para hacer una pregunta de sus datos, mientras Pig Latin le permite escribir un flujo de datos que describe c√≥mo se transforman los datos. Los scripts Pig Latin pueden ser gr√°ficos (en lugar de requerir una sola salida) es posible construir flujos de datos compleja que involucren m√∫ltiples entradas, transformaciones y salidas. Los usuarios pueden ampliar Pig Latin escribiendo sus propias funciones, utilizando Java, Python, Ruby, u otros lenguajes de script. [33] El usuario puede ejecutar Pig en dos modos: 1. Modo Local. Con acceso a una sola m√°quina, todos los archivos se instalan y se ejecutan utilizando un sistema anfitri√≥n y el archivo local. [19] 2. Modo MapReduce. Este es el modo por defecto, lo que requiere el acceso a un cluster Hadoop. [33] El usuario puede ejecutar Pig en cualquiera de los modos mediante el comando "java" o el comando "pig". 2.4.5.3. HCatalog Apache HCatalog es una capa que gestiona el almacenamiento de datos en tablas que permite a los usuarios utilizando diferentes herramientas de procesamiento leer y escribir datos de manera m√°s f√°cil en la red. La abstracci√≥n que provee HCatalog en base a tablas presenta a los usuarios una visi√≥n relacional de los datos en el sistema de archivos distribuidos de Hadoop (HDFS) y adem√°s asegura a los usuarios que no deben preocuparse acerca de d√≥nde o en qu√© formato se almacenan los datos. Hcatalog muestra datos provenientes desde fuentes con varios formatos en una vista tabular. Tambi√©n proporciona medios para que los sistemas externos puedan acceder a los datos de las tablas.[34] ¬øQu√© hace HCatalog? Cap√≠tulo 2. Marco Conceptual 69 Apache HCatalog ofrece los siguientes beneficios a los administradores de la red: ÔÇ∑ Libera al usuario de tener que saber d√≥nde se almacenan los datos, con la abstracci√≥n en base a tablas [34] ÔÇ∑ Activa las notificaciones de la disponibilidad de datos [34] ÔÇ∑ Proporciona visibilidad para herramientas de limpieza y almacenamiento de datos [34] ¬øC√≥mo trabaja HCatalog? HCatalog apoya la lectura y la escritura de archivos en cualquier formato para el que Hive SerDe funcione. Por defecto HCatalog soporta los siguientes formatos: RCFile, CSV, JSON y SequenceFile. Para utilizar un formato personalizado se debe proporcionar el formato de entrada, el de salida y el SerDe. [34] HCatalog se construye en la parte superior de Hive e incorpora componentes DDL de Hive. HCatalog proporciona interfaces de lectura y escritura interfaces para Pig y MapReduce y usa la interfaz de l√≠nea de comandos de Hive para la emisi√≥n de comando para la definici√≥n y exploraci√≥n de datos. Tambi√©n presenta una interfaz REST para permitir a las herramientas externas el acceso a las operaciones DDL (Data Definition Language) de Hive, como "create table" y "describe table". [34] HCatalog presenta una vista relacional de datos. Los datos se almacenan en tablas y estas tablas se pueden colocar en las bases de datos. Las tablas tambi√©n se pueden dividir en una o m√°s claves. Para un valor dado de una clave (o conjunto de claves) habr√° una partici√≥n que contiene todas las filas con ese valor (o conjunto de valores). [34] 2.4.5.4. Apache Spark A medida que la relaci√≥n de la memoria a la potencia de procesamiento evoluciona r√°pidamente, muchos dentro de la comunidad Cap√≠tulo 2. Marco Conceptual 70 Hadoop est√°n gravitando hacia Apache Spark para procesamiento r√°pido de datos en memoria.[35] Apache Spark es un framework de c√≥digo abierto para an√°lisis de datos en cl√∫steres, desarrollado originalmente en el AMPLab en UC Berkeley. [36] Spark encaja en la comunidad de c√≥digo abierto Hadoop, sobre la parte superior del sistema de archivos distribuido Hadoop (HDFS). Sin embargo, Spark no est√° ligado al paradigma MapReduce de dos etapas, y promete un rendimiento de hasta 100 veces m√°s r√°pido que Hadoop MapReduce para ciertas aplicaciones.[36] Spark proporciona primitivas para la computaci√≥n de cl√∫steres en memoria que permite a los programas de usuario cargar datos en un la memoria de cl√∫steres y consultarla varias veces, por lo que es muy adecuado para los algoritmos de aprendizaje autom√°tico. [36] Apache Spark permite a los cient√≠ficos de datos implementar de manera efectiva y simple algoritmos iterativos para an√°lisis avanzados como la agrupaci√≥n y clasificaci√≥n de conjuntos de datos. Actualmente es un proyecto Apache nivel superior y se est√° convirtiendo en una alternativa atractiva para ejecutar algunas cargas discretas de trabajo de ciencia de datos. [35] 2.4.5.5. Apache Flume Apache Flume es un servicio disponible, distribuido y confiable para la recolecci√≥n, agregaci√≥n y el movimiento de manera eficiente de grandes cantidades de datos en el sistema de archivos distribuidos de Hadoop (HDFS). Cuenta con una arquitectura simple y flexible basada en la transmisi√≥n de flujos de datos; es robusto y tolerante a fallos con mecanismos de confiabilidad sintonizables para la conmutaci√≥n por error y recuperaci√≥n. [38] ¬øQu√© hace Flume? Flume permite a los usuarios de Hadoop sacar mayor provecho a los datos de registro con mayor valor. En concreto, Flume permite a los usuarios hacer: Cap√≠tulo 2. Marco Conceptual 71 1. Secuencias de datos a partir de m√∫ltiples fuentes en Hadoop para el an√°lisis. [38] 2. Recoger registros Web de alto volumen en tiempo real. [38] 3. Aislarse de picos transitorios cuando la tasa de datos entrantes excede la tasa a la que los datos se pueden escribir en el destino. [38] 4. Garant√≠a en la entrega de datos. [38] 5. Escala horizontal para manejar el volumen de datos adicional. [38] ¬øC√≥mo funciona Flume? La arquitectura de alto nivel de Flume se centra en la entrega de una base de c√≥digo optimizada que es f√°cil de usar y f√°cil de extender. El equipo del proyecto ha dise√±ado Flume con los siguientes componentes: a) Event - una unidad singular de los datos que se transporta por el canal de flujo (por lo general una sola entrada de registro). [38] b) Source - la entidad a trav√©s de la cual los datos de entrada en Flume. Source o bien sondea activamente para datos o pasivamente espera que los datos sean entregados a ellos. [38] c) Sink - la entidad que entrega los datos al destino. [38] d) Channel - el conducto entre el Source y el Sink. Source ingieren Events en el Channel y los Sinks drenan el Channel. [38] e) Agent - cualquier m√°quina virtual f√≠sica Java que ejecute Flume. Se trata de una colecci√≥n de Source, Sink y Channel. [38] f) Client - produce y transmite el Event a Source que opera dentro del Agent. [38] Un flujo de Flume se inicia desde el Client. El Client transmite el Event a una Source que opera dentro del Agent. La Source de recibir este Event lo entrega a uno o m√°s Channels. Estos Channels son drenados por uno o m√°s Sinks que operan dentro del mismo Agent. [38] 2.4.5.6. Hue Hue es una interfaz Web para analizar datos con Apache Hadoop. Es compatible con un explorador de archivos y trabajos, Hive, Pig, Impala, Cap√≠tulo 2. Marco Conceptual 72 Spark, editores oozie, Solr Search cuadros de mando, HBase, Sqoop2, y m√°s.[39] Hue cuenta con: ÔÇ∑ Explorador de archivos para acceder a HDFS ÔÇ∑ Editor Hive para desarrollar y ejecutar consultas Hive ÔÇ∑ Search App para consultar, explorar, visualizar datos y cuadros de mando con Solr ÔÇ∑ Impala App para ejecutar consultas SQL interactivas ÔÇ∑ Spark Editor y Dashboard ÔÇ∑ Editor Pig para la presentaci√≥n de scripts Pig ÔÇ∑ Editor Oozie y Dashboard para la presentaci√≥n y seguimiento de flujos de trabajo, de coordinadores y de los paquetes ÔÇ∑ HBase Browser para visualizar, consultar y modificar tablas HBase ÔÇ∑ MetaStore Browser para acceder a los metadatos de Hive y HCatalog ÔÇ∑ Navegador de empleo para acceder a puestos de trabajo de MapReduce (MR1/MR2-YARN) ÔÇ∑ Dise√±ador de trabajos para la creaci√≥n de trabajos MapReduce/Streaming/Java ÔÇ∑ Un editor y dashboard para Sqoop 2 ÔÇ∑ Un navegador y editor ZooKeeper ÔÇ∑ Un editor de consultas DB para MySql, Postgres, SQLite y Oracle 2.4.5.7. Apache ZooKeeper Escribir aplicaciones distribuidas es dif√≠cil. Es complicado principalmente debido a las fallas parciales. Cuando es enviado un mensaje a trav√©s de la red entre dos nodos y la red falla, el remitente no sabe si el receptor recibi√≥ el mensaje. La √∫nica manera de que el emisor pueda saber si se recibi√≥ el mensaje o no es reconectarse con el receptor y preguntarle. Este es el fracaso parcial, cuando no se sabe si una operaci√≥n ha fallado. [40] Apache ZooKeeper es un servidor de c√≥digo abierto que coordina de forma fiable procesos distribuidos. [40] Apache ZooKeeper ofrece servicios operativos para un cl√∫ster Hadoop. ZooKeeper ofrece un servicio de configuraci√≥n distribuida, un Cap√≠tulo 2. Marco Conceptual 73 servicio de sincronizaci√≥n y un registro de denominaci√≥n para los sistemas distribuidos. Las aplicaciones distribuidas utilizan Zookeeper para almacenar y mediar cambios a la informaci√≥n de configuraci√≥n importante. [40] ZooKeeper no puede hacer que las fallas parciales se vayan, ya que son intr√≠nsecos al sistema distribuido. Ciertamente tampoco esconde los fracasos parciales. Pero lo que hace ZooKeeper es proporcionar un conjunto de herramientas para construir aplicaciones distribuidas que puedan manejar de forma segura los fracasos parciales. [40] ZooKeeper tambi√©n tiene las siguientes caracter√≠sticas: ZooKeeper es simple. ZooKeeper es, en su esencia, un sistema de archivos que expone algunas simples operaciones, y algunas abstracciones adicionales, tales como ordenaciones y notificaciones. [40] ZooKeeper es expresivo. Las primitivas ZooKeeper son un rico conjunto de bloques de construcci√≥n que se puede utilizar para construir una gran clase de estructuras de datos y protocolos de coordinaci√≥n. Los ejemplos incluyen: colas distribuidas, cerraduras distribuidas y elecci√≥n de un l√≠der entre un grupo de compa√±eros. [40] ZooKeeper es altamente disponible. ZooKeeper se ejecuta en una colecci√≥n de m√°quinas y est√° dise√±ado para ser altamente disponible, por lo que las aplicaciones pueden depender de √©l. [40] ZooKeeper facilita las interacciones d√©bilmente acopladas. Las interacciones de ZooKeeper apoyan a los participantes que no necesitan saber acerca de otros. Por ejemplo, ZooKeeper se puede utilizar como un mecanismo de encuentro de manera que los procesos que no saben de la existencia de otros (o detalles de la red) puedan descubrir e interactuar con los dem√°s. Las partes de coordinaci√≥n pueden incluso no ser contempor√°neas, ya que un proceso puede dejar un mensaje en ZooKeeper el cual puese ser le√≠do por otro despu√©s de que el primero se haya apagado. [40] ZooKeeper es una biblioteca. ZooKeeper proporciona un repositorio compartido de implementaciones y recetas de patrones de coordinaci√≥n comunes, de c√≥digo abierto. Los programadores individuales se esparcen la carga de la escritura protocolos comunes entre ellos mismos (que a menudo son dif√≠ciles de conseguir de manera correcta). Con el tiempo, la comunidad Cap√≠tulo 2. Marco Conceptual 74 puede aumentar y mejorar las bibliotecas, que es para beneficio de todos. [40] ZooKeeper es de gran rendimiento tambi√©n. En Yahoo!, donde fue creado, el rendimiento para un cl√∫ster ZooKeeper se ha evaluado en m√°s de 10.000 operaciones por segundo para cargas de trabajo de escritura dominante generados por cientos de clientes. Para cargas de trabajo donde la lectura domina, que es la norma, el rendimiento es varias veces alto.[40] ¬øQu√© hace ZooKeeper? ZooKeeper proporciona una interfaz muy simple y servicios. ZooKeeper trae los siguientes beneficios clave: a) R√°pido. ZooKeeper es especialmente r√°pido con cargas de trabajo donde la lectura de los datos es m√°s com√∫n que la escritura. La proporci√≥n ideal de lectura/escritura es de aproximadamente 10: 1. [40] b) Fiable. ZooKeeper se replica a trav√©s de una serie de hosts (llamado un conjunto) y los servidores son conscientes unos de otros. Mientras una masa cr√≠tica de servidores est√° disponible, el servicio ZooKeeper tambi√©n estar√° disponible. No hay ning√∫n punto √∫nico de fallo. [40] c) Sencillo. ZooKeeper mantiene un espacio de nombres jer√°rquico est√°ndar, similar a los archivos y directorios. d) Ordenado. El servicio mantiene un registro de todas las transacciones, que se pueden utilizar para abstracciones de nivel superior, como primitivas de sincronizaci√≥n. ¬øC√≥mo trabaja ZooKeeper? ZooKeeper permite procesos distribuidos para coordinar entre s√≠ a trav√©s de un espacio de nombres jer√°rquico compartido de registros de datos, conocidos como znodes. Cada znode se identifica por un camino, con elementos de ruta separados por una barra ("/"). Aparte de la ra√≠z, cada znode tiene un padre y un znode no puede ser eliminado si tiene hijos. [40] Esto es muy similar a un sistema de archivos normal, pero ZooKeeper ofrece una fiabilidad superior a trav√©s de servicios redundantes. Un servicio Cap√≠tulo 2. Marco Conceptual 75 se replica a trav√©s de una serie de m√°quinas y cada uno mantiene una imagen en memoria de los √°rboles de los datos y de transacciones. Los clientes se conectan a un √∫nico servidor ZooKeeper y mantienen una conexi√≥n TCP a trav√©s del cual env√≠an peticiones y reciben respuestas. [40] Esta arquitectura permite a ZooKeeper proporcionar un alto rendimiento y disponibilidad con baja latencia, pero el tama√±o de la base de datos que puede gestionar ZooKeeper est√° limitado por la memoria. [40] 2.4.5.8. Shark Shark es un sistema de almacenamiento de datos a gran escala para Spark dise√±ado para ser compatible con Apache Hive. Puede ejecutar consultas Hive QL hasta 100 veces m√°s r√°pido que Hive sin ninguna modificaci√≥n a los datos o consultas existentes. Shark soporta el lenguaje de consulta Hive, MetaStore, formatos de serializaci√≥n, y funciones definidas por el usuario, proporcionando una integraci√≥n perfecta con los despliegues Hive existentes y una opci√≥n familiar, m√°s potente para los nuevos. [41] Shark se construye en la parte superior de Spark, un motor de ejecuci√≥n de datos en paralelo que es r√°pido y de alta disponibilidad. Incluso si los datos est√°n en el disco, Shark puede ser notablemente m√°s r√°pido que Hive debido al motor de ejecuci√≥n r√°pida. Evita la tarea lanzamiento de alta sobrecarga de Hadoop MapReduce y no requiere la materializaci√≥n de datos intermedios entre las etapas en el disco. Gracias a este motor r√°pido, Shark puede responder a las consultas en menos de un segundo de latencia. [41] Las consultas anal√≠ticas por lo general se centran en un subgrupo en particular o en una ventana de tiempo, por ejemplo, los registros de HTTP desde el mes anterior, tocando solamente las tablas de dimensiones y una peque√±a porci√≥n de la tabla de hechos. Estas consultas tienen una fuerte localidad temporal, y en muchos casos, es plausible para encajar el conjunto de trabajo en la memoria de un cl√∫ster. Shark permite a los usuarios explotar esta localidad temporal mediante el almacenamiento de su conjunto de trabajo de datos a trav√©s de la memoria de un grupo, o en t√©rminos de base de datos, para crear en memoria vistas materializadas.[41] Cap√≠tulo 2. Marco Conceptual 76 2.4.5.9. Apache Sqoop Apache Sqoop es una herramienta dise√±ada para transferir datos de manera eficiente a granel entre Hadoop y almacenes de datos estructurados como bases de datos relacionales. Sqoop importa datos de almacenes estructurados externos dentro de los sistemas HDFS o cualquier medio de almacenamiento que se utilice, como Hive y HBase. Sqoop tambi√©n se puede utilizar para extraer datos de Hadoop y exportarlo a almacenes estructurados externos tales como bases de datos relacionales y almacenes de datos empresariales. Sqoop trabaja con bases de datos relacionales, tales como: Teradata, Netezza, Oracle, MySQL, Postgres, y HSQLDB. [42] ¬øQu√© hace Sqoop? Est√° dise√±ado para transferir datos de manera eficiente a granel entre Hadoop y almacenes estructurados como bases de datos relacionales, Apache Sqoop: ÔÇ∑ Permite la importaci√≥n de datos de almacenes externos y almacenes de datos empresariales en Hadoop [42] ÔÇ∑ Paraleliza la transferencia de datos para un rendimiento r√°pido y la utilizaci√≥n √≥ptima del sistema [42] ÔÇ∑ Copia datos r√°pidamente de sistemas externos a Hadoop [42] ÔÇ∑ Hace un an√°lisis de datos m√°s eficiente [42] ÔÇ∑ Mitiga cargas excesivas a sistemas externos. [42] ¬øC√≥mo trabaja Sqoop? Sqoop proporciona un mecanismo conector enchufable para una √≥ptima conectividad a sistemas externos. La API de extensi√≥n de Sqoop proporciona un marco conveniente para la construcci√≥n de nuevos conectores que pueden ser ignorados en las instalaciones de Sqoop para proporcionar conectividad a varios sistemas. Sqoop s√≠ viene incluido con varios conectores que pueden ser utilizados para los sistemas de base de datos y almacenes de datos populares. [42] Cap√≠tulo 2. Marco Conceptual 77 2.4.6. Distribuciones Hadoop La arquitectura flexible y modular de hadoop permite a√±adir nuevas funcionalidades para la realizaci√≥n de diversas tareas de Big Data. Un n√∫mero de vendedores han aprovechado el framework de composici√≥n abierta de Hadoop ajustando sus c√≥digos para cambiar o mejorar sus funcionalidades. En el proceso han sido capaces de solucionar algunos de los inconvenientes inherentes de Hadoop. En lo que se refiere a las distribuciones de Hadoop, las tres empresas que realmente se destacan en la terminaci√≥n son: Cloudera, MapR y Hortonworks. [20] Cloudera ha estado presente por mucho m√°s tiempo, desde la creaci√≥n de Hadoop. Hortonworks vino despu√©s. Mientras Cloudera y Hortonworks son 100 por ciento de c√≥digo abierto, la mayor√≠a de las versiones de MapR vienen con m√≥dulos propietarios. [20] 2.4.6.1. MapR MapR reemplaza el componente HDFS y en su lugar utiliza su propio sistema de archivo propietario, llamado MapRFS. MapRFS ayuda a incorporar caracter√≠sticas de nivel empresarial en Hadoop, lo que permite una gesti√≥n m√°s eficiente de los datos, fiabilidad y lo m√°s importante, la facilidad de uso. [20] A trav√©s de una alianza con Canonical, el creador del sistema operativo Ubuntu, MapR est√° ofreciendo Hadoop como un componente predeterminado del sistema operativo Ubuntu. Bajo los t√©rminos de la alianza, la edici√≥n M3 de MapR para Hadoop se integrar√° en el sistema operativo Ubuntu. [20] 2.4.6.2. Cloudera Cloudera Inc. fue fundada por los genios de Big Data de Facebook, Google, Oracle y Yahoo en 2008. Fue la primera empresa en desarrollar y distribuir software basado en Apache Hadoop y todav√≠a tiene la mayor base de usuarios con mayor n√∫mero de clientes. Aunque el n√∫cleo de la distribuci√≥n est√° basado en Hadoop, tambi√©n proporciona una Suite de Cap√≠tulo 2. Marco Conceptual 78 gesti√≥n propietaria llamada Management Suite Cloudera para automatizar el proceso de instalaci√≥n y proporcionar otros servicios para mejorar la comodidad de los usuarios, que incluyen la reducci√≥n de tiempo de implementaci√≥n, mostrando recuento nodos en tiempo real, etc. [20] 2.4.6.3. Hortonworks Hortonworks, fundada en 2011, se ha convertido r√°pidamente en uno de los principales proveedores de Hadoop. La distribuci√≥n proporciona la plataforma de c√≥digo abierto basado en Hadoop para analizar, almacenar y gestionar grandes vol√∫menes de datos. Hortonworks es el √∫nico proveedor comercial para distribuir c√≥digo abierto completamente Hadoop sin software propietario adicional. La distribuci√≥n 2.0 de Hadoop Data Platform (HDP2.0) de Hortonworks se puede descargar directamente desde su p√°gina web de forma gratuita y es f√°cil de instalar. Los ingenieros de Hortonworks est√°n detr√°s de la mayor√≠a de las innovaciones recientes de Hadoop incluido YARN, que es mejor que MapReduce en el sentido de que permitir√° inclusi√≥n de m√°s frameworks para el procesamiento de datos. [20] 2.4.6.4 Comparaci√≥n entre Hortonworks y Cloudera 2.4.6.4.1. Similitudes ÔÇ∑ Ofrecen distribuciones de Hadoop listas para la empresa. Las distribuciones han resistido la prueba del tiempo, as√≠ como los consumidores, garantizando la seguridad y la estabilidad. Adem√°s, proporcionan servicios de capacitaci√≥n y familiarizaci√≥n pagos a los reci√©n llegados que pisan el camino de Big Data. ÔÇ∑ Han establecido comunidades que participan de forma activa y ayudan con los problemas que enfrentan. ÔÇ∑ Ambas distribuciones tienen una arquitectura maestro-esclavo. ÔÇ∑ Soportan y dan apoyo a MapReduce as√≠ como a YARN. Cap√≠tulo 2. Marco Conceptual 79 2.4.6.4.2. Diferencias ÔÇ∑ Cloudera ha anunciado que su objetivo a largo plazo es convertirse en un "centro de datos empresariales", disminuyendo as√≠ la necesidad de almacenamiento de datos. Hortonworks, por el contrario, sigue siendo firmemente un proveedor de Hadoop, y se ha asociado con la compa√±√≠a de almacenamiento de datos Teradata. ÔÇ∑ Mientras Cloudera CDH se puede ejecutar en un servidor de Windows, HDP est√° disponible como un componente nativo en un servidor de Windows. Un cluster Hadoop basado en Windows se puede implementar en Windows Azure a trav√©s del Servicio HDInsight. ÔÇ∑ Cloudera tiene un software de gesti√≥n propietario llamado Cloudera Manager, una interfaz de manejo de consulta SQL llamada Impala y Cloudera Search qu√© es un acceso f√°cil y en tiempo real de los productos. Hortonworks no tiene software propietario, utiliza Ambari para la gesti√≥n y Stinger para el manejo de consultas y Apache Solr para b√∫squedas de datos. ÔÇ∑ Cloudera tiene uso comercial, mientras Hortonworks tiene licencia de c√≥digo abierto. ÔÇ∑ Cloudera tambi√©n permite el uso de sus proyectos de c√≥digo abierto de manera gratuita, pero el paquete no incluye la suite de gesti√≥n de Cloudera Manager o cualquier otro software propietario. ÔÇ∑ Cloudera tiene una prueba gratuita de 60 d√≠as, Hortonworks es totalmente gratuito. Cap√≠tulo 2. Marco Conceptual 80 2.4.6.5. Comparaci√≥n general Hortonworks Cloudera MapR Rendimiento Ingreso de datos Por lotes Por lotes Por lotes y escritura de tipo streaming Arquitectura de los metadatos Centralizada Centralizada Distribuida Rendimiento de HBase Picos en latencia Picos en latencia Consistente de baja latencia Aplicaciones NoSQL Principalmente aplicaciones con datos por lotes Principalmente aplicaciones con datos por lotes Aplicaciones con datos por lotes y de tiempo real Dependencia Alta disponibilidad Recuperaci√≥n de fallas simples Recuperaci√≥n de fallas simples Auto recuperaci√≥n a trav√©s de m√∫ltiples fallas Replicaci√≥n Datos Datos Datos y meta- datos Recuperaci√≥n tras cat√°strofe No Planificaci√≥n de copia de archivos (BDR) Mirroring Manejabilidad Herramientas de manejo Ambari Cloudera Manager MapR Control System Integraci√≥n con API¬¥s REST S√≠ S√≠ S√≠ Acceso a los Datos Acceso al HDFS, s√≥lo HDFS, s√≥lo HDFS, lectura y Cap√≠tulo 2. Marco Conceptual 81 Sistema de Archivos lectura NFS lectura NFS escritura NFS Entrada y Salida de Archivos S√≥lo Append S√≥lo Append Lectura y escritura Autenticaci√≥n Kerberos Kerberos Kerberos y Nativa Tabla 2: Comparaci√≥n de las principales distribuciones de Hadoop 82 3. M√©todo de Desarrollo Para el desarrollo de software de manera eficiente se emplean m√©todos de desarrollo acorde a los requerimientos que amerite el software. Dentro del conjunto de m√©todos de desarrollo de Software, existen unos para el desarrollo √°gil, estos tienen como objetivo fundamental minimizar las actividades que no se considera relevantes, aumentar la productividad del equipo de desarrollo y elevar la adaptabilidad del resultado. En este cap√≠tulo se describen algunos t√≥picos requeridos para el desarrollo del Trabajo Especial de Grado. Entre estos t√≥picos se encuentran el Manifiesto √Ågil y m√©todos √°giles Ad Hoc. 3.1. Manifiesto √Ågil El 17 de febrero de 2001 diecisiete cr√≠ticos de los modelos de mejora del desarrollo de software basados en procesos, convocados por Kent Beck, quien hab√≠a publicado un par de a√±os antes Extreme Programming Explained, libro en el que expon√≠a una nueva metodolog√≠a denominada Extreme Programming, se reunieron en Snowbird, Utah para tratar sobre t√©cnicas y procesos para desarrollar software. En la reuni√≥n se acu√±√≥ el t√©rmino ‚ÄúM√©todos √Ågiles‚Äù para definir a los m√©todos que estaban surgiendo como alternativa a las metodolog√≠as formales (CMMI, SPICE) a las que consideraban excesivamente ‚Äúpesadas‚Äù y r√≠gidas por su car√°cter normativo y fuerte dependencia de planificaciones detalladas previas al desarrollo. Los integrantes de la reuni√≥n resumieron los principios sobre los que se basan los m√©todos alternativos en cuatro postulados, lo que ha quedado denominado como Manifiesto √Ågil. [21] Cap√≠tulo 3. M√©todo de Desarrollo 83 3.1.1. Principios del Manifiesto √Ågil ÔÇ∑ Nuestra mayor prioridad es satisfacer al cliente mediante la entrega temprana y continua de software con valor. ÔÇ∑ Aceptamos que los requisitos cambien, incluso en etapas tard√≠as del desarrollo. Los procesos √Ågiles aprovechan el cambio para proporcionar ventaja competitiva al cliente. ÔÇ∑ Entregamos software funcional frecuentemente, entre dos semanas y dos meses, con preferencia al periodo de tiempo m√°s corto posible. ÔÇ∑ Los responsables de negocio y los desarrolladores trabajamos juntos de forma cotidiana durante todo el proyecto. ÔÇ∑ Los proyectos se desarrollan en torno a individuos motivados. Hay que darles el entorno y el apoyo que necesitan, y confiarles la ejecuci√≥n del trabajo. ÔÇ∑ El m√©todo m√°s eficiente y efectivo de comunicar informaci√≥n al equipo de desarrollo y entre sus miembros es la conversaci√≥n cara a cara. ÔÇ∑ El software funcionando es la medida principal de progreso. ÔÇ∑ Los procesos √Ågiles promueven el desarrollo sostenible. Los promotores, desarrolladores y usuarios debemos ser capaces de mantener un ritmo constante de forma indefinida. ÔÇ∑ La atenci√≥n continua a la excelencia t√©cnica y al buen dise√±o mejora la Agilidad. ÔÇ∑ La simplicidad, o el arte de maximizar la cantidad de trabajo no realizado, es esencial. ÔÇ∑ Las mejores arquitecturas, requisitos y dise√±os emergen de equipos auto-organizados. ÔÇ∑ A intervalos regulares el equipo reflexiona sobre c√≥mo ser m√°s efectivo para a continuaci√≥n ajustar y perfeccionar su comportamiento en consecuencia. 3.2. M√©todos √Ågiles El desarrollo √°gil de software refiere a m√©todos de ingenier√≠a del software basados en el desarrollo iterativo e incremental, donde los requisitos y soluciones evolucionan mediante la colaboraci√≥n de grupos auto Cap√≠tulo 3. M√©todo de Desarrollo 84 organizados y multidisciplinarios. Existen muchos m√©todos de desarrollo √°gil; la mayor√≠a minimiza riesgos desarrollando software en lapsos cortos. El software desarrollado en una unidad de tiempo es llamado una iteraci√≥n, la cual debe durar de una a cuatro semanas. Cada iteraci√≥n del ciclo de vida incluye: planificaci√≥n, an√°lisis de requisitos, dise√±o, codificaci√≥n, revisi√≥n y documentaci√≥n. Una iteraci√≥n no debe agregar demasiada funcionalidad para justificar el lanzamiento del producto al mercado, sino que la meta es tener una ‚Äúdemo‚Äù (sin errores) al final de cada iteraci√≥n. Al final de cada iteraci√≥n el equipo vuelve a evaluar las prioridades del proyecto. Los m√©todos √°giles enfatizan las comunicaciones cara a cara en vez de la documentaci√≥n. La mayor√≠a de los equipos √°giles est√°n localizados en una simple oficina abierta, a veces llamadas "plataformas de lanzamiento" (bullpen en ingl√©s). La oficina debe incluir revisores, escritores de documentaci√≥n y ayuda, dise√±adores de iteraci√≥n y directores de proyecto. Los m√©todos √°giles tambi√©n enfatizan que el software funcional es la primera medida del progreso. Combinado con la preferencia por las comunicaciones cara a cara, generalmente los m√©todos √°giles son criticados y tratados como "indisciplinados" por la falta de documentaci√≥n t√©cnica. [22] 3.2.1. Metodolog√≠a Ad Hoc orientada a prototipos Antes de hablar de una metodolog√≠a Ad hoc se debe explicar que significa ad hoc. Ad hoc es una locuci√≥n latina que significa literalmente ‚Äúpara esto‚Äù. [23] Generalmente se refiere a una soluci√≥n espec√≠ficamente elaborada para un problema o fin preciso y, por tanto, no generalizable ni utilizable para otros prop√≥sitos. Se usa pues para referirse a algo que es adecuado s√≥lo para un determinado fin o en una determinada situaci√≥n. Cuando hablamos de una metodolog√≠a de desarrollo de software Ad hoc se refiere a una metodolog√≠a particular para un determinado problema tomando en cuenta aspectos como el n√∫mero de desarrolladores, el objetivo a cumplir, entre otros. https://en.wikipedia.org/wiki/bullpen Cap√≠tulo 3. M√©todo de Desarrollo 85 Para el desarrollo particular de esta aplicaci√≥n se adecuo de manera tal que no se necesitar√≠a ning√∫n artefacto entregable y se manejar√≠a en base a prototipos funcionales o no cumpliendo los distintos objetivos plasmados para esa entrega. Dependiendo de los resultados obtenidos por cada prototipo se generar√°n nuevos objetivos o se eliminaran anteriores para el siguiente prototipo. Se manejan dos roles para este desarrollo. El rol de l√≠der, el cual se encarga de liderizar el desarrollo. Sus actividades principales son las de definir los objetivos, verificar los resultados de cada prototipo y estimar el tiempo de desarrollo de cada prototipo. El segundo rol es el de desarrollador, el cual se encarga de desarrollar valga la redundancia. Su actividad principal es la de completar los objetivos plasmados por el l√≠der. En la entrega de cada prototipo ambos roles pueden discutir sobre los objetivos siguientes o los anteriores, tomando en cuenta la opini√≥n de cada ente. En la siguiente figura se ejemplifica el ciclo de desarrollo de cada prototipo. Figura 19: Ciclo de la metodolog√≠a utilizada Analisis de Objetivos para el prototipo Preparaci√≥n de soluci√≥n Verificaci√≥n de resultados Despliegue del Prototipo Cap√≠tulo 3. M√©todo de Desarrollo 86 En la fase de an√°lisis los dos roles involucrados discuten sobre los objetivos a cumplir para el prototipo. En la siguiente fase el desarrollador ejecuta los objetivos planteados en la fase anterior, luego se verifican los resultados y se hace el despliegue del mismo. Las conclusiones obtenidas sirven para la fase de an√°lisis del siguiente prototipo. 87 4. Desarrollo de la Soluci√≥n Para el desarrollo de la aplicaci√≥n son necesarios dos ambientes, el primero es el cl√∫ster basado en Hadoop d√≥nde se ejecutaran los algoritmos MapReduce y el segundo es el ambiente de desarrollo como tal en el cual se ejecutar√° la aplicaci√≥n. En ambos es necesaria la instalaci√≥n de R debido a que en ese lenguaje se desarroll√≥ la aplicaci√≥n. En estos dos ambientes se tienen que configurar con las librer√≠as, herramientas y paquetes necesarios para el funcionamiento correcto de la aplicaci√≥n. A continuaci√≥n se listan en detalle las configuraciones necesarias que se realizaron para el desarrollo de la aplicaci√≥n. 4.1. Cl√∫ster En lo que se refiere al cl√∫ster basado en Hadoop s√≥lo se necesita la instalaci√≥n de R en cada nodo. 4.1.1. Instalaci√≥n de R Para la instalaci√≥n de R en cada nodo se siguen los siguientes pasos (ver anexo 1). Junto con R son necesarios dos paquetes junto con sus dependencias los cuales se listan a continuaci√≥n: 4.1.1.1. Instalaci√≥n de rmr Para la instalaci√≥n del paquete rmr en cada nodo primero se deben instalar sus dependencias y luego seguir los pasos que se reflejan en el anexo 1. 4.1.1.2. Instalaci√≥n de rhdfs Para la instalaci√≥n del paquete rhdfs en cada nodo primero se deben instalar sus dependencias y luego seguir los pasos que se reflejan en el anexo 1. Cap√≠tulo 4. Desarrollo de la Soluci√≥n 88 4.2. Ambiente de Desarrollo En lo que se refiere al ambiente de desarrollo de la aplicaci√≥n si son necesarias m√°s instalaciones en comparaci√≥n con el cl√∫ster. A continuaci√≥n se listan y se describen las mismas. 4.2.1. Instalaci√≥n de GTK+ Para poder crear widgets es necesaria la herramienta GTK+. Para ver el proceso de instalaci√≥n por favor v√©ase el anexo 2. Cabe resaltar que esta especificaci√≥n solamente aplica para sistemas operativos Linux, en sistemas operativos Windows no es necesaria debido a que se instala autom√°ticamente al instalar el paquete gWidgets2 en R. 4.2.2. Instalaci√≥n de R La instalaci√≥n de R es necesaria en el ambiente local en el anexo 3 se especifican los pasos a seguir para instalar el mismo. 4.2.2.1. Instalaci√≥n de R-Studio R-Studio es la interfaz gr√°fica para el desarrollo de proyectos en R. Su instalaci√≥n se especifica en el anexo 4. 4.2.2.2. Instalaci√≥n y actualizaci√≥n de paquetes A diferencia del cl√∫ster que s√≥lo necesita dos paquetes, en el ambiente de desarrollo se necesitan muchos m√°s. A continuaci√≥n se listan los paquetes necesarios instalados, la forma en la que se instal√≥ y la funci√≥n de cada uno: ÔÇ∑ gWidgets2: Se instala ejecutando el siguiente comando en una consola de R: install.packages('gWidgets2', dependencies = TRUE). V√©ase el capitulo dos para m√°s detalles del paquete. ÔÇ∑ RGtk2: Es un paquete en el lenguaje R para el desarrollo de interfaces gr√°ficas utilizando GTK. Se instala ejecutando el Cap√≠tulo 4. Desarrollo de la Soluci√≥n 89 siguiente comando en una consola de R: install.packages('RGtk2', dependencies = TRUE). ÔÇ∑ gWidgets2RGtk2: Es el puerto de conexi√≥n entre el API gWidgets2 hacia RGtk2. Se instala ejecutando el siguiente comando en una consola de R: install.packages('gWidgets2RGtk2', dependencies = TRUE). ÔÇ∑ FactoMineR: Es un paquete que contiene m√©todos para el an√°lisis exploratorio de datos, tales como los m√©todos de componentes principales y de clustering. Se instala ejecutando el siguiente comando en una consola de R: install.packages('FactoMineR', dependencies = TRUE). ÔÇ∑ kknn: Paquete que contiene el m√©todo k vecinos m√°s cercanos. Se instala ejecutando el siguiente comando en una consola de R: install.packages('kknn', dependencies = TRUE). ÔÇ∑ e1071: Paquete que contiene funciones para el an√°lisis de datos tales como: transformada de Fourier, fuzzy clustering, m√°quinas de vectores soporte, c√°lculo de camino m√°s corto, bagged clustering, clasificador naive Bayes, entre otros. Se instala ejecutando el siguiente comando en una consola de R: install.packages('e1071', dependencies = TRUE). ÔÇ∑ MASS: Contiene funciones y conjuntos de datos para su posterior an√°lisis. Se instala ejecutando el siguiente comando en una consola de R: install.packages('MASS', dependencies = TRUE). ÔÇ∑ class: Contiene varias funciones para la clasificaci√≥n. Se instala ejecutando el siguiente comando en una consola de R: install.packages('class', dependencies = TRUE). ÔÇ∑ rpart: Provee particionamiento recursivo para √°rboles de clasificaci√≥n, regresi√≥n y supervivencia .Se instala ejecutando el Cap√≠tulo 4. Desarrollo de la Soluci√≥n 90 siguiente comando en una consola de R: install.packages('rpart', dependencies = TRUE). ÔÇ∑ rpart.plot: Paquete para gr√°ficar los modelos generados con rpart. Se instala ejecutando el siguiente comando en una consola de R: install.packages('rpart.plot', dependencies = TRUE). ÔÇ∑ randomForest: Provee bosques aleatorios para la clasificaci√≥n y regresi√≥n. Se instala ejecutando el siguiente comando en una consola de R: install.packages('randomForest', dependencies = TRUE). ÔÇ∑ nnet: Software para redes neuronales con una sola capa oculta, y para los modelos multinomiales. Se instala ejecutando el siguiente comando en una consola de R: install.packages('nnet', dependencies = TRUE). 4.2.3. Instalaci√≥n de Openssh y sshpass Para la comunicaci√≥n entre el ambiente de desarrollo y el cl√∫ster es necesario utilizar el protocolo Secure Shell (SSH) el cual se obtiene instalando la aplicaci√≥n Openssh y sshpass como se ve en el anexo 5. Esta instalaci√≥n s√≥lo es v√°lida para los sistemas operativos basados en Linux debido a que estos programas son netos de estos sistemas. 4.3. Aplicaci√≥n Despu√©s de tener ambos ambientes completamente configurados se empez√≥ con el desarrollo de la aplicaci√≥n utilizando la metodolog√≠a previamente definida. Como se dijo anteriormente esta metodolog√≠a consist√≠a de la realizaci√≥n de prototipos funcionales o no utilizando el lenguaje de programaci√≥n R. A continuaci√≥n se listan todos los prototipos desarrollados con sus objetivos, resultados y conclusiones: Cap√≠tulo 4. Desarrollo de la Soluci√≥n 91 4.3.1. Prototipo 0 Este prototipo se bas√≥ en la exploraci√≥n de las herramientas que provee R y sus paquetes para la realizaci√≥n de widgets, por esto previo a trazar objetivos se realiz√≥ una exploraci√≥n a fondo del paquete gWidgets. Figura 20: Ejemplo de widget utilizando R con el paquete gWidgets Luego de realizar esta exploraci√≥n se procedi√≥ a la primera reuni√≥n con el fin de establecer los objetivos para el primer prototipo. 4.3.1.1. Objetivos 1. Crear una interfaz gr√°fica utilizando R y el paquete gWidgets 2. Ejecutar el m√©todo K medias sobre un conjunto de datos provenientes de un archivo con valores separados por coma. 3. Ejecutar el m√©todo An√°lisis de componentes principales sobre un conjunto de datos provenientes de un archivo con valores separados por coma. 4. Ejecutar el m√©todo de cl√∫ster jer√°rquico sobre un conjunto de datos provenientes de un archivo con valores separados por coma. 4.3.1.2. Resultados Para el primer objetivo se logro crear una interfaz sencilla con una barra de herramientas, un toolbar y tres secciones, una para cada m√©todo. En cada secci√≥n se requieren los par√°metros necesarios para cada m√©todo V√©anse las Figuras 21, 22 y 23. Cap√≠tulo 4. Desarrollo de la Soluci√≥n 92 Figura 21: Secci√≥n K-medias del Prototipo 0 Figura 22: Secci√≥n de An√°lisis de Componentes Principales del Prototipo 0 Cap√≠tulo 4. Desarrollo de la Soluci√≥n 93 Figura 23: Secci√≥n Cl√∫ster Jer√°rquico del Prototipo 0 Para el segundo objetivo se utilizaron funciones de R para realizar el an√°lisis. El resultado de la ejecuci√≥n del m√©todo se muestra por una consola de R como se ve en la Figura 24. Figura 24: Resultado del m√©todo K medias del prototipo 0 Cap√≠tulo 4. Desarrollo de la Soluci√≥n 94 Para el tercer objetivo al igual que en el objetivo anterior se imprime el resultado del modelo por una consola de R, v√©ase la figura 25, pero tambi√©n se muestra a trav√©s de otro widget el circulo de correlaciones y las distancias entre cada individuo, v√©ase la figura 26. Figura 25: Resultado An√°lisis de componentes Principales del Prototipo 0 Figura 26: Resultados gr√°ficos de An√°lisis de componentes principales del Prototipo 0 Para el cuarto y √∫ltimo objetivo solamente se imprime el dendograma resultante en un nuevo widget, v√©ase la figura 27. Cap√≠tulo 4. Desarrollo de la Soluci√≥n 95 Figura 27: Resultado Agrupamiento Jer√°rquico 4.3.1.3. Conclusiones Luego de entregar este prototipo se llegaron a las siguientes conclusiones: ÔÇ∑ Se deben mejorar las interfaces de usuario debido a que existieron muchos descontroles en los elementos. ÔÇ∑ Los resultados se deben ver en alg√∫n widget generado por la aplicaci√≥n. ÔÇ∑ El agrupamiento jer√°rquico no agrupa, s√≥lo muestra el dendograma. ÔÇ∑ Ser√≠a mejor tener una secci√≥n para la carga de datos solamente. Cap√≠tulo 4. Desarrollo de la Soluci√≥n 96 ÔÇ∑ No se hace referencia a la teor√≠a de grandes vol√∫menes de datos. 4.3.2. Prototipo 1 Tomando como premisa los resultados y las conclusiones del prototipo 0 se procedi√≥ a establecer los objetivos para a siguiente entrega bajo el nombre de Prototipo 1. 4.3.2.1. Objetivos 1. Mejorar la interfaz de usuario colocando iconos a los botones acorde a sus funcionalidades 2. Crear secci√≥n √∫nica para la carga de datos de entrada 3. Crear secci√≥n √∫nica para el an√°lisis exploratorio de datos 4. Crear secci√≥n √∫nica para el agrupamiento de datos 5. Crear secci√≥n √∫nica para los algoritmos de Big Data 6. Mostrar resultados de los m√©todos de manera gr√°fica 7. Ejecutar m√©todo K medias bajo el paradigma MapReduce 8. Establecer funcionalidad para determinar el K √≥ptimo para el m√©todo K medias 4.3.2.2. Resultados El primer objetivo se cumpli√≥ mejorando el marco de la aplicaci√≥n, v√©ase la figura 28. Cap√≠tulo 4. Desarrollo de la Soluci√≥n 97 Figura 28: Vista principal del prototipo 1 Los objetivos dos, tres, cuatro y cinco se ven representados en las siguientes im√°genes: Cap√≠tulo 4. Desarrollo de la Soluci√≥n 98 Figura 29: Secci√≥n de carga de datos del prototipo 1 Cap√≠tulo 4. Desarrollo de la Soluci√≥n 99 Figura 30: Secci√≥n de an√°lisis exploratorio de datos del prototipo 1 Cap√≠tulo 4. Desarrollo de la Soluci√≥n 100 Figura 31: Secci√≥n para el agrupamiento de datos del prototipo 1 Cap√≠tulo 4. Desarrollo de la Soluci√≥n 101 Figura 32: Secci√≥n de Big Data del prototipo 1 El objetivo seis se cumpli√≥ para todas las secciones como se muestra en las siguientes im√°genes: Cap√≠tulo 4. Desarrollo de la Soluci√≥n 102 Figura 33: Resultados gr√°ficos de la secci√≥n de exploraci√≥n de datos del prototipo 1 Figura 34: Resultados gr√°ficos del m√©todo K medias del prototipo 1 Cap√≠tulo 4. Desarrollo de la Soluci√≥n 103 Figura 35: Resultados gr√°ficos del m√©todo agrupamiento jer√°rquico del prototipo 1 Los objetivos siete y ocho no pudieron ser cumplidos por limitaciones de tiempo. 4.3.2.3. Conclusiones Luego de la entrega de este prototipo se lleg√≥ a estas conclusiones: ÔÇ∑ Es necesaria la ejecuci√≥n del algoritmo K medias MapReduce ÔÇ∑ Se debe mostrar gr√°fico con la agrupaci√≥n del m√©todo de agrupaci√≥n jer√°rquico Cap√≠tulo 4. Desarrollo de la Soluci√≥n 104 4.3.3. Prototipo 2 El prototipo 2 no tuvo muchos cambios con respecto al prototipo 1. A continuaci√≥n se listan los objetivos 4.3.3.1. Objetivos 1. Ejecutar el m√©todo K medias MapReduce a un conjunto de datos en el ambiente local. 4.3.3.2. Resultados El √∫nico objetivo que se traz√≥ se cumpli√≥ perfectamente c√≥mo se muestra en la siguiente figura que muestra los resultados obtenidos. Figura 36: Resultado K medias MapReduce del prototipo 2 El m√©todo K medias MapReduce utilizado se encuentra en el anexo 6. 4.3.3.3. Conclusiones Las conclusiones m√°s importantes tras el despliegue del prototipo 2 son: Cap√≠tulo 4. Desarrollo de la Soluci√≥n 105 ÔÇ∑ El prototipo tiene muy pocos m√©todos disponibles ÔÇ∑ Resulta engorroso tener que cambiar entre conjuntos de datos ÔÇ∑ No existe una visualizaci√≥n de datos previos a la carga 4.3.4. Prototipo 3 Tras las conclusiones obtenidas en el prototipo dos se empez√≥ a utilizar el paquete gWidgets2 en vez de gWidgets y tambi√©n se procedi√≥ a la generaci√≥n de los nuevos objetivos para el siguiente prototipo. 4.3.4.1. Objetivos Los objetivos principales fueron: 1. Incluir m√©todos de clasificaci√≥n en una nueva secci√≥n 2. Capacidad de crear conexiones de datos y acceder a ellas siempre 3. Crear los siguientes tipos de conexiones de datos: Archivos de tipo csv, archivos de tipo HDFS y muestra de archivos de tipo HDFS 4. Ver la estad√≠stica de los archivos de tipo csv antes de ser almacenados 5. Ver los datos antes de ser almacenados 6. Decidir que variable ser√° la variable destino para los m√©todos de clasificaci√≥n 7. Mostrar la lista de todas las conexiones creadas 8. Poder editar la lista de todas las conexiones creadas 9. Mostrar los m√©todos disponibles dependiendo que tipo de conexi√≥n se haya escogido 10. Poder mostrar la clasificaci√≥n del m√©todo agrupamiento jer√°rquico 4.3.4.2. Resultados El primer objetivo se ve reflejado en la siguiente figura en la cual se listan todos los m√©todos disponibles para la conexi√≥n seleccionada. Cap√≠tulo 4. Desarrollo de la Soluci√≥n 106 Figura 37: Secci√≥n modelo del prototipo 3 El objetivo n√∫mero dos se logr√≥ pero no de manera completa, se crean las conexiones y se pueden acceder a ellas siempre y cuando no se haya reiniciado la aplicaci√≥n, es decir, si la aplicaci√≥n se cierra con algunas conexiones las mismas no se podr√°n acceder cuando se inicie otra vez, se deben volver a crear. El objetivo n√∫mero tres se logr√≥ aunque los archivos de tipo HDFS y muestra HDFS son iguales a los archivos csv, esto debido s√≥lo para ilustrar Cap√≠tulo 4. Desarrollo de la Soluci√≥n 107 que la selecci√≥n de m√©todos disponibles dependiendo del tipo de conexi√≥n funciona. Figura 38: Secci√≥n para la creaci√≥n de conexiones del prototipo 3 Los objetivos cuatro, cinco y seis se ven en las siguientes figuras: Cap√≠tulo 4. Desarrollo de la Soluci√≥n 108 Figura 39: Resultado de carga previa al almacenamiento de conexiones en el prototipo 3 Cap√≠tulo 4. Desarrollo de la Soluci√≥n 109 Figura 40: Datos de una conexi√≥n del prototipo 3 El resultado de la realizaci√≥n del objetivo siete se muestra a continuaci√≥n: Cap√≠tulo 4. Desarrollo de la Soluci√≥n 110 Figura 41: Secci√≥n d√≥nde se muestran todas las conexiones disponibles del prototipo 3 El objetivo ocho no se cumpli√≥ y quedo rezagado para la siguiente entrega, mientras el objetivo nueve s√≠ como se muestra a continuaci√≥n: Cap√≠tulo 4. Desarrollo de la Soluci√≥n 111 Figura 42: M√©todos disponibles para las conexiones de tipo archivo csv del prototipo 3 Cap√≠tulo 4. Desarrollo de la Soluci√≥n 112 Figura 43: M√©todos disponibles para las conexiones de tipo archivo HDFS del prototipo 3 El objetivo diez se cumpli√≥ a cabalidad y se ve representado en la siguiente figura: Cap√≠tulo 4. Desarrollo de la Soluci√≥n 113 Figura 44: Resultado de clasificaci√≥n por el m√©todo de agrupamiento jer√°rquico 4.3.4.3. Conclusiones Las principales conclusiones son que para cada m√©todo sigue sin imprimir el resultado en la aplicaci√≥n, s√≥lo lo imprime en una consola de R. Adem√°s de esta tambi√©n se concluy√≥ lo siguiente: ÔÇ∑ La clasificaci√≥n y los modelos generados s√≥lo se tienen de manera visual, ser√≠a ideal poder descargarlos. 4.3.5. Prototipo 4 Cap√≠tulo 4. Desarrollo de la Soluci√≥n 114 El prototipo cuatro no tuvo muchas diferencias con respecto al tres. S√≥lo se incluy√≥ un nuevo tipo de conexi√≥n llamada datos de R el cual provee algunos conjuntos de datos para la utilizaci√≥n de la aplicaci√≥n. 4.3.5.1. Objetivos El √∫nico objetivo fue el de crear el nuevo tipo de conexi√≥n. 4.3.5.2. Resultados El √∫nico objetivo fue cumplido como se muestra en la siguiente imagen: Cap√≠tulo 4. Desarrollo de la Soluci√≥n 115 Figura 45: Secci√≥n crear nueva conexi√≥n del prototipo 4 4.3.5.3. Conclusiones Las conclusiones de este prototipo son las de terminar los objetivos que ha quedado pendiente. 4.3.6. Prototipo 5 En este prototipo se cumplieron varios de los objetivos anteriores que no se lograron los cuales se listan a continuaci√≥n: Cap√≠tulo 4. Desarrollo de la Soluci√≥n 116 4.3.6.1. Objetivos 1. Imprimir resultado de las clasificaciones y de los modelos en la aplicaci√≥n 2. Mostrar funcionalidad que grafique el n√∫mero √≥ptimo de grupos para el m√©todo K medias 3. Posibilidad de descargar los resultados obtenidos de cualquier m√©todo ya sea la clasificaci√≥n o el modelo predictivo generado. 4.3.6.2. Resultados El cumplimiento del objetivo uno se muestra en las siguientes figuras: Figura 46: Resultado del m√©todo K medias del prototipo 5 Cap√≠tulo 4. Desarrollo de la Soluci√≥n 117 Figura 47: Resultado del m√©todo Bosques Aleatorios del prototipo 5 El gr√°fico que muestra el n√∫mero de grupos √≥ptimos en cumplimiento con el objetivo dos se muestra a continuaci√≥n: Cap√≠tulo 4. Desarrollo de la Soluci√≥n 118 Figura 48: Gr√°fico del codo de jambu Por √∫ltimo en cumplimiento con el objetivo tres se cumple que por los m√©todos de clasificaci√≥n se descargue un archivo csv con la clasificaci√≥n obtenida y por los m√©todos predictivos el modelo generado para poder utilizarlo en otro conjunto de datos desde R. 4.3.6.3. Conclusiones Las conclusiones principales fueron: ÔÇ∑ Es necesario para la investigaci√≥n poder utilizar un cl√∫ster Hadoop por eso se debe programar el tipo de conexiones de archivos HDFS para ejecutar algoritmos en un cl√∫ster. Cap√≠tulo 4. Desarrollo de la Soluci√≥n 119 ÔÇ∑ Es indispensable poder tener conexiones constantes escribi√©ndolas en un archivo o en alg√∫n lugar de almacenamiento. ÔÇ∑ Tener s√≥lo un algoritmo MapReduce es muy poco 4.3.7. Prototipo 6 Todos los prototipos anteriores solamente eran un archivo, aunque seg√∫n las buenas pr√°cticas de programaci√≥n en R dicen que es mejor tener todo en un solo archivo a la hora de codificar resultaba muy engorroso por ende se decidi√≥ cambiar la estructura del proyecto en base a una jerarqu√≠a de archivos y otros cambios que se listan a continuaci√≥n: 4.3.7.1. Objetivos 1. Cambiar la estructura de archivos de la aplicaci√≥n de un archivo a varios m√≥dulos 2. Remover botones de m√°s 3. Crear un nuevo tipos de conexi√≥n, para Subir funciones MAP y funciones REDUCE 4. Guardar tipo de conexi√≥n en la cual se guarden las credenciales de acceso para conectarse a un cl√∫ster Hadoop 5. Crear secci√≥n para la ejecuci√≥n de las funciones MAP y REDUCE sobre un cl√∫ster Hadoop utilizando la funcionalidad del Hadoop Streaming 6. Mejorar secci√≥n donde se muestran las conexiones con la posibilidad de ver el detalle y eliminarlas 7. Colocar tooltips a algunas secciones de la aplicaci√≥n 8. Ejecutar el algoritmo K medias MapReduce sobre un cl√∫ster Hadoop 9. Colocar el algoritmo regresi√≥n log√≠stica MapReduce para ejecutarlo en un cl√∫ster Hadoop 4.3.7.2. Resultados Como se mencion√≥ de manera previo el proyecto de la aplicaci√≥n pas√≥ de ser un solo archivo a la siguiente estructura de archivos: Cap√≠tulo 4. Desarrollo de la Soluci√≥n 120 Figura 49: Jer√°rquia del proyecto ÔÇ∑ vars: Almacena un script que contiene la definici√≥n de todas las variables a utilizar ÔÇ∑ templates: Contiene los scripts necesarios para el dise√±o de las secciones de la aplicaci√≥n ÔÇ∑ scripts: Almacena de manera din√°mica los scripts que ser√°n enviados para la ejecuci√≥n en el cl√∫ster ÔÇ∑ handlers: Contiene los scripts que realizan la l√≥gica de negocio ÔÇ∑ functions: Contiene las funciones MAP y REDUCE que ser√°n ejecutadas en el cl√∫ster ÔÇ∑ conections: Contiene el archivo que funciona como almacenamiento de las conexiones de datos. La aplicaci√≥n se inicia ejecutando solamente el archivo main.R desde una consola de R. Los objetivos dos, tres, cuatro, cinco, seis y siete se cumplieron a cabalidad como se muestra en las figuras 50, 51, 52, 53, 54 y 55. Cap√≠tulo 4. Desarrollo de la Soluci√≥n 121 Figura 50: Vista principal del prototipo 6 Cap√≠tulo 4. Desarrollo de la Soluci√≥n 122 Figura 51: Funcionalidad de Subir funciones MAP y REDUCE del prototipo 6 Cap√≠tulo 4. Desarrollo de la Soluci√≥n 123 Figura 52: Funcionalidad para crear conexi√≥n de tipo Archivo HDFS Cap√≠tulo 4. Desarrollo de la Soluci√≥n 124 Figura 53: Secci√≥n para ejecutar funciones MAP y REDUCE sobre un cl√∫ster Hadoop Cap√≠tulo 4. Desarrollo de la Soluci√≥n 125 Figura 54: Secci√≥n que muestra las conexiones almacenadas del prototipo 6 Cap√≠tulo 4. Desarrollo de la Soluci√≥n 126 Figura 55: Ejemplo de tooltip en el prototipo 6 El resultado del objetivo ocho se muestra a continuaci√≥n: Cap√≠tulo 4. Desarrollo de la Soluci√≥n 127 Figura 56: Ejecuci√≥n del m√©todo K medias MapReduce Se incorpor√≥ el algoritmo Regresi√≥n Log√≠stica bajo el marco MapReduce como se muestra en la siguiente imagen. El m√©todo se encuentra en el anexo siete. Cap√≠tulo 4. Desarrollo de la Soluci√≥n 128 Figura 57: Ejecuci√≥n del m√©todo Regresi√≥n Log√≠stica MapReduce 4.3.7.3. Conclusiones Las conclusiones para este prototipo se especificaran el pr√≥ximo cap√≠tulo luego de verificar los resultados. 129 5. Conclusiones y Resultados 5.1. Resultados Se realizaron las siguientes pruebas con el fin de obtener los resultados pertinentes para as√≠ concluir la investigaci√≥n. Para realizar las pruebas se definieron las siguientes conexiones: 1) Conexi√≥n 1: a. Nombre: mtcars b. Tipo: Archivo csv c. Variable a predecir: Ninguna d. Variables a ignorar: Ninguna e. Estad√≠sticas por Variable: Figura 58: Estad√≠sticas de la Conexi√≥n 1 2) Conexi√≥n 2: a. Nombre: iris b. Tipo: Datos de R c. Variable a predecir: Species d. Variables a ignorar: Ninguna e. Porcentaje de muestreo: 70 f. Porcentaje de prueba: 30 g. Estad√≠sticas por Variable: Cap√≠tulo 5. Conclusiones y Resultados 130 Figura 59: Estad√≠sticas de la Conexi√≥n 2 3) Conexi√≥n 3: a. Nombre: hadoop b. Tipo: Archivo HDFS c. Usuario: pascual d. Contrase√±a: hadoop e. Dominio: 192.168.0.107 f. Puerto: 2222 g. Hadoop_cmd: /usr/lib/hadoop/bin/hadoop h. Hadoop_streaming: /usr/lib/hadoop-mapreduce/hadoop- streaming-2.4.0.2.1.1.0-385.jar i. Archivo: El mismo que se utiliz√≥ en la conexi√≥n 1 ya almacenado en HDFS 4) Conexi√≥n 4: a. Nombre: wordcount b. Funci√≥n MAP: La funci√≥n que se utiliz√≥ se puede ver en el anexo 8 c. Funci√≥n REDUCE: La funci√≥n que se utilizo se puede ver en el anexo 9 Luego de tener definidas las conexiones se procedi√≥ a probar las funcionalidades m√°s relevantes de la aplicaci√≥n. I. Componentes principales: Utilizando como entrada la Conexi√≥n 1, generando cinco componentes y graficando las componentes uno y dos se tuvieron los siguientes resultados: Cap√≠tulo 5. Conclusiones y Resultados 131 Figura 60: Resultado An√°lisis de Componentes Principales Cap√≠tulo 5. Conclusiones y Resultados 132 Figura 61: Resultado An√°lisis de Componentes Principales (Individuos) Cap√≠tulo 5. Conclusiones y Resultados 133 Figura 62: Resultados An√°lisis de Componentes Principales (Variables) II. K medias Utilizando la Conexi√≥n 1 con un n√∫mero de grupos igual a cuatro y un n√∫mero de iteraciones igual a diez se obtuvieron los siguientes resultados en el m√©todo de K medias disponible para las conexiones locales: Cap√≠tulo 5. Conclusiones y Resultados 134 Figura 63: Resultados del m√©todo K medias Cap√≠tulo 5. Conclusiones y Resultados 135 Figura 64: Diagrama de datos del m√©todo K medias Cap√≠tulo 5. Conclusiones y Resultados 136 Figura 65: Clasificaci√≥n despu√©s de aplicar el m√©todo K medias III. Agrupamiento Jer√°rquico Utilizando la Conexi√≥n 1 con un par√°metro de distancia igual a Euclidean y un par√°metro de aglomeraci√≥n igual a Ward.D se obtuvieron los siguientes resultados en el m√©todo de Agrupamiento Jer√°rquico: Cap√≠tulo 5. Conclusiones y Resultados 137 Figura 66: Resultado Agrupamiento Jer√°rquico Tomando un n√∫mero de grupos igual a cuatro se obtuvieron los siguientes resultados: Cap√≠tulo 5. Conclusiones y Resultados 138 Figura 67: Clasificaci√≥n del m√©todo Agrupamiento Jer√°rquico Cap√≠tulo 5. Conclusiones y Resultados 139 Figura 68: Clasificaci√≥n despu√©s de ejecutar el m√©todo Agrupamiento Jer√°rquico IV. K medias MapReduce Utilizando la Conexi√≥n 3 con un n√∫mero de grupos igual a cuatro y un n√∫mero de iteraciones igual a diez se obtuvieron los siguientes resultados en el m√©todo de K medias disponible para las conexiones que corren sobre un cl√∫ster Hadoop: Figura 69: Centros de grupos generados tras la ejecuci√≥n del m√©todo K medias MapReduce sobre un cl√∫ster Hadoop Cabe resaltar que el m√©todo tardo alrededor de sesenta minutos en dar el resultado. Cap√≠tulo 5. Conclusiones y Resultados 140 V. Bosques Aleatorios Utilizando la Conexi√≥n 2 como entrada al m√©todo de Bosques Aleatorios se obtuvieron los siguientes resultados: Figura 70: Resultado del m√©todo Bosques Aleatorios utilizando la conexi√≥n 2 VI. Regresi√≥n Log√≠stica MapReduce Utilizando la Conexi√≥n 3 con un n√∫mero de iteraciones igual a dos, un n√∫mero de dimensiones igual a diez y un par√°metro alpha igual a 0.05 se obtuvieron los siguientes resultados en el m√©todo de regresi√≥n log√≠stica disponible para las conexiones que corren sobre un cl√∫ster Hadoop: Figura 71: Resultado del m√©todo Regresi√≥n Log√≠stica utilizando la conexi√≥n 3 VII. Streaming Utilizando la conexi√≥n 3 junto con la conexi√≥n 4 como funciones map y reduce respectivamente y como par√°metro de entrada un archivo de texto se obtuvo el siguiente resultado: Palabra Repeticiones ¬°Ah 1 Cap√≠tulo 5. Conclusiones y Resultados 141 ¬°Feliz 1 ¬°Oh! 2 ¬øEres 1 ¬øPorqu√© 2 a 23 abandon√©. 1 Tabla 3: Primeros siete resultados del Hadoop Streaming S√≥lo se muestran los primeros siete resultados, esto debido a que la salida arrojo quinientas palabras. 5.2. Conclusiones Se logr√≥ desarrollar todos los objetivos planeados para el √∫ltimo prototipo junto con los objetivos espec√≠ficos de la investigaci√≥n. Se instal√≥ R en el cl√∫ster junto con los paquetes rmr2 y rhdfs. En el ambiente local tambi√©n se instal√≥ R junto con R Studio, GTK+, SSH y todos los paquetes necesarios que se definieron de manera previa. La aplicaci√≥n se program√≥ utilizando una metodolog√≠a propia basada en la entrega de prototipos con ning√∫n otro artefacto entregable m√°s que el prototipo como tal, esto debido a qu√© s√≥lo existi√≥ un desarrollador por lo cual ser√≠a muy engorroso generar artefactos de sincronizaci√≥n cuando no hab√≠a con quien sincronizarse. Se definieron siete casos de estudios para as√≠ probar las funcionalidades principales de la aplicaci√≥n. Los resultados fueron lo esperado aunque hubo ciertos problemas de rendimiento esto debido a que la aplicaci√≥n es muy propensa a la funcionalidad del cl√∫ster, es decir si el cl√∫ster es de bajo rendimiento la aplicaci√≥n se comportar√° de igual manera. El desarrollo de esta aplicaci√≥n fue todo un reto personal debido a que la programaci√≥n en R es orientada a scripts que resuelvan un solo problema no al desarrollo de aplicaciones, pero pese a esto se obtuvo una aplicaci√≥n Cap√≠tulo 5. Conclusiones y Resultados 142 potente que puede hacer an√°lisis de datos de manera local y remota incentivando as√≠ al desarrollo de nuevas investigaciones. Este trabajo de investigaci√≥n contribuye principalmente con la Escuela de Computaci√≥n de la Facultad de Ciencias de la Universidad Central de Venezuela, ya que esta aplicaci√≥n fue creada inicialmente para ser utilizada por los docentes y alumnos de la escuela. M√°s all√° de la UCV, esta aplicaci√≥n puede ser √∫til para todo aquel que desee explorar en el an√°lisis de grandes vol√∫menes de datos tambi√©n queda abierta para cualquier contribuci√≥n futura ya sea un nuevo trabajo de grado o simplemente alguna mejora. 5.3. Recomendaciones Tras las conclusiones obtenidas las recomendaciones basadas en esas conclusiones son las siguientes: ÔÇ∑ Incentivar m√°s las ciencias de datos con la apertura de m√°s materias en la Facultad de Ciencias ÔÇ∑ La programaci√≥n de interfaces en R son algo complicadas, por ende ser√≠a muy √∫til utilizar un lenguaje distinto para la realizaci√≥n de las interfaces y los c√°lculos en R ÔÇ∑ Investigar m√°s m√©todos de an√°lisis de datos basados en el marco MapReduce 5.4. Trabajos Futuros El principal trabajo de investigaci√≥n que puede desencadenar desde el presente es la mejora de las interfaces utilizando tecnolog√≠as como html, css y javascript junto con un lenguaje del lado del servidor que pueda conectarse con R como java o php. Tambi√©n se podr√≠an incluir m√°s m√©todos y/o m√≥dulos a este trabajo de investigaci√≥n. 143 Anexos Gu√≠a de instalaci√≥n de R, rmr y rhdfs Pasos para distribuciones de Linux basadas en Red Hat. 1. Actualizar los repositorios epel Se actualizan estos repositorios para futuras instalaciones de paquetes. Se utiliza el siguiente comando: sudo rpm -Uvh http://dl.fedoraproject.org/pub/epel/6/x86_64/epel- release-6-8.noarch.rpm 2. Instalar R Se instala R con el siguiente comando: sudo yum -y install git wget R 3. Instalar Rstudio Server Se descarga he instala con los siguientes comandos: wget http://download2.rstudio.org/rstudio-server-0.97.332-x86_64.rpm sudo yum install --nogpgcheck rstudio-server-0.97.332-x86_64.rpm 4. Instalar rmr2 Primero se descargan las dependencias con el siguiente comando install.packages( c('RJSONIO', 'itertools', 'digest', 'Rcpp', 'functional', 'plyr', 'stringr'), repos='http://cran.revolutionanalytics.com') install.packages( c('reshape2'), repos='http://cran.revolutionanalytics.com') Anexos 144 Se descarga e instala con los siguientes comandos: wget --no-check-certificate https://github.com/RevolutionAnalytics/rmr2/releases/download/3.3.1/r mr2_3.3.1.tar.gz sudo R CMD INSTALL rmr2_3.3.1.tar.gz 5. Instalar rhdfs Primero se deben resolver las dependencias que se listan a continuaci√≥n: a. export JAVA_HOME=/usr/lib/java/jdk-version b. export PATH=$PATH:$JAVA_HOME/bin c. export HADOOP_CMD=/usr/lib/hadoop/bin/hadoop d. En una consola de R instalar el paquete 'rJava' Luego ejecutar los siguientes comandos wget --no-check-certificate https://github.com/RevolutionAnalytics/rhdfs/blob/master/build/rhdfs_1. 0.8.tar.gz?raw=true sudo R CMD INSTALL rhdfs_1.0.8.tar.gz?raw=true Anexos 145 Gu√≠a de instalaci√≥n de gtk+ Se deben ejecutar las dos siguientes l√≠neas en distribuciones de Linux basadas en Red Hat: 1. yum groupinstall "Development Tools" 2. yum install gtk+-devel gtk2-devel Anexos 146 Gu√≠a de instalaci√≥n de R En distribuciones de Linux basadas en Red Hat: 1. sudo yum -y install git wget R Anexos 147 Gu√≠a de instalaci√≥n de R-Studio En distribuciones de Linux basadas en Red Hat: 1. wget http://download2.rstudio.org/rstudio-server-0.97.332- x86_64.rpm 2. sudo yum install --nogpgcheck rstudio-server-0.97.332-x86_64.rpm Anexos 148 Gu√≠a de instalaci√≥n Openssh y sshpass En distribuciones de Linux basadas en Red Hat: 1. yum ‚Äìy install openssh-server openssh-clients 2. yum install sshpass Anexos 149 Algoritmo de K-medias en MapReduce en R Sys.setenv(HADOOP_CMD="/usr/lib/hadoop/bin/hadoop") Sys.setenv(HADOOP_STREAMING="/usr/lib/hadoop-mapreduce/hadoop- streaming-2.4.0.2.1.1.0-385.jar") library(rhdfs) hdfs.init() library(rmr2) rmr.options(backend="hadoop") ## @knitr kmeans-signature kmeans.mr = function( P, num.clusters, num.iter, combine, in.memory.combine) { ## @knitr kmeans-dist.fun dist.fun = function(C, P) { apply( C, 1, function(x) colSums((t(P) - x)^2))} ## @knitr kmeans.map kmeans.map = function(., P) { nearest = { if(is.null(C)) sample( 1:num.clusters, nrow(P), replace = TRUE) else { D = dist.fun(C, P) nearest = max.col(-D)}} if(!(combine || in.memory.combine)) keyval(nearest, P) else keyval(nearest, cbind(1, P))} ## @knitr kmeans.reduce kmeans.reduce = { if (!(combine || in.memory.combine) ) function(., P) t(as.matrix(apply(P, 2, mean))) else function(k, P) keyval( k, t(as.matrix(apply(P, 2, sum))))} ## @knitr kmeans-main-1 Anexos 150 C = NULL for(i in 1:num.iter ) { C = values( from.dfs( mapreduce( P, map = kmeans.map, reduce = kmeans.reduce))) if(combine || in.memory.combine) C = C[, -1]/C[, 1] ## @knitr end # points(C, col = i + 1, pch = 19) ## @knitr kmeans-main-2 if(nrow(C) < num.clusters) { C = rbind( C, matrix( rnorm( (num.clusters - nrow(C)) * nrow(C)), ncol = nrow(C)) %*% C) }} C} testdata = data kmeans.mr(testdata, num.clusters = 3, num.iter = 10, combine = FALSE, in.memory.combine = FALSE) Disponible en [51] Anexos 151 Algoritmo de Regresi√≥n Log√≠stica en MapReduce en R Sys.setenv(HADOOP_CMD="/usr/lib/hadoop/bin/hadoop") Sys.setenv(HADOOP_STREAMING="/usr/lib/hadoop-mapreduce/hadoop- streaming-2.4.0.2.1.1.0-385.jar") library(rhdfs) hdfs.init() library(rmr2) rmr.options(backend="hadoop") logistic.regression = function(input, iterations, dims, alpha){ lr.map = function(., M) { Y = M[,1] X = M[,-1] keyval( 1, Y * X * g(-Y * as.numeric(X %*% t(plane)))) } lr.reduce = function(k, Z) keyval(k, t(as.matrix(apply(Z,2,sum)))) plane = t(rep(0, dims)) g = function(z) 1/(1 + exp(-z)) for (i in 1:iterations) { gradient = values( from.dfs( mapreduce( input, map = lr.map, reduce = lr.reduce, combine = T))) plane = plane + alpha * gradient } plane } testdata = data logistic.regression(testdata, 10, 10, 0.05) Disponible en [51] Anexos 152 Funci√≥n Map del algoritmo Wordcount en R #! /usr/bin/env Rscript # mapper.R - Wordcount program in R # script for Mapper (R-Hadoop integration) trimWhiteSpace <- function(line) gsub("(^ +)|( +$)", "", line) splitIntoWords <- function(line) unlist(strsplit(line, "[[:space:]]+")) ## **** could wo with a single readLines or in blocks con <- file("stdin", open = "r") while (length(line <- readLines(con, n = 1, warn = FALSE)) > 0) { line <- trimWhiteSpace(line) words <- splitIntoWords(line) ## **** can be done as cat(paste(words, "\t1\n", sep=""), sep="") for (w in words) cat(w, "\t1\n", sep="") } close(con) Anexos 153 Funci√≥n Reduce del algoritmo Wordcount en R #! /usr/bin/env Rscript # reducer.R - Wordcount program in R # script for Reducer (R-Hadoop integration) trimWhiteSpace <- function(line) gsub("(^ +)|( +$)", "", line) splitLine <- function(line) { val <- unlist(strsplit(line, "\t")) list(word = val[1], count = as.integer(val[2])) } env <- new.env(hash = TRUE) con <- file("stdin", open = "r") while (length(line <- readLines(con, n = 1, warn = FALSE)) > 0) { line <- trimWhiteSpace(line) split <- splitLine(line) word <- split$word count <- split$count if (exists(word, envir = env, inherits = FALSE)) { oldcount <- get(word, envir = env) assign(word, oldcount + count, envir = env) } else assign(word, count, envir = env) } close(con) for (w in ls(env, all = TRUE)) cat(w, "\t", get(w, envir = env), "\n", sep = "") 154 Bibliograf√≠a [1] Weka 3: Data Mining Software in Java [en l√≠nea]: documenting electronic sources on the Internet. s.f. [Fecha de consulta: 4 de septiembre 2015, 10:11 am] Disponible en < http://www.cs.waikato.ac.nz/ml/weka/ > [2] Weka (aprendizaje autom√°tico) [en √≠nea]: documenting electronic sources on the Internet. s.f. [Fecha de consulta: 4 de septiembre 2015, 10:15 am] Disponible en < https://es.wikipedia.org/wiki/Weka_(aprendizaje_autom%C3%A1tico) > [3] Rcommander a graphical interface for R [en l√≠nea]: documenting electronic sources on the Internet. 2013. [Fecha de consulta: 4 de septiembre 2015, 10:18 am] Disponible en < http://www.rcommander.com/ > [4] Rattle GUI [en l√≠nea]: documenting electronic sources on the Internet. 2015. [Fecha de consulta: 4 de septiembre 2015, 10:21 am] Disponible en < https://en.wikipedia.org/wiki/Rattle_GUI > [5] DHAR, V. Data Science and Prediction [en l√≠nea]: documenting electronic sources on the Internet. 2013 [Fecha de consulta: 5 de octubre 2014, 8:06 pm] Disponible en <http://cacm.acm.org/magazines/2013/12/169933-data-science-and- prediction/fulltext/ > [6] LEAK, J. The keyword in ‚ÄúData Science‚Äù is not Data, It is Science [en l√≠nea]: documenting electronic sources on the Internet. 2013 [Fecha de consulta: 5 de octubre de 2014, 8:06 pm] Disponible en <http://simplystatistics.org/2013/12/12/the-key-word-in-data-science-is-not- data-it-is-science/> [7] HERNANDEZ, J. Introducci√≥n a la Miner√≠a de Datos. Pearson Prentice Hall 2004. [8] WITTEN, I. Data Mining, Third Edition. Morgan Kauffman 2011. http://www.cs.waikato.ac.nz/ml/weka/ https://es.wikipedia.org/wiki/Weka_(aprendizaje_autom%C3%A1tico) http://www.rcommander.com/ https://en.wikipedia.org/wiki/Rattle_GUI http://cacm.acm.org/magazines/2013/12/169933-data-science-and-prediction/fulltext/ http://cacm.acm.org/magazines/2013/12/169933-data-science-and-prediction/fulltext/ http://simplystatistics.org/2013/12/12/the-key-word-in-data-science-is-not-data-it-is-science/ http://simplystatistics.org/2013/12/12/the-key-word-in-data-science-is-not-data-it-is-science/ Bibliograf√≠a 155 [9] An√°lisis de componentes principales [en l√≠nea]: documenting electronic sources on the Internet. s.f [Fecha de consulta: 17 de febrero de 2015, 8:05 pm] Disponible en < http://es.wikipedia.org/wiki/An%C3%A1lisis_de_componentes_principales> [10] Agrupamiento jer√°rquico [en l√≠nea]: documenting electronic sources on the Internet. s.f [Fecha de consulta: 17 de febrero de 2015, 8:52 pm] Disponible en < http://es.wikipedia.org/wiki/Agrupamiento_jer%C3%A1rquico> [11] Regresi√≥n Log√≠stica [en l√≠nea]: documenting electronic sources on the Internet. 2014 [Fecha de consulta: 4 de septiembre de 2015, 10:24 am] Disponible en < https://es.wikipedia.org/wiki/Regresi%C3%B3n_log%C3%ADstica > [12] Operating System [en l√≠nea]: documenting electronic sources on the Internet. 2015 [Fecha de consulta: 4 de septiembre de 2015, 10:27 am] Disponible en < https://en.wikipedia.org/wiki/Operating_system > [13] MARTINEZ, R. Sobre Linux [en l√≠nea]: documenting electronic sources on the Internet. 2014. [Fecha de consulta: 4 de septiembre de 2015, 10: 29 am] Disponible en < http://www.linux-es.org/sobre_linux > [14] The GTK+ Project [en l√≠nea]: documenting electronic sources on the Internet. 2015. [Fecha de consulta: 4 de septiembre de 2015, 10:32 am] Disponible en < http://www.gtk.org/ > [15] Secure Shell [en l√≠nea]: documenting electronic sources on the Internet. 2015. [Fecha de consulta: 4 de septiembre de 2015, 10:34 am] Disponible en < https://es.wikipedia.org/wiki/Secure_Shell > [16] VERZANI, J. gWidgets2-package [en l√≠nea]: documenting electronic sources on the Internet. s.f [Fecha de consulta: 4 de septiembre de 2015, 10:37 am] Disponible en < http://www.rdocumentation.org/packages/gWidgets2/functions/gWidgets2- package > http://es.wikipedia.org/wiki/An%C3%A1lisis_de_componentes_principales http://es.wikipedia.org/wiki/Agrupamiento_jer%C3%A1rquico https://es.wikipedia.org/wiki/Regresi%C3%B3n_log%C3%ADstica https://en.wikipedia.org/wiki/Operating_system http://www.linux-es.org/sobre_linux http://www.gtk.org/ https://es.wikipedia.org/wiki/Secure_Shell http://www.rdocumentation.org/packages/gWidgets2/functions/gWidgets2-package http://www.rdocumentation.org/packages/gWidgets2/functions/gWidgets2-package Bibliograf√≠a 156 [17] rmr-package [en l√≠nea]: documenting sources on the Internet. s.f [Fecha de consulta: 4 de septiembre de 2015, 10:39 am] Disponible en < http://www.rdocumentation.org/packages/rmr2/functions/rmr-package > [18] rhdfs [en l√≠nea]: documenting electronic sources on the Internet. s.f [Fecha de consulta: 4 de septiembre de 2015, 10:41 am] Disponible en < http://www.rdocumentation.org/packages/rhdfs/functions/rhdfs > [19] Hadoop Streaming [en l√≠nea]: documenting electronic sources on the Internet. 2013 [Fecha de consulta: 4 de septiembre de 2015, 10:43 am] Disponible en < http://hadoop.apache.org/docs/r1.2.1/streaming.html > [20] Cloudera vs Hortonworks vs MapR: Comparing Hadoop Distributions [en l√≠nea]: documenting electronic sources on the Internet. 2014 [Fecha de consulta: 4 de septiembre de 2015, 10:47 am] Disponible en: < http://www.experfy.com/blog/cloudera-vs-hortonworks-comparing-hadoop- distributions/ > [21] Manfiesto √Ågil [en l√≠nea]: documenting electronic sources on the Internet. 2015 [Fecha de consulta: 4 de septiembre de 2015, 10:50 am] Disponible en < https://es.wikipedia.org/wiki/Manifiesto_%C3%A1gil > [22] Desarrollo √°gil de software [en l√≠nea]: documenting electronic sources on the Internet. 2015 [Fecha de consulta: 4 de septiembre de 2015, 10:52 am] Disponible en < https://es.wikipedia.org/wiki/Desarrollo_%C3%A1gil_de_software > [23] Knn [en l√≠nea]: documenting electronic sources on the Internet. s.f [Fecha de consulta: 17 de febrero de 2015, 1:33 pm] Disponible en < http://es.wikipedia.org/wiki/Knn> [24] WHITE, T. Hadoop: The Definitive Guide, Third Edition. O‚ÄôReilly Media 2012 . [25] WARDEN, P. Big Data Glossary. O‚ÄôReilly Media 2011. [26] MINER, D. MapReduce Design Patterns. O‚ÄôReilly Media 2013. http://www.rdocumentation.org/packages/rmr2/functions/rmr-package http://www.rdocumentation.org/packages/rhdfs/functions/rhdfs http://hadoop.apache.org/docs/r1.2.1/streaming.html http://www.experfy.com/blog/cloudera-vs-hortonworks-comparing-hadoop-distributions/ http://www.experfy.com/blog/cloudera-vs-hortonworks-comparing-hadoop-distributions/ https://es.wikipedia.org/wiki/Manifiesto_%C3%A1gil https://es.wikipedia.org/wiki/Desarrollo_%C3%A1gil_de_software http://es.wikipedia.org/wiki/Knn Bibliograf√≠a 157 [27] ¬øQu√© es Big Data? [en l√≠nea]: documenting electronic sources on the Internet. 2012 [Fecha de consulta: 5 de octubre de 2014, 8:08 pm] Disponible en <http://www.ibm.com/developerworks/ssa/local/im/que-es-big-data/> [28] Hadoop YARN [en l√≠nea]: documenting electronic sources on the Internet. s.f [Fecha de consulta: 5 de octubre de 2014, 8:11 pm] Disponible en <http://hortonworks.com/hadoop/yarn/> [29] ROUSE, Margaret. Apache Hadoop YARN (Yet Another Resource Negotiator) [en l√≠nea]: documenting electronic sources on the Internet. s.f [Fecha de consulta: 5 de octubre de 2014, 8:12 pm] Disponible en <http://searchdatamanagement.techtarget.com/definition/Apache-Hadoop- YARN-Yet-Another-Resource-Negotiator> [30] Apache Hadoop NextGen MapReduce (YARN) [en l√≠nea]: documenting electronic sources on the Internet. 2014 [Fecha de consulta: 5 de octubre de 2014, 8:13 pm] Disponible en <http://hadoop.apache.org/docs/r2.3.0/hadoop-yarn/hadoop-yarn- site/YARN.html> [31] Apache Hive [en l√≠nea]: documenting electronic sources on the Internet. s.f [Fecha de consulta: 5 de octubre de 2014, 8:14 pm] Disponible en <http://hortonworks.com/hadoop/hive/> [32] amplab/shark [en l√≠nea]: documenting electronic sources on the Internet. s.f [Fecha de consulta: 5 de octubre de 2014, 8:19 pm] Disponible en <https://github.com/amplab/shark/wiki> [33] Apache Pig [en l√≠nea]: documenting electronic sources on the Internet. s.f [Fecha de consulta: 5 de octubre de 2014, 8:15 pm] Disponible en <http://hortonworks.com/hadoop/pig/> [34] Apache HCatalog [en l√≠nea]: documenting electronic sources on the Internet. s.f [Fecha de consulta: 16 de febrero de 2015, 9:34 pm] Disponible en <http://hortonworks.com/hadoop/hcatalog/> http://www.ibm.com/developerworks/ssa/local/im/que-es-big-data/ http://hortonworks.com/hadoop/yarn/ http://searchdatamanagement.techtarget.com/definition/Apache-Hadoop-YARN-Yet-Another-Resource-Negotiator http://searchdatamanagement.techtarget.com/definition/Apache-Hadoop-YARN-Yet-Another-Resource-Negotiator http://hadoop.apache.org/docs/r2.3.0/hadoop-yarn/hadoop-yarn-site/YARN.html http://hadoop.apache.org/docs/r2.3.0/hadoop-yarn/hadoop-yarn-site/YARN.html http://hortonworks.com/hadoop/hive/ https://github.com/amplab/shark/wiki http://hortonworks.com/hadoop/pig/ http://hortonworks.com/hadoop/hcatalog/ Bibliograf√≠a 158 [35] Apache Spark [en l√≠nea]: documenting electronic sources on the Internet. s.f [Fecha de consulta: 5 de octubre de 2014, 8:16 pm] Disponible en <http://hortonworks.com/hadoop/spark/> [36] METZ, C. (2013). Spark: Open Source Superstar Rewrites Future of Big Data [en l√≠nea]: documenting electronic sources on the Internet. 2013 [Fecha de consulta: 5 de octubre de 2014, 8:17 pm] Disponible en <http://www.wired.com/2013/06/yahoo-amazon-amplab-spark/all/> [37] Las 5 V¬¥s del Big Data [en l√≠nea]: documenting electronic sources on the Internet. 2014 [Fecha de consulta: 13 de noviembre de 2014, 10:38 pm] Disponible en <http://www.quanticsolutions.es/big-data/las-5-v-big-data/> [38] Apache Flume [en l√≠nea]: documenting electronic sources on the Internet. s.f [Fecha de consulta: 5 de octubre de 2014, 8:18 pm] Disponible en <http://hortonworks.com/hadoop/flume/> [39] cloudera/hue [en l√≠nea]: documenting electronic sources on the Internet. s.f [Fecha de consulta: 5 de octubre de 2014, 8:20 pm] Disponible en <https://github.com/cloudera/hue> [40] Apache ZooKeeper [en l√≠nea]: documenting electronic sources on the Internet. s.f [Fecha de consulta: 5 de octubre de 2014, 8:18 pm] Disponible en <http://hortonworks.com/hadoop/zookeeper/> [41] amplab/shark [en l√≠nea]: documenting electronic sources on the Internet. s.f [Fecha de consulta: 5 de octubre de 2014, 8:19 pm] Disponible en <https://github.com/amplab/shark/wiki> [42] Apache Sqoop [en l√≠nea]: documenting electronic sources on the Internet. s.f [Fecha de consulta: 16 de febrero de 2015, 10:06 pm] Disponible en <http://hortonworks.com/hadoop/hcatalog/> [43] M√°quinas de vectores de soporte [en l√≠nea]: documenting electronic sources on the Internet. s.f [Fecha de consulta: 17 de febrero de 2015, 2:35 pm] Disponible en <http://es.wikipedia.org/wiki/M%C3%A1quinas_de_vectores_de_soporte> [44] RODRIGUEZ, Oldemar. Aprendizaje Supervisado. Redes Neuronales, M√©todos de Consenso y Potenciaci√≥n [en l√≠nea]: documenting electronic sources on the Internet. s.f [Fecha de consulta: 17 de febrero de 2015, 7:15 pm] Disponible en http://hortonworks.com/hadoop/spark/ http://www.wired.com/2013/06/yahoo-amazon-amplab-spark/all/ http://www.quanticsolutions.es/big-data/las-5-v-big-data/ http://hortonworks.com/hadoop/flume/ https://github.com/cloudera/hue http://hortonworks.com/hadoop/zookeeper/ https://github.com/amplab/shark/wiki http://hortonworks.com/hadoop/hcatalog/ http://es.wikipedia.org/wiki/M%C3%A1quinas_de_vectores_de_soporte Bibliograf√≠a 159 <http://www.oldemarrodriguez.com/yahoo_site_admin/assets/docs/Presentaci %C3%B3n_-_Redes_-_Consenso_-_Potenciacion.293124147.pdf> [45] Random forest [en l√≠nea]: documenting electronic sources on the Internet. s.f [Fecha de consulta: 17 de febrero de 2015, 7:31 pm] Disponible en < http://es.wikipedia.org/wiki/Random_forest> [46] Red neuronal artificial [en l√≠nea]: documenting electronic sources on the Internet. s.f [Fecha de consulta: 17 de febrero de 2015, 7:53 pm] Disponible en < http://es.wikipedia.org/wiki/Red_neuronal_artificial> [47] An√°lisis de componentes principales [en l√≠nea]: documenting electronic sources on the Internet. s.f [Fecha de consulta: 17 de febrero de 2015, 8:05 pm] Disponible en < http://es.wikipedia.org/wiki/An%C3%A1lisis_de_componentes_principales> [48] RevolutionAnalytics/RHadoop [en l√≠nea]: documenting electronic sources on the Internet. s.f [Fecha de consulta: 21 de febrero de 2015, 5:58 pm] Disponible en < https://github.com/RevolutionAnalytics/RHadoop/wiki> [49] Scipy/Scipy [en l√≠nea]: documenting electronic sources on the Internet. s.f [Fecha de consulta: 21 de febrero de 2015, 6:15 pm] Disponible en <https://github.com/scipy/scipy> [50] Scipy/.org [en l√≠nea]: documenting electronic sources on the Internet. s.f [Fecha de consulta: 21 de febrero de 2015, 6:16 pm] Disponible en <http://www.scipy.org> [51] DEVLIN, H. Mapreduce in R [en l√≠nea]: documenting electronic sources on the Internet. 2014 [Fecha de consulta: 4 de septiembre de 2015, 10:59 am] Disponible en < https://github.com/RevolutionAnalytics/rmr2/blob/master/docs/tutorial.md > http://www.oldemarrodriguez.com/yahoo_site_admin/assets/docs/Presentaci%C3%B3n_-_Redes_-_Consenso_-_Potenciacion.293124147.pdf http://www.oldemarrodriguez.com/yahoo_site_admin/assets/docs/Presentaci%C3%B3n_-_Redes_-_Consenso_-_Potenciacion.293124147.pdf http://es.wikipedia.org/wiki/Random_forest http://es.wikipedia.org/wiki/Red_neuronal_artificial http://es.wikipedia.org/wiki/An%C3%A1lisis_de_componentes_principales https://github.com/RevolutionAnalytics/RHadoop/wiki https://github.com/scipy/scipy https://github.com/RevolutionAnalytics/rmr2/blob/master/docs/tutorial.md