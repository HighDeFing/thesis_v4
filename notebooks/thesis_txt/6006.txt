Solución de Inteligencia de Negocios por medio de NoSQL UNIVERSIDAD CENTRAL DE VENEZUELA FACULTAD DE CIENCIAS ESCUELA DE COMPUTACIÓN CENTRO DE INVESTIGACIÓN DE SISTEMAS DE INFORMACIÓN CISI Trabajo Especial de Grado presentado ante la ilustre Universidad Central de Venezuela por Br. Mayra, Perez Tutores: Prof. Mercy Ospina Caracas, Mayo 2017. SOLUCIÓN DE INTELIGENCIA DE NEGOCIOS PARA EL SEGUIMIENTO DE PROYECTOS DE INVESTIGACIÓN DE LA FACULTAD DE CIENCIAS, UCV Prof. Cor)(21 tr)G-1) r Vces4k (Jurado) UNIVERSIDAD CENTRAL DE VENEZUELA FACULTAD DE CIENCIAS ESCUELA DE COMPUTACIÓN ACTA Quienes suscriben, miembros del jurado designado por el Consejo de la Escuela de Computación, para examinar el Trabajo Especial de Grado titulado "SOLUCIÓN DE INTELIGENCIA DE NEGOCIOS PARA EL SEGUIMIENTO DE PROYECTOS DE INVESTIGACIÓN DE LA FACULTAD DE CIENCIAS, UCV" y presentado por el bachiller: Br Mayra Perez, a los fines de optar al título de Licenciado en Computación, dejamos constancia de lo siguiente: Leído como fue dicho trabajo, por cada uno de los miembros del jurado, se fijó el día 22 de Mayo del 2017 a las 9 a.m horas, para que la autora lo defendiera en forma pública, lo que estos hicieron en la Sala Aula 1 de la Escuela de Computación, mediante una presentación oral de su contenido, luego de lo cual respondieron a las preguntas formuladas. Finalizada la defensa pública del Trabajo Especial de Grado, el jurado decidió aprobar con la nota de puntos. En fe de lo cual se levanta la presente Acta, en Caracas el día 22 de O del apn- Prof. Mercy Ospina (Tutora) AGRADECIMIENTOS Quiero comenzar agradeciendo a Dios, esa fuerza toda poderosa que siempre me indica el camino correcto a seguir cuando me encuentro desorientada. Quiero agradecerle por cada persona que ha puesto en mi vida durante todos estos años de carrera, ya que todas me han ayudado y enseñado muchas cosas. Quiero agradecer a mis madres, por su amor, por su apoyo, por la educación y los principios que me han dado, porque me han hecho ser la persona que soy ahora, una persona buena, correcta y que da lo mejor de sí. A mi hermana Maye y Jenni les agradezco por apoyarme a seguir adelante, a pesar de los obstáculos, y mi hermanita Paola que es mi tesoro y mi fuerza a ser cada día mejor. Quiero agradecer enormemente a mi querido amigo German, por haberme ayudado y ser un ejemplo a seguir en mi carrera. Gracias por haber confiado en mí y darme la oportunidad de aprender tantas cosas de usted. Quiero agradecer a mis también profesora Mercy y al profesor Franky, quienes me han dado su cariño y confianza. Les agradezco por todo el tiempo que me han dedicado cada vez que he necesito de su ayuda y por todas las palabras de motivación que me han hecho seguir adelante. Quiero agradecer a mi novio Daniel, tantos años de amistad, amor, de cariño, confianza y tolerancia hacia mi difícil carácter. Gracias por siempre ayudarme, gracias por siempre motivarme, por estar cuando te necesito, gracias por ser quien eres, gracias por estar en mi vida, gracias mi amor. Quiero agradecer a mi buen amigo Victor, que desde que apareció en mi vida siempre ha confiado en mí, me ha ayudado de manera excepcional y me ha dado su apoyo en todo momento. Finalmente quiero agradecer a todas aquellas personas que me dijeron “Sí puedes”, cuando yo sólo me repetía “No puedo, es imposible”. Gracias Sra. Omarira, gracias Leo, gracias Jhonatan, gracias Mafer, gracias Dorjes, gracias a todos. UNIVERSIDAD CENTRAL DE VENEZUELA FACULTAD DE CIENCIAS ESCUELA DE COMPUTACIÓN CISI SOLUCIÓN DE INTELIGENCIA DE NEGOCIOS PARA EL SEGUIMIENTO DE PROYECTOS DE INVESTIGACIÓN DE LA FACULTAD DE CIENCIAS, UCV Autor: Br. Mayra, Perez Tutor: Prof. Mercy Ospina Fecha: Mayo 2017 RESUMEN: El presente Trabajo Especial de Grado describe una solución de Inteligencia de Negocio para la Coordinación de Investigación de la Facultad de Ciencias de la UCV, que permite obtener de sus sistemas, la información adecuada para el apoyo en la toma decisiones en los procesos relacionados con los proyectos de investigación de los profesores y profesionales de la Facultad. La Coordinación de Investigación cuenta con una base de datos para almacenar y procesar los datos, pero no tiene mecanismos efectivos para la interpretación, análisis y visualización adecuados para la información almacenada en ella. Conociendo las necesidades existentes, en el presente Trabajo de Grado, se plantea el desarrollo de una solución adecuada de Inteligencia de Negocio, que permite establecer una serie de indicadores de gestión, para apoyar en la toma de decisiones gerenciales a la Coordinación de Investigación, generando información confiable que permita interpretar los datos almacenados. La solución de Inteligencia de Negocio fue creada en su mayor parte con tecnología de software libre (PostgreSQL y Pentaho Data Integration o Kettle), junto con Tableau que es un software propietario. El desarrollo se hizo bajo una adaptación de la metodología ascendente (Bottom-Up) de Ralph Kimball. El presente trabajo es un prototipo debido a que la base de datos no se encuentra datos reales. Sin embargo, es completamente funcional y está listo para cuando se tengan los datos. Adicionalmente puede ser ampliado cuando sea necesario. Palabras Claves: Investigación, Inteligencia de Negocios, PostgreSQL, Kettle, Tableau Desktop. ESTUDIO DE UNA SOLUCIÓN DE INTELIGENCIA DE NEGOCIOS PARA EL SEGUIMIENTO DE PROYECTOS DE INVESTIGACIÓN DE LA FACULTAD DE CIENCIAS, UCV Índice general 1. Problema de Investigación 7 1.1. Situación Actual . . . . . . . . . . . . . . . . . . . . . . . . 7 1.2. Planteamiento del Problema . . . . . . . . . . . . . . . . . 7 1.3. Solución Propuesta . . . . . . . . . . . . . . . . . . . . . . 8 1.3.1. Objetivo General . . . . . . . . . . . . . . . . . . . 9 1.3.2. Objetivo Especí�cos . . . . . . . . . . . . . . . . . . 9 1.4. Justi�cación . . . . . . . . . . . . . . . . . . . . . . . . . . 10 1.5. Alcance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10 2. Marco Conceptual 11 2.1. Facultad de Ciencias . . . . . . . . . . . . . . . . . . . . . 11 2.1.1. Estructura Organizativa . . . . . . . . . . . . . . . . 11 2.1.2. Coordinación de Investigación . . . . . . . . . . . . 12 2.2. Indicadores . . . . . . . . . . . . . . . . . . . . . . . . . . . 14 2.2.1. Criterios de los Indicadores . . . . . . . . . . . . . . 14 2.2.2. Objetivo de un indicador . . . . . . . . . . . . . . . 15 2.2.3. Características . . . . . . . . . . . . . . . . . . . . . 15 2.2.4. Tipología de Indicadores . . . . . . . . . . . . . . . 16 2.3. Inteligencia de Negocio (Business Intelligence) . . . . . . . . 17 2.3.1. Inteligencia . . . . . . . . . . . . . . . . . . . . . . . 17 2.3.2. Negocio . . . . . . . . . . . . . . . . . . . . . . . . 17 2.3.3. De�nición de Inteligencia de Negocio . . . . . . . . . 17 2.3.3.1. Características . . . . . . . . . . . . . . . . 18 2.3.4. Niveles de Soluciones de Inteligencia de Negocio . . . 19 2.3.5. Arquitectura de una Solución de Inteligencia de Ne- gocio . . . . . . . . . . . . . . . . . . . . . . . . . . 19 2 ÍNDICE GENERAL 3 2.3.6. Fuentes de Datos . . . . . . . . . . . . . . . . . . . 21 2.3.7. Procesos de Extracción, Transformación y Carga (ETL) 21 2.3.8. Almacén de Datos (Data Warehouse) . . . . . . . . 22 2.3.8.1. De�nición . . . . . . . . . . . . . . . . . . 23 2.3.8.2. Características . . . . . . . . . . . . . . . . 23 2.3.8.3. Arquitectura . . . . . . . . . . . . . . . . . 25 2.3.8.4. Metadata . . . . . . . . . . . . . . . . . . 27 2.3.8.5. Requerimientos de un DWH . . . . . . . . 27 2.3.9. Bodega de Datos (Data Mart) . . . . . . . . . . . . 28 2.3.9.1. Estrategias de Construcción . . . . . . . . 29 2.3.10. Modelo Dimensional del DWH . . . . . . . . . . . . 29 2.3.10.1. De�nición . . . . . . . . . . . . . . . . . . 30 2.3.10.2. Tabla de Dimensión . . . . . . . . . . . . . 30 2.3.10.3. Tabla de Hechos . . . . . . . . . . . . . . . 30 2.3.10.4. Esquema Estrella (Star Scheme) . . . . . . 31 2.3.10.5. Esquema Copo de Nieve (Snow�ake Scheme) 32 2.3.10.6. Esquema Constelación (Star�ake Scheme) . 33 2.3.10.7. Granularidad . . . . . . . . . . . . . . . . 34 2.3.10.8. Jerarquía . . . . . . . . . . . . . . . . . . . 34 2.3.10.9. Agregación . . . . . . . . . . . . . . . . . . 35 2.4. Herramientas Tecnológicas . . . . . . . . . . . . . . . . . . 35 2.4.1. Herramientas de Análisis y visualización . . . . . . . 35 2.4.1.1. Reportes . . . . . . . . . . . . . . . . . . . 35 2.4.1.2. Indicadores . . . . . . . . . . . . . . . . . 36 2.4.2. Herramienta de Extracción, Transformación y Carga (ETL) . . . . . . . . . . . . . . . . . . . . . . . . . 37 2.4.2.1. Pentaho . . . . . . . . . . . . . . . . . . . 37 2.4.2.2. Pentaho Data Integration . . . . . . . . . . 38 2.4.3. Herramienta para crear la bodega de datos (Datamart) 39 2.4.3.1. PostgreSQL . . . . . . . . . . . . . . . . . 40 2.4.4. Herramientas de Visualización . . . . . . . . . . . . 41 2.4.4.1. Tableau . . . . . . . . . . . . . . . . . . . 41 3. Marco Metodológico 46 3.1. Metodología Descendente (TOP-DOWN) . . . . . . . . . . 46 ÍNDICE GENERAL 4 3.1.1. Metodología de Bill Inmon . . . . . . . . . . . . . . 46 3.1.2. Parte 1: Desarrollo de Sistemas Operacionales . . . . 48 3.1.3. Parte 2: Desarrollo del almacén de datos . . . . . . . 50 3.1.4. Parte 3: Uso del Almacén de Datos . . . . . . . . . . 51 3.1.5. Plan de Migración (Migration Path) . . . . . . . . . 51 3.2. Metodología Ascendente (BOTTOM-UP) . . . . . . . . . . 53 3.2.1. Metodología de Ralph Kimball . . . . . . . . . . . . 54 3.2.2. Plani�cación del Proyecto . . . . . . . . . . . . . . . 55 3.2.3. De�nición de los Requerimientos del Negocio . . . . 55 3.2.4. Diseño de la Arquitectura . . . . . . . . . . . . . . . 56 3.2.5. Selección de productos e instalación . . . . . . . . . 58 3.2.6. Diseño de Datos o modelado dimensional . . . . . . 58 3.2.7. Especi�cación y desarrollo de aplicaciones analíticas 61 3.2.8. Implementación . . . . . . . . . . . . . . . . . . . . 61 3.2.9. Despliegue y Crecimiento . . . . . . . . . . . . . . . 62 3.3. Metodología a seguir . . . . . . . . . . . . . . . . . . . . . 63 4. Marco Aplicativo 65 4.1. Plani�cación del Proyecto . . . . . . . . . . . . . . . . . . . 65 4.2. De�nición de los Requerimientos . . . . . . . . . . . . . . . 66 4.3. Diseño de la Arquitectura Técnica . . . . . . . . . . . . . . 67 4.4. Selección de Productos e Instalación . . . . . . . . . . . . . 68 4.5. Modelo Dimensional . . . . . . . . . . . . . . . . . . . . . . 69 4.6. Diseño físico . . . . . . . . . . . . . . . . . . . . . . . . . . 76 4.7. Diseño y Construcción de procesos ETL . . . . . . . . . . . 79 4.7.1. Diseño de Procesos de ETL y Desarrollo (almacén de datos) . . . . . . . . . . . . . . . . . . . . . . . . . 79 4.7.2. Veri�car la calidad de los datos . . . . . . . . . . . . 81 4.7.3. Veri�cación de la calidad de los datos de los compo- nentes del modelo implementado . . . . . . . . . . . 87 4.7.3.1. Veri�cación de la tabla de hecho investiga- ción con sus dimensiones . . . . . . . . . . 87 4.7.3.2. Detallar los requerimientos según el modelo 92 4.8. Desarrollo de los requerimientos de información . . . . . . . 93 4.8.1. Con�guración de la conexión . . . . . . . . . . . . . 93 ÍNDICE GENERAL 5 4.8.2. Generador de los indicadores de gestión . . . . . . . 94 4.8.3. Desarrollo y distribución de consultas . . . . . . . . 95 4.8.3.1. Tabla de hecho de investigación . . . . . . 95 4.8.4. Veri�car la calidad de los datos en la herramienta de manipulación y visualización de datos . . . . . . . . 105 4.9. Implementación . . . . . . . . . . . . . . . . . . . . . . . . 108 4.9.1. Ajuste de las consultas . . . . . . . . . . . . . . . . 108 Índice de �guras 1.1. Arquitectura de la Solución Propuesta . . . . . . . . . . . . . . . . . . 9 2.1. Estructura organizativa de investigación de la Escuela de Física de la Facultad de Ciencias de la UCV. (Fuente [CoorInv, 2011]). . . . . . . . 12 2.2. Indicadores de Gestión (Fuente [Indicador,2014]) . . . . . . . . . . . . . 15 2.3. Clasi�cación según los factores claves . . . . . . . . . . . . . . . . . . . 16 2.4. Niveles (Fuente [Inteligencia de Negocios, 2017]) . . . . . . . . . . . . . 19 2.5. Componentes de inteligencia de negocio . . . . . . . . . . . . . . . . . . 20 2.6. Fuentes de Datos . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21 2.7. Procesos de Extracción, Transformación y Carga (ETL) (Fuente [Cano, 2007]) 22 2.8. Almacén de Datos . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22 2.9. Histórico de DWH (Fuente [DWH, 2015]) . . . . . . . . . . . . . . . . . 24 2.10. No Volátil (Fuente [DWH, 2015]) . . . . . . . . . . . . . . . . . . . . . 24 2.11. La Arquitectura (Fuente [DWH, 2010] ) . . . . . . . . . . . . . . . . . . 26 2.12. Bodega de Datos (Fuente [Cano, 2007]) . . . . . . . . . . . . . . . . . . 28 2.13. Tablas de Dimensión (Fuente [Kimball, 2002]) . . . . . . . . . . . . . . 30 2.14. Tabla de Hechos (Fuente [Kimball, 2002] ) . . . . . . . . . . . . . . . . 31 2.15. Esquema Estrella de lo tickets (Fuente [Cano, 2007]) . . . . . . . . . . 32 2.16. Esquema Copo de Nieve o Snow�ake (fuente [Cano, 2007]) . . . . . . . 32 2.17. Esquema Constelación [Bernabeu, 2009] . . . . . . . . . . . . . . . . . 33 2.18. Jerarquía de lugar (Fuente [Cano, 2007]) . . . . . . . . . . . . . . . . . 34 2.19. Herramienta de Análisis y visualización (Fuente [Cano, 2007]) . . . . . 35 2.20. Ejemplos Reportes (Fuente [Planeaux, 2007]) . . . . . . . . . . . . . . . 36 2.21. Ejemplos Indicadores (Fuente [Planeaux, 2007]) . . . . . . . . . . . . . 36 2.22. Pentaho Arquitectura (Fuente:[Pentaho, 2016] ) . . . . . . . . . . . . . 38 2.23. Interfaz grá�ca de Spoon . . . . . . . . . . . . . . . . . . . . . . . . . . 39 2.24. Tableau Server (Fuente[TableauPDF, 2016]) . . . . . . . . . . . . . . . 42 2.25. Arquitectura de Tableau Server (Fuente [TableauPDF, 2016]) . . . . . . 43 3.1. Enfoque Inmon (Fuente [Kimball, 2010]) . . . . . . . . . . . . . . . . . 48 3.2. Enfoque R. Kimball (Fuentes [Kimball, 2010]) . . . . . . . . . . . . . . 53 3.3. Ciclo de Vida de la Metodología de Ralph Kimball (Fuente [Kimball, 2002]) 55 3.4. Ciclo de vida dimensional adaptado a inteligencia de negocio . . . . . . 64 1 ÍNDICE DE FIGURAS 2 4.1. Arquitectura de Diseño . . . . . . . . . . . . . . . . . . . . . . . . . . . 67 4.2. Arquitectura de Diseño con sus herramientas . . . . . . . . . . . . . . . 68 4.3. Modelo Dimensiona tipo estrella . . . . . . . . . . . . . . . . . . . . . . 70 4.4. Jerarquía de las dimensiones . . . . . . . . . . . . . . . . . . . . . . . . 70 4.5. Dimensión de Área de aplicación . . . . . . . . . . . . . . . . . . . . . 73 4.6. Modelo de�nitivo tipo estrella . . . . . . . . . . . . . . . . . . . . . . . 76 4.7. Dimensión Tiempo . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 77 4.8. Diseño lógico de las dimensiones . . . . . . . . . . . . . . . . . . . . . 77 4.9. ETL de la Dimension Investigador . . . . . . . . . . . . . . . . . . . . . 78 4.10. Modelo dimensional . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 79 4.11. ETL de Dimensión Investigador . . . . . . . . . . . . . . . . . . . . . . 79 4.12. ETL de los Hechos del nivel académico a la Tabla de Hecho de investigación 80 4.13. El llenado del almacén de datos . . . . . . . . . . . . . . . . . . . . . . 81 4.14. Veri�cación de la dimensión investigador . . . . . . . . . . . . . . . . . 81 4.15. Veri�cación de la cantidad de los datos de la dimensión investigador . . 82 4.16. Veri�cación de la dimensión área de conocimiento . . . . . . . . . . . . 82 4.17. Veri�cación de la cantidad de datos de la dimensión área de conocimiento 82 4.18. Veri�cación de la dimensión área de aplicación . . . . . . . . . . . . . . 83 4.19. Veri�cación de la cantidad de datos de área de aplicación . . . . . . . 83 4.20. Veri�cación de la dimensión institución . . . . . . . . . . . . . . . . . . 83 4.21. Veri�cación de la cantidad de datos de la dimensión institución . . . . . 84 4.22. Veri�cación de la dimensión proyecto . . . . . . . . . . . . . . . . . . . 84 4.23. Veri�cación de la cantidad de datos de la dimensión proyecto . . . . . . 84 4.24. Veri�cación de la dimensión producto . . . . . . . . . . . . . . . . . . . 85 4.25. Veri�cación de la cantidad de datos de la dimensión producto . . . . . 85 4.26. Veri�cación de la dimensión evento . . . . . . . . . . . . . . . . . . . . 85 4.27. Veri�cación de la cantidad de datos de la dimensión evento . . . . . . . 86 4.28. Veri�cación de la cantidad de datos de la dimensión nivel académico . . 86 4.29. Veri�cación de la cantidad de datos de la dimensión nivel académico . . 86 4.30. Veri�cación de datos de la dimensión tiempo . . . . . . . . . . . . . . . 87 4.31. Comparación de los dato del modelo con la dimensión tiempo . . . . . 88 4.32. Proyecto en la base de datos . . . . . . . . . . . . . . . . . . . . . . . . 88 4.33. Dimensión proyecto con la tabla de hecho investigación . . . . . . . . . 89 4.34. Dimensión área de conocimiento con la tabla de hecho investigación . . 89 4.35. Área de conocimiento en el almacén de datos . . . . . . . . . . . . . . . 89 4.36. Subárea de aplicación en la base de datos . . . . . . . . . . . . . . . . 90 4.37. Dimensión área de aplicación con la tabla de hecho investigación . . . . 90 4.38. Dependencia en la base de datos . . . . . . . . . . . . . . . . . . . . . . 91 4.39. Dimensión institución con la tabla de hecho investigación . . . . . . . . 91 4.40. Usuario en la base de datos . . . . . . . . . . . . . . . . . . . . . . . . 91 4.41. Dimensión investigador con la tabla de hecho investigador . . . . . . . 92 4.42. Creación de la conexión con la fuentes de dato desde Tableau . . . . . . 93 4.43. La tabla de hecho investigación con sus dimensiones . . . . . . . . . . . 94 ÍNDICE DE FIGURAS 3 4.44. Elemento de almacén de datos . . . . . . . . . . . . . . . . . . . . . . . 94 4.45. Conteo de proyectos del investigador . . . . . . . . . . . . . . . . . . . 95 4.46. Conteo de proyectos por área de conocimiento . . . . . . . . . . . . . . 96 4.47. Grá�ca de conteo de proyectos del investigador . . . . . . . . . . . . . . 96 4.48. Conteo de proyectos por área de aplicación . . . . . . . . . . . . . . . . 97 4.49. Grá�ca de conteo de proyectos por área de aplicación . . . . . . . . . . 97 4.50. Conteo de proyectos por institución . . . . . . . . . . . . . . . . . . . . 98 4.51. Grá�ca de conteo de proyectos por institución . . . . . . . . . . . . . . 98 4.53. Cantidad de productos por institución . . . . . . . . . . . . . . . . . . 99 4.52. Conteo de producto del investigador . . . . . . . . . . . . . . . . . . . . 99 4.54. Conteo de productos por área de conocimiento . . . . . . . . . . . . . . 100 4.55. Grá�ca de conteo de productos por área de conocimiento . . . . . . . . 100 4.56. Conteo de productos por área de aplicación . . . . . . . . . . . . . . . . 101 4.57. Grá�ca de conteo de productos por área de aplicación . . . . . . . . . . 101 4.58. Conteo de eventos por investigador . . . . . . . . . . . . . . . . . . . . 102 4.59. Los proyectos del investigador . . . . . . . . . . . . . . . . . . . . . . . 102 4.60. Los proyectos del área de conocimiento . . . . . . . . . . . . . . . . . . 103 4.61. Los proyectos de las instituciones . . . . . . . . . . . . . . . . . . . . . 103 4.62. Los productos del investigador . . . . . . . . . . . . . . . . . . . . . . . 104 4.63. Los productos del área de aplicación . . . . . . . . . . . . . . . . . . . 104 4.64. Evento de los investigador . . . . . . . . . . . . . . . . . . . . . . . . . 105 4.65. El nivel académico de los investigador . . . . . . . . . . . . . . . . . . . 105 4.66. Veri�cación de la tabla de hecho investigación con base de datos . . . . 106 4.67. Veri�cación de la tabla de hecho investigación con base de datos . . . . 106 4.68. Veri�cación de la tabla de hecho investigación con base de datos . . . . 107 4.69. Veri�cación de la tabla de hecho de nivel académico con base de datos . 107 Índice de cuadros 3.1. Marco de trabajo de la Arquitectura . . . . . . . . . . . . . . . . . . . 57 3.2. Comparación de las metodologías . . . . . . . . . . . . . . . . . . . . . 63 4.1. Plani�cación del proyecto . . . . . . . . . . . . . . . . . . . . . . . . . 66 4.2. Dimensión Tiempo . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 71 4.3. Detalle de la Dimensión Investigador . . . . . . . . . . . . . . . . . . . 72 4.4. Dimensión de Institución . . . . . . . . . . . . . . . . . . . . . . . . . . 72 4.5. Dimensión de Área de Conocimiento . . . . . . . . . . . . . . . . . . . 73 4.6. Dimensión de Proyecto . . . . . . . . . . . . . . . . . . . . . . . . . . . 73 4.7. Dimensión de Producto . . . . . . . . . . . . . . . . . . . . . . . . . . . 74 4.8. Dimensión de Evento . . . . . . . . . . . . . . . . . . . . . . . . . . . . 74 4.9. Dimensión Nivel Académico . . . . . . . . . . . . . . . . . . . . . . . . 75 4.10. Tabla de Hecho Gestión de los proyectos . . . . . . . . . . . . . . . . . 75 4 Introducción �Las organizaciones pueden ser ricas en datos y pobres en información...� Stuart Madnick, 1993 Trabajo de Grado se presenta un conjunto de conceptos, metodologías y herramien- tas que permiten llevar a cabo el desarrollo de una solución de Inteligencia de Negocio para la Coordinación de Investigación de la Facultad de Ciencias de la Universidad Central de Venezuela. La Facultad de Ciencias de la Universidad Central de Venezuela está conformada por Escuelas e Institutos, y éstas a su vez por Centros y Laboratorios de Investigación, donde profesores y otros profesionales llevan a cabo investigaciones. Para administrar las unidades de investigación de la Facultad, existe una Coordi- nación de Investigación. Esta coordinación dispone de una base de datos relacional, llamada Base de Datos del Sistema de Gestión de Información Cientí�ca (BD SIGIC), donde se centraliza la información de los investigadores y sus proyectos. BD SIGIC es usada para almacenar y procesar los datos, pero no tiene mecanismos efectivos para la interpretación de la información. Para poder interpretar toda esa información, fue necesario extraerla del medio donde se encontraba, para llevarla a un almacén de datos (DWH) y luego procesarla mediante una herramienta de inteligencia de negocio. La herramienta de inteligencia de negocio permite una gran �exibilidad y manipu- lación de los datos, dando la capacidad de hacer todo tipo de análisis y visualizaciones para la generación de conocimiento y ayudar así en la toma de decisiones gerenciales. El presente trabajo es un prototipo debido a que la base de datos de la Coordina- ción de Investigación se encuentra con datos incompletos. Sin embargo, este prototipo es completamente funcional y está listo para cuando se introduzcan los datos. Adicio- nalmente el sistema es �exible y puede ser ampliado cuando se carguen los datos, no es una actividad de una sola vez sino un proceso continuo y de mejoramiento. Este documento se encuentra organizado en cuatro (4) capítulos, y una sección de conclusiones y recomendaciones. Dichos capítulos se encuentran estructurados de la siguiente manera: Capítulo 1 - Problema de Investigación. Se expone la situación actual, el problema, los objetivos generales y especí�cos contemplados, la justi�cación del proyecto, la solución propuesta y el alcance de�nido para la investigación. 5 ÍNDICE DE CUADROS 6 Capítulo 2 - Marco Conceptual. Se describen los tópicos más relevantes que se encuentran relacionados con el tema de investigación, los aspectos contemplados se describen a continuación: � Facultad de Ciencias. Su estructura organizativa, la Coordinación de In- vestigación. � Inteligencia de Negocio. De�nición, arquitectura de una solución de in- teligencia de negocio. ◦ Almacén de Datos. De�nición, características y su arquitectura. Adi- cionalmente se de�ne los conceptos concernientes al modelo dimensional. ◦ Indicadores de Gestión. De�nición, tipos de indicadores de gestión y los criterios de los indicadores de gestión. � Herramientas Tecnológicas. Componente para el desarrollo de la solu- ción, herramienta ETL, herramienta para construir el almacén de datos y herramientas analíticas y de explotación. Capítulo 3 - Marco Metodológico. Se describen las distintas etapas que com- ponen la metodología propuesta por Ralph Kimball para el desarrollo de una solución de inteligencia de negocio. Capítulo 4 - Marco Aplicativo. Se especi�can las actividades realizadas para el desarrollo de una solución de inteligencia de negocio para la Coordinación de Investigación siguiendo las etapas de metodología de�nida por Ralph Kimball de manera no estricta. Finalmente se presentan las conclusiones y recomendaciones del presente trabajo inves- tigativo, así como también la bibliografía. Capítulo 1 Problema de Investigación En este Capítulo se presenta el problema que motiva este Trabajo Especial de Grado (TEG), una descripción general de las soluciones propuesta, alcance, objetivo general y objetivos especí�cos del TEG. 1.1. Situación Actual En la Actualidad, la Coordinación de Investigación, tiene un Sistema de Gestión de Información Cientí�ca (SIGIC), la cual permite registrar y gestionar la información, actividades, proyectos y productos producidos por los investigadores de la Facultad de Cienciasde manera rápida y sencilla, en una base de datos centralizada, el cual será de gran utilidad para permitir el pleno funcionamiento de cualquier aplicación que requiera de esta información, pero no se cuenta con reportes y indicadores para el análisis de datos y apoyar la toma de decisiones por parte de la Coordinación de Investigación [Pérez, 2016]. Sin embargo se tiene la necesidad de visualizar ciertos reportes y indicadores de gestión para tener la información de una manera más resumida, es decir transformar los datos crudos en información para la toma decisiones. Porque la información es uno de los recursos más importante que tiene una organización siempre y cuando sea con�able y acertada, demás es la base para plantear estrategias de negocio. Además la mayoría de las organizaciones tienden a tener un gran número de datos, pero muy poca información ya que no saben como resumir y categorizar los datos. 1.2. Planteamiento del Problema La Coordinación de Investigación de la Facultad de Ciencias de la Universidad Central de Venezuela cuenta con una base de datos centralizada donde se almacena información de los proyecto de investigación. A pesar de la cantidad de datos que se recolecta continuamente y del control, se tiene muy poca información de los proyectos, productos de investigación.. 7 CAPÍTULO 1. PROBLEMA DE INVESTIGACIÓN 8 Dado a que usualmente se manejan los datos, se di�culta la tarea de obtener in- formación útil para analizar y visualizar los reportes generados, los cuales requieren de mucho tiempo para su elaboración. Esta demora di�culta la toma de decisiones acertadas y oportunas. La Coordinación de Investigación cuenta con una base de datos donde se almacena la información relacionada con las actividades de investigación de la Facultad, junto con una aplicación que permite de manera sencilla, registrar y administrar dicha informa- ción. Este tipo de almacenamiento tiene problemas en cuanto a mecanismos efectivos para la interpretación, análisis y visualización de los datos almacenados en ella. Es por ello que se crea un módulo de análisis de datos para toma de decisiones partiendo de las fuentes de datos y llevarla a un almacén de datos (Data Warehouse) y que esta sea visualizada mediante una herramienta de visualización y de exploración. Se desarrolla una capa de análisis de procesos, que podrá comunicarse directamente con los esquemas propios de la bases de datos de la Coordinación de Investigación. La idea es tener toda la información que servirá para generar una serie de responder y indicadores de gestión de los proyectos, productos, eventos, y nivel académico. 1.3. Solución Propuesta Dados los inconvenientes mencionados, se necesita desarrollar una serie de reportes y indicadores de gestión relacionados con de los proyectos, productos, eventos, y nivel académico de los investigadores para la toma de decisiones, de manera consistente y oportuna. Se propone una solución de Inteligencias de negocio (BI), cuya arquitectura se des- cribe en �gura 1.1, el cual parte de las fuentes de datos, se incorpora los datos mediante el proceso de extracción, transformación y carga de los datos (ETL) al almacén de datos, bodega de datos (Data Mart), y mediante las herramientas de análisis y de exploración se visualizara la información. Dicho prototipo se desarrolló para la Coordinación de In- vestigación de la Facultad de Ciencias y permite la obtención de reportes, indicadores para apoyar la toma de decisiones, ya que por cierta problemática no se logró emplear dicha solución. CAPÍTULO 1. PROBLEMA DE INVESTIGACIÓN 9 Figura 1.1: Arquitectura de la Solución Propuesta Fuentes de datos. Corresponde a la fuente de datos de la organización que sean relevantes para el BI. ETL. Encargada de la integración desde múltiples fuentes existentes para la cons- trucción del almacén de datos. Almacén de datos. La colección de datos orientados a temáticas, integrados, no volátiles que cambian en el tiempo que apoya la toma de decisiones. Bodegas de Datos que se re�ere a una vista del DWH orientado solo a un aspecto de la organización. Visualización y explotación de datos. Es la encargada de desplegar los aná- lisis de la información. La metodología que se va a emplear para desarrollar esta solución de Inteligencia de Negocio, es una adaptación la metodología Ascendente (Bottom-up) de Ralph Kimball, pero no se empleara de manera estricta. 1.3.1. Objetivo General Desarrollar una solución de Inteligencia de Negocio para generar reportes y indica- dores de investigación de la Facultad de Ciencias. 1.3.2. Objetivo Especí�cos 1. Analisis de los requerimientos, indicadores de investigación de la Facultad de Cien- cias. 2. Analizar y de�nir las fuentes de datos que permitan alimentar al almacén de datos (DWH). 3. Diseñar el modelo dimensional. CAPÍTULO 1. PROBLEMA DE INVESTIGACIÓN 10 4. Construcción del almacén de datos. 5. Desarrollar los reportes y indicadores de gestión para el monitoreo del DWH. 6. Realizar pruebas de integración, funcionales, calidad de datos, de aceptación. 1.4. Justi�cación Se pretende desarrollar un prototipo de inteligencia de negocio que se adapte a los requerimientos de la coordinación, con respecto a los proyectos de investigación, que permita observar y evaluar la gestión de los procesos, para realizar el análisis basándose en los hechos del sistema. Adicionalmente, se pueden hacer comparaciones con los datos históricos y usar éstos para hacer proyecciones en el tiempo y análisis, con la �nalidad de solventar, permite corregir o mejorar el proceso. El desarrollo de una solución de inteligencia de negocio, permitirá a la coordinación disponer de un sistema orientado a la toma decisiones, utilizando tecnología de software libre como PostgreSQL, Pentaho y Tableau que un software con versión gratuita. Se tiene las herramientas necesarias para generar la solución de inteligencia de negocio orientado al análisis del negocio, y en consecuencia, apoyar la toma decisiones de la Coordinación de Investigación de la Facultad de Ciencias de la UCV. 1.5. Alcance Un prototipo que plantea ser de gran utilidad para el desarrollo de una solución Inteligencia de Negocio (BI) de la Coordinación de Investigación, para la toma de decisiones de una manera precisa y oportuna, ya que existe la necesidad de poder interpretar de una manera sencilla, versátil y rápida todos los datos que se generan a raíz de los procesos de negocios y así tomar decisiones efectivas que incrementen la productividad. Se realizará el análisis de los proyectos de investigación, diseño e implementación de dicha solución que abarcará, desde diseño y extracción de los datos, además del almacén de datos (DWH), y la creación de los diferentes reportes y indicadores de gestión para la toma decisiones. No es una actividad de una sola vez, es un proceso de mejoramiento continuo. Capítulo 2 Marco Conceptual En este capítulo se abordan todos los elementos a emplear como base teórica para el desarrollo de la solución de inteligencia de negocio. Es decir, se detallan los distin- tos conceptos, de�niciones, arquitectura, esquemas, entre otros, que están relacionado: inteligencia de negocio, almacén de datos, Modelo Dimensional, Bodegas de Datos, Herramientas Tecnológicas. 2.1. Facultad de Ciencias La Facultad de Ciencias es una de las facultades de la Universidad Central de Venezuela (UCV) que ofrece continuamente aportes a la Ciencia y a la Tecnología del país, en ella se realizan numerosas investigaciones en las distintas Escuelas e Institutos que la conforman. Dentro de la Facultad de Ciencias se encuentra la Coordinación de Investigación, encargada de apoyar y administrar los proyectos de investigación. 2.1.1. Estructura Organizativa La Facultad de Ciencias está conformada por cinco escuelas y cuatro institutos. Las escuelas de la Facultad de Ciencias son biología, computación, física, matemáticas y química, y los cuatro institutos son ciencias de la tierra, zoología ecología tropical, ciencias de tecnologías de alimentos y biología experimental. Es estas escuelas e institutos, grupos de investigadores, profesores y profesionales se dedican a la búsqueda y experimentación de diferentes líneas de investigación. En los Centros de Investigación se realizan constantemente actividades de investiga- ción cientí�ca y/o tecnológica, que favorezcan el desarrollo del país y el bienestar de la sociedad venezolana, además de: captación y entrenamiento de capital humano, transfe- rencia de tecnología, difusión, divulgación cientí�ca y gestión, seguimiento y evaluación de procesos de ciencia y tecnología [Borges, 2006]. En los Laboratorios de Investigación se elaboran y ejecutan proyectos de investiga- ción, se contribuye con la formación de investigadores, se organizan y/o dictan cursos, se brinda asesoramiento y se gestionan recursos económicos y materiales. 11 CAPÍTULO 2. MARCO CONCEPTUAL 12 Normalmente, los Laboratorios de Investigación están adscritos a un Centro de In- vestigación, pero también pueden existir Laboratorios que no pertenezcan a ningún Centro. Esto ocurre porque no hay un Centro relacionado con la línea de investigación del Laboratorio y porque la cantidad de investigadores pertenecientes a dicho Labo- ratorio no es su�ciente para crear un nuevo Centro y así poder cumplir con todas las formalidades necesarias. En la �gura 2.1 se puede ver un ejemplo de una escuela de la Facultad de Cien- cias que tiene Laboratorios de Investigación que no están adscritos a un Centro de Investigación. Figura 2.1: Estructura organizativa de investigación de la Escuela de Física de la Fa- cultad de Ciencias de la UCV. (Fuente [CoorInv, 2011]). 2.1.2. Coordinación de Investigación La Coordinación de Investigación de la Facultad de Ciencias es un ente adminis- trativo que se ocupa de la promoción y el apoyo de actividades de investigación, así como también del fomento de relaciones con entes universitarios, gubernamentales y privados, dedicados al �nanciamiento de la ciencia. Fue creada por aprobación de la Facultad de Ciencias, en diciembre de 1991. Inicialmente existía una Comisión de In- CAPÍTULO 2. MARCO CONCEPTUAL 13 vestigación adscrita a la Coordinación de Postgrado formada por los Coordinadores de Investigación de las escuelas, Centros e Institutos de la Facultad de Ciencias, la cual había sido creada por el Consejo de Facultad en enero de 1986 [CoorInv, 2011]. La Coordinación de Investigación está constituida por un Coordinador y por un Consejo de Investigación. El Consejo está formado por el Coordinador de Investigación, quien lo preside, los representantes de cada uno de los Consejos Técnicos de los insti- tutos, los representantes de las Comisiones de Investigación de cada una de las escuelas y representantes de la Facultad ante el Consejo de Desarrollo Cientí�co y Humanístico (CDCH) [CoorInv, 2011]. Entre sus funciones esenciales está realizar el balance de la investigación que se realiza anualmente en la Facultad, analizar y promover el potencial productivo de la misma, dar a conocer a los diferentes entes del entorno nacional el resultado de las investigaciones y facilitar la conexión entre los investigadores y las instituciones externas que puedan promover �nanciamiento a la actividad de investigación [CoorInv, 2011]. El Consejo de Investigación tiene las siguientes atribuciones [CoorInv, 2011]: Proponer al Consejo de Facultad lineamientos generales de política para las ac- tividades de investigación de la Facultad, así como las normas que obliguen a su cumplimiento. Velar por el uso adecuado de los recursos ordinarios y extraordinarios destinados a la investigación en la Facultad. Mantener una base de datos de los recursos de investigación en la Facultad de Ciencias. Proponer al Consejo de Facultad los Representantes de la Coordinación de Inves- tigación ante organismos o entes del Gobierno. Proponer programas de investigación que se consideren necesarios a objeto de solucionar problemas prioritarios en nuestra sociedad. Velar porque las actividades de investigación de la Facultad reciban el apoyo de los recursos y hacer la distribución racional del mismo. Estudiar y evaluar las proposiciones de creación de Institutos y Centros de Inves- tigación, Laboratorios de Investigación y Laboratorios de Apoyo a la Investigación dentro de la Facultad, y hacer las recomendaciones correspondientes. Estimular y orientar las solicitudes de fondos por parte de las diferentes estructu- ras organizativas de investigación de la Facultad ante entes intra y extra univer- sitarios que la fomentan. Divulgar el potencial de investigación de la Facultad de Ciencias, así como los resultados de investigaciones ya realizadas, distinciones y/o premios. CAPÍTULO 2. MARCO CONCEPTUAL 14 Fomentar la creación de Grupos Interdisciplinarios de Investigación, dentro y fuera de la Facultad. Propiciar la realización de eventos que bene�cien las actividades de investigación de la Facultad tales como: Seminarios, Jornadas, Conferencias, Cursos y Reunio- nes. 2.2. Indicadores Los Indicadores de Gestión son expresiones cualitativas o cuantitativas que describen características, comportamiento o fenómenos de una organización, permitiendo evaluar el desempeño y evolución en el tiempo, es decir es un instrumento para la evaluación, medición y análisis de las variables asociadas a las metas y objetivos de la organización. El valor de los indicadores expresan cualitativa o cuantitativa el desempeño de toda una organización o sus partes que permiten proponer una solución y toma acciones que conlleven a los objetivos planteados. Por medio de los indicadores podemos observar la evolución de una variable, establecimiento de una relación entre variables, comparación con períodos anteriores, productos similares o una meta. 2.2.1. Criterios de los Indicadores Los indicadores para que sean útiles y efectivos tienen que cumplir los siguientes criterios: Relevante. Debe tener relación y estar alineado con los objetivos y metas de la organización. Comparable. Se debe poder comparar los valores a lo largo del tiempo en la organización e incluso entre otras organizaciones. Veri�cable. Se debe poder con�rmar que los valores obtenidos sean correctos. (con respecto a lo que se desea medir) Fácil de comprender. Se debe mostrar de una forma clara y sencilla lo que se desea expresar como vemos2.2.1. CAPÍTULO 2. MARCO CONCEPTUAL 15 Figura 2.2: Indicadores de Gestión (Fuente [Indicador,2014]) 2.2.2. Objetivo de un indicador A través de los indicadores puedes observar la evolución de una variable, establecer una relación entre variables es decir: Genera información útil para mejorar el proceso de toma de decisiones. Monitorear y evaluar el desempeño. Cuanti�car los cambios. Identi�car problemas y oportunidades. Medir comportamiento y facilitar la delegación. 2.2.3. Características Las características de los indicadores �SMART� son: Especí�cos (Speci�c). Permite describir la situación o fenómeno determinado. Medible (Measurable). Debe ser cuanti�cable que permitan obtener unos re- sultados objetivos. Siguiendo el principio �lo que no se puede medir, no se puede controlar�. Accionable (Actionable). Que los resultados y análisis permitan tomar deci- siones. Relevante (Relevance). Un objetivo este realmente orientado a la obtención de los resultados en un momento determinado. CAPÍTULO 2. MARCO CONCEPTUAL 16 Oportuno (Timely). Estableciendo el período de tiempo en el que se debe completar cada uno de ellos. 2.2.4. Tipología de Indicadores Existen muchos tipos de clasi�caciones comunes en la teoría sobre indicadores: Medición (Cuantitativos/ Cualitativos). Es una representación numérica. � Cuantitativos. Su característica más importante es que, al encontrarse va- lores diferentes, estos pueden ordenarse de forma ascendente o descendente. � Cualitativos. Su características principal es que su resultado se re�ere a una escala de cualidades. Calidad (E�cacia, E�ciencia, Efectividad). Dan cuenta de la dinámica de actividades especi�cas. � E�cacia. Miden el grado de cumplimiento de los objetivos propuestos o metas programadas. Se concentra en Qué se debe hacer. EficaciaDeObjetivos = ObjetivosAlcanzados ObjetivosP lanteados � E�ciencia. Miden el nivel de ejecución del proceso con un mínimo de recur- sos, se concentran en el Cómo se hicieron las cosas. EficienciaDeObjetivos = ObjetivosLogrados RecursosUtilizados � Efectividad. Este concepto relaciona la e�ciencia y la e�cacia, es decir el logro de los resultados programados en el tiempo y con los costos mas razo- nables posibles. EfictividadDeObjetivos = (PuntajeEficiencia+PuntajeEficacia)/2 MáximoPuntaje Los indicadores se clasi�can según los factores claves de éxito: Figura 2.3: Clasi�cación según los factores claves Jerarquía de objetivos (Gestión/ Estratégicos). � Gestión. Re�eja cuáles fueron las consecuencias de acciones tomadas en el pasado en el marco de una organización. La idea es que estos indicadores CAPÍTULO 2. MARCO CONCEPTUAL 17 sienten bases para acciones o tomar en el presente y en el futuro. Es impor- tante que los indicadores de gestión re�ejen datos veraces y �ables, ya que el análisis de la situación, de otra manera, no será correcto. 2.3. Inteligencia de Negocio (Business Intelligence) En la actualidad la información es uno de los recursos importantes que poseen las organizaciones, sin embargo, su obtención, análisis y manejo no siempre es tan sencillo. La información con�able y acertada es la base para la creación de un estrategia de negocio rentable y productiva. Es por ello, que las distintas organizaciones han enfocado sus esfuerzos no solo en la recopilación de los datos para la generación de información, sino que también, en soluciones que permitan la visualización de reportes e indicadores que ayuden a realizar análisis para la toma de decisiones. 2.3.1. Inteligencia �La inteligencia es información procesada y explotada a un muy alto nivel� [Prior, 2007], es decir, la inteligencia es la capacidad de abstracción para solucionar un problema y de organizar grandes cantidades de información para luego razonar y pensar sobre un aspecto en especí�co. 2.3.2. Negocio Un negocio o una organización es �La acción y el efecto de articular, disponer y hacer operativos un conjunto de medios, factores o elementos para la consecución de un �n concreto� [Andrade, 2005], es decir, es un conjunto de personas que trabajan en conjunto desempeñando diversas actividades para lograr un objetivo en común (satisfacer las necesidades de la sociedad). 2.3.3. De�nición de Inteligencia de Negocio inteligencia de negocio por las siglas en ingles BI (Business Intelligence) por Ho- ward Dresner 1989, cuando era consultor de Gartner, mediante el uso de tecnología y metodologías se quiere convertir datos en información y a partir de la información ser capaces de descubrir conocimientos basados en hechos. También puede intervenir en todos los procesos de una compañía, actuando en las tareas y actividades de los em- pleados, creando nuevas actividades y nuevas habilidades, mejorando la comunicación entre departamentos e incrementando la capacidad de reacción de la compañía. Para de�nir BI partiremos de la de�nición de Gartner 1.[Cano, 2007] 1Glosario de Gartner, www.gartner.com, enero 2006. Gartner es una consultora internacional espe- cializada en Tecnologías de Información y Comunicación. CAPÍTULO 2. MARCO CONCEPTUAL 18 �BI es un proceso interactivo para explorar y analizar información estructurada sobre un área (normalmente almacenada en un datawarehouse), para descubrir tenden- cias o patrones, a partir de los cuales derivar ideas y extraer conclusiones. El proceso de Business Intelligence incluye la comunicación de los descubrimientos y efectuar los cambio.� El origen de la Business Intelligence va ligado a proveer acceso directo a la infor- mación a los usuarios de negocio para ayudarles en la toma de decisiones. [Cano, 2007] Una solución de BI nos proporcionara los siguientes bene�cios a la empresa. 2.3.3.1. Características La Inteligencia de Negocio tiene características como [Cano, 2007]: Proceso interactivo. Hablar de BI estamos suponiendo que se trata de un aná- lisis de información continuado en el tiempo, no sólo en un momento puntual. Aunque evidentemente este último tipo de análisis nos puede aportar valor, es incomparable con lo que nos puede aportar un proceso continuado de análisis de información, en el que por ejemplo podemos ver tendencias, cambios, variabilida- des, etc. Explorar. En todo proyecto de BI hay un momento inicial en el que por primera vez accedemos a información que nos facilita su interpretación. En esta primera fase, lo que hacemos es �explorar� para comprender qué sucede en nuestro nego- cio; es posible incluso que descubramos nuevas relaciones que hasta el momento desconocíamos. Analizar. Pretendemos descubrir relaciones entre variables, tendencias, es decir, cuál puede ser la evolución de la variable, o patrones. Si un cliente tiene una serie de características, cuál es la probabilidad que otro con similares características actué igual que el anterior. Área de análisis. Todo proyecto de BI debe tener un objeto de análisis con- creto. Nos podemos centrar en los clientes, los productos, los resultados de una localización, etc. que pretendemos analizar con detalle y con un objetivo concre- to: por ejemplo, la reducción de costes, el incremento de ventas, el aumento de la participación de mercado, el ajuste de previsiones de venta, el cumplimiento los objetivos de venta presupuestados, etc. Comunicar los resultados y efectuar los cambios. Un objetivo fundamen- tal del BI es que, una vez descubierto algo, sea comunicado a aquellas personas que tengan que realizar los cambios pertinentes en la organización para mejorar nuestra competitividad. CAPÍTULO 2. MARCO CONCEPTUAL 19 2.3.4. Niveles de Soluciones de Inteligencia de Negocio La inteligencia de negocio muestra resultados, de acuerdo a las necesidades de los distintos niveles jerárquicos de la organización 2.4 se presenta una pirámide con los distintos tipos de BI, mostrando de izquierda a derecha el personal y a la derecha las herramientas o instrumentos que utilizan para realizar las tareas de la organización. Figura 2.4: Niveles (Fuente [Inteligencia de Negocios, 2017]) Apoyan a los distintos niveles de la organización [Inteligencia de Negocios, 2017]: Nivel Operativo. Se permite a los empleados de la empresa recibir de forma oportuna, exacta y adecuada la información operativa, basándose en herramientas de trabajos como reportes, hojas de cálculos, manteniendo siempre un formato �jo cuya información se actualiza cada cierto tiempo. Nivel Táctico. Permite a los analistas de datos y a la gerencia media de una empresa, utilizar herramientas de análisis y consultas con el �n de obtener acceso a la información sin intervención de terceros. Nivel Estratégico. Permite que los directivos de la empresa pueda analizar y seguir día a día las tendencias, patrones, metas y objetivos estratégicos de la empresa. Un ejemplo de ello, lo constituye el cuadro de mando integral, entre otros. 2.3.5. Arquitectura de una Solución de Inteligencia de Negocio Una solución de inteligencia de negocio tiende a ser una de las piezas más complejas de software que se puedan llegar a implementar en una organización, debido a que se requiere de la integración de diversos sistemas que usualmente no tienen una conexión directa entre sí. Por esta razón, vale destacar que una solución BI es mucho más que un software que despliega los datos de la empresa al usuario. CAPÍTULO 2. MARCO CONCEPTUAL 20 Una organización que maneja grandes cantidades de datos, necesita para maximizar sus ingresos e incrementar su e�ciencia, monitorear una serie de indicadores claves que informen sobre el funcionamiento de la empresa en tiempo real. Para poder generar conocimientos en una organización a partir de los datos que esta maneje, es necesario involucrar un conjunto de elementos mínimos indispensables, los cuales, permitirán aplicar inteligencia de negocio en las organizaciones que lo requieran. Los diversos componentes que componen a una solución de inteligencia de negocio se ven expresados en la 2.5: Figura 2.5: Componentes de inteligencia de negocio Fuentes de Datos. Es el proceso de donde se parte DWH para alimentar de información el DWH. ETL Proceso de extracción, transformación y carga de los datos en el DWH. Antes de almacenar los datos en un DWH, éstos deben ser transformados, limpiados, �ltrados y rede�nidos. Normalmente, la información que se tiene en los sistemas transaccionales no está preparada para la toma de decisiones. Almacén de Datos (DWH). Metadata o Diccionario de datos. Se busca almacenar los datos de una forma que maximice su �exibilidad, facilidad de acceso y administración. Motor OLAP 2. Provee capacidad de cálculo, consultas, funciones de planea- miento, pronóstico y análisis de escenarios en grandes volúmenes de datos, sin embargo, en la actualidad existen otras alternativas tecnológicas al OLAP. Las herramientas de acceso. Permiten el análisis y la navegación de la infor- mación a través de los mismos. 2OLAP: On-Line Analytical Processing / Procesamiento Analítico en Línea CAPÍTULO 2. MARCO CONCEPTUAL 21 2.3.6. Fuentes de Datos A la hora de desarrollar una un solución de BI, se debe determinar que datos se necesitan para realizar los análisis requeridos, por esta razón, un sistema de este tipo sin una fuente de datos correcta válida, tendría poco valor para la organización. El conjunto de datos que se puede usar 2.6 para una solución de BI es muy amplia, se puede usar datos internos de la empresa, así como también datos externos que sirvan para efectos de los análisis a realizar. Figura 2.6: Fuentes de Datos En esta etapa deberíamos plantearnos una serie de preguntas, como: ¿ Qué in- formación necesita la organización?, ¿Cuándo se requiere dicha información?, ¿En que formato se necesita?, ¿Que información posee la empresa? y ¿Para quién está dirigida?, esto servirá para complementar los análisis para implementar la solución. La mayoría de las implementaciones de BI usan snapshots (imágenes instantáneas de uno o más sistemas de archivos) o copias de seguridad como datos fuentes, debido a que esto garantiza que los datos en el sistema sean precisos y correctos. Si se tomaran los datos de los sistemas transaccionales de la empresa a medida que se van generando, una actualización a un registro en el sistema transaccional generaría una pérdida de exactitud en los datos que se emplearán para los análisis, lo cual conlleva a que los resultados que se obtengan sean incorrectos o pocos precisos y adicionalmente, el rendimiento del sistema operacional bajaría considerablemente. 2.3.7. Procesos de Extracción, Transformación y Carga (ETL) Una vez que ya hayamos seleccionado la data necesaria para el sistema procedemos ETL de los datos a la plataforma de BI. Es la encargada de la integración de los datos desde las multiples fuentes existentes para la construcción del almacén de datos (DWH) y los Data Marts, formando el ciclo de vida de una implementación de BI. Cada proceso de de�ne como: CAPÍTULO 2. MARCO CONCEPTUAL 22 Figura 2.7: Procesos de Extracción, Transformación y Carga (ETL) (Fuente [Cano, 2007]) Extracción. Consiste en la identi�cación y selección de los datos de los sistemas operacionales para satisfacer las necesidades de la organización. Una vez seleccio- nados los datos, se extraen los datos. Se considera la consolidación de los datos desde las diversas fuentes que usan diferentes estructuras y formatos, establecien- do el acceso a las fuentes de datos, extrayendo de manera e�ciente cada una de los datos requeridos. Transformación. Los datos de la transacciones se convierten en datos con un formato consistente y orientado a los negocios, es decir, unos datos correctos, no ambiguos, consistentes y completos. Aplicando una serie de reglas o funciones a los datos extraídos desde la fuente para generar los datos a cargar al destino �nal. Carga. Se toman los datos y registran en el almacén de datos siguiendo las especi�caciones que se de�nieron con anterioridad 2.3.8. Almacén de Datos (Data Warehouse) El almacén de datos (DWH) 3 es una base de datos corporativa que proporcio- na múltiple funciones a un número determinado de usuarios, como el de disponer de Sistemas de Información de apoyo a la toma de decisiones. Figura 2.8: Almacén de Datos La tecnología DWH se ha desarrollado rápidamente, y representa mejor que otros sistemas, las compleja estructura de una organización a la hora de administrar su datos generenciales [Inmon, 2002]. 3Data Warehouse siglas en inglés CAPÍTULO 2. MARCO CONCEPTUAL 23 2.3.8.1. De�nición Un DWH es una colección de información creada para soportar las aplicaciones de toma de decisiones.4 Es decir es una BD corporativa que abarca los procesos, las herramientas y las tecnologías para convertir datos en información, en conocimiento y planes para conducir de forma e�caz las actividades de negocios. [Cano, 2007] El término DWH tiene sus orígenes en dos fuentes, �An Architecture for a Bussinesdd and Information Systems� de Barry Devlin y Paul Morphy56 y �Building the Data Warehouse� de Inmon, William H.7 La primera fuente, �An Architecture for a Bussinesdd and Information Systems�, publicado en el IBM Systems Journal, es considerado como uno de los primeros artículos que describe la arquitectura de un DWH, desarrollado entre 1985 y 1986 para uso interno de IBM Europa en Dublín. En dicho artículo se hizo uso del término �Information Warehouse� para hacer referencia al proyecto. En la actualidad, suele usarse de manera general, para referirse a un DWH, la siguiente expresión que aparecía en el artículo: �El almacén de datos es un único, completo y consistente almacén de datos obtenido de una variedad de fuentes, y puesto a la disposición de los usuarios �nales, de manera que ellos puedan entender y usar en el contexto del negocio� [Cano, 2007]. La segunda fuente, �Building the Data Warehouse�, describe al DWH como �un conjunto de datos orientados hacia una materia, integrados, no transitorios y que varían en el tiempo, los cuáles apoyan el tema de toma de decisiones de una administración� Inmon,1992. Inmon es considerado el padre del DWH y ha escrito una serie de libros, junto con otros autores, donde abordan diversos tópicos relacionados con la arquitectura almacén de datos [Cano, 2007]. 2.3.8.2. Características Las características principales del almacén de datos son las siguientes: Integrado. Los datos almacenados en el DWH deben estar integrados en una estructura que sea capaz de eliminar cualquier tipo de inconsistencias existentes entre los diversos sistemas operacionales que sirven de fuentes de datos. Al mismo tiempo, la información suele estructurarse en distintos niveles de detalle para adecuarse a los requerimientos preestablecidos por todos los usuarios �nales. Temático u Orientado a un área. Sólo los datos necesarios para generar in- formación del negocio se integran desde el entorno operacional. Los datos se orga- nizan por temas, no por aplicación, así se facilita el acceso y entendimiento de los 4La primera aproximación es la del Watson, que de�ne DWH 5Devlin, 1997 6�An Architecture for a Bussinesdd and Information Systems� de Barry Devlin y Paul Morphy 7�Building the Data Warehouse� de William H. Inmon CAPÍTULO 2. MARCO CONCEPTUAL 24 datos contenidos en el DWH. Eventualmente, esta característica permite realizar análisis y minería de datos. Histórico o Indexado en el tiempo (�gura: 2.9). El tiempo es parte implíci- ta de la información contenida en un DWH. , en el DWH se carga con los distintos valores que puede tomar una variable en el tiempo, para poder hacer compara- ciones y análisis, soportando de esta manera el proceso de toma de decisiones. Es decir, el DWH se carga con los distintos valores que toma una variable en el tiempo para permitir comparaciones. Los datos históricos son de poco uso en el procedimiento operacional. La información del depósito por el contrario, de- be incluir los datos históricos para usarse en la identi�cación y evaluación de tendencias. Figura 2.9: Histórico de DWH (Fuente [DWH, 2015]) No volátil. El DWH se construye para ser leído, y no modi�cado. La información que existe en un DWH es permanente, su actualización consiste en la incorporación de los últimos valores que tomaron las distintas variables sin alteración de los datos que ya existían se actualiza de manera periódica ya establecida. Figura 2.10: No Volátil (Fuente [DWH, 2015]) Como se puede observar en la �gura: 2.10 en la BD operacional la actualización (actualizar, borrar y modi�car) se hace regularmente, mientras en el DWH sea CAPÍTULO 2. MARCO CONCEPTUAL 25 una sola actualización esto hace que cuando tengamos que tomar una decisión con esta información tengamos seguridad de esta. Además de las características previamente mencionadas, otras, quizás menos relevantes, pero que igualmente sirven para remarcar la potencialidad de un DWH: Contiene datos diversos. Es un repositorio uni�cado de información. Los da- tos de toda la organización, aunque pertenezcan a aplicaciones diferentes, son integrados en el DWH. Optimizado para la consulta masiva. El diseño físico de un DWH tiene un objetivo diferente al de las bases de datos transaccionales, mejorar los tiempos de respuesta de procesos de consultas de datos masivos de información, tomando en cuenta que deben ser orientados a temas, así como también brindar facilidad de entendimiento al usuario �nal. La interfaz de usuario. Está dirigida a los ejecutivos y diversos analistas, por lo que deben ser intuitivas. Gran volumen. Cuando se habla de almacén de datos, el espacio de almacena- miento suele medirse en Gigabytes y Terabytes debido a la cantidad de informa- ción sumarizada. Cabe destacar que un DWH admite redundancia de datos y un tiempo de vida de información entre 5 y 10 años. 2.3.8.3. Arquitectura Una arquitectura de almacén de datos es una forma de representar la estructura global de los datos, la comunicación, los procesos y la presentación al usuario �nal. La arquitectura está constituida por las siguientes partes interconectadas [DWH, 2010]: Elementos que constituyen la arquitectura de un almacén de datos: Nivel de base de datos externos, base de datos operacional. Las organiza- ciones adquieren datos de Bases de Datos externas a la propia organización, que incluyen datos demográ�cos, económicos, datos sobre la competencia, etc. Mediante el proceso de DWH se extrae la información que está en la bases de datos operacionales y se mezcla con otras fuentes de datos. Enriquecemos la in- formación. Nivel de acceso a la información. Es la capa con la que trata el usuario �nal. La información almacenada se convierte en información fácil y transparente para las herramientas que utilizan los usuarios. Se obtienen informes, grá�cos, diagramas, etc. Nivel de acceso a los datos. Comunica el nivel de acceso a la información con el nivel operacional, es el responsable de la interfaz entre las herramientas de acceso a la información y las bases de datos. CAPÍTULO 2. MARCO CONCEPTUAL 26 Figura 2.11: La Arquitectura (Fuente [DWH, 2010] ) La clave de este nivel está en proveer al usuario de un acceso universal a los datos, es decir, que los usuarios sin tener en cuenta la ubicación de los datos o la herramienta de acceso a la información, deberían ser capaces de acceder a cualquier dato del DWH que les fuera necesario para realizar su trabajo. Nivel de directorio de datos (metadatos). Para proveer de un acceso uni- versal, es absolutamente necesario mantener alguna clase de directorio de datos o repositorio de información de metadato que ayude a mantener un control sobre los datos. El metadato aporta información sobre los datos de la organización, de dónde proviene, qué formato tenía, cuál era su signi�cado y si se trata de un agregado, cómo se ha calculado éste. Para mantener un almacén completamente funcional, es necesario disponer de una amplia variedad de metadatos, información sobre las vistas de datos para los usuarios �nales y sobre las bases de datos operacionales. Nivel de gestión de proceso. Este nivel tiene que ver con la plani�cación de las tareas que se deben realizar, no sólo para construir, sino también para mantener el DWH y la información del directorio de datos. Es o el controlador de alto nivel de los procesos que se han de llevar a cabo para que el almacén de datos permanezca actualizado. Nivel de mensaje de la aplicación. El nivel de mensaje de la aplicación tie- ne que ver con el transporte de información alrededor de la red de la empresa. Puede usarse para aislar aplicaciones operacionales o estratégicas a partir de un formato de datos exacto, recolectar transacciones o los mensajes y entregarlos a una ubicación segura en un tiempo especí�co. CAPÍTULO 2. MARCO CONCEPTUAL 27 Nivel Almacén de Datos (físico). Es el repositorio central, altamente �exible de información, donde residen las copias de datos operacionales usados. En un DWH físico las copias de datos, operaciones y/o externos se almacenan de forma que sea fácil de acceder. En la actualidad un DWH se almacena en plataformas cliente/servidor, pero también existen con�guraciones sobre mainframes, equipos externos para su rápido acceso mediante consulta. Nivel de organización de datos. El componente �nal de la arquitectura es la organización de los datos. Incluye todos los procesos necesarios para seleccionar, editar, resumir, combinar y cargar datos en el y para acceder a la información desde bases de datos operacionales y/o externas. La forma de implementar un está sujeta a la forma en la que se va a estructurar el almacenamiento de los datos dentro del mismo. Independientemente del modelo que se escoja el objetivo principal es escoger uno que satisfaga las necesidades empresariales. 2.3.8.4. Metadata La Metadata es el repositorio central de la información y es un componente crítico del DWH. Nos da el signi�cado de cada uno de los componentes y sus atributos que se encuentran en el DWH. Puede incluir de�niciones de negocio gestión del Almacén de Datos, descripciones detalladas de los tipos de datos, formatos y otras características [Cano, 2007]. Son los datos que describen la información, campos y formatos de BD y del DWH. Para gestionar metadatos es necesario proporcionar una guía del punto de vista técnico y comercial de éstos. Los metadatos pueden ser categorizados en dos tipos: Los metadatos técnicos. Son metadatos que se crean durante el principio de un repositorio de datos , los cuales sirven para apoyar la gestión del repositorio. Éstos incluyen normas de adquisición, la transformación de los datos dentro del formato requerido por el repositorio, horarios para realizar copias de seguridad y la actualización de los datos. Los metadatos de negocio. Permiten al usuario �nal comprender información que se tiene guardada en el DWH y de qué manera se puede acceder a ella. 2.3.8.5. Requerimientos de un DWH Se de�ne los requerimientos que debería cumplir un DWH 8: Fácil acceso. Lograr que la información de la organización sea de fácil acceso. El alcance del Almacén de Datos puede ser bien un departamento o un corpora- tivo. Aportando datos entendibles, manejables, rápidos de acceder y navegables, facilitándole al personal obtener dicha información para poder lograr un objetivo en especí�co. 8(Kimball & Margy, 2002), De�ne los objetivos de un DWH CAPÍTULO 2. MARCO CONCEPTUAL 28 Consistencia. Lograr que la información de la organización sea consistente. Lo- grando que la información que se trabaja en la organización tenga el mismo nom- bre, signi�cado, lógica, coherencia y solidez. Adaptable y elástica. Proporcionar información adaptable y elástica. La infor- mación en el DWH puede ser separada y combinada para analizar cada una de las posibles medidas del negocio. Tanto los datos, como la tecnología existente, no cambian en absoluto. Seguridad. Proporcionar un mecanismo de seguridad que protege los valores de la información. Permite al usuario �nal la manipulación de los datos, según la permisología asignada, logrando brindar seguridad en la información, ya que no todos los usuarios pueden modi�car la información. Fundamentar la toma de decisiones. Almacenando los datos correctos, como el volumen de datos necesarios, para apoyar la toma de decisiones en la organiza- ción. 2.3.9. Bodega de Datos (Data Mart) Los DWH representan una gran cantidad de información, es decir una gran base de datos que puede estar distribuida en distintas bases de datos, sería muy costoso y tiempo que ninguna organización podría aceptar. Es por ello que surge la bodega de datos, que está dirigido a un grupo de usuarios dentro de la organización. Figura 2.12: Bodega de Datos (Fuente [Cano, 2007]) Una bodega de datos es una bases de datos departamental, especializada en el al- macenamiento de los datos de un área de negocio especí�ca. Se caracteriza por disponer la estructura óptima de datos, para analizar la información al detalle desde todas las perspectivas que afecten a los procesos de dicho departamento [sinnexus, 2016]. Los bodega de datos son más pequeños que los DWH y tienen menos información, menos modelos de negocios y son utilizados por un grupo menor de usuarios, pueden CAPÍTULO 2. MARCO CONCEPTUAL 29 ser dependientes e independientes. Un bodega de datos independiente puede originar inconsistencia con otro bodega de datos ver en la �gura: 2.12. 2.3.9.1. Estrategias de Construcción Dos estrategias básicas para la construcción de un DWH, una propuesta por Kimball y la otra por Inmon: W.H Inmon, Propone construir un DWH corporativo y a partir de él ir constru- yendo los modelos de análisis para los distintos niveles y departamentos de la organización; es decir, una estrategia de arriba abajo, desde la estrategia a lo más operativo se conoce como Descendente[Cano, 2007]. R. Kimball, Propone construir distintos bodega de datos que cubran las distintas necesidades de la organización, sin la necesidad de construir un DWH se conoce como Ascendente [Cano, 2007]. Las dos estrategias son válidas. De construir un DWH corporativo es desarrollo en fases es decir se construye un bodega de datos dependiente con una parte de información del DWH y en partes pos- teriores se van desarrollando bodega de datos usando subconjuntos del DWH. Igual que los proyectos complejos, es caro,y necesita mucho tiempo y es propenso al fracaso. Cuando tenemos éxito conseguimos un DWH integrado y escalable [Cano, 2007]. Si optamos por la más común, de construir distintos bodega de datos, el proyecto comienza con un bodega de datos único al que posteriormente se irán añadiendo otros bodega de datos que cubrirán otras áreas de negocio. Normalmente no requiere de grandes inversiones y es fácil de implementar, aunque con lleva algunos riesgos. Si seguimos esta estrategia debemos tener claro el plan de acción, es decir, qué áreas cubriremos y la integración de los distintos modelos. Esta estrategia se utiliza a veces como un paso previo al desarrollo de un DWH corporativo. 2.3.10. Modelo Dimensional del DWH El modelo dimensional se describe en el año 1996 por Ralph Kimball, como propuesta para el diseño del Almacén de Datos, partiendo de la visión multidimensional que los usuarios tienen de los datos empresariales cuando se enfrentan a ellos con propósito de análisis (análisis multidimensional � OLAP � en concreto). Todo DWH comienza con modelo dimensional, ya que se identi�can los hechos, que es la tabla central de dicho modelo y la dimensiones son categorías que describen el contexto en el cual se analizan la tabla de hecho. Existen dos tipos de esquema en el modelo relacional: esquema estrella y copo de nieve. CAPÍTULO 2. MARCO CONCEPTUAL 30 2.3.10.1. De�nición El modelo dimensional es una técnica de diseño para el DWH (a nivel lógico) que pretende representar los hechos del negocio. Este modelo está optimizado para llevar a cabo consultas con un alto rendimiento. El modelo dimensional es una de las técnicas de modelado de un Almacén de Datos. En el proceso de modelado dimensional, un modelo de tablas y relaciones se constituye con el propósito de optimizar el soporte de toma de decisiones a nivel de desempeño del query en bases de datos Relacionales relativo al proceso de negocio que se esté mo- delando. En contraste, los modelos convencionales de Entidad-Relación se constituyen para eliminar la redundancia en el modelo de datos, facilitar la obtención de registros en base a indicadores establecidos y por lo tanto optimizar el nivel de desempeño de los sistemas OLTP. Por tal motivo, es necesario de�nir y tener claros los conceptos básicos al modelo dimensional, los tipos de tablas involucradas, y los esquemas de trabajo que pueden emplearse en una solución. La Dimensión es una entidad independiente en el modelo dimensional que sirve como un punto de entrada o como un mecanismo de reordenamiento y fraccionamiento de las medidas sumarizadas, localizadas en la tabla de hechos del modelo [Kimball, 2002]. 2.3.10.2. Tabla de Dimensión Las tablas de dimensiones contiene descripciones textuales, tablas que integran la tabla de hechos, cada dimensión se de�ne por su clave primaria única, designada por la notación PK como vemos en la �gura: 2.13, que sirve como base para la integridad referencial con cualquier tabla de hechos a la que se une y una columnas de atributos descriptivos que juegan un papel fundamental en el DWH son lo que queremos medir. Figura 2.13: Tablas de Dimensión (Fuente [Kimball, 2002]) 2.3.10.3. Tabla de Hechos Es la representación en el DWH de los procesos de negocio de la organización. La tabla principal del DWH con las mediciones de rendimiento numéricas que son caracterizadas por una clave compuesta, donde cada elemento de la misma es una clave CAPÍTULO 2. MARCO CONCEPTUAL 31 foránea que corresponde a una tabla de dimensiones se encuentra todo lo que queremos medir, y analizar. Una medida se toma en la intersección de todas las dimensiones (fecha, producto y la tienda) como podemos ver en la �gura:2.14. Una �la de una tabla de hechos corresponde a la medida. Todas la medidas de una tabla de hechos deben estar al mismo grano o granularidad [Kimball, 2002]. Figura 2.14: Tabla de Hechos (Fuente [Kimball, 2002] ) 2.3.10.4. Esquema Estrella (Star Scheme) El esquema de estrella es la representación genérica de un modelo dimensional en una base de datos relacional, en la cual una tabla de hechos con una clave compuesta que forma la clave de cada dimensión, es unidad a un número de tablas de dimensiones (Em- pleado, tiempo, centro, etc.), cada una con una clave primaria simple [Kimball, 2002]. El esquema estrella es ideal por su simplicidad y simetría porque son más fáciles de en- tender, navegar y es altamente reconocible por los usuarios de negocios como podemos ver en la �gura 2.15. Las características del esquema estrella [Cano, 2007]: Una tabla de hechos,que contiene los datos sin redundancias. Una sola tabla por dimensión. La tabla de hechos (Fact table) tiene un atributo columna que forma la clave de cada dimensión. Cada tabla de dimensión (Dimension table) es una tabla simple desnormalizada. Cuando unimos distintos esquemas �estrella� que tienen distintas tablas de hechos, pero comparten las de las dimensiones, hablamos de constelaciones de hechos; algunos autores hablan incluso de esquema �galaxia� [Cano, 2007]. CAPÍTULO 2. MARCO CONCEPTUAL 32 Figura 2.15: Esquema Estrella de lo tickets (Fuente [Cano, 2007]) 2.3.10.5. Esquema Copo de Nieve (Snow�ake Scheme) El esquema de copo de nieve es una dimensión normalizada en el cual una tabla de dimensión simple es descompuesta en una estructura de árbol con muchos niveles [Kimball, 2002]. Figura 2.16: Esquema Copo de Nieve o Snow�ake (fuente [Cano, 2007]) CAPÍTULO 2. MARCO CONCEPTUAL 33 El esquema �estrella� no es totalmente normalizado, como podemos ver en la �gura: 2.15 ya que en la tabla de la �Dimensión Centro� tenemos una redundancia que es �Descripción zona�,se repetirá tantas veces la zona como centros existan en la misma. Es por eso que nace el esquema copo de nieve o Snow�ake para solucionar este problema. Como vemos en la �gura: 2.16, en el esquema �copo de nieve� aparecen relaciones entre las tablas de dimensiones, mientras que en el esquema �estrella� sólo hay relaciones entre la tabla de hechos y las de dimensiones [Cano, 2007]. 2.3.10.6. Esquema Constelación (Star�ake Scheme) El esquema constelación está compuesto por una serie de esquema estrellas y tal como se puede apreciar en la siguiente �gura 2.17, está formado por una tabla de hechos principal (�HECHOS_A�) y por una o más tablas de hechos auxiliares (�HECHOS_B�), las cuales pueden ser sumarizaciones de la principal. Dichas tablas yacen en el centro del modelo y están relacionadas con sus respectivas tablas de dimensiones [Bernabeu, 2009]. No es necesario que las diferentes tablas de hechos compartan las mismas tablas de dimensiones, ya que, las tablas de hechos auxiliares pueden vincularse con solo algunas de las tablas de dimensiones asignadas a la tabla de hechos principal, y también pueden hacerlo con nuevas tablas de dimensiones[Bernabeu, 2009]. Figura 2.17: Esquema Constelación [Bernabeu, 2009] Las características del esquema constelación: Su diseño y cualidades son muy similares a las del esquema en estrella, pero posee una serie de diferencias con el mismo, que son precisamente las que lo destacan y caracterizan. Entre ellas se pueden mencionar [Bernabeu, 2009]: Permite tener más de una tabla de hechos, por lo cual se podrán analizar más aspectos claves del negocio con un mínimo esfuerzo adicional de diseño. CAPÍTULO 2. MARCO CONCEPTUAL 34 Contribuye a la reutilización de las tablas de dimensiones, ya que una misma tabla de dimensión puede utilizarse para varias tablas de hechos. No es soportado por todas las herramientas de consulta y análisis. 2.3.10.7. Granularidad Presenta el nivel de detalle al que se desea almacenar la información que posee cada registro de una tabla de hechos en un DWH [Kimball, 2002]. Es decir deberemos decidir cuál es el nivel de granularidad necesario para poder construir un modelo que nos permita responder a aquellas preguntas que nos hemos formulado a determinar un nivel de granularidad podemos responder unas preguntas pero no otras.Por ejemplo, los datos referentes a ventas o compras realizadas por una empresa, pueden registrarse día a día, en cambio, los datos pertinentes a pagos de sueldos o cuotas de socios, podrán almacenarse a nivel de mes. 2.3.10.8. Jerarquía Es una serie de relaciones en cascada de uno a muchos [Kimball, 2002]. Después de que ya se sabe cuál sería la granularidad, se realiza la jerarquía. Esta jerarquía corresponde con las tablas de dimensión que se de�nen como los niveles de asociación que tienen de los datos. Una dimensión debe contener al menos una jerarquía, la cual puede tener varios niveles. Figura 2.18: Jerarquía de lugar (Fuente [Cano, 2007]) Como por ejemplo la dimensión tiempo, una jerarquía del tiempo como podemos ver en la �gura: 2.18. Años se pueden descomponer en trimestres, los trimestres en meses y los meses en días. La existencia de las jerarquías en las dimensiones nos permite pasar del máximo detalle a la agregación en los distintos niveles. En nuestro ejemplo CAPÍTULO 2. MARCO CONCEPTUAL 35 podemos por tanto analizar las ventas de un artículo por días, por meses, por trimestres o por años. 2.3.10.9. Agregación Se trata de una medida, es decir un dato contable. Por ejemplo, si se quiere tener el total del salario de una empresa, lo que se hace es hacerle un proceso de agregación, de�niendo como operación la suma de los sueldos de los empleados, logrando que cada vez que entre más información en el atributo sueldo, se va a ir mostrando sumarizado. 2.4. Herramientas Tecnológicas El proceso de selección de una herramienta tecnológica puede llegar a ser complejo debido a las múltiples alternativas existentes en el mercado (Oracle BI, Pentaho BI, IBM Cognos, MicroStrategy, entre otros) y a la diversa gama de funcionalidades que cada herramienta brinda. Independientemente de la herramienta a seleccionar, ésta debe proveer un repositorio centralizado, visualización de cuadros de mando y la posibilidad de construir consultas a la medida. 2.4.1. Herramientas de Análisis y visualización Con el surgimiento de aplicaciones de inteligencia de negocio, se han creado herra- mientas especializadas que permiten mostrarle a la alta gerencia los datos más relevantes de una empresa de manera resumida, en forma de indicadores y reportes para la toma decisiones. Figura 2.19: Herramienta de Análisis y visualización (Fuente [Cano, 2007]) 2.4.1.1. Reportes Es un informe generado por un sistema, que nos muestra de forma estructurada y resumida, datos relevantes generados por las aplicaciones, de manera que se pueda realizar la toma de decisiones. CAPÍTULO 2. MARCO CONCEPTUAL 36 Figura 2.20: Ejemplos Reportes (Fuente [Planeaux, 2007]) 2.4.1.2. Indicadores Es una medida cuantitativa que permite identi�car cambios en el tiempo, cuyo objetivo es determinar el buen funcionamiento de un sistema o negocio. Logrando así identi�car los problemas y poder tomar medidas para solucionarlos. Figura 2.21: Ejemplos Indicadores (Fuente [Planeaux, 2007]) CAPÍTULO 2. MARCO CONCEPTUAL 37 2.4.2. Herramienta de Extracción, Transformación y Carga (ETL) Las herramientas de Extracción (E), Transformación (T) y Carga (L � de Load en inglés) permiten de manera sencilla recuperar datos de distintas fuentes de información, limpiarlos y realizar las transformaciones necesarias para cargarlos en un repositorio, minimizando fallos comunes como la existencia de campos o valores nulos, tablas de referencia inexistentes, entre otros. Siguiendo la línea de tecnologías de código abierto, se ha seleccionado la herramienta de ETL de Pentaho, llamada Pentaho Data Integration (PDI) o también conocida como Kettel, la cual se explica a continuación. 2.4.2.1. Pentaho Es una plataforma Open Source de BI orientada a soluciones y centrada en procesos fundada en el 2004. Ofreciendo soluciones para la gestión y análisis de la información, incluyendo el análisis multidimensional OLAP, presentación de informes, minería de datos y creación de cuadros de mando para el usuario. La plataforma ha sido desarrollada bajo el lenguaje de programación Java y tiene un ambiente de implementación también basado en Java, haciendo así que Pentaho sea una solución muy �exible al cubrir una alta gama de necesidades empresariales. Arquitectura Los módulos de la arquitectura de Pentaho BI son: Pentaho Data Integration. Permite tomar información de diferentes fuentes y cargarlas en un repositorio analítico. Provee una consistencia, una sola versión de todos los recursos de información mediante ETL 9. Pentaho reporting. Es un potente generador de informe permitiendo la dis- tribución de los resultados del análisis en multiples formatos como PDF, XLS, HTML y textos. Los reportes Pentaho permiten también programación de tareas y ejecución automática de informes con una determinada periodicidad. Pentaho Analysis. Suministra a los usuarios un sistema avanzado de análisis de información es un servidor OLAP10. Es compatible con expresiones multidimen- sionales y el lenguaje de consulta XML para el análisis Pentaho Dashboards. Proporcionar información sobre sus datos, donde se pue- den ver informes, grá�cos interactivos y los cubos creados con las herramientas Pentaho Report Designer. Pentaho Data Minina. Es el proceso de correr datos en algoritmos comple- tamente so�sticados, relevando signi�cantes patrones y correlaciones que pueden estar escondidos median la herramienta Weka. Esto puede ser usado para ayudar a entender lo mejor para el negocio y explotar el rendimiento de este en un futuro prediciendo completamente en el análisis. 9ETL (Extracción, Transformación y Carga) 10OLAP ( Procesamiento analítico en línea) CAPÍTULO 2. MARCO CONCEPTUAL 38 Pentaho para Apache Hadoop. Es una herramientas de desarrollo visual fá- ciles de usar y grandes análisis de datos que permiten a los usuarios preparar, modelar, visualizar y explorar conjuntos de datos estructurados y no estructu- rados en Hadoop. Pentaho simpli�ca el ciclo de vida de los datos de Hadoop de extremo a extremo proporcionando una plataforma completa desde la preparación de datos hasta el análisis predictivo. Pentaho es único al proporcionar ejecución en Hadoop para un rendimiento extremadamente rápido.[?] Figura 2.22: Pentaho Arquitectura (Fuente:[Pentaho, 2016] ) 2.4.2.2. Pentaho Data Integration Pentaho Data Integration (PDI) es una herramienta que permite extraer, transfor- mar y cargar (ETL- Extract, Transform and load) la información disponible en apli- caciones y bases de datos separadas y Hojas de Cálculos para ponerlas en manos del usuario, proyectando consistencia. También es conocido como kettle y posee las siguien- tes aplicaciones: Spoon. Herramienta grá�ca que permite diseñar procesos ETL. Soporta conexión con diversas fuentes de datos y permiten transformar los datos necesarios para cargarlos dentro de la Base Datos destino. Pan. Herramienta que permite ejecutar transformar diseñar con Spoon en XML o en un repositorio de base de datos. Generalmente las transformaciones se pro- graman en modo por lotes para ser ejecutadas en intervalos de tiempo regulares. Chef. Permite ejecutar trabajos complejos que automatizan los procesos de ac- tualización de la base de datos. CAPÍTULO 2. MARCO CONCEPTUAL 39 Kitchen. Herramienta que ayuda a ejecutar el trabajo por lotes, permitiendo iniciar y controlar fácilmente procesos ETL. Carte. Servidor web que permite la supervisión remota de procesos ETL. De las aplicaciones nombrada anteriormente una de las más usadas es Spoon, cuya interfaz se puede ver . Spoon es fácil de usar y resulta muy útil incluso para realizar migraciones pequeña, como pasar datos de una Hoja de Cálculo a una base de datos. Figura 2.23: Interfaz grá�ca de Spoon 2.4.3. Herramienta para crear la bodega de datos (Datamart) Un bodega de datos es una bases de datos departamental, especializada en el alma- cenamiento de los datos de un área de negocio especí�ca. Se caracteriza por disponer la estructura óptima de datos, para analizar la información al detalle desde todas las CAPÍTULO 2. MARCO CONCEPTUAL 40 perspectivas que afecten a los procesos de dicho departamento es decir donde los da- tos están denormalizados basandose en la información que necesite un departamento. Siguiendo la línea de tecnologías de código abierto, se ha seleccionado la herramienta para crear la bodega de datos. 2.4.3.1. PostgreSQL PostgreSQL es un Sistema Manejador de base de datos objeto-relacional, de có- digo abierto, que cuenta con más de 15 años de desarrollo activo y una arquitectura probada que se ha ganado una sólida reputación por su �abilidad, integridad de datos y corrección. Además, permite desarrollar procedimientos en diferentes lenguajes de programación como Java, C++, Ruby y Python, lo que hace a PostgreSQL altamente personalizable[PosrgreSQL, 1996]. Soporta grandes cantidades de datos y una alta concurrencia de usuarios accediendo a la vez al sistema, por lo que se considera una herramienta que favorece a los usuarios con sistemas empresariales de gran tamaño. PostgreSQL se ha enfocado tradicionalmente en la �abilidad, integridad de datos y características integradas enfocadas al desarrollador. Tiene un plani�cador de consultas extremadamente so�sticado, que es capaz de unir cantidades relativamente grandes de tablas e�cientemente [2nsPostgreSQL, 2001]. Se distribuye bajo la Licencia PostgreSQL, que es una licencia similar a la de la Distribución de Software de Berkeley (BSD) y a la del Instituto de Tecnología de Mas- sachusetts (MIT), que permite a los usuarios hacer cualquier cosa que quieran con el código, incluyendo la reventa de los binarios sin el código [2nsPostgreSQL, 2001]. PostgreSQL tiene las siguientes ventajas: Es código abierto. La velocidad de respuesta se mantiene al aumentar el tamaño de la base de datos, cosa que no sucede con otros programas que se suelen poner lentos. Proporciona estabilidad y con�abilidad. Tiene una gran capacidad de almacenamiento. Soporta gran número de peticiones simultáneas a la base de datos de forma co- rrecta. Puede operar sobre distintas plataformas como Linux, Windows, Unix, Solaris y MacOS X. Provee un buen sistema de seguridad mediante la gestión de usuarios, grupos de usuarios y contraseñas. Soporta los tipos de datos, cláusulas, funciones y comandos de tipo estándar SQL92/SQL99 y extendidos propios de PostgreSQL. CAPÍTULO 2. MARCO CONCEPTUAL 41 También presenta las siguientes desventajas: En comparación con otros Sistemas Manejadores de Base de Batos, como por ejemplo MySQL, es más lento en inserciones y actualizaciones, ya que cuenta con cabeceras de intersección. Cuenta con muchos foros o�ciales de ayuda, pero no con una documentación de ayuda obligatoria. La sintaxis de algunos comandos o sentencias no es tan intuitiva. 2.4.4. Herramientas de Visualización Se presenta la siguiente herramienta de visualización, para observar de manera más reducida los grandes volúmenes de datos de forma más �exible y que apoye la toma de decisiones. 2.4.4.1. Tableau Tableau es una herramienta o software de inteligencia de negocio11 que permite visualizar de una manera reducida grandes volúmenes de información, en forma rápida, �exible y gran usabilidad 12. Tableau es en la actualidad la herramienta de BI líder y de mayor velocidad de crecimiento según Gartner, destacando por su facilidad de uso, potencialidad para generar visualizaciones y capacidad de manejo de grandes volúmenes de Datos. A diferencia de las herramientas tradicionales de inteligencia de negocio (BI) desarrolladas pensando en el usuario técnico del área de sistemas, Tableau está orientado a que personas de todos los ámbitos puedan manejar información fácilmente y presentarla en forma atractiva. Así, abogados, periodistas, ingenieros, médicos, entre otros, que trabajen en una organización o en forma independiente, encontrarán en Tableau un poderoso aliado analítico. Tableau Software se fundó sobre la idea de que el análisis de datos y los informes subsiguientes no deben ser actividades aisladas, sino que deben integrarse en un proceso único de análisis visual: uno que les permita a los usuarios ver rápidamente patrones en sus datos y cambiar las vistas al instante para seguir su línea de pensamiento. Tableau combina la exploración de los datos y la visualización de estos en una aplicación fácil de usar que todos pueden aprender rápidamente. Cualquier persona acostumbrada al uso de Excel puede crear análisis interactivos y enriquecidos, e�caces para compartirlos de manera segura en la empresa. Los equipos de TI pueden administrar los datos y metada- tos de manera centralizada, controlar los permisos y escalar hasta implementaciones en toda la empresa. Esta descripción general se diseñó para responder las preguntas comu- nes de los gerentes y administradores de TI y ayudarles a admitir las implementaciones de software de análisis visual de cualquier tamaño. 11Inteligencia de Negocio es poner la información adecuada, en las manos de las personas que toman decisiones 12Usabilidad Cualidad de la página web o del programa informático que son sencillos de usar CAPÍTULO 2. MARCO CONCEPTUAL 42 Arquitectura Tableau Server cuenta con una arquitectura de cliente-servidor de n niveles altamente escalable que presta servicios a clientes móviles, clientes web y softwa- re instalado en equipos de escritorio. Las soluciones de Tableau tienen 2 componentes principales: Tableau Desktop y Tableau Server.[TableauPDF, 2016] Figura 2.24: Tableau Server (Fuente[TableauPDF, 2016]) Tableau Server es una plataforma de análisis de negocios de clase empresarial que puede escalar verticalmente hasta cientos de miles de usuarios. Ofrece poderosos análisis móviles y basados en navegador, y funciona con la arquitectura de datos, la adminis- tración del ciclo de vida y las restricciones de seguridad y gestión existentes en la empresa.[TableauPDF, 2016] Tableau Server cumple con requisitos empresariales, entre los que se incluyen [TableauPDF, 2016]: Escalabilidad Tableau Server puede escalar vertical y horizontalmente para satis- facer las necesidades de su empresa. El servidor puede escalar verticalmente con la incorporación de CPU y RAM adicionales. Todos los componentes de Tableau Server son de multiproceso y pueden con�gurarse en función de sus patrones de uso. Se puede escalar aún más agregando nodos adicionales que pueden con�gu- rarse de manera que cumplan con los requisitos de la organización. Alta disponibilidad con administración de clústeres interna y admite equilibrado- res de carga externos. Seguridad, cifra el trá�co interno, admite integración con Active Directory, SAML y OAuth. Facilidad de administración directa, desde la gestión de usuarios hasta las actua- lizaciones. Extensibilidad ofrece API e�caces. El siguiente diagrama muestra la arquitectura de Tableau Server[TableauPDF, 2016] : CAPÍTULO 2. MARCO CONCEPTUAL 43 Figura 2.25: Arquitectura de Tableau Server (Fuente [TableauPDF, 2016]) Capa de datos. Una de las características fundamentales de Tableau es que admite la arquitectura de datos que usted elija. Tableau no requiere que sus datos se almacenen en un solo sistema, propietario o de otro tipo. La mayoría de las organizaciones tiene un entorno de datos heterogéneo: almacenes de datos conviven con bases de datos, aunque sean locales o se encuentren en la nube. Los cubos y los archivos planos como los de Excel se siguen usando mucho. Tableau puede trabajar con todos ellos de manera simultánea. No es necesario que reúna todos los datos en la memoria, a menos que así lo decida. Si sus plataformas de datos actuales son rápidas y escalables, Tableau le permite bene�ciarse de manera directa de su inversión aprovechando la e�cacia de la base de datos para responder preguntas. Si este no es el caso, Tableau proporciona opciones simples para actualizar sus datos a �n de que sean rápidos y respondan con nuestro motor de datos en memoria. Conectores de datos. Tableau incluye más de 40 conectores de datos optimiza- dos para fuentes de datos como Microsoft Excel, SQL Server, Google BigQuery, Amazon Redshift, Oracle, SAP HANA, Salesforce.com, Teradata, Vertica, Clou- dera y Hadoop, y se agregan conectores de datos nuevos regularmente. También hay un conector ODBC genérico para cualquier sistema sin conector nativo. Ta- bleau proporciona dos modos de interacción con los datos: conexión en vivo o en memoria. Los usuarios pueden cambiar entre la conexión en vivo y en memoria, según lo deseen. Componentes de Tableau Server. El trabajo de Tableau Server se realiza mediante los siguientes cuatro procesos de servidor: � Servidor de aplicaciones. Los procesos del servidor de aplicaciones (wgser- ver.exe) controlan la exploración de contenido, la administración del servidor CAPÍTULO 2. MARCO CONCEPTUAL 44 y los permisos para las interfaces web y móvil de Tableau Server. Cuando un usuario abre una vista en un dispositivo cliente, ese usuario inicia una sesión (workgroup_session_id) en Tableau Server. El administrador puede con�- gurar fácilmente el tiempo de expiración predeterminado de esta sesión. El usuario puede ejecutar dos o más procesos de servidor de aplicaciones para satisfacer sus necesidades de escalabilidad y disponibilidad. VizQL Server: una vez que el usuario recibe la autenti�cación del servidor de aplicacio- nes, puede abrir una vista. El cliente envía una solicitud al proceso VizQL (vizqlserver.exe). A continuación, el proceso VizQL envía las consultas di- rectamente a la fuente de datos y devuelve un conjunto de resultados que se expresa en imágenes y se presenta al usuario. En muchos casos, Tableau Ser- ver aprovecha las representaciones y el almacenamiento en caché del cliente para reducir la carga del servidor. Además, cada VizQL Server tiene su pro- pia memoria caché que pueden compartir varios usuarios de manera segura. El usuario puede ejecutar dos o más procesos de VizQL Server para satisfacer sus necesidades de escalabilidad y disponibilidad. � Data Server. A diferencia de los enfoques tradicionales de administración de metadatos, el Data Server de Tableau es un componente clave que per- mite a los administradores de TI habilitar el monitoreo, la administración de metadatos y el control para los equipos de TI, a la vez que se habilitan los análisis de autoservicio para usuarios profesionales. Permite administrar y almacenar fuentes de datos de Tableau de manera centralizada y propor- ciona a los usuarios �nales acceso seguro a datos con�ables por medio de implementaciones de análisis de autoservicio. Usted puede administrar cen- tralizadamente metadatos, como conexiones, controladores y �ltros de fuen- tes de datos, para acceder a los datos. Puede asignar permisos especí�cos a las fuentes de datos de manera que permita al equipo de TI administrar los permisos a las fuentes de datos en función de grupos de identi�cación especí�ca. En un entorno administrado, los usuarios que conocen mejor sus datos también cuentan con la �exibilidad de de�nir y publicar de�niciones, cálculos y grupos. Estos se pueden compartir para que los usen todos los miembros de la organización o los usuarios de Tableau Desktop para crear y aprovisionar sus propios cálculos, de�niciones y grupos. La fuente de datos publicada se puede basar en: ◦ Una extracción del motor de datos de Tableau; ◦ Una conexión en vivo (los cubos no se admiten como conexiones en vivo). � Componente de segundo plano. El componente de segundo plano actua- liza las extracciones programadas, entrega noti�caciones y administra otras tareas de segundo plano. El componente de segundo plano está diseñado para consumir todos los recursos de CPU disponibles a �n de concluir la actividad de segundo plano tan pronto como sea posible. CAPÍTULO 2. MARCO CONCEPTUAL 45 Puerta de enlace/equilibrador de carga. La puerta de enlace dirige solicitu- des a otros componentes. Las solicitudes de los clientes, primero, se encuentran con un equilibrador de carga externo, si se con�gura uno, o la puerta de enlace y, de allí, se los dirige al proceso adecuado. En caso de que no haya un equilibrador de carga externo, si varios procesos se con�guran para cualquier componente, la puerta de enlace actúa como un equilibrador de carga y distribuye las solicitudes hacia los procesos. En una con�guración de un solo servidor, todos los procesos residen en la puerta de enlace o en el servidor primario. Cuando se trabaja en un entorno distribuido, se designa una máquina física como servidor primario, y las otras se designan como servidores de trabajo y pueden ejecutar cualquier cantidad de procesos adicionales. Tableau Server siempre usa una sola máquina como servidor primario. Clientes: navegadores web y aplicaciones móviles. Tableau Server propor- ciona dashboards interactivos a los usuarios mediante HTML5 que no deja rastro en navegadores web o móviles, o de manera nativa mediante una aplicación móvil. No se necesita ActiveX, Java ni Flash para ejecutar informes o visualizaciones. No se requieren complementos ni aplicaciones auxiliares. Tableau Server admite: � Navegadores web: Internet Explorer, Firefox, Chrome y Safari. ◦ Safari para móviles: las vistas optimizadas para la función táctil se pre- sentan automáticamente en Safari para móviles. ◦ Aplicación para iPad: aplicación nativa para iPad que proporciona vis- tas, contenido, navegación y edición optimizados para la función táctil. ◦ Navegador de Android: vistas optimizadas para la función táctil que se ofrecen automáticamente en el navegador de Android. ◦ Aplicación para Android: aplicación nativa para Android que proporcio- na vistas, contenido, navegación y edición optimizados para la función táctil. Clientes: Tableau Desktop. Tableau Desktop es el entorno de creación rápida de análisis de negocios que se usa para crear y publicar vistas, informes y dash- boards en Tableau Server. Mediante Tableau Desktop, un autor de informes puede conectarse a varias fuentes de datos, explorar relaciones, crear dashboards, modi- �car metadatos y, por último, publicar un libro de trabajo completo o una fuente de datos en Tableau Server. Tableau Desktop también puede abrir cualquier li- bro de trabajo publicado en Tableau Server o conectarse con cualquier fuente de datos publicada, ya sea que se haya publicado como una extracción o como una conexión en vivo. Tableau Desktop es compatible con escritorios de Windows y de Mac. Capítulo 3 Marco Metodológico 3.1. Metodología Descendente (TOP-DOWN) Este enfoque Descendente, se recomienda aplicar cuando se tiene un conocimiento previo de la tecnología y las necesidades de la empresa. Se trata de un método sistémico, que disminuye los problemas de integración pero que resulta ser costoso debido a la gran cantidad de datos que debe manejarse y a la poca �exibilidad en esta metodología. Lo esencial es ir desde lo más general a lo más especí�co. Es decir que primero debe formularse un resumen del sistema sin especi�car detalles para luego rede�nir cada parte del sistema con mayor detalle y así sucesivamente hasta que las especi�caciones sean lo más detalladas para validar el modelo. Uno de los elementos que nos ayuda en el diseño son las llamadas �cajas negras�, aunque las mismas no expliquen en detalle los componentes individuales. Una de las principales ventajas de este enfoque radica en que mediante el mismo almacén de datos resultante se enfoca realmente en las necesidades del cliente y por lo tanto su proceso de apoyo al proceso de toma de decisiones es más preciso. Por otro lado, este enfoque tiene como inconveniente principal que aumenta la com- plejidad en la obtención de información para la carga de datos, sobre todo en los casos en los que las fuentes no se encuentran automatizadas. Este enfoque se basa en la visión de Bill Inmon quien considera que el repositorio de datos debe responder a las necesidades de todos los usuarios en la organización y no solo a un pequeño grupo. 3.1.1. Metodología de Bill Inmon Esta metodología fue de�nida por Bill Inmon en el año 1992 en el libro �Building the Data Warehouse� [Inmon, 2002]. En él se proponen los mecanismos necesarios para llevar a cabo la correcta realización de un almacén de datos. B. Inmon presenta dos camino a seguir para la construcción de un almacén de datos. Una metodología y un plan de migración. La metodología describe actividades especí- �cas, y el orden en el que deben ejecutarse las actividades, sin embargo las dinámicas 46 CAPÍTULO 3. MARCO METODOLÓGICO 47 no describen los procesos. Mientras que el plan de migración describe actividades ge- nerales dinámicamente que deben ejecutarse a lo largo de todo el desarrollo. Juntos forman una imagen completa de lo que se requiere para construir el almacén de datos. [Inmon, 2002]. Sobre la metodología, argumenta que los ambientes del almacén de datos son diri- gidos por los datos, en comparación con los sistemas clásicos los cuales tienen un ciclo de vida de desarrollo dirigido por los requerimientos. Mantiene que los requerimientos son el último elemento a ser considerado en el ciclo de vida del proceso de desarrollo del soporte de decisiones, los mismos son �nalmente entendidos luego que el almacén de datos ha sido poblado con datos y los resultados de las consultas han sido analizados por los usuarios [Inmon, 2002]. Uno de los aspectos sobresalientes de la metodología dirigida por los datos es que la misma construye a partir de esfuerzos previos, es decir construye tanto sobre los códigos como de los procesos que han sido desarrollados anteriormente. La única forma en que el desarrollo sobre esfuerzos previos pueda ser completado es mediante el reconocimiento de aspectos comunes. Esto quiere decir que antes que el desarrollador inicie su trabajo, él o ella necesita entender y conocer lo que realmente existe y como se relaciona con el desarrollo del almacén de datos. Esta fase es esencial en la metodología[Inmon, 2002]. B. Inmon fue el primero en de�nir y defender el concepto de almacén de datos, por lo cual se reconoce como el padre del almacén de datos, ve la necesidad de transferir la información de los diferentes Sistemas Transaccionales (OLTP) de las organizaciones a un lugar centralizado donde los datos puedan ser utilizados para el análisis que sería el Corporate Information Factory (CIF). Insiste además en que ha de tener las siguientes características[Kimball, 2010]: Orientado a temas. Los datos en la base de datos están organizados de manera que todos los elementos de datos relativos al mismo evento u objeto del mundo real queden unidos entre sí. Integrado. La base de datos contiene los datos de todos los sistemas operacionales de la organización, y dichos datos deben ser consistentes. No volátil. La información no se modi�ca ni se elimina, una vez almacenado un dato, éste se convierte en información de sólo lectura, y se mantiene para futuras consultas. Variante en el tiempo. Los cambios producidos en los datos a lo largo del tiempo quedan registrados para que los informes que se puedan generar re�ejen esas variaciones. La información ha de estar a los máximos niveles de detalle. Los DWH departamentales o bodega de datos son tratados como subconjuntos de este DWH corporativo, que son construidos para cubrir las necesidades individuales de análisis de cada departamento, y siempre a partir de este DWH Central donde se pueden construir las estructuras Operational Data Stores (ODS) o similares. CAPÍTULO 3. MARCO METODOLÓGICO 48 Los datos son extraídos de los sistemas operacionales por los procesos ETL y carga- dos en las áreas de stage, donde son validados y consolidados en el DWH corporativo, donde además existen los llamados metadatos que documentan de una forma clara y precisa el contenido del DWH. Una vez realizado este proceso, los procesos de refresco de los bodega de datos departamentales obtienen la información de la organización, y con las consiguientes transformaciones, organizan los datos en las estructuras particulares requeridas por cada uno de ellos, refrescando su contenido. Figura 3.1: Enfoque Inmon (Fuente [Kimball, 2010]) La metodología propuesta por B. Inmon explica los resultados que deben obtenerse y el orden en el que deben estar ejecutados los pasos. La manera en la que los resultados sean logrados es un elemento que se deja enteramente a juicio del desarrollador. La metodología se dividió en tres partes componentes, incluye actividades las actividades clásicas necesarias para que sea una metodología dirigida por los datos [Inmon, 2002]. A continuación se de�nirán de manera general los elementos de cada una de las partes, y componentes de la metodología [Inmon, 2002]. 3.1.2. Parte 1: Desarrollo de Sistemas Operacionales Actividades iniciales del proyecto. Se basa en la recolección de cada uno de los requerimientos a través de entrevistas, recopilación de datos. Uso de código y datos existentes. Como la premisa indica, en este elemento debemos considerar todos los elementos reutilizables posibles. Determinación de tamaño y fases. En este punto se divide el proyecto en fases lo más pequeñas y manejables posibles. CAPÍTULO 3. MARCO METODOLÓGICO 49 Formalización de los requerimientos. Asegurar que los requerimientos sean completos, organizados, legibles, comprensibles y a un nivel de detalle que permita ser efectivos. Sobre el modelado de datos o modelo dimensional Diagrama Entidad Relación. A partir de los requerimientos ya de�nidos se de�nen los elementos constitutivos del sistema y la relación de cardinalidad entre ellos. Conjunto de Elemento de Datos (CED). Los CED contiene los atributos de los datos, agrupamiento de los atributos, claves, tipos de datos, conectores y agrupamiento secundario de los datos. Solo los datos primitivos se manejan aquí. Análisis de Desempeño. Este elemento permite pulir los elementos de ingreso y actualización de data haciendo el proceso más e�ciente. Diseño físico de la base de datos. Se obtienen las tablas y bases de datos diseñadas físicamente, luego de transformar todas las consideraciones lógicas de diseño de datos, desempeño, actualización, ingreso, disponibilidad, etc. Sobre el Especi�caciones de Proceso Descomposición Funcional. Es la descripción de todas las actividades a ser realizadas durante el desarrollo desde el nivel alto hasta un nivel bajo. Nivel de Contexto 0. Corresponde a D1, Diagrama Entidad-Relación, en el modelado de datos. Nivel de Contexto 1-n. Los niveles restantes de la descomposición funcional describen más detalladamente las actividades que ocurren, de manera ordenada, organizada, completa y en concordancia con el �ujo de actividades. Diagramas de Flujo de Datos (DFD). Existe un DFD para cada nivel de contexto n, indica la entrada de un proceso, la salida del proceso, el almacena- miento de datos necesario para establecer el proceso y una breve descripción del proceso. Especi�caciones Algorítmicas. Los procesos de cada DFD se dividen en espe- ci�caciones algorítmicas detalladas, tomando en cuenta los aspectos de desempeño que deben ser resueltos en el diseño de los programas. Pseudocódigo. Los algoritmos y especi�caciones de programas se re�nan en pseudocódigo, el cual debe incluir completitud, orden de ejecución, todos los casos requeridos. Corresponde a D4 en modelado de datos. CAPÍTULO 3. MARCO METODOLÓGICO 50 Codi�cación. Construcción del código fuente. La traducción completa y e�ciente de pseudocódigo en código, incluyendo la documentación en código. Caminata. Explicación verbal del código a los colegas, para encontrar y corregir la mayor cantidad de errores posibles antes de las pruebas. Compilación. El código fuente es compilado y se corrigen todos los errores en- contrados. Pruebas unitarias. pruebas del código a diferentes niveles. Implementación. esta etapa incluye actividades como: descarga inicial de datos, conversión de datos, escritura de la documentación y establecimiento de procesos de respaldo. 3.1.3. Parte 2: Desarrollo del almacén de datos Este es el componente de la metodología que se ocupa del desarrollo de sistemas y procesamiento de soporte a la toma de decisiones. Análisis del Modelo de Datos. Con�rmación que el modelo de datos de la organización es sólido y que contiene la identi�cación de los temas de mayor interés, cada tema tiene separada su propia de�nición de datos: subtipos de datos, atributos, relaciones, identi�cación de claves, entre otros. Análisis Breadbox. Permite la determinación del tamaño �estimación bruta- del entorno de los sistemas de soporte de toma de decisiones. Simplemente proyecta, en términos crudos, qué cantidad de datos mantendrá el almacén de datos. Valoración Técnica. Contiene de�niciones técnicas que tienen la habilidad de manejar grandes cantidades de datos, permitir que los datos sean ingresados �exi- blemente, organizar los datos de acuerdo al modelo de datos y tanto recibir como enviar datos a una amplia variedad de tecnologías. Preparación del entorno técnico. Instalación, ubicación y desarrollo de los componentes técnicos que recibirán los datos. Análisis de los temas del almacén de datos. Determinación del tema que será el primero en implementarse. Diseño del almacén de datos. Este subelemento toma en cuenta las siguiente características; acomodación de los niveles de granularidad, orientación de los datos a los principales temas de organización, la ausencia de datos que no apoya al sistema de soporte de las decisiones, desnormalización donde sea aplicable y �nalmente adaptar los datos del entorno operacional al entorno analítico. CAPÍTULO 3. MARCO METODOLÓGICO 51 Análisis de los sistemas fuentes. Identi�cación del sistema de registro, es decir el mapeo de los datos del ambiente operacional al ambiente analítico. Especi�caciones. Aquí veri�ca qué datos operacionales deben ser obtenidos y cómo guardarlos. Programación. Programas de transformación que permitan la extracción, inte- gración y ubicación en perspectiva de tiempo de los datos. Población. Ejecución de los programas desarrollados en las etapas anteriores. Se deben resolver los aspectos de frecuencia de población, reglas de purga, adminis- tración de múltiples niveles de granularidad y refrescamiento. Con este paso �nal se obtiene un almacén de datos poblado y funcional, accesible y comprensible que sirve las necesidades de las comunidades de los sistemas de soporte a la toma de decisiones. 3.1.4. Parte 3: Uso del Almacén de Datos Este último componente describe el uso del almacén de datos para propósitos de análisis. Repetición del desarrollo estándar. Para la obtención de reportes estándares, el procesamiento analítico repetitivo debe seguir el procesamiento normal descrito en la �Parte 1�, exceptuando el modelado de datos, porque la fuente de datos es el mismo almacén de datos. Una vez comentados los elementos constitutivos de cada una de las partes de la metodología vamos a abordar el segundo elemento de la visión de Inmon, el Migration Path [Inmon, 2002] 3.1.5. Plan de Migración (Migration Path) El punto de arranque del plan de migración es el modelo de datos o modelo dimensio- nal. El modelo suele representar las necesidades de la organización, no necesariamente lo que realmente tiene. El modelo dimensional debe representar lo siguiente [Inmon, 2002]: Atributos Las claves Los grupos repetitivos de atributos y claves Conectores entre las áreas de los temas principales Relaciones de subtipos CAPÍTULO 3. MARCO METODOLÓGICO 52 Una vez que se ha de�nido el modelo de datos es necesario de�nir el sistema de registros, el cual se de�ne en términos de los sistemas existentes que la organización ya tiene. La determinación de la mejor fuente de datos se basa en los siguientes criterios [Inmon, 2002]: Datos más precisos Datos más cercanos a la fuente de entrada Datos más cercanos a la estructura del modelado de datos Datos más complejos El siguiente paso consiste en diseñar el almacén de datos. Si el modelo de datos está elaborado correctamente solo se deben cambiar algunos aspectos para hacerlo más �el a un diseño de almacén de datos. Luego del diseño de datos, el siguiente paso es diseñar y construir las interfaces entre el sistema de registro y el almacén de datos, las cuales poblarán el almacén de datos en periodos de tiempo regulares. Entre las actividades que realizan las interfaces tenemos [Inmon, 2002]: Integración de los datos Alteración de las bases de tiempo de los datos Condensación de los datos La etapa �nal de este plan de migración es iniciar la población del almacén de datos con el primer tema de interés. Es importante que sólo una parte del almacén de datos sea poblada, de esta manera cuando surjan los cambios, a partir de los procesos ite- rativos de análisis y reconocimiento de la data, los mismos sean fáciles de manejar e implementar. Una vez que el usuario �nal tiene acercamiento a los datos y proporciona retroalimentación al arquitecto de datos, entonces puede ser sano poblar cantidades mayores de datos. De esta manera podemos ver la relación que establece Inmon entre los dos com- ponentes de su visión. El componente Migration Path es quien dictamina los pasos a ejecutar para el desarrollo del almacén de datos, mientras que el componente de me- todología describe cuáles son los pasos que debe ejecutarse dentro de cada paso del Migration Path. Finalmente, la naturaleza global del enfoque de Inmon hace que su visión resulte más atractiva a la hora de desarrollar un almacén de datos a gran escala, pero para desarrollos de almacén de datos más pequeños, en los que el factor tiempo también es importante, esta metodología no suele resultar tan atractiva. CAPÍTULO 3. MARCO METODOLÓGICO 53 3.2. Metodología Ascendente (BOTTOM-UP) En este enfoque el objetivo, es entregar valor de negocio mediante la implementación del modelo dimensional lo más rápido posible. Los datos se modela en un diseño de esquema en estrella para optimizar la facilidad de uso y rendimiento de las consultas. Se van construyendo bodega de datos relativamente independientes para ir midiendo las ventajas a medida que se va avanzando. A medida que los bodega de datos resultan exitosos se comienzan a enlazar con otros bodega de datos previamente realizados y así sucesivamente hasta que se tiene la completitud del sistema. Las estrategias en la que funcionan el enfoque Ascendente se basan en el conocimiento de todas las variables que traten del sistema El almacén de datos es un conglomerado de todos los bodega de datos dentro de una empresa, siendo una copia de los datos transaccionales estructurados de una for- ma especial para el análisis, de acuerdo al Modelo Dimensional (no normalizado), que incluye, como ya vimos, las dimensiones de análisis y sus atributos, su organización jerárquica, así como los diferentes hechos de negocio que se quieren analizar. Por un lado tenemos tablas para las representar las dimensiones y por otro lado tablas para los hechos ( facts tables). Los diferentes bodega de datos están conectados entre si por la llamada bus structure, que contiene los elementos anteriormente citados a través de las dimensiones conformadas (que permiten que los usuarios puedan realizar querys conjuntos sobre los diferentes bodega de datos, pues este bus contiene los elementos en común que los comunican). Una dimensión conformada puede ser, por ejemplo, la dimensión cliente, que incluye todos los atributos o elementos de análisis referentes a los clientes y que puede ser compartida por diferentes bodega de datos (ventas, pedidos, gestión de cobros, etc)[Kimball, 2010]. Figura 3.2: Enfoque R. Kimball (Fuentes [Kimball, 2010]) Pues al �nal el almacén de datos Corporativo no es mas que la unión de los diferen- tes bodega de datos, que están estructurados de una forma común a través de la bus CAPÍTULO 3. MARCO METODOLÓGICO 54 structure. Esta característica le hace mas �exible y sencillo de implementar, pues pode- mos construir un Bodega de Dato como primer elemento del sistema de análisis, y luego ir añadiendo otros que comparten las dimensiones ya de�nidas o incluyen otras nuevas. En este sistema, los procesos ETL extraen la información de los sistemas operacionales y los procesan igualmente en el área stage, realizando posteriormente el llenado de cada uno de los Bodega de Dato de una forma individual, aunque siempre respetando la estandarización de las dimensiones (dimensiones conformadas) [Kimball, 2010]. Uno de los bene�cio de este enfoque, es que se centra en la creación de estructuras de datos �exibles, fáciles de usar, utilizando modelos de esquema dimensional, estrella. También ofrece un valor rápidamente por que no ofrece una infraestructura pesada en la delantera. Permite automatizar los procesos de carga de data para así simpli�car procesos de mantenimiento y administración de la información. Un problema con un enfoque, es que se requiere que las organizaciones para ha- cer cumplir el uso de dimensiones y hechos estándar para garantizar la integración y entregar una única versión de la verdad. Cuando los bodega de datos se ordenan lógi- camente dentro de una sola base de datos física, esta integración se realiza fácilmente. Pero en una organización distribuida, descentralizada, puede ser demasiado para pedir a los departamentos y unidades de negocio a que se adhieran y reutilizar las referencias y las reglas para el cálculo de los hechos. No puede haber una tendencia a que las organizaciones crear mercados de datos "independiente" o no integrados. Este enfoque se adapta a la visión de R. Kimball quien considera que el factor tiempo a la hora de explotar las bondades de un almacén de datos es un elemento determinante a la hora de decidirse por esta tecnología. Este enfoque parte de los requerimientos de negocio, mientras que el enfoque Descendente deja la validación de requerimientos para el �nal del proceso. 3.2.1. Metodología de Ralph Kimball La implementación de una solución de BI requiere seguir una metodología con un conjunto de actividades relacionadas entre sí, las cuales han de tener un punto especí�co de inicio y de �n. Se tiene que tomar en cuenta en todo momento que la construcción de una solución de BI debe enfocarse directamente en las necesidades de la organización y que los datos presentados al usuario �nal deben ser consistentes. Esta metodología se basa en la interpretación de la frase �Ciclo de Vida�, que suele usarse en el argot computacional para referirse a todos los pasos del proceso de desarrollo de software pero adaptados a la visión de desarrollo de almacén de datos, en ella se describe paso a paso cómo diseñar, desarrollar y desplegar almacén de datos y bodega de datos. El libro también aborda el proceso de construcción de inicio a �n de forma iterativa y también se muestra la utilización de las técnicas del modelado dimensional. En el mismo, R. Kimball se muestra mucho más técnico que los autores anteriores logrando descripciones más detalladas. CAPÍTULO 3. MARCO METODOLÓGICO 55 Figura 3.3: Ciclo de Vida de la Metodología de Ralph Kimball (Fuente [Kimball, 2002]) El diagrama no re�eja una línea temporal absoluta. Mientras que las cajas son igualmente amplia, hay una gran diferencia en el tiempo y esfuerzo que se requiere para cada actividad principal. Sin embargo a partir de la �gura: 3.3 anterior se puede entonces dividir la metodología en [Kimball, 1998]: 3.2.2. Plani�cación del Proyecto En su metodología R. Kimball plantea que los pasos iniciales para el desarrollo de un almacén de datos son la planeación del proyecto y la obtención de requerimientos. Cada elemento cumple funciones determinadas [Kimball, 2002]. Planeación y Gestión del Proyecto. Este es el primer paso que debe llevarse a cabo para poder iniciar el desarrollo del almacén de datos. En este paso se establece la situación actual de la empresa y se elabora un plan para el proyecto, de�niendo el alcance del mismo. Obtención de Requerimientos. Este paso se re�ere a la implementación de los mecanismos necesarios para poder obtener datos de la información que la empresa desea que se manejen en el almacén de datos. Dichos datos son los que le darán sentido al almacén de datos. Los mecanismos a emplear para obtener dicha información van desde entrevistas hasta sesiones con un facilitador. 3.2.3. De�nición de los Requerimientos del Negocio Consiste en plasmar y expresar los requerimientos de los usuarios basándose en las necesidades de la organización. Este levantamiento de información se puede llevar a cabo realizando reuniones, encuestas, entrevistas, o cualquier otro método que permita expresar de una forma clara y no ambigua los requerimientos del cliente. Los requerimientos obtenidos han de documentarse, dado a que no sólo servirá para certi�car que se contempló todo lo que el cliente necesita, sino que también servirá para el grupo de desarrollo conozca las funcionalidades que ha de tener el sistema, lo que se CAPÍTULO 3. MARCO METODOLÓGICO 56 necesita para cumplir con los requerimientos especi�cados, los usuarios involucrados en el proyecto, el léxico que se emplea, entre otras cosas. Como podemos observar 3.3, después de de�nir los requerimientos, se realiza tres actividades de forma concurrente, las cuales se enfocan en la tecnología, los datos y las aplicaciones analíticas. 3.2.4. Diseño de la Arquitectura El diseño técnico sirve como un marco organizativo que soporta la integración de los elementos tecnológicos necesarios para el desarrollo de la solución de inteligencia de negocio. Este diseño permite identi�car los componentes más importantes y minimizar im- previstos al momento de desarrollar e implementar la solución especi�cada, por medio del análisis de las problemáticas que podrían afectar el proceso de desarrollo. Adicional- mente la realización del diseño permite coordinar la ejecución de diversos procesos en paralelo, acelerando de esta forma el desarrollo mediante la utilización de componentes modulares. Con los requerimientos documentados se procede a realizar una estructura básica que soporte las necesidades de la implementación de la arquitectura para así llevar a cabo el desarrollo de la solución de inteligencia de negocio. Una vez especi�cada la estructura elemental para la solución se procede a realizar el diseño especí�co de cada uno de los subsistemas que se encuentran implicados con nuestra solución, es decir, se de�nen los requisitos por cada uno de los componentes con el mayor nivel de detalle posible. También se deben de considerar los requerimien- tos de seguridad, de la infraestructura física y de las necesidades con respecto a la con�guración. Además de considerar los requerimientos funcionales de la solución, se necesita to- mar en cuenta aspectos como la capacidad que debe tener el almacén de datos, la escalabilidad, la �exibilidad y el desempeño de la solución. Es importante establecer las fases del plan de implementación, darle prioridad a los aspectos técnicos de la arquitectura debido a que usualmente no se pueden implementar todos los elementos deseados desde el inicio del proyecto, por esta razón, se deben de�nir cuáles son los aspectos necesarios para la implementación del mismo y cuáles pueden obtenerse luego para aportar un valor agregado a la solución. Para concluir, es necesario documentar el diseño técnico de la arquitectura inclu- yendo las fases del plan de implementación. Este documento debe incluir información pertinente para que los profesionales cali�cados procedan con la construcción de la solución. En la siguiente tabla se resume el modelo de arquitectura que propone R. Kimball. La misma recibe el nombre de marco de trabajo de la arquitectura como vemos en la 3.1 donde las columnas muestran las principales área de la arquitectura: datos, téc- nica e infraestructura y las �las representan los niveles de detalle en orden creciente: requerimientos del negocio, modelo de arquitectura, modelo detallado, implementación. CAPÍTULO 3. MARCO METODOLÓGICO 57 Cuadro 3.1: Marco de trabajo de la Arquitectura Arquitectura de Datos Este nivel abarca tanto el diseño físico y lógico de los modelos de datos. Todo lo relacionado a dicho diseño ya fue explicado en puntos anteriores. Arquitectura Técnica El área de la arquitectura técnica cubre los procesos y herramientas que se aplican a los datos. Esta área está dividida a su vez en dos elementos con sus requeri- mientos y mecanismos propios [Kimball, 1998]: � Back Room: responsable de la obtención y preparación de los datos. �Es el cuarto de máquinas del almacén de datos� . La función principal de este elemento es resolver los problemas de migración y transformación de datos desde las fuentes de datos hasta el entorno almacén de datos. En la arquitectura del back room, se debe analizar los aspectos relativos a: los sitios donde se almacenan los datos (sistemas fuente), los servicios que proporcionará (extracción, transformación, carga) y la administración de los activos del back room (respaldo y recuperación, entre otros). � Front Room: responsable de entregar los datos a los usuarios determinados. La función principal de este elemento es de servir de intermediario entre los usuarios y la información, de manera tal de poder ofrecerle a dichos usuarios lo que necesiten pero sin que los mismos vean las complejidades latentes en dichos procesos. En la arquitectura del front room se deben analizar los aspectos relativos a: los sitios donde se almacenan los datos (herramientas de acceso a los almacenes, entre otros) y los servicios que proporcionarán para el acceso de datos (navegación, acceso y seguridad, administración de consultas, entre otros). Arquitectura de Infraestructura y Metadatos Este apartado se re�ere a las plataformas sobre las cuales se va a cimentar el CAPÍTULO 3. MARCO METODOLÓGICO 58 almacén de datos. La infraestructura incluye el hardware, la red y elementos de bajo nivel que no suelen ser competencia de las otras áreas. Los elementos a tomar en consideración para esta área son: � Los requerimientos del negocio: los cuales son los que determinan la dirección a tomar por parte del almacén de datos. � Los factores de la infraestructura del back room: tamaño de datos, volatilidad de la data, hardware, sistema operativo, entre otros. � Los factores de infraestructura del front room: servidores de aplica- ción, entre otros. � Factores de redes y conectividad: ancho de banda, acceso remoto, co- nectividad a la base de datos, entre otros. 3.2.5. Selección de productos e instalación El producto a seleccionar debe acoplarse al marco de�nido en el diseño de la arqui- tectura, adaptándose a los procesos de la organización. Para seleccionar el producto más apropiado para la solución se debe desarrollar una matriz de evaluación, la cual debe contener los diversos criterios que se deseen analizar. Mientras más especí�cos y detallados los criterios mejor se adapta a los requerimientos necesarios para el desarrollo de la solución. Además de la matriz, es necesario conocer la mayor cantidad de productos posibles que se encuentren en el mercado, para así poder tener más fundamentos al momento de seleccionar un producto en especí�co. Después de realizar dicha evaluación se selecciona el producto que (según los análisis realizados) se adapte mejor para el cumplimiento de los requerimientos funcionales, así como también, de las especi�caciones del diseño técnico de la arquitectura. 3.2.6. Diseño de Datos o modelado dimensional El modelado dimensional, según su creador R. Kimball, es el diseño tanto físico como lógico que se va a encargar de transformar las fuentes de datos, previamente de�nidas en el paso anterior, en estructuras aptas para el almacén de datos. Cada modelo dimensional está compuesto de una tabla que tiene una clave compuesta llamada tabla de hechos y un conjunto de tablas más pequeñas llamadas dimensiones. Cada tabla dimensión tiene una clave primaria simple, que a su vez forma parte de la clave compuesta de la tabla de hechos. Esta descripción se re�ere al esquema estrella explicado en el Capítulo 2. Los pasos necesarios para convertir un Diagrama Entidad-Relación (ERD) a un conjunto de diagramas que se basan en el modelado dimensional son [Kimball, 2002]: Separar el Diagrama Entidad-Relación en procesos �nitos y discretos e ir los modelando por separado. CAPÍTULO 3. MARCO METODOLÓGICO 59 Determinar cuáles serán las tablas de hechos mediante la selección de las relaciones muchos a muchos del modelo que no tengan claves primarias simples. Determinar cuáles serán las tablas de hechos mediante la selección de las relaciones muchos a muchos del modelo que no tengan claves primarias simples. Crear las tablas dimensionales desnormalizando todas las tablas y añadiéndoles claves primarias simples. De�nir también las tablas dimensionales conformadas que son aquellas que sirven de dimensión a más de una tablas de hechos. Se fundamenta en las siguientes ventajas para proponer el modelado dimensional [Kimball, 2002]: Soporta cambios inesperados en el comportamiento del usuario. Es capaz de crecer y extenderse para aceptar nuevos elementos de datos y de diseño. Otros elementos que se toman en cuenta dentro del aspecto del modelado dimensional son [Kimball, 2002]: Arquitectura de Bus del almacén de datos La arquitectura del bus de almacén de datos se basa en la idea que un almacén de datos está compuesto por muchos bodega de datos. Cada Bodega de Dato a su vez debe estar representado dentro de un modelo dimensional y compuesto por tablas de hechos y tablas dimensionales [Kimball, 2002]. Por lo tanto el autor plantea que es necesario al principio del proyecto de�nir una arquitectura estricta y �nita de datos sobre la cual se desarrollará el almacén de datos. Posteriormente, y basándose en la arquitectura previamente de�nida, deben irse construyendo los bodega de datos. R. Kimball explica que �cada Bo- dega de Dato para que sea práctico debe ser basado en los datos más granulares (atómicos) que sea posible colectar y almacenar� [Kimball, 2002]. La correcta adherencia entre un Bodega de Dato y otro se consigue a través de las tablas dimensionales conformadas, ya que a través de ellas se logra [Kimball, 2002]: � Una tabla dimensional solo puede ser usada contra múltiples tablas de hechos en el mismo espacio de base de datos. � Las interfaces de usuario y los datos que contienen son consistentes en cual- quier instante en que se utilice la dimensión. � Existe una interpretación consistente de los atributos en cada Bodega de Dato. � A partir de lo anteriormente expuesto podemos entender que las dimensiones conformadas son las que hacen de bus en el almacén de datos. Por lo tanto, al de�nir una interfase estándar de bus (mediante dimensiones conformadas) un nuevo Bodega de Dato puede añadirse al almacén de datos y coexistir con los otros sin ningún inconveniente. CAPÍTULO 3. MARCO METODOLÓGICO 60 A partir de lo anteriormente expuesto podemos entender que las dimensiones conformadas son las que hacen de bus en el almacén de datos. Por lo tanto, al de�nir una interfase estándar de bus (mediante dimensiones conformadas) un nuevo Bodega de Dato puede añadirse al almacén de datos y coexistir con los otros sin ningún inconveniente. Elementos del Modelado Dimensional Los siguientes son elementos esenciales para el Modelado Dimensional: � Hechos: un hecho es una observación del mercado de trabajo. � Atributos: usualmente son campos de texto que describen las características de algo tangible, como las descripciones del producto. � Dimensiones: se re�ere a los atributos que describen al objeto y que a su vez se correlacionan entre ellos. Método de Diseño de cuatro pasos para diseñar una tabla de hechos Los siguientes son pasos necesarios para un diseño lógico de un esquema dimen- sional: � Escoger el bodega de datos. Como se desea en primera instancia mantener un nivel de simplicidad adecuado entonces es recomendable en lo posible escoger una única fuente de datos para el bodega de datos. � Declarar la granularidad de la tabla de Hechos. Consiste en de�nir qué se considera una tabla de hechos para el diseño dimensional que se propone. � Escoger las dimensiones. escoger, en lo posible, aquellas dimensiones que sean capaces de tomar un valor único en el contexto de un conjunto dado de medidas del negocio. � Escoger los hechos. Los hechos deben ser siempre especí�cos a la granula- ridad de la tabla de hechos. No se deben hacer manipulaciones convenientes a otros cálculos porque eso podría afectar la naturaleza del hecho. Construcción de Modelos Dimensionales R. Kimball concibe cada bodega de datos como un modelo dimensional separado y el conjunto de modelos dimensionales constituye el diseño lógico del almacén de datos. Para la construcción de los bodega de datos R. Kimball propone emplear un enfoque Ascendente al que llama Matriz de Arquitectura del almacén de datos, en el cual se identi�can todos los bodega de datos que se puedan construir y a su vez todas las dimensiones que implican a cada bodega de datos, posteriormente se deben relacionar ambos elementos para así de�nir cuáles dimensiones podrán ser utilizadas por más de un bodega de datos. Dichas dimensiones pasarán a formar el denominado Bus de almacén de datos. En la siguiente etapa, una vez que se han identi�cado los bodega de datos a cons- truir junto con sus respectivas dimensiones, se procede a realizar los diseños físicos CAPÍTULO 3. MARCO METODOLÓGICO 61 y lógicos de las tablas individuales usando el método de cuatro pasos explicado anteriormente. Con todos estos elementos se podrá elaborar entonces un borrador inicial del sistema el cual permitirá identi�car los hechos base y los hechos derivados que deberán ser incluidos y así pulir el modelo para adaptarlo mejor a las característi- cas y exigencias del negocio. En este proceso se podrán realizar todos los cambios necesarios, los cuales deben estar debidamente documentados, junto a todas las decisiones que se realicen, desde elegir las fuentes de datos hasta determinar las fórmulas de cálculo de los hechos derivados y demás. 3.2.7. Especi�cación y desarrollo de aplicaciones analíticas Como se puede apreciar en la 3.3, la especi�cación y el desarrollo de las aplicaciones analíticas se realiza después de obtener los requerimientos del negocio. Para realizar las especi�caciones de las aplicaciones analíticas debemos llevar a ca- bo un análisis de los diversos productos existentes en el mercado, buscando siempre aquel que se adapte mejor a lo que se requiere para satisfacer las necesidades de la organización. En la fase de desarrollo de las aplicaciones analíticas es necesario establecer con- venciones con respecto a los nombres, cálculos, librerías y codi�caciones para evitar rehacer trabajo a futuro. Esta actividad puede iniciarse una vez que el diseño de la base de datos esté completo, las herramientas de acceso a los datos y metadatos estén instaladas y los datos históricos hayan sido cargados al almacén. 3.2.8. Implementación En esta fase de la metodología es necesario contemplar todos aquellos factores que durante fases iniciales y de diseño no fueron contempladas. A nivel del diseño lógico se debe realizar una última revisión sobre el diseño lógico para determinar cuáles hechos deben ser agregados con respecto a qué dimensiones para mejorar así el rendimiento del almacén de datos. A nivel del diseño físico el mismo debe culminarse. La secuencia básica es iniciar con elementos de planeación, que se re�eren a establecer estándares de nomenclatura, de bases de datos, estrategias de seguridad, entre otros. Luego, a partir del estado del diseño físico, realizar un corte preliminar en el tamaño de la base de datos y su respectiva tasa de crecimiento. Al mismo tiempo, cuando se tienen ya de�nidas todas las tablas, se debe hacer un corte para la estrategia de establecimiento de índices. A partir de este momento se puede dar por concluido el diseño físico y se puede iniciar realmente el proceso de implementación pues se cuenta con su�ciente información acerca de lo que ocurre en la base de datos en sus mínimos detalles. Posteriormente quedarían pendientes dos elementos dentro de esta fase de la meto- dología: la consolidación de datos y construir aplicaciones al usuario �nal. CAPÍTULO 3. MARCO METODOLÓGICO 62 Sobre la consolidación de datos R. Kimball propone dividir este proceso en un plan de 10 pasos para conseguir con éxito el proceso de consolidación de los Datos en el almacén de datos [Kimball, 1998]: Plan � Crear un esquema de alto nivel, muy consolidado, del �ujo de fuente a des- tino. � Probar, escoger e implementar la herramienta de consolidación de datos. � Bosquejar grá�camente cualquier reestructuración o transformación de datos compleja. Carga de Dimensiones � Construir y probar la carga de una tabla de dimensión estática. � Construir y probar el proceso de cambio lento para una dimensión. � Construir y probar la carga de las dimensiones faltantes. Tablas de hechos y automatización � Construir y probar la carga de las tablas de hechos históricas. � Construir y probar el proceso de carga incremental. � Construir y probar la carga de las tablas de agregaciones. � Diseñar, construir y probar las aplicaciones de automatización del proceso de conciliación. Debido a que en esta etapa deben cuidarse todos los detalles de data y los inherentes a la implementación entonces suele considerarse que la etapa de conciliación de datos es una de las más complicadas en el proceso de desarrollo de un almacén de datos. Sobre la construcción de aplicaciones de usuario �nal, este proceso está relacionado a la herramienta que se vaya a emplear para el acceso a los datos y por lo tanto deberá brindar soporte a los usuarios con requerimientos de análisis tanto de�nidos como improvisados. 3.2.9. Despliegue y Crecimiento Un despliegue exitoso de un almacén de datos requiere: Planeación del despliegue �Despliegue es la convergencia de tecnología, datos y aplicaciones en los escritorios de los usuarios de negocios, junto con la necesaria educación y estructura de soporte al usuario� [Kimball, 1998]. CAPÍTULO 3. MARCO METODOLÓGICO 63 La planeación del despliegue se puede dividir en varias partes. En una de ellas se determina la disponibilidad de los escritorios de los usuarios para su instalación, en otra parte se desarrolla una estrategia para educar al usuario �nal sobre la mejor manera de explotar las bondades del almacén de datos. El desarrollo de un plan para brindar soporte al usuario �nal sobre el uso de la herramienta es fundamental para cimentar el proceso de aprendizaje y así garantizar el éxito del proyecto. Un último elemento a ser tomado en consideración es el desarrollo de un marco de trabajo para la emisión del despliegue. Cada emisión estará de�nida dentro de nuevos requerimientos que vayan añadiéndose al almacén de datos o nuevos grupos de usuarios que vayan a hacer uso del mismo. Es importante que cada emisión de despliegue esté debidamente documentada. Mantenimiento y Crecimiento del almacén de datos Este el último componente dentro de la metodología propuesta por R. Kimball. Este apartado se basa en la constante retroalimentación que deberá existir entre los usuarios �nales y el equipo técnico de forma de poder medir y proyectar el éxito del proyecto y también gestionar adecuadamente las operaciones del almacén de datos. 3.3. Metodología a seguir Desde un estudio de las dos metodología, se puede establecer una serie de compa- raciones, descritas en la tabla 3.2 Cuadro 3.2: Comparación de las metodologías Bill Inmon plantea que el desarrollo de la solución tiene de ser descendente es decir que se debe realizar primero el almacén de datos que abarque toda la estructura de CAPÍTULO 3. MARCO METODOLÓGICO 64 la organización, pasando por un proceso de integración y puri�cación de los datos. Posteriormente se generan la bodega de datos que serán subconjuntos del almacén de datos que se crean a partir de agrupaciones lógicas existentes, como por ejemplo agrupar los elementos que tienen que ver con el área de ventas y generar una bodega de datos. Ralph Kimball plantea que el desarrollo de la solución se tiene que realizar de manera inversa a la ofrecida por Inmon, puesto que se basa en la construcción de las bodegas de datos departamentales, para luego hacer su integración en un almacén de datos que abarque toda la organización, este tipo de diseño se denomina �Ascendnete�. Ralph establece que la complejidad de las organizaciones di�culta la realización de una solución inicial que abarque toda la organización. Por lo que la realización de bodega de datos que apoyen los procesos organizacionales especí�cos, es un mejor comienzo para el desarrollo de una solución. Eventualmente, a medida que se van construyendo más bodega de datos, estos pueden conectarse por elementos en común (atributos, dimensiones, etc) por lo que se va generando una solución que va abarcando íntegramente la organización. La metodología Kimball es idónea cuando se está empezando a desarrollar una infraestructura de inteligencia de negocio, porque se puede desarrollar mercado de datos los cuales tienen una complejidad menor e instaurar una solución de negocios completa sobre un área determinada. Esto ayuda a que el proyecto pueda ser puesto en producción de forma rápida que si se compara con Inmon, lo cual ayuda a la organización a recuperar su inversión más rápido. La metodología a seguir en una adaptación a la metodología de Kimball que se muestra en la �gura 3.4 en cuando a una solución de inteligencia de negocio, ya que la metodología busca es el desarrollo de un almacén de datos, cuando se realiza su adaptación es incorporarle un componente de manipulación de la información. Figura 3.4: Ciclo de vida dimensional adaptado a inteligencia de negocio Capítulo 4 Marco Aplicativo Para cumplir con los objetivos plateados, la solución de BI para la Coodrinación de Investigación se realizó empleando una adaptación a la metodología de Ralph Kimball. La descripción de las actividades realizadas a lo largo del proceso de desarrollo de la solución de inteligencia de negocio, usando la metodología seleccionada, se exhiben a continuación. 4.1. Plani�cación del Proyecto Como en todo proyecto software, es necesario realizar una plani�cación del mismo parar tratar de garantizar que el desarrollo, se realizara según las siguientes actividades previstas: Levantamiento de la información. De�nición de indicadores de gestión. Diseño de modelo dimensional. Implementación del almacén de datos. Implementación de las consultas analíticas y reportes. Elaboración de la implementación Pruebas a la aplicación. El mayor tiempo del proyecto se destina al modelo dimensional, fase que agrupa cuatro subtareas que son: De�nir el modelo de negocio, De�nir el grano, Elegir las dimensiones, Identi�car los hechos. En la tabla 4.1 se de�ne con detalle cada una de las fases del proyecto que se desarrolla. 65 CAPÍTULO 4. MARCO APLICATIVO 66 Cuadro 4.1: Plani�cación del proyecto Se realizó un análisis de la base de datos de los proyectos de investigación de la Facultad de Ciencias para poder determinar los elemento de los proyectos, productos, eventos, área de conocimiento, la formación de los investigadores, entre otros. Es decir lo que se desea conocer. Con la investigación realizada se logró establecer un modelo de constelación del proceso estudiado, así como también, se logró de�nir una serie reportes y de indicadores, facilitar la toma de decisiones en la Coordinación de Investigación de la Facultad de Ciencias. 4.2. De�nición de los Requerimientos Bajo la perspectiva de seguimiento de proyectos de investigación, abstrayéndonos de las variantes que pudieran implementarse en el mismo, para poder generar bene�cios a la organización necesitan poder monitorear los proyectos, productos, eventos y el nivel académico en términos generales, entre otros. Para facilitar a la Coordinación de Investigación la obtención de información rápida, precisa y de calidad para saber de ellos. Por esta razón basándonos en lo que se desea saber, se contempló una serie de reportes y indicadores de la coordinación para apoyar en la toma de decisiones. Se muestran a continuación: 1. Conteo de productos de los investigadores, por área de conocimiento, área de aplicación, institución, y la fecha de publicación de dicho producto. 2. Conteo de proyectos de los investigadores, por área de conocimiento, área de aplicación, institución, y la fecha que inicia y �naliza un proyecto. 3. Conteo de eventos de los investigadores, por área de conocimiento, institución, y la fecha en que inicia y �naliza el evento. 4. Saber el Nivel académico de los investigadores, por institución, y fecha de titula- ción. CAPÍTULO 4. MARCO APLICATIVO 67 Para poder desarrollar los indicadores y reportes referentes a los requerimientos contem- plados para la solución de inteligencia de negocio propuesta para un modelo de gestión de los proyectos de la Coordinación de Investigación, es necesario especi�car cómo se puede obtener lo deseado. Se realiza un análisis de los indicadores, especi�cando las fórmulas utilizadas para calcularlos. 4.3. Diseño de la Arquitectura Técnica El diseño de la arquitectura implementado para la solución de inteligencia de negocio se expone en la �gura 4.1. Figura 4.1: Arquitectura de Diseño La arquitectura implementada está conformada por cuatro (4) componentes y di- versos procesos y elementos que permiten llevar a cabo el �ujo de trabajo de la misma: 1. Se presentan las fuentes de datos que es la base de datos de la coordinación, que se considera para la solución de inteligencia de negocio. Estos datos pueden provenir de fuentes internas y/o externas, usualmente se emplean aquellos almacenados en los sistemas transaccionales y en archivos utilizados por la organización. 2. Es el proceso de extracción, transformación y carga que se ejecutará periódica- mente, se procede a almacenar los datos de las fuentes de datos en el almacén de datos. 3. La estructura del almacén de dato que permite llevar a cabo la obtención de los datos requeridos por el usuario con un alto rendimiento. 4. El ultimo componente se re�ere a la capa de presentación, es decir, a las herra- mientas de acceso a los datos que hacen uso del almacén de datos para permitir a los usuarios visualizar y analizar los distintos indicadores y reportes contemplados para la solución de inteligencia de negocio CAPÍTULO 4. MARCO APLICATIVO 68 4.4. Selección de Productos e Instalación El proceso de selección de una herramienta tecnológica puede llegar a ser complejo debido a las múltiples alternativas existentes en el mercado (Oracle BI, Pentaho BI, IBM Cognos, MicroStrategy, entre otros) y a la diversa gama de funcionalidades que cada herramienta brinda. Después de realizar un análisis de las distintas herramientas existentes en el mercado, se decidió utilizar para el desarrollo de la solución de inteligencia de negocio planteada para el modelo, la herramienta a utilizar para realizar la extracción , transformación y carga de los dato (ETL) es Data Integration (kettle), PostgreSQL para la construcción del almacén de datos y la herramienta de acceso y visualización de los datos Tableau como podemos ver en la �gura 4.2. Figura 4.2: Arquitectura de Diseño con sus herramientas Entre las razones por las que se utilizó Tableau para el desarrollo de la solución de inteligencia de negocio se enumeran a continuación: Usabilidad de la herramienta enfocada a los usuarios �nales e inexpertos. No es necesario tener conocimientos técnicos ni de programación como para poder usar la herramienta. La instalación y con�guración de la herramienta es sencilla y no requiere de co- nocimientos técnicos. Se cuenta con expertos en el área técnica dispuestos a dar asesoramiento y soporte. Existe una amplia documentación sobre tableau. CAPÍTULO 4. MARCO APLICATIVO 69 4.5. Modelo Dimensional El diseño del modelo dimensional se realizó basándose en los requerimientos de�- nidos, se de�nió en un modelo tipo estrella para los proyectos de investigación, éstos fueron analizados para determinar qué elementos podrían considerarse como hechos o dimensiones que pudieran formar parte de la solución de inteligencia de negocio. Para poder saber que hechos y dimensiones son necesarios para poder realizar la solución planteada, se desglosó uno a uno los requerimientos haciendo hincapié en de- terminar lo que se quería medir y bajo qué perspectivas se deseaba ver. Los hechos medibles que se tomaron en cuenta para la solución planteada son los elementos o indicadores que se quieren saber en la Coordinación de Investigación, éstos son: Conteo de proyectos. Conteo de productos. Conteo de Eventos. El Nivel Académico de los investigadores Así como se contemplaron los hechos, el análisis indico las diversas perspectivas con los cuales se desearía o se pudiera agrupar los datos. Indicó como se identi�caron las distintas dimensiones que se contemplan en la solución y se mencionan a continuación: Tiempo. Investigador. Área de Conocimiento. Área de Aplicación. Institución. Proyectos. Producto. Evento. Nivel Académico. Con los elementos expuestos anteriormente se construyo el modelo dimensional tipo estrella como se muestra en la �gura 4.3. CAPÍTULO 4. MARCO APLICATIVO 70 Figura 4.3: Modelo Dimensiona tipo estrella Una vez de�nidas las perspectivas a utilizar y los hechos a medir en la solución propuesta, se procedió a identi�car por cada dimensión los atributos y las jerarquías que se consideraron para poder cumplir con los objetivos planteados. Una vez establecida las dimensiones, puede establecerse las distintas jerarquías aso- ciadas a ella. Entendiendo que las jerarquías van a permitir navegar sobre los distintos niveles lógicos existentes. En la �gura 4.4 se observan las jerarquías establecidas para cada una de las dimensiones. Figura 4.4: Jerarquía de las dimensiones La jerarquía en cada dimensión se de�ne dependiendo de lógica del negocio. Una vez de�nidos los niveles jerárquicos para cada dimensión contemplada para la solución de inteligencia de negocio propuesta, se de�nen los atributos necesarios para cumplir con los requerimientos planteados. CAPÍTULO 4. MARCO APLICATIVO 71 A continuación se describen todas las dimensiones y la tabla de hecho contempladas para la solución de inteligencia de negocio para un modelo tipo estrella de los proyectos de investigación: Dimensión Tiempo. Permite ver los proyectos de investigación en función del momento en que se crea, termina un proyecto. Por esto, dicha dimensión tomara distintos roles como la fecha de inicio y fecha �n en el modelo dimensional. Una característica particular de la dimensión tiempo es que son generadas todas las fechas acorde a un período de tiempo en el proceso de ETL, para luego asociar las fechas especí�cas a las ocurrencias en las instancias. Esta forma de trabajo permite generar en los cuadros de mandos calendarios porque se poseen todas las fechas, para posteriormente solo obtener los proyectos a partir de un rango de fechas establecido. La tabla 4.2 muestra los atributos de la dimensión tiempo. Cuadro 4.2: Dimensión Tiempo Dimensión Investigador. Permite ver el investigador con sus atributos que lo de�nen como se muestra en la �gura 4.5. CAPÍTULO 4. MARCO APLICATIVO 72 Cuadro 4.3: Detalle de la Dimensión Investigador Dimensión Institución. Permite ver la institución con sus atributos que los de�nen como se muestra en la �gura 4.5. Cuadro 4.4: Dimensión de Institución CAPÍTULO 4. MARCO APLICATIVO 73 Dimensión de Área de Conocimiento. Permite ver el área de conocimiento con sus atributos que lo de�nen como se muestra en la �gura 4.5 . Cuadro 4.5: Dimensión de Área de Conocimiento Dimensión de Área de aplicación. Permite ver el área de aplicación con sus atributos que lo de�nen como se muestra en la �gura 4.5 . Figura 4.5: Dimensión de Área de aplicación Dimensión Proyecto. Permite ver el proyecto con sus atributos que lo de�nen como se muestra en la �gura 4.6 . Cuadro 4.6: Dimensión de Proyecto CAPÍTULO 4. MARCO APLICATIVO 74 Dimensión Producto. Permite ver el producto con sus atributos que lo de�nen como se muestra en la �gura 4.7 . Cuadro 4.7: Dimensión de Producto Dimensión Evento. Permite ver el evento con sus atributos que lo de�nen como se muestra en la �gura 4.8 . Cuadro 4.8: Dimensión de Evento Dimensión Nivel Académico. Permite ver el nivel de académico con sus atri- butos que lo de�nen como se muestra en la �gura 4.9 . CAPÍTULO 4. MARCO APLICATIVO 75 Cuadro 4.9: Dimensión Nivel Académico Tabla de Hecho investigación. El modelo dimensional tipo estrella busca la representación de los proyectos de investigación. Por tanto la medida en el modelo dimensional descrito anteriormente es la incidencia de un hecho (tabla de hechos sin hechos) es llamado FACTLESS y no medidas especí�cas. Por tanto la tabla de hechos, como se observa en la tabla 4.10 está conformada por un conjunto de claves foráneas que enlazan al hecho con las dimensiones, una clave que identi�ca unívocamente ese hecho y un atributo medida con valor por defecto 1, que ayuda a comprender que cada instancia tiene el mismo valor. Cuadro 4.10: Tabla de Hecho Gestión de los proyectos Ya con la de�nición del modelo dimensional tipo estrella, contempla la solución de inte- ligencia de negocio y con los hechos necesarios para cumplir con los objetivos trazados, CAPÍTULO 4. MARCO APLICATIVO 76 se realizó la elaboración del modelo dimensional de�nitivo que puede apreciarse. Figura 4.6: Modelo de�nitivo tipo estrella 4.6. Diseño físico Una vez que se de�nió la arquitectura, las herramientas y el modelo dimensional a utilizar en la solución de inteligencia de negocio se continuó con la realización del diseño físico. El almacén de datos se desarrolló físicamente usando PostgreSQL y basándose en el modelo dimensional realizado y descrito con anterioridad. En la primera instancia, usando PostgreSQL, se de�nieron cada una de las dimen- siones contempladas en el modelo dimensional, estableciendo inicialmente el nombre de la dimensión, luego sus atributos y por último sus niveles jerárquicos. Para crear la dimensión tiempo se utilizó Data Integration de Pentaho que permite generar está dimensión. En este caso se especi�có el nombre que se deseaba para dicha dimensión y los atributos a considerar (ano, mes y día) a partir del año 2000, de esta forma la herramienta se generó las fechas con su respectiva jerarquía como vemos en la �gura 4.7. CAPÍTULO 4. MARCO APLICATIVO 77 Figura 4.7: Dimensión Tiempo Una vez completado dicho diseño se realizó el despliegue del mismo usando Post- greSQL herramienta seleccionada, de esta forma se crearon todas tablas y elementos que componen el almacén de datos propuesto para la solución de inteligencia de negocio. Figura 4.8: Diseño lógico de las dimensiones CAPÍTULO 4. MARCO APLICATIVO 78 Cabe destacar que al crear las tablas para el almacén de datos, se agregaron una serie de campos o columnas necesarias para el correcto funcionamiento de las distintas aplicaciones. Estos campos adicionales no inter�eren de ninguna manera con el modelo dimensio- nal propuesto para la solución de inteligencia de negocio, tanto los requerimientos como los objetivos establecidos pueden cumplirse aún con las modi�caciones de las dimen- siones, que son los atributo que tienen por nombre (versión, fecha inicio, fecha_�n). Como vemos en �gura 4.9 Figura 4.9: ETL de la Dimension Investigador El resultado del despliegue del modelo dimensional realizado puede apreciarse en la �gura 4.10 CAPÍTULO 4. MARCO APLICATIVO 79 Figura 4.10: Modelo dimensional 4.7. Diseño y Construcción de procesos ETL Dado a la arquitectura propuesta se contempla (la base de datos, y el almacén de datos), fue necesario elaborar procesos ETL para las extraer los datos de la base de datos de la coordinación. Un proceso capaz de permitir el llenado del almacén de datos usando como fuente de datos la base de datos. Dichos procesos se muestra a continuación. 4.7.1. Diseño de Procesos de ETL y Desarrollo (almacén de datos) El diseño de los procesos de extracción, transformación y carga para el almacén de datos se realizó utilizando la herramienta Data Integration de Pentaho (kettle). El proceso de ETL para cada una de la dimensiones, es similar al mostrado en la �gura 4.11. Figura 4.11: ETL de Dimensión Investigador El proceso de construcción de los ETL, para el llenado de la única tabla de hecho llamada hechos investigación, conllevan a un conjunto de elementos adicionales que CAPÍTULO 4. MARCO APLICATIVO 80 serán descritos a continuación. Es requerido usar las dimensiones del almacén de datos, y extraer los hechos que se quieren analizar de la fuentes de datos, en nuestro caso la fuente es solo una base de datos. Figura 4.12: ETL de los Hechos del nivel académico a la Tabla de Hecho de investigación Como vemos en la �gura 4.12, a partir del uso de la tabla relacional BD_TABLA _USUARIO_ESTUDIO, se van realizando una serie de uniones para asociar el con- junto de dimensiones. Esto porque una instancia de la tabla BD_TABLA_USUARIO _ESTUDIO, representa el nivel de granularidad asociado al modelo dimensional tipo estrella, lo que implica que se requiere ir agregando las claves asociadas a las dimensiones que caracterizan esa acción correctiva en particular. Una vez realizado todas las transformaciones o ETL, se creara el �ujo del proceso es decir el job que ejecutara todos los procesos según el �ujo se crea como vemos en la �gura 4.13 CAPÍTULO 4. MARCO APLICATIVO 81 Figura 4.13: El llenado del almacén de datos 4.7.2. Veri�car la calidad de los datos Una vez se ha realizado la inserción de los datos en el almacén de datos, es necesario comprobar que la carga ha sido correcta y que el almacén de datos representa de forma acertada los datos del modelo dimensional, para esto se realiza la veri�cación consistente en la aplicación de un conjunto de consultas en ambos ambientes y que estén cargados de forma adecuados los datos del modelo relacional de la base de datos fuente. Se muestra la comparación de cada elemento del modelo dimensional que se encuentre relacionado con la base de datos. Dimensión investigador. Se extraer los datos del usuario que solo tienen el roll investigador, se muestra en la �gura 4.14 los primeros 19 registros de ambas tablas y la consulta de la cantidad de valores existentes en cada una de las tablas como vemos en la �gura4.15. Figura 4.14: Veri�cación de la dimensión investigador CAPÍTULO 4. MARCO APLICATIVO 82 Figura 4.15: Veri�cación de la cantidad de los datos de la dimensión investigador Dimensión área de conocimiento. Esta compuesta por tres tablas en la base de datos, que es la tabla disciplina, subárea de conocimiento y área de conocimiento. Donde podemos ver las primeras nueve �las de ambas tablas y la cantidad de valores existentes en cada una de las tablas. Figura 4.16: Veri�cación de la dimensión área de conocimiento Figura 4.17: Veri�cación de la cantidad de datos de la dimensión área de conocimiento Dimensión área de aplicación. Dicha dimensión esta compuesta de dos tablas de las base de datos, que es la tabla de subárea de aplicación, y área de aplicación. CAPÍTULO 4. MARCO APLICATIVO 83 Figura 4.18: Veri�cación de la dimensión área de aplicación Figura 4.19: Veri�cación de la cantidad de datos de área de aplicación Dimensión institución. Esta compuesta de tres tabla a partir de la dependencia, facultad, y institución. Figura 4.20: Veri�cación de la dimensión institución CAPÍTULO 4. MARCO APLICATIVO 84 Figura 4.21: Veri�cación de la cantidad de datos de la dimensión institución Dimensión proyecto. La validación de los datos se ha realizado observando la tabla de proyecto. Figura 4.22: Veri�cación de la dimensión proyecto Figura 4.23: Veri�cación de la cantidad de datos de la dimensión proyecto Dimensión producto. La validación de los datos se ha realizado observando los productos y su tipo. CAPÍTULO 4. MARCO APLICATIVO 85 Figura 4.24: Veri�cación de la dimensión producto Figura 4.25: Veri�cación de la cantidad de datos de la dimensión producto Dimensión evento. La validación de datos se ha realizado observando los eventos en función de su nombre y tipo de evento. Figura 4.26: Veri�cación de la dimensión evento CAPÍTULO 4. MARCO APLICATIVO 86 Figura 4.27: Veri�cación de la cantidad de datos de la dimensión evento Dimensión nivel académico. La validación de los datos se ha realizado obser- vando la tabla de grado académico, y nivel académico Figura 4.28: Veri�cación de la cantidad de datos de la dimensión nivel académico Figura 4.29: Veri�cación de la cantidad de datos de la dimensión nivel académico Dimensión tiempo. La dimensión no requiere una veri�cación de datos con respecto a la base de datos, sin embargo puede con�rmarse que los datos son consistentes en función de una fecha. CAPÍTULO 4. MARCO APLICATIVO 87 Figura 4.30: Veri�cación de datos de la dimensión tiempo 4.7.3. Veri�cación de la calidad de los datos de los componentes del modelo implementado Adicionalmente a la veri�cación de los datos por tabla, se ha realizado una veri- �cación para comprobar que efectivamente los datos del modelo relacional han sido transformados y cargados en el modelo dimensional tipo estrella, ya que existe una única tabla de hechos. Para esto hay que comprender que la realización del modelo de estrella, la tabla de hecho y dimensiones, generan nueva clave primaria llamada clave subrogada para el registro de cualquier elemento. Por lo que, la inserción de dicho elemento en la tabla de hechos conlleva a que se haga una relación a partir de estas claves generadas en el proceso ETL. La veri�cación del modelo estrella implica comprobar que las distintas claves subrogadas en la tabla de hecho, corresponden efectivamente a los datos que se quiere enlazar en las distintas dimensiones. Se realiza del modo que la tabla de hecho se relaciona con una dimensión, y está se encuentra relacionada con ella en la base de datos. 4.7.3.1. Veri�cación de la tabla de hecho investigación con sus dimensiones Como es un modelo dimensional tipo estrella, todas las dimensiones se relacionan con la tabla de hechos. Así que se realiza la veri�cación de esas tablas con la tabla de hecho investigación. Dimensión tiempo. Para la comprobación de que efectivamente se están repre- sentando los datos del modelo relacional con respecto a la dimensión tiempo. Se muestra un registro de la tabla de proyecto de la base de datos de la fecha de inicio y de �n del proyecto y la tabla de hecho producto con eso mismo valor CAPÍTULO 4. MARCO APLICATIVO 88 asociado una clave subrogada de la dimensión tiempo. Figura 4.31: Comparación de los dato del modelo con la dimensión tiempo Dimensión proyecto. Para la comprobación de dicha dimensión se realiza dado unos registros como en la �gura 4.33, sus valores en la dimensión y su veracidad como en la �gura 4.32 en la base de datos. Figura 4.32: Proyecto en la base de datos CAPÍTULO 4. MARCO APLICATIVO 89 Figura 4.33: Dimensión proyecto con la tabla de hecho investigación Dimensión área de conocimiento. Para la comprobación de dicha dimensión se realiza unos registros como en la �gura 4.34, sus valores en la dimensión y su veracidad como en la �gura 4.35 en la base de datos. Figura 4.34: Dimensión área de conocimiento con la tabla de hecho investigación Figura 4.35: Área de conocimiento en el almacén de datos CAPÍTULO 4. MARCO APLICATIVO 90 Dimensión área de aplicación. Para la comprobación de dicha dimensión se realiza unos registros como en la �gura 4.37, sus valores en la dimensión y su veracidad como en la �gura 4.36 en la base de datos. Figura 4.36: Subárea de aplicación en la base de datos Figura 4.37: Dimensión área de aplicación con la tabla de hecho investigación Dimensión institución. Para la comprobación de dicha dimensión se realiza unos registros como en la �gura 4.39 , sus valores en la dimensión y su veracidad como en la �gura 4.38 en la base de datos. CAPÍTULO 4. MARCO APLICATIVO 91 Figura 4.38: Dependencia en la base de datos Figura 4.39: Dimensión institución con la tabla de hecho investigación Dimensión investigador. Para la comprobación de dicha dimensión se realiza dado unos registros como en la �gura 4.41, sus valores en la dimensión y su veracidad como en la �gura 4.40 en la base de datos. Figura 4.40: Usuario en la base de datos CAPÍTULO 4. MARCO APLICATIVO 92 Figura 4.41: Dimensión investigador con la tabla de hecho investigador 4.7.3.2. Detallar los requerimientos según el modelo Desde el estudio del modelo dimensional, que plasma los datos relevantes de la base de datos, especí�camente los proyectos, productos, eventos, y el nivel académico, y utilizando los grá�cos que se estaban generando en la base de datos para buscar satisfacer las necesidades analíticas, se han propuesto un conjunto de requerimientos analíticos presentados a continuación: 1. Indicadores a) Conteo de proyectos por investigador. b) Conteo de proyectos por área de conocimiento. c) Conteo de proyectos por área de aplicación. d) Conteo de proyectos por institución. e) Conteo de producto por investigador. f ) Conteo de producto por área de conocimiento. g) Conteo de producto por área de aplicación. h) Conteo de producto por institución. i) Conteo de evento por investigador. 2. Reportes a) Los proyectos del investigador. b) Los proyectos por área de conocimiento. c) Los proyectos de la institución. d) Los productos del investigador e) Los productos del área de aplicación f ) Los eventos de los investigadores g) Nivel académico del investigador. CAPÍTULO 4. MARCO APLICATIVO 93 4.8. Desarrollo de los requerimientos de información Esta fase consiste en la creación de los indicadores de gestión usando la herra- mienta de inteligencia de negocio (Tableau), de forma tal que puedan satisfacerse los requerimientos analíticos planteados previamente. Para esto se debe con�gurar desde la herramienta a utilizar la conexión a la base de datos en este caso es la conexión a PostgreSQL, realizar las consultas que satisfacen los requerimientos analíticos para luego de forma sencilla poder visualizar los distintos indicadores dispuesto de una forma ordenada. Por último se realiza una veri�cación de los datos para con�rmar la exactitud de los indicadores. 4.8.1. Con�guración de la conexión Implica integrar la implementación del modelo dimensional ubicado en el almacén de datos PostgraSQL en Tableau, de forma que se puedan manipular los datos dentro de la herramienta de inteligencia de negocio. Figura 4.42: Creación de la conexión con la fuentes de dato desde Tableau Tableau enlaza las distintas tablas a partir de atributos clave, un atributo clave es aquel que su nombre que se repite en dos tablas, Tableau realiza una unión entre dichas tablas por lo que se puede navegar entre los atributos de dichas tablas. CAPÍTULO 4. MARCO APLICATIVO 94 Figura 4.43: La tabla de hecho investigación con sus dimensiones A continuación se detallara los elementos que conforman la fuente de datos. Figura 4.44: Elemento de almacén de datos 4.8.2. Generador de los indicadores de gestión Disponibles los datos en la herramienta de inteligencia de negocio se procede a desarrollar los indicadores de gestión son indicadores e�ciente, es decir miden los resul- tados en �n que se cumplan con la propuesta de los requerimientos analíticos señalados CAPÍTULO 4. MARCO APLICATIVO 95 previamente. Y mostrar los reportes que fueron solicitados La construcción de los indicadores de gestión implico la evaluación de las distintas formas como pueden observarse los mismos y la forma de distribuir los indicadores de gestión dentro de la fuente de datos de forma que se tuviera una lógica al ser observado. 4.8.3. Desarrollo y distribución de consultas Para la realización de las consultas, se ha optado por seleccionar la tabla de hecho investigación con sus dimensiones asociadas, para luego observar las dimensiones con sus hechos. Una de las ventajas que ofrece Tableau es que permite las agrupaciones de las dimensiones a las tabla de hecho siempre que esta tenga una relación con esas tablas. Se muestran a continuación. 4.8.3.1. Tabla de hecho de investigación Se presentan todas las tablas con que se relaciona la tabla de hecho investigación, que se desea analizar para responder los indicadores y mostrar los reportes nombrado anteriormente. 1. Indicadores a) Proyectos por investigador. Se puede observar desde la fuente de datos la �gura 4.44, permite seleccionar la unión que se desea tener. lo que se quiere analizar y observar. Figura 4.45: Conteo de proyectos del investigador b) Proyectos por área de conocimiento. Se provee las área de conocimiento para la clasi�cación de los proyectos según las áreas. CAPÍTULO 4. MARCO APLICATIVO 96 Figura 4.46: Conteo de proyectos por área de conocimiento Figura 4.47: Grá�ca de conteo de proyectos del investigador c) Proyectos por área de aplicación. Provee las áreas de aplicación para saber las distintas áreas que siguen los proyectos. CAPÍTULO 4. MARCO APLICATIVO 97 Figura 4.48: Conteo de proyectos por área de aplicación Figura 4.49: Grá�ca de conteo de proyectos por área de aplicación d) Proyectos por área de institución. Provee las instituciones a la que un proyecto puede pertenecer. CAPÍTULO 4. MARCO APLICATIVO 98 Figura 4.50: Conteo de proyectos por institución Figura 4.51: Grá�ca de conteo de proyectos por institución e) Producto por investigador. Se puede observar desde la fuente de datos la �gura 4.44, permite seleccionar la unión que se desea tener. lo que se quiere analizar y observar. CAPÍTULO 4. MARCO APLICATIVO 99 Figura 4.53: Cantidad de productos por institución Figura 4.52: Conteo de producto del investigador f ) Producto por área de institución. Provee las instituciones a la que un producto puede pertenecer. g) Producto por área de conocimiento. Se provee las área de conocimiento para la clasi�cación de los productos según las áreas. CAPÍTULO 4. MARCO APLICATIVO 100 Figura 4.54: Conteo de productos por área de conocimiento Figura 4.55: Grá�ca de conteo de productos por área de conocimiento h) Producto por área de aplicación. Provee las área de aplicación para saber las distintas áreas que siguen los productos. CAPÍTULO 4. MARCO APLICATIVO 101 Figura 4.56: Conteo de productos por área de aplicación Figura 4.57: Grá�ca de conteo de productos por área de aplicación i) Eventos por investigador. Se puede observar los eventos de los investiga- dores y el conteo de los eventos. CAPÍTULO 4. MARCO APLICATIVO 102 Figura 4.58: Conteo de eventos por investigador 2. Reportes a) Proyectos por investigador. Se puede observar en la �gura 4.59, los pro- yectos del investigador Figura 4.59: Los proyectos del investigador b) Proyectos por área de conocimiento. Se puede observar los proyectos que hay por área de conocimiento. CAPÍTULO 4. MARCO APLICATIVO 103 Figura 4.60: Los proyectos del área de conocimiento c) Proyectos de la institución. Se puede observar los proyectos de las insti- tuciones. Figura 4.61: Los proyectos de las instituciones d) Productos del investigador. Se puede observar los proyectos del investi- gador. CAPÍTULO 4. MARCO APLICATIVO 104 Figura 4.62: Los productos del investigador e) Productos del área de aplicación. Se puede observar los proyectos del área de aplicación. Figura 4.63: Los productos del área de aplicación f ) Evento de los investigadores. Se puede observar los eventos de los investiga- dores CAPÍTULO 4. MARCO APLICATIVO 105 Figura 4.64: Evento de los investigador g) Nivel académico por investigador. Se puede observar desde la fuente de datos la �gura 4.44, permite seleccionar la unión que se desea tener. lo que se quiere analizar y observar. Figura 4.65: El nivel académico de los investigador 4.8.4. Veri�car la calidad de los datos en la herramienta de manipulación y visualización de datos Una vez generado la visualización de los datos, se realiza la veri�cación de los datos. En este caso fueron analizadas las distintas dimensiones lo cual implica la realización de consultas sobre la base de datos relacional ajustando los indicadores de gestión a partir de los �ltros planteados las fuentes de datos para comprobar su igualdad. Cantidad de proyecto. Como en la �gura 4.66, la consulta al sistema de la base de datos muestra el mismo resultado que en la consulta en Tableau. CAPÍTULO 4. MARCO APLICATIVO 106 Figura 4.66: Veri�cación de la tabla de hecho investigación con base de datos Figura 4.67: Veri�cación de la tabla de hecho investigación con base de datos Cantidad de producto. Como en la �gura 4.67, la consulta al sistema de la base de datos muestra el mismo resultado que en la consulta en Tableau. Cantidad de eventos. Como en la �gura 4.68, la consulta al sistema de la base de datos muestra el mismo resultado que en la consulta en Tableau. Nivel Académico de los investigadores. Como se observa en la �gura 4.69, la consulta al sistema de la base de dato muestra el mismo resultado que la consulta en Tableau. CAPÍTULO 4. MARCO APLICATIVO 107 Figura 4.68: Veri�cación de la tabla de hecho investigación con base de datos Figura 4.69: Veri�cación de la tabla de hecho de nivel académico con base de datos CAPÍTULO 4. MARCO APLICATIVO 108 4.9. Implementación Debido a que el trabajo presentado forma parte de una solución de inteligencia de negocio para un trabajo especial de grado, su implementación dentro de la coordinación no trabajo con datos reales, por tanto las pruebas de aceptación no fue realizada. Esto genera que dicha fase de desarrollo de la solución no sea ejecutada de forma total. Con estas herramientas, tal y como se explicó en el capítulo anterior, se integró la capa física con el modelo del negocio, y éste a su vez con la capa de presentación que es la que se exhibe a los usuarios. 4.9.1. Ajuste de las consultas Para el ajuste de consultas se realizaron pruebas de visualización de los indicadores para comprobar la vialidad en la forma como se estaban desplegando los indicadores de gestión. De estas reuniones con el tutor se plateo los indicadores y reportes, para así diseñar el modelo dimensional. Conclusiones y recomendaciones Los fundamentos teóricos aprendidos en la carrera y los estudios realizados para el desarrollo del seminario y la tesis fueron importantes para el cumplimiento de los objetivos planteados, dado a que de esta forma, se obtuvieron las bases sobre los co- nocimientos y experiencia necesarios para el desarrollo de la solución de inteligencia de negocio. Este desarrolló es un prototipo de una solución de inteligencia de negocio para la Coordinación de Investigación, ya que no se logro trabajar con los datos reales. En la construcción de la solución de negocio se desarrolló un modelo dimensional que permite observar los proyectos, productos, eventos, y nivel académico a partir de distintas perspectivas. La utilización de la metodología propuesta por Ralph Kimball para el desarrollo de soluciones de inteligencia de negocio facilitó el cumplimiento de los objetivos planteados. Se logró desarrollar una solución adaptada a las necesidades y requerimientos de la Coordinación de Investigación. Sin embargo, debido a que el trabajo de investigación se efectuó en un ambiente de pruebas y no en un ambiente de producción, algunas tareas se realizaron parcialmente. La �exibilidad a la hora de realizar informes o visualizar indicadores usando grá�- cos permite el análisis de datos de forma e�ciente. La realización de nuevas consultas y grá�cos a partir de necesidades presentadas pueden ser atendidas rápidamente. La facilidad de uso se traduce en que el sistema es capaz de resolver necesidades analíticas sin necesidad de que el usuario �nal recurra a programadores que tengan que generar un nuevo elemento para la obtención de información. Como recomendaciones generales tenemos: Se plantea realizar un proceso de adiestramiento a los usuarios en el uso de las herramientas. Ajustar las consultas en función a necesidades adicionales de los usuarios e im- plementar efectivamente la solución en la organización. Se plantea establecer la conexión con la base de datos real para la implementación de los indicadores y que sea de gran utilidad para la toma de decisiones. Hacer uso extensivo de la herramienta Tableau, ya que es una herramienta de fácil manejo por el usuario, y entrenar a los usuarios en su uso para que puedan generar mucha más información que la mostrada en este proyecto. 109 Bibliografía [Andrade, 2005] Andrade, S. (2005). Diccionario de Economía (3era ed.). Andrade. [CoorInv, 2011] Coordinación de Investigación. (2011). ¿Quiénes So- mos?. Caracas, Venezuela: Facultad de Ciencias de la Universidad Central de Venezuela. Recuperado en julio 2016 de: http://www.coordinv.ciens.ucv.ve/ investigacion/quienes.php [Pérez, 2016] Pérez V. (2016). GENCI�2 Sistema de Gestión de In- formación Cientí�ca para la Coordinación de Investi- gación de la Facultad de Ciencias de la UCV . Cara- cas, Facultad de Ciencias de la Universidad Central de Venezuela (UCV). [Borges, 2006] Borges C. & Rivero A. (2006). Generador de Sitios Web de Centros de Investigación. Centro de Ingeniería de Software y Sistemas, Facultad de Ciencias, Univer- sidad Central de Venezuela, Caracas, Venezuela. Re- cuperado en julio 2015, de: http://www.coordinv. ciens.ucv.ve/investigacion/genci/index.php [Prior, 2007] Prior V. (2007). Glossary of Terms used in Competitive Intelligence and Knowledge Management. Knowledge- Board. [Thomas, 2005] Thomas M. & Carolyn E. (2005). �Sistemas de bases de datos�. Pearson Education. [Michael, 2007] Michael, V. (2007). Administración de bases de da- tos Diseño y desarrollo de aplicaciones. México: McGRAW-HILL/INTERAMERICANA EDITORES, S.A. DE C.V. [Date, 2001] Date, C. (2001). Introducción a los sistemas de Base de datos. México: Pearson Educación 110 http://www.coordinv.ciens.ucv.ve/investigacion/quienes.php http://www.coordinv.ciens.ucv.ve/investigacion/quienes.php http://www.coordinv.ciens.ucv.ve/investigacion/genci/index.php http://www.coordinv.ciens.ucv.ve/investigacion/genci/index.php BIBLIOGRAFÍA 111 [Ramaskrishnan, 1999] Ramakrishnan, R. & Gehrke, J. (1999). Database Ma- nagement Systems. US: McGRAW-HILL Higher Edu- cation [CCM, 2016] CCM. (2016). Administración de bases de datos (DBMS). Recuperado en Julio 2016 de: http://es.ccm.net/contents/ 66-introduccion-bases-de-datos [Peña, 2006] Peña A. (2006). inteligencia de negocio: Una Propues- ta para su Desarrollo en las organizaciones. Primera Edición. Instituto Politécnico Nacional. México: INS- TITUTO POLITÉCNICO NACIONAL [Cano, 2007] Cano, J. (2007). Business Intelligence: competir con información. Madrid: Fundación Cultural Banesto . [1] Planeaux, D., & Alvin, D. (2007). Oracle Business Intelligence Standard Edition One. California: Oracle Parkway. [sinnexus, 2016] Sinnexus. (2016). Data Warehouse. Recuperado en Julio 2016 de: http://www.sinnexus.com/business_ intelligence/datamart.aspx [DWH, 2010] Buigues, A. (2010). Arquitectura de un Da- ta Warehouse. Recuperado en Julio 2016 de: http://anabuigues.com/2010/03/05/ arquitectura-de-un-data-warehouse/ [DWH, 2015] Pacheco, O. (2015). Características de un Data Warehouse. Recuperado en Julio 2016 de: http://dwhucv.blogspot.com/p/ caracteristicas-de-un-datawarehouse.html [Inmon, 2002] Inmon, W. (2002). Building the Data Warehouse. Ca- nada: Technical Publishing Group. [Inteligencia de Negocios, 2017] Inteligencia de Negocios. (2017). Inteligencia de Nego- cios. Recuperado en Enero de 2017, de: http://www. idensa.com/ [Kimball, 2010] Espinosa, R. (2010). 15.2. Kimball vs In- mon. Ampliación de conceptos del Modelado Dimensional. Recuperado en Julio 2016 de: https://churriwifi.wordpress.com/2010/04/19/ 15-2-ampliacion-conceptos-del-modelado-dimensional http://es.ccm.net/contents/66-introduccion-bases-de-datos http://es.ccm.net/contents/66-introduccion-bases-de-datos http://www.sinnexus.com/business_intelligence/datamart.aspx http://www.sinnexus.com/business_intelligence/datamart.aspx http://anabuigues.com/2010/03/05/arquitectura-de-un-data-warehouse/ http://anabuigues.com/2010/03/05/arquitectura-de-un-data-warehouse/ http://dwhucv.blogspot.com/p/caracteristicas-de-un-datawarehouse.html http://dwhucv.blogspot.com/p/caracteristicas-de-un-datawarehouse.html http://www.idensa.com/ http://www.idensa.com/ https://churriwifi.wordpress.com/2010/04/19/15-2-ampliacion-conceptos-del-modelado-dimensional https://churriwifi.wordpress.com/2010/04/19/15-2-ampliacion-conceptos-del-modelado-dimensional BIBLIOGRAFÍA 112 [Eckerson, 2012] Eckerson, W. (2012). For Payés to Build a Data Wa- rehouse. Recuperado en Julio 2016 de:http://www. bi-bestpractices.com/view-articles/4770 [Kimball, 2002] Kimball R. & Ross M. (2002). The Data Warehouse Toolkit. Canada: Wiley Computer Publishing. [Kimball, 1998] Kimball R. (1998). The Data Warehouse Life Cycle Toolkit. Canada: Wiley Computer Publishing. [Bernabeu, 2009] Bernabeu, R..(2009).Datawarehouse manager. Recu- perado en Julio 2016 de: http://www.dataprix.com/ datawarehouse-manager#x1-520003.4.5.3 [PosrgreSQL, 1996] The PostgreSQL Global Development Group. (1996- 2015). PostgreSQL. Recuperado en julio 2015, de: http://www.postgresql.org/about/ [2nsPostgreSQL, 2001] 2ndQuadrant Ltd. (2001-2015). 2ndQuadrant Profes- sional PostgreSQL. Recuperado en julio 2015, de: http://2ndquadrant.com/es/postgresql/ [Rouda, 2014] Rouda, N. & Anlyst, S. (2014). Getting Real About Big Data : Build Versus Buy. Re- cuperado en Julio 2016 de: http://www. oracle.com/us/corporate/analystreports/ esg-getting-real-bigdata-2228170.pdf [Tableau, 2016] © 2003-2016 Tableau Software. Todos los derechos re- servados. Recuperado en Octubre de: http://www. tableau.com/es-es/about/leadership#aselipsky [TableauPDF, 2016] Kamkolkar, N. & Fields, E. & Rueter, M.(2016). Ta- bleau para la empresa: descripción general de TI. ta- bleau software. [Pentaho, 2016] bligoo. (2016). Pentaho Open BI. Recuperado en Noviembre de:http://cognus2.bligoo.cl/content/ view/1020771/Pentaho-Open-BI.html [OracleBI,2016] GoLive. (2016). Oracle Business Intelligence. Recupe- rado en Noviembre de:http://onegolive.com/es/ portfolio-golive-soluciones-consultoriaerp-crm-bi/ oracle-bi http://www.bi-bestpractices.com/view-articles/4770 http://www.bi-bestpractices.com/view-articles/4770 http://www.dataprix.com/datawarehouse-manager#x1-520003.4.5.3 http://www.dataprix.com/datawarehouse-manager#x1-520003.4.5.3 http://www.oracle.com/us/corporate/analystreports/esg-getting-real-bigdata-2228170.pdf http://www.oracle.com/us/corporate/analystreports/esg-getting-real-bigdata-2228170.pdf http://www.oracle.com/us/corporate/analystreports/esg-getting-real-bigdata-2228170.pdf http://www.tableau.com/es-es/about/leadership#aselipsky http://www.tableau.com/es-es/about/leadership#aselipsky http://cognus2.bligoo.cl/content/view/1020771/Pentaho-Open-BI.html http://cognus2.bligoo.cl/content/view/1020771/Pentaho-Open-BI.html http://onegolive.com/es/portfolio-golive-soluciones-consultoriaerp-crm-bi/oracle-bi http://onegolive.com/es/portfolio-golive-soluciones-consultoriaerp-crm-bi/oracle-bi http://onegolive.com/es/portfolio-golive-soluciones-consultoriaerp-crm-bi/oracle-bi BIBLIOGRAFÍA 113 [Gartner, 2014] Gartnet Magic Quadrant. Recuperado en Noviembre de 2016 de: http://www.gartner.com/technology/ research/methodologies/research_mq.jsp. [Indicador,2014] ALTAG. (2014). 85% de las empresas no anali- za correctamente los recursos. Recuperado en Mar- zo de 2017 de: http://www.altag.net/wp-content/ uploads/2014/03/indicadores1.jpg [Planeaux, 2007] Planeaux, D. & Alvin, D. (2007). Oracle Business Intelligence Standard Edition One. California: Oracle Parkway. http://www.gartner.com/technology/research/methodologies/research_mq.jsp. http://www.gartner.com/technology/research/methodologies/research_mq.jsp. http://www.altag.net/wp-content/uploads/2014/03/indicadores1.jpg http://www.altag.net/wp-content/uploads/2014/03/indicadores1.jpg Problema de Investigación Situación Actual Planteamiento del Problema Solución Propuesta Objetivo General Objetivo Específicos Justificación Alcance Marco Conceptual Facultad de Ciencias Estructura Organizativa Coordinación de Investigación Indicadores Criterios de los Indicadores Objetivo de un indicador Características Tipología de Indicadores Inteligencia de Negocio (Business Intelligence) Inteligencia Negocio Definición de Inteligencia de Negocio Características Niveles de Soluciones de Inteligencia de Negocio Arquitectura de una Solución de Inteligencia de Negocio Fuentes de Datos Procesos de Extracción, Transformación y Carga (ETL) Almacén de Datos (Data Warehouse) Definición Características Arquitectura Metadata Requerimientos de un DWH Bodega de Datos (Data Mart) Estrategias de Construcción Modelo Dimensional del DWH Definición Tabla de Dimensión Tabla de Hechos Esquema Estrella (Star Scheme) Esquema Copo de Nieve (Snowflake Scheme) Esquema Constelación (Starflake Scheme) Granularidad Jerarquía Agregación Herramientas Tecnológicas Herramientas de Análisis y visualización Reportes Indicadores Herramienta de Extracción, Transformación y Carga (ETL) Pentaho Pentaho Data Integration Herramienta para crear la bodega de datos (Datamart) PostgreSQL Herramientas de Visualización Tableau Marco Metodológico Metodología Descendente (TOP-DOWN) Metodología de Bill Inmon Parte 1: Desarrollo de Sistemas Operacionales Parte 2: Desarrollo del almacén de datos Parte 3: Uso del Almacén de Datos Plan de Migración (Migration Path) Metodología Ascendente (BOTTOM-UP) Metodología de Ralph Kimball Planificación del Proyecto Definición de los Requerimientos del Negocio Diseño de la Arquitectura Selección de productos e instalación Diseño de Datos o modelado dimensional Especificación y desarrollo de aplicaciones analíticas Implementación Despliegue y Crecimiento Metodología a seguir Marco Aplicativo Planificación del Proyecto Definición de los Requerimientos Diseño de la Arquitectura Técnica Selección de Productos e Instalación Modelo Dimensional Diseño físico Diseño y Construcción de procesos ETL Diseño de Procesos de ETL y Desarrollo (almacén de datos) Verificar la calidad de los datos Verificación de la calidad de los datos de los componentes del modelo implementado Verificación de la tabla de hecho investigación con sus dimensiones Detallar los requerimientos según el modelo Desarrollo de los requerimientos de información Configuración de la conexión Generador de los indicadores de gestión Desarrollo y distribución de consultas Tabla de hecho de investigación Verificar la calidad de los datos en la herramienta de manipulación y visualización de datos Implementación Ajuste de las consultasSolución de Inteligencia de Negocios por medio de NoSQL UNIVERSIDAD CENTRAL DE VENEZUELA FACULTAD DE CIENCIAS ESCUELA DE COMPUTACIÓN CENTRO DE INVESTIGACIÓN DE SISTEMAS DE INFORMACIÓN CISI Trabajo Especial de Grado presentado ante la ilustre Universidad Central de Venezuela por Br. Mayra, Perez Tutores: Prof. Mercy Ospina Caracas, Mayo 2017. SOLUCIÓN DE INTELIGENCIA DE NEGOCIOS PARA EL SEGUIMIENTO DE PROYECTOS DE INVESTIGACIÓN DE LA FACULTAD DE CIENCIAS, UCV Prof. Cor)(21 tr)G-1) r Vces4k (Jurado) UNIVERSIDAD CENTRAL DE VENEZUELA FACULTAD DE CIENCIAS ESCUELA DE COMPUTACIÓN ACTA Quienes suscriben, miembros del jurado designado por el Consejo de la Escuela de Computación, para examinar el Trabajo Especial de Grado titulado "SOLUCIÓN DE INTELIGENCIA DE NEGOCIOS PARA EL SEGUIMIENTO DE PROYECTOS DE INVESTIGACIÓN DE LA FACULTAD DE CIENCIAS, UCV" y presentado por el bachiller: Br Mayra Perez, a los fines de optar al título de Licenciado en Computación, dejamos constancia de lo siguiente: Leído como fue dicho trabajo, por cada uno de los miembros del jurado, se fijó el día 22 de Mayo del 2017 a las 9 a.m horas, para que la autora lo defendiera en forma pública, lo que estos hicieron en la Sala Aula 1 de la Escuela de Computación, mediante una presentación oral de su contenido, luego de lo cual respondieron a las preguntas formuladas. Finalizada la defensa pública del Trabajo Especial de Grado, el jurado decidió aprobar con la nota de puntos. En fe de lo cual se levanta la presente Acta, en Caracas el día 22 de O del apn- Prof. Mercy Ospina (Tutora) AGRADECIMIENTOS Quiero comenzar agradeciendo a Dios, esa fuerza toda poderosa que siempre me indica el camino correcto a seguir cuando me encuentro desorientada. Quiero agradecerle por cada persona que ha puesto en mi vida durante todos estos años de carrera, ya que todas me han ayudado y enseñado muchas cosas. Quiero agradecer a mis madres, por su amor, por su apoyo, por la educación y los principios que me han dado, porque me han hecho ser la persona que soy ahora, una persona buena, correcta y que da lo mejor de sí. A mi hermana Maye y Jenni les agradezco por apoyarme a seguir adelante, a pesar de los obstáculos, y mi hermanita Paola que es mi tesoro y mi fuerza a ser cada día mejor. Quiero agradecer enormemente a mi querido amigo German, por haberme ayudado y ser un ejemplo a seguir en mi carrera. Gracias por haber confiado en mí y darme la oportunidad de aprender tantas cosas de usted. Quiero agradecer a mis también profesora Mercy y al profesor Franky, quienes me han dado su cariño y confianza. Les agradezco por todo el tiempo que me han dedicado cada vez que he necesito de su ayuda y por todas las palabras de motivación que me han hecho seguir adelante. Quiero agradecer a mi novio Daniel, tantos años de amistad, amor, de cariño, confianza y tolerancia hacia mi difícil carácter. Gracias por siempre ayudarme, gracias por siempre motivarme, por estar cuando te necesito, gracias por ser quien eres, gracias por estar en mi vida, gracias mi amor. Quiero agradecer a mi buen amigo Victor, que desde que apareció en mi vida siempre ha confiado en mí, me ha ayudado de manera excepcional y me ha dado su apoyo en todo momento. Finalmente quiero agradecer a todas aquellas personas que me dijeron “Sí puedes”, cuando yo sólo me repetía “No puedo, es imposible”. Gracias Sra. Omarira, gracias Leo, gracias Jhonatan, gracias Mafer, gracias Dorjes, gracias a todos. UNIVERSIDAD CENTRAL DE VENEZUELA FACULTAD DE CIENCIAS ESCUELA DE COMPUTACIÓN CISI SOLUCIÓN DE INTELIGENCIA DE NEGOCIOS PARA EL SEGUIMIENTO DE PROYECTOS DE INVESTIGACIÓN DE LA FACULTAD DE CIENCIAS, UCV Autor: Br. Mayra, Perez Tutor: Prof. Mercy Ospina Fecha: Mayo 2017 RESUMEN: El presente Trabajo Especial de Grado describe una solución de Inteligencia de Negocio para la Coordinación de Investigación de la Facultad de Ciencias de la UCV, que permite obtener de sus sistemas, la información adecuada para el apoyo en la toma decisiones en los procesos relacionados con los proyectos de investigación de los profesores y profesionales de la Facultad. La Coordinación de Investigación cuenta con una base de datos para almacenar y procesar los datos, pero no tiene mecanismos efectivos para la interpretación, análisis y visualización adecuados para la información almacenada en ella. Conociendo las necesidades existentes, en el presente Trabajo de Grado, se plantea el desarrollo de una solución adecuada de Inteligencia de Negocio, que permite establecer una serie de indicadores de gestión, para apoyar en la toma de decisiones gerenciales a la Coordinación de Investigación, generando información confiable que permita interpretar los datos almacenados. La solución de Inteligencia de Negocio fue creada en su mayor parte con tecnología de software libre (PostgreSQL y Pentaho Data Integration o Kettle), junto con Tableau que es un software propietario. El desarrollo se hizo bajo una adaptación de la metodología ascendente (Bottom-Up) de Ralph Kimball. El presente trabajo es un prototipo debido a que la base de datos no se encuentra datos reales. Sin embargo, es completamente funcional y está listo para cuando se tengan los datos. Adicionalmente puede ser ampliado cuando sea necesario. Palabras Claves: Investigación, Inteligencia de Negocios, PostgreSQL, Kettle, Tableau Desktop. ESTUDIO DE UNA SOLUCIÓN DE INTELIGENCIA DE NEGOCIOS PARA EL SEGUIMIENTO DE PROYECTOS DE INVESTIGACIÓN DE LA FACULTAD DE CIENCIAS, UCV Índice general 1. Problema de Investigación 7 1.1. Situación Actual . . . . . . . . . . . . . . . . . . . . . . . . 7 1.2. Planteamiento del Problema . . . . . . . . . . . . . . . . . 7 1.3. Solución Propuesta . . . . . . . . . . . . . . . . . . . . . . 8 1.3.1. Objetivo General . . . . . . . . . . . . . . . . . . . 9 1.3.2. Objetivo Especí�cos . . . . . . . . . . . . . . . . . . 9 1.4. Justi�cación . . . . . . . . . . . . . . . . . . . . . . . . . . 10 1.5. Alcance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10 2. Marco Conceptual 11 2.1. Facultad de Ciencias . . . . . . . . . . . . . . . . . . . . . 11 2.1.1. Estructura Organizativa . . . . . . . . . . . . . . . . 11 2.1.2. Coordinación de Investigación . . . . . . . . . . . . 12 2.2. Indicadores . . . . . . . . . . . . . . . . . . . . . . . . . . . 14 2.2.1. Criterios de los Indicadores . . . . . . . . . . . . . . 14 2.2.2. Objetivo de un indicador . . . . . . . . . . . . . . . 15 2.2.3. Características . . . . . . . . . . . . . . . . . . . . . 15 2.2.4. Tipología de Indicadores . . . . . . . . . . . . . . . 16 2.3. Inteligencia de Negocio (Business Intelligence) . . . . . . . . 17 2.3.1. Inteligencia . . . . . . . . . . . . . . . . . . . . . . . 17 2.3.2. Negocio . . . . . . . . . . . . . . . . . . . . . . . . 17 2.3.3. De�nición de Inteligencia de Negocio . . . . . . . . . 17 2.3.3.1. Características . . . . . . . . . . . . . . . . 18 2.3.4. Niveles de Soluciones de Inteligencia de Negocio . . . 19 2.3.5. Arquitectura de una Solución de Inteligencia de Ne- gocio . . . . . . . . . . . . . . . . . . . . . . . . . . 19 2 ÍNDICE GENERAL 3 2.3.6. Fuentes de Datos . . . . . . . . . . . . . . . . . . . 21 2.3.7. Procesos de Extracción, Transformación y Carga (ETL) 21 2.3.8. Almacén de Datos (Data Warehouse) . . . . . . . . 22 2.3.8.1. De�nición . . . . . . . . . . . . . . . . . . 23 2.3.8.2. Características . . . . . . . . . . . . . . . . 23 2.3.8.3. Arquitectura . . . . . . . . . . . . . . . . . 25 2.3.8.4. Metadata . . . . . . . . . . . . . . . . . . 27 2.3.8.5. Requerimientos de un DWH . . . . . . . . 27 2.3.9. Bodega de Datos (Data Mart) . . . . . . . . . . . . 28 2.3.9.1. Estrategias de Construcción . . . . . . . . 29 2.3.10. Modelo Dimensional del DWH . . . . . . . . . . . . 29 2.3.10.1. De�nición . . . . . . . . . . . . . . . . . . 30 2.3.10.2. Tabla de Dimensión . . . . . . . . . . . . . 30 2.3.10.3. Tabla de Hechos . . . . . . . . . . . . . . . 30 2.3.10.4. Esquema Estrella (Star Scheme) . . . . . . 31 2.3.10.5. Esquema Copo de Nieve (Snow�ake Scheme) 32 2.3.10.6. Esquema Constelación (Star�ake Scheme) . 33 2.3.10.7. Granularidad . . . . . . . . . . . . . . . . 34 2.3.10.8. Jerarquía . . . . . . . . . . . . . . . . . . . 34 2.3.10.9. Agregación . . . . . . . . . . . . . . . . . . 35 2.4. Herramientas Tecnológicas . . . . . . . . . . . . . . . . . . 35 2.4.1. Herramientas de Análisis y visualización . . . . . . . 35 2.4.1.1. Reportes . . . . . . . . . . . . . . . . . . . 35 2.4.1.2. Indicadores . . . . . . . . . . . . . . . . . 36 2.4.2. Herramienta de Extracción, Transformación y Carga (ETL) . . . . . . . . . . . . . . . . . . . . . . . . . 37 2.4.2.1. Pentaho . . . . . . . . . . . . . . . . . . . 37 2.4.2.2. Pentaho Data Integration . . . . . . . . . . 38 2.4.3. Herramienta para crear la bodega de datos (Datamart) 39 2.4.3.1. PostgreSQL . . . . . . . . . . . . . . . . . 40 2.4.4. Herramientas de Visualización . . . . . . . . . . . . 41 2.4.4.1. Tableau . . . . . . . . . . . . . . . . . . . 41 3. Marco Metodológico 46 3.1. Metodología Descendente (TOP-DOWN) . . . . . . . . . . 46 ÍNDICE GENERAL 4 3.1.1. Metodología de Bill Inmon . . . . . . . . . . . . . . 46 3.1.2. Parte 1: Desarrollo de Sistemas Operacionales . . . . 48 3.1.3. Parte 2: Desarrollo del almacén de datos . . . . . . . 50 3.1.4. Parte 3: Uso del Almacén de Datos . . . . . . . . . . 51 3.1.5. Plan de Migración (Migration Path) . . . . . . . . . 51 3.2. Metodología Ascendente (BOTTOM-UP) . . . . . . . . . . 53 3.2.1. Metodología de Ralph Kimball . . . . . . . . . . . . 54 3.2.2. Plani�cación del Proyecto . . . . . . . . . . . . . . . 55 3.2.3. De�nición de los Requerimientos del Negocio . . . . 55 3.2.4. Diseño de la Arquitectura . . . . . . . . . . . . . . . 56 3.2.5. Selección de productos e instalación . . . . . . . . . 58 3.2.6. Diseño de Datos o modelado dimensional . . . . . . 58 3.2.7. Especi�cación y desarrollo de aplicaciones analíticas 61 3.2.8. Implementación . . . . . . . . . . . . . . . . . . . . 61 3.2.9. Despliegue y Crecimiento . . . . . . . . . . . . . . . 62 3.3. Metodología a seguir . . . . . . . . . . . . . . . . . . . . . 63 4. Marco Aplicativo 65 4.1. Plani�cación del Proyecto . . . . . . . . . . . . . . . . . . . 65 4.2. De�nición de los Requerimientos . . . . . . . . . . . . . . . 66 4.3. Diseño de la Arquitectura Técnica . . . . . . . . . . . . . . 67 4.4. Selección de Productos e Instalación . . . . . . . . . . . . . 68 4.5. Modelo Dimensional . . . . . . . . . . . . . . . . . . . . . . 69 4.6. Diseño físico . . . . . . . . . . . . . . . . . . . . . . . . . . 76 4.7. Diseño y Construcción de procesos ETL . . . . . . . . . . . 79 4.7.1. Diseño de Procesos de ETL y Desarrollo (almacén de datos) . . . . . . . . . . . . . . . . . . . . . . . . . 79 4.7.2. Veri�car la calidad de los datos . . . . . . . . . . . . 81 4.7.3. Veri�cación de la calidad de los datos de los compo- nentes del modelo implementado . . . . . . . . . . . 87 4.7.3.1. Veri�cación de la tabla de hecho investiga- ción con sus dimensiones . . . . . . . . . . 87 4.7.3.2. Detallar los requerimientos según el modelo 92 4.8. Desarrollo de los requerimientos de información . . . . . . . 93 4.8.1. Con�guración de la conexión . . . . . . . . . . . . . 93 ÍNDICE GENERAL 5 4.8.2. Generador de los indicadores de gestión . . . . . . . 94 4.8.3. Desarrollo y distribución de consultas . . . . . . . . 95 4.8.3.1. Tabla de hecho de investigación . . . . . . 95 4.8.4. Veri�car la calidad de los datos en la herramienta de manipulación y visualización de datos . . . . . . . . 105 4.9. Implementación . . . . . . . . . . . . . . . . . . . . . . . . 108 4.9.1. Ajuste de las consultas . . . . . . . . . . . . . . . . 108 Índice de �guras 1.1. Arquitectura de la Solución Propuesta . . . . . . . . . . . . . . . . . . 9 2.1. Estructura organizativa de investigación de la Escuela de Física de la Facultad de Ciencias de la UCV. (Fuente [CoorInv, 2011]). . . . . . . . 12 2.2. Indicadores de Gestión (Fuente [Indicador,2014]) . . . . . . . . . . . . . 15 2.3. Clasi�cación según los factores claves . . . . . . . . . . . . . . . . . . . 16 2.4. Niveles (Fuente [Inteligencia de Negocios, 2017]) . . . . . . . . . . . . . 19 2.5. Componentes de inteligencia de negocio . . . . . . . . . . . . . . . . . . 20 2.6. Fuentes de Datos . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21 2.7. Procesos de Extracción, Transformación y Carga (ETL) (Fuente [Cano, 2007]) 22 2.8. Almacén de Datos . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22 2.9. Histórico de DWH (Fuente [DWH, 2015]) . . . . . . . . . . . . . . . . . 24 2.10. No Volátil (Fuente [DWH, 2015]) . . . . . . . . . . . . . . . . . . . . . 24 2.11. La Arquitectura (Fuente [DWH, 2010] ) . . . . . . . . . . . . . . . . . . 26 2.12. Bodega de Datos (Fuente [Cano, 2007]) . . . . . . . . . . . . . . . . . . 28 2.13. Tablas de Dimensión (Fuente [Kimball, 2002]) . . . . . . . . . . . . . . 30 2.14. Tabla de Hechos (Fuente [Kimball, 2002] ) . . . . . . . . . . . . . . . . 31 2.15. Esquema Estrella de lo tickets (Fuente [Cano, 2007]) . . . . . . . . . . 32 2.16. Esquema Copo de Nieve o Snow�ake (fuente [Cano, 2007]) . . . . . . . 32 2.17. Esquema Constelación [Bernabeu, 2009] . . . . . . . . . . . . . . . . . 33 2.18. Jerarquía de lugar (Fuente [Cano, 2007]) . . . . . . . . . . . . . . . . . 34 2.19. Herramienta de Análisis y visualización (Fuente [Cano, 2007]) . . . . . 35 2.20. Ejemplos Reportes (Fuente [Planeaux, 2007]) . . . . . . . . . . . . . . . 36 2.21. Ejemplos Indicadores (Fuente [Planeaux, 2007]) . . . . . . . . . . . . . 36 2.22. Pentaho Arquitectura (Fuente:[Pentaho, 2016] ) . . . . . . . . . . . . . 38 2.23. Interfaz grá�ca de Spoon . . . . . . . . . . . . . . . . . . . . . . . . . . 39 2.24. Tableau Server (Fuente[TableauPDF, 2016]) . . . . . . . . . . . . . . . 42 2.25. Arquitectura de Tableau Server (Fuente [TableauPDF, 2016]) . . . . . . 43 3.1. Enfoque Inmon (Fuente [Kimball, 2010]) . . . . . . . . . . . . . . . . . 48 3.2. Enfoque R. Kimball (Fuentes [Kimball, 2010]) . . . . . . . . . . . . . . 53 3.3. Ciclo de Vida de la Metodología de Ralph Kimball (Fuente [Kimball, 2002]) 55 3.4. Ciclo de vida dimensional adaptado a inteligencia de negocio . . . . . . 64 1 ÍNDICE DE FIGURAS 2 4.1. Arquitectura de Diseño . . . . . . . . . . . . . . . . . . . . . . . . . . . 67 4.2. Arquitectura de Diseño con sus herramientas . . . . . . . . . . . . . . . 68 4.3. Modelo Dimensiona tipo estrella . . . . . . . . . . . . . . . . . . . . . . 70 4.4. Jerarquía de las dimensiones . . . . . . . . . . . . . . . . . . . . . . . . 70 4.5. Dimensión de Área de aplicación . . . . . . . . . . . . . . . . . . . . . 73 4.6. Modelo de�nitivo tipo estrella . . . . . . . . . . . . . . . . . . . . . . . 76 4.7. Dimensión Tiempo . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 77 4.8. Diseño lógico de las dimensiones . . . . . . . . . . . . . . . . . . . . . 77 4.9. ETL de la Dimension Investigador . . . . . . . . . . . . . . . . . . . . . 78 4.10. Modelo dimensional . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 79 4.11. ETL de Dimensión Investigador . . . . . . . . . . . . . . . . . . . . . . 79 4.12. ETL de los Hechos del nivel académico a la Tabla de Hecho de investigación 80 4.13. El llenado del almacén de datos . . . . . . . . . . . . . . . . . . . . . . 81 4.14. Veri�cación de la dimensión investigador . . . . . . . . . . . . . . . . . 81 4.15. Veri�cación de la cantidad de los datos de la dimensión investigador . . 82 4.16. Veri�cación de la dimensión área de conocimiento . . . . . . . . . . . . 82 4.17. Veri�cación de la cantidad de datos de la dimensión área de conocimiento 82 4.18. Veri�cación de la dimensión área de aplicación . . . . . . . . . . . . . . 83 4.19. Veri�cación de la cantidad de datos de área de aplicación . . . . . . . 83 4.20. Veri�cación de la dimensión institución . . . . . . . . . . . . . . . . . . 83 4.21. Veri�cación de la cantidad de datos de la dimensión institución . . . . . 84 4.22. Veri�cación de la dimensión proyecto . . . . . . . . . . . . . . . . . . . 84 4.23. Veri�cación de la cantidad de datos de la dimensión proyecto . . . . . . 84 4.24. Veri�cación de la dimensión producto . . . . . . . . . . . . . . . . . . . 85 4.25. Veri�cación de la cantidad de datos de la dimensión producto . . . . . 85 4.26. Veri�cación de la dimensión evento . . . . . . . . . . . . . . . . . . . . 85 4.27. Veri�cación de la cantidad de datos de la dimensión evento . . . . . . . 86 4.28. Veri�cación de la cantidad de datos de la dimensión nivel académico . . 86 4.29. Veri�cación de la cantidad de datos de la dimensión nivel académico . . 86 4.30. Veri�cación de datos de la dimensión tiempo . . . . . . . . . . . . . . . 87 4.31. Comparación de los dato del modelo con la dimensión tiempo . . . . . 88 4.32. Proyecto en la base de datos . . . . . . . . . . . . . . . . . . . . . . . . 88 4.33. Dimensión proyecto con la tabla de hecho investigación . . . . . . . . . 89 4.34. Dimensión área de conocimiento con la tabla de hecho investigación . . 89 4.35. Área de conocimiento en el almacén de datos . . . . . . . . . . . . . . . 89 4.36. Subárea de aplicación en la base de datos . . . . . . . . . . . . . . . . 90 4.37. Dimensión área de aplicación con la tabla de hecho investigación . . . . 90 4.38. Dependencia en la base de datos . . . . . . . . . . . . . . . . . . . . . . 91 4.39. Dimensión institución con la tabla de hecho investigación . . . . . . . . 91 4.40. Usuario en la base de datos . . . . . . . . . . . . . . . . . . . . . . . . 91 4.41. Dimensión investigador con la tabla de hecho investigador . . . . . . . 92 4.42. Creación de la conexión con la fuentes de dato desde Tableau . . . . . . 93 4.43. La tabla de hecho investigación con sus dimensiones . . . . . . . . . . . 94 ÍNDICE DE FIGURAS 3 4.44. Elemento de almacén de datos . . . . . . . . . . . . . . . . . . . . . . . 94 4.45. Conteo de proyectos del investigador . . . . . . . . . . . . . . . . . . . 95 4.46. Conteo de proyectos por área de conocimiento . . . . . . . . . . . . . . 96 4.47. Grá�ca de conteo de proyectos del investigador . . . . . . . . . . . . . . 96 4.48. Conteo de proyectos por área de aplicación . . . . . . . . . . . . . . . . 97 4.49. Grá�ca de conteo de proyectos por área de aplicación . . . . . . . . . . 97 4.50. Conteo de proyectos por institución . . . . . . . . . . . . . . . . . . . . 98 4.51. Grá�ca de conteo de proyectos por institución . . . . . . . . . . . . . . 98 4.53. Cantidad de productos por institución . . . . . . . . . . . . . . . . . . 99 4.52. Conteo de producto del investigador . . . . . . . . . . . . . . . . . . . . 99 4.54. Conteo de productos por área de conocimiento . . . . . . . . . . . . . . 100 4.55. Grá�ca de conteo de productos por área de conocimiento . . . . . . . . 100 4.56. Conteo de productos por área de aplicación . . . . . . . . . . . . . . . . 101 4.57. Grá�ca de conteo de productos por área de aplicación . . . . . . . . . . 101 4.58. Conteo de eventos por investigador . . . . . . . . . . . . . . . . . . . . 102 4.59. Los proyectos del investigador . . . . . . . . . . . . . . . . . . . . . . . 102 4.60. Los proyectos del área de conocimiento . . . . . . . . . . . . . . . . . . 103 4.61. Los proyectos de las instituciones . . . . . . . . . . . . . . . . . . . . . 103 4.62. Los productos del investigador . . . . . . . . . . . . . . . . . . . . . . . 104 4.63. Los productos del área de aplicación . . . . . . . . . . . . . . . . . . . 104 4.64. Evento de los investigador . . . . . . . . . . . . . . . . . . . . . . . . . 105 4.65. El nivel académico de los investigador . . . . . . . . . . . . . . . . . . . 105 4.66. Veri�cación de la tabla de hecho investigación con base de datos . . . . 106 4.67. Veri�cación de la tabla de hecho investigación con base de datos . . . . 106 4.68. Veri�cación de la tabla de hecho investigación con base de datos . . . . 107 4.69. Veri�cación de la tabla de hecho de nivel académico con base de datos . 107 Índice de cuadros 3.1. Marco de trabajo de la Arquitectura . . . . . . . . . . . . . . . . . . . 57 3.2. Comparación de las metodologías . . . . . . . . . . . . . . . . . . . . . 63 4.1. Plani�cación del proyecto . . . . . . . . . . . . . . . . . . . . . . . . . 66 4.2. Dimensión Tiempo . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 71 4.3. Detalle de la Dimensión Investigador . . . . . . . . . . . . . . . . . . . 72 4.4. Dimensión de Institución . . . . . . . . . . . . . . . . . . . . . . . . . . 72 4.5. Dimensión de Área de Conocimiento . . . . . . . . . . . . . . . . . . . 73 4.6. Dimensión de Proyecto . . . . . . . . . . . . . . . . . . . . . . . . . . . 73 4.7. Dimensión de Producto . . . . . . . . . . . . . . . . . . . . . . . . . . . 74 4.8. Dimensión de Evento . . . . . . . . . . . . . . . . . . . . . . . . . . . . 74 4.9. Dimensión Nivel Académico . . . . . . . . . . . . . . . . . . . . . . . . 75 4.10. Tabla de Hecho Gestión de los proyectos . . . . . . . . . . . . . . . . . 75 4 Introducción �Las organizaciones pueden ser ricas en datos y pobres en información...� Stuart Madnick, 1993 Trabajo de Grado se presenta un conjunto de conceptos, metodologías y herramien- tas que permiten llevar a cabo el desarrollo de una solución de Inteligencia de Negocio para la Coordinación de Investigación de la Facultad de Ciencias de la Universidad Central de Venezuela. La Facultad de Ciencias de la Universidad Central de Venezuela está conformada por Escuelas e Institutos, y éstas a su vez por Centros y Laboratorios de Investigación, donde profesores y otros profesionales llevan a cabo investigaciones. Para administrar las unidades de investigación de la Facultad, existe una Coordi- nación de Investigación. Esta coordinación dispone de una base de datos relacional, llamada Base de Datos del Sistema de Gestión de Información Cientí�ca (BD SIGIC), donde se centraliza la información de los investigadores y sus proyectos. BD SIGIC es usada para almacenar y procesar los datos, pero no tiene mecanismos efectivos para la interpretación de la información. Para poder interpretar toda esa información, fue necesario extraerla del medio donde se encontraba, para llevarla a un almacén de datos (DWH) y luego procesarla mediante una herramienta de inteligencia de negocio. La herramienta de inteligencia de negocio permite una gran �exibilidad y manipu- lación de los datos, dando la capacidad de hacer todo tipo de análisis y visualizaciones para la generación de conocimiento y ayudar así en la toma de decisiones gerenciales. El presente trabajo es un prototipo debido a que la base de datos de la Coordina- ción de Investigación se encuentra con datos incompletos. Sin embargo, este prototipo es completamente funcional y está listo para cuando se introduzcan los datos. Adicio- nalmente el sistema es �exible y puede ser ampliado cuando se carguen los datos, no es una actividad de una sola vez sino un proceso continuo y de mejoramiento. Este documento se encuentra organizado en cuatro (4) capítulos, y una sección de conclusiones y recomendaciones. Dichos capítulos se encuentran estructurados de la siguiente manera: Capítulo 1 - Problema de Investigación. Se expone la situación actual, el problema, los objetivos generales y especí�cos contemplados, la justi�cación del proyecto, la solución propuesta y el alcance de�nido para la investigación. 5 ÍNDICE DE CUADROS 6 Capítulo 2 - Marco Conceptual. Se describen los tópicos más relevantes que se encuentran relacionados con el tema de investigación, los aspectos contemplados se describen a continuación: � Facultad de Ciencias. Su estructura organizativa, la Coordinación de In- vestigación. � Inteligencia de Negocio. De�nición, arquitectura de una solución de in- teligencia de negocio. ◦ Almacén de Datos. De�nición, características y su arquitectura. Adi- cionalmente se de�ne los conceptos concernientes al modelo dimensional. ◦ Indicadores de Gestión. De�nición, tipos de indicadores de gestión y los criterios de los indicadores de gestión. � Herramientas Tecnológicas. Componente para el desarrollo de la solu- ción, herramienta ETL, herramienta para construir el almacén de datos y herramientas analíticas y de explotación. Capítulo 3 - Marco Metodológico. Se describen las distintas etapas que com- ponen la metodología propuesta por Ralph Kimball para el desarrollo de una solución de inteligencia de negocio. Capítulo 4 - Marco Aplicativo. Se especi�can las actividades realizadas para el desarrollo de una solución de inteligencia de negocio para la Coordinación de Investigación siguiendo las etapas de metodología de�nida por Ralph Kimball de manera no estricta. Finalmente se presentan las conclusiones y recomendaciones del presente trabajo inves- tigativo, así como también la bibliografía. Capítulo 1 Problema de Investigación En este Capítulo se presenta el problema que motiva este Trabajo Especial de Grado (TEG), una descripción general de las soluciones propuesta, alcance, objetivo general y objetivos especí�cos del TEG. 1.1. Situación Actual En la Actualidad, la Coordinación de Investigación, tiene un Sistema de Gestión de Información Cientí�ca (SIGIC), la cual permite registrar y gestionar la información, actividades, proyectos y productos producidos por los investigadores de la Facultad de Cienciasde manera rápida y sencilla, en una base de datos centralizada, el cual será de gran utilidad para permitir el pleno funcionamiento de cualquier aplicación que requiera de esta información, pero no se cuenta con reportes y indicadores para el análisis de datos y apoyar la toma de decisiones por parte de la Coordinación de Investigación [Pérez, 2016]. Sin embargo se tiene la necesidad de visualizar ciertos reportes y indicadores de gestión para tener la información de una manera más resumida, es decir transformar los datos crudos en información para la toma decisiones. Porque la información es uno de los recursos más importante que tiene una organización siempre y cuando sea con�able y acertada, demás es la base para plantear estrategias de negocio. Además la mayoría de las organizaciones tienden a tener un gran número de datos, pero muy poca información ya que no saben como resumir y categorizar los datos. 1.2. Planteamiento del Problema La Coordinación de Investigación de la Facultad de Ciencias de la Universidad Central de Venezuela cuenta con una base de datos centralizada donde se almacena información de los proyecto de investigación. A pesar de la cantidad de datos que se recolecta continuamente y del control, se tiene muy poca información de los proyectos, productos de investigación.. 7 CAPÍTULO 1. PROBLEMA DE INVESTIGACIÓN 8 Dado a que usualmente se manejan los datos, se di�culta la tarea de obtener in- formación útil para analizar y visualizar los reportes generados, los cuales requieren de mucho tiempo para su elaboración. Esta demora di�culta la toma de decisiones acertadas y oportunas. La Coordinación de Investigación cuenta con una base de datos donde se almacena la información relacionada con las actividades de investigación de la Facultad, junto con una aplicación que permite de manera sencilla, registrar y administrar dicha informa- ción. Este tipo de almacenamiento tiene problemas en cuanto a mecanismos efectivos para la interpretación, análisis y visualización de los datos almacenados en ella. Es por ello que se crea un módulo de análisis de datos para toma de decisiones partiendo de las fuentes de datos y llevarla a un almacén de datos (Data Warehouse) y que esta sea visualizada mediante una herramienta de visualización y de exploración. Se desarrolla una capa de análisis de procesos, que podrá comunicarse directamente con los esquemas propios de la bases de datos de la Coordinación de Investigación. La idea es tener toda la información que servirá para generar una serie de responder y indicadores de gestión de los proyectos, productos, eventos, y nivel académico. 1.3. Solución Propuesta Dados los inconvenientes mencionados, se necesita desarrollar una serie de reportes y indicadores de gestión relacionados con de los proyectos, productos, eventos, y nivel académico de los investigadores para la toma de decisiones, de manera consistente y oportuna. Se propone una solución de Inteligencias de negocio (BI), cuya arquitectura se des- cribe en �gura 1.1, el cual parte de las fuentes de datos, se incorpora los datos mediante el proceso de extracción, transformación y carga de los datos (ETL) al almacén de datos, bodega de datos (Data Mart), y mediante las herramientas de análisis y de exploración se visualizara la información. Dicho prototipo se desarrolló para la Coordinación de In- vestigación de la Facultad de Ciencias y permite la obtención de reportes, indicadores para apoyar la toma de decisiones, ya que por cierta problemática no se logró emplear dicha solución. CAPÍTULO 1. PROBLEMA DE INVESTIGACIÓN 9 Figura 1.1: Arquitectura de la Solución Propuesta Fuentes de datos. Corresponde a la fuente de datos de la organización que sean relevantes para el BI. ETL. Encargada de la integración desde múltiples fuentes existentes para la cons- trucción del almacén de datos. Almacén de datos. La colección de datos orientados a temáticas, integrados, no volátiles que cambian en el tiempo que apoya la toma de decisiones. Bodegas de Datos que se re�ere a una vista del DWH orientado solo a un aspecto de la organización. Visualización y explotación de datos. Es la encargada de desplegar los aná- lisis de la información. La metodología que se va a emplear para desarrollar esta solución de Inteligencia de Negocio, es una adaptación la metodología Ascendente (Bottom-up) de Ralph Kimball, pero no se empleara de manera estricta. 1.3.1. Objetivo General Desarrollar una solución de Inteligencia de Negocio para generar reportes y indica- dores de investigación de la Facultad de Ciencias. 1.3.2. Objetivo Especí�cos 1. Analisis de los requerimientos, indicadores de investigación de la Facultad de Cien- cias. 2. Analizar y de�nir las fuentes de datos que permitan alimentar al almacén de datos (DWH). 3. Diseñar el modelo dimensional. CAPÍTULO 1. PROBLEMA DE INVESTIGACIÓN 10 4. Construcción del almacén de datos. 5. Desarrollar los reportes y indicadores de gestión para el monitoreo del DWH. 6. Realizar pruebas de integración, funcionales, calidad de datos, de aceptación. 1.4. Justi�cación Se pretende desarrollar un prototipo de inteligencia de negocio que se adapte a los requerimientos de la coordinación, con respecto a los proyectos de investigación, que permita observar y evaluar la gestión de los procesos, para realizar el análisis basándose en los hechos del sistema. Adicionalmente, se pueden hacer comparaciones con los datos históricos y usar éstos para hacer proyecciones en el tiempo y análisis, con la �nalidad de solventar, permite corregir o mejorar el proceso. El desarrollo de una solución de inteligencia de negocio, permitirá a la coordinación disponer de un sistema orientado a la toma decisiones, utilizando tecnología de software libre como PostgreSQL, Pentaho y Tableau que un software con versión gratuita. Se tiene las herramientas necesarias para generar la solución de inteligencia de negocio orientado al análisis del negocio, y en consecuencia, apoyar la toma decisiones de la Coordinación de Investigación de la Facultad de Ciencias de la UCV. 1.5. Alcance Un prototipo que plantea ser de gran utilidad para el desarrollo de una solución Inteligencia de Negocio (BI) de la Coordinación de Investigación, para la toma de decisiones de una manera precisa y oportuna, ya que existe la necesidad de poder interpretar de una manera sencilla, versátil y rápida todos los datos que se generan a raíz de los procesos de negocios y así tomar decisiones efectivas que incrementen la productividad. Se realizará el análisis de los proyectos de investigación, diseño e implementación de dicha solución que abarcará, desde diseño y extracción de los datos, además del almacén de datos (DWH), y la creación de los diferentes reportes y indicadores de gestión para la toma decisiones. No es una actividad de una sola vez, es un proceso de mejoramiento continuo. Capítulo 2 Marco Conceptual En este capítulo se abordan todos los elementos a emplear como base teórica para el desarrollo de la solución de inteligencia de negocio. Es decir, se detallan los distin- tos conceptos, de�niciones, arquitectura, esquemas, entre otros, que están relacionado: inteligencia de negocio, almacén de datos, Modelo Dimensional, Bodegas de Datos, Herramientas Tecnológicas. 2.1. Facultad de Ciencias La Facultad de Ciencias es una de las facultades de la Universidad Central de Venezuela (UCV) que ofrece continuamente aportes a la Ciencia y a la Tecnología del país, en ella se realizan numerosas investigaciones en las distintas Escuelas e Institutos que la conforman. Dentro de la Facultad de Ciencias se encuentra la Coordinación de Investigación, encargada de apoyar y administrar los proyectos de investigación. 2.1.1. Estructura Organizativa La Facultad de Ciencias está conformada por cinco escuelas y cuatro institutos. Las escuelas de la Facultad de Ciencias son biología, computación, física, matemáticas y química, y los cuatro institutos son ciencias de la tierra, zoología ecología tropical, ciencias de tecnologías de alimentos y biología experimental. Es estas escuelas e institutos, grupos de investigadores, profesores y profesionales se dedican a la búsqueda y experimentación de diferentes líneas de investigación. En los Centros de Investigación se realizan constantemente actividades de investiga- ción cientí�ca y/o tecnológica, que favorezcan el desarrollo del país y el bienestar de la sociedad venezolana, además de: captación y entrenamiento de capital humano, transfe- rencia de tecnología, difusión, divulgación cientí�ca y gestión, seguimiento y evaluación de procesos de ciencia y tecnología [Borges, 2006]. En los Laboratorios de Investigación se elaboran y ejecutan proyectos de investiga- ción, se contribuye con la formación de investigadores, se organizan y/o dictan cursos, se brinda asesoramiento y se gestionan recursos económicos y materiales. 11 CAPÍTULO 2. MARCO CONCEPTUAL 12 Normalmente, los Laboratorios de Investigación están adscritos a un Centro de In- vestigación, pero también pueden existir Laboratorios que no pertenezcan a ningún Centro. Esto ocurre porque no hay un Centro relacionado con la línea de investigación del Laboratorio y porque la cantidad de investigadores pertenecientes a dicho Labo- ratorio no es su�ciente para crear un nuevo Centro y así poder cumplir con todas las formalidades necesarias. En la �gura 2.1 se puede ver un ejemplo de una escuela de la Facultad de Cien- cias que tiene Laboratorios de Investigación que no están adscritos a un Centro de Investigación. Figura 2.1: Estructura organizativa de investigación de la Escuela de Física de la Fa- cultad de Ciencias de la UCV. (Fuente [CoorInv, 2011]). 2.1.2. Coordinación de Investigación La Coordinación de Investigación de la Facultad de Ciencias es un ente adminis- trativo que se ocupa de la promoción y el apoyo de actividades de investigación, así como también del fomento de relaciones con entes universitarios, gubernamentales y privados, dedicados al �nanciamiento de la ciencia. Fue creada por aprobación de la Facultad de Ciencias, en diciembre de 1991. Inicialmente existía una Comisión de In- CAPÍTULO 2. MARCO CONCEPTUAL 13 vestigación adscrita a la Coordinación de Postgrado formada por los Coordinadores de Investigación de las escuelas, Centros e Institutos de la Facultad de Ciencias, la cual había sido creada por el Consejo de Facultad en enero de 1986 [CoorInv, 2011]. La Coordinación de Investigación está constituida por un Coordinador y por un Consejo de Investigación. El Consejo está formado por el Coordinador de Investigación, quien lo preside, los representantes de cada uno de los Consejos Técnicos de los insti- tutos, los representantes de las Comisiones de Investigación de cada una de las escuelas y representantes de la Facultad ante el Consejo de Desarrollo Cientí�co y Humanístico (CDCH) [CoorInv, 2011]. Entre sus funciones esenciales está realizar el balance de la investigación que se realiza anualmente en la Facultad, analizar y promover el potencial productivo de la misma, dar a conocer a los diferentes entes del entorno nacional el resultado de las investigaciones y facilitar la conexión entre los investigadores y las instituciones externas que puedan promover �nanciamiento a la actividad de investigación [CoorInv, 2011]. El Consejo de Investigación tiene las siguientes atribuciones [CoorInv, 2011]: Proponer al Consejo de Facultad lineamientos generales de política para las ac- tividades de investigación de la Facultad, así como las normas que obliguen a su cumplimiento. Velar por el uso adecuado de los recursos ordinarios y extraordinarios destinados a la investigación en la Facultad. Mantener una base de datos de los recursos de investigación en la Facultad de Ciencias. Proponer al Consejo de Facultad los Representantes de la Coordinación de Inves- tigación ante organismos o entes del Gobierno. Proponer programas de investigación que se consideren necesarios a objeto de solucionar problemas prioritarios en nuestra sociedad. Velar porque las actividades de investigación de la Facultad reciban el apoyo de los recursos y hacer la distribución racional del mismo. Estudiar y evaluar las proposiciones de creación de Institutos y Centros de Inves- tigación, Laboratorios de Investigación y Laboratorios de Apoyo a la Investigación dentro de la Facultad, y hacer las recomendaciones correspondientes. Estimular y orientar las solicitudes de fondos por parte de las diferentes estructu- ras organizativas de investigación de la Facultad ante entes intra y extra univer- sitarios que la fomentan. Divulgar el potencial de investigación de la Facultad de Ciencias, así como los resultados de investigaciones ya realizadas, distinciones y/o premios. CAPÍTULO 2. MARCO CONCEPTUAL 14 Fomentar la creación de Grupos Interdisciplinarios de Investigación, dentro y fuera de la Facultad. Propiciar la realización de eventos que bene�cien las actividades de investigación de la Facultad tales como: Seminarios, Jornadas, Conferencias, Cursos y Reunio- nes. 2.2. Indicadores Los Indicadores de Gestión son expresiones cualitativas o cuantitativas que describen características, comportamiento o fenómenos de una organización, permitiendo evaluar el desempeño y evolución en el tiempo, es decir es un instrumento para la evaluación, medición y análisis de las variables asociadas a las metas y objetivos de la organización. El valor de los indicadores expresan cualitativa o cuantitativa el desempeño de toda una organización o sus partes que permiten proponer una solución y toma acciones que conlleven a los objetivos planteados. Por medio de los indicadores podemos observar la evolución de una variable, establecimiento de una relación entre variables, comparación con períodos anteriores, productos similares o una meta. 2.2.1. Criterios de los Indicadores Los indicadores para que sean útiles y efectivos tienen que cumplir los siguientes criterios: Relevante. Debe tener relación y estar alineado con los objetivos y metas de la organización. Comparable. Se debe poder comparar los valores a lo largo del tiempo en la organización e incluso entre otras organizaciones. Veri�cable. Se debe poder con�rmar que los valores obtenidos sean correctos. (con respecto a lo que se desea medir) Fácil de comprender. Se debe mostrar de una forma clara y sencilla lo que se desea expresar como vemos2.2.1. CAPÍTULO 2. MARCO CONCEPTUAL 15 Figura 2.2: Indicadores de Gestión (Fuente [Indicador,2014]) 2.2.2. Objetivo de un indicador A través de los indicadores puedes observar la evolución de una variable, establecer una relación entre variables es decir: Genera información útil para mejorar el proceso de toma de decisiones. Monitorear y evaluar el desempeño. Cuanti�car los cambios. Identi�car problemas y oportunidades. Medir comportamiento y facilitar la delegación. 2.2.3. Características Las características de los indicadores �SMART� son: Especí�cos (Speci�c). Permite describir la situación o fenómeno determinado. Medible (Measurable). Debe ser cuanti�cable que permitan obtener unos re- sultados objetivos. Siguiendo el principio �lo que no se puede medir, no se puede controlar�. Accionable (Actionable). Que los resultados y análisis permitan tomar deci- siones. Relevante (Relevance). Un objetivo este realmente orientado a la obtención de los resultados en un momento determinado. CAPÍTULO 2. MARCO CONCEPTUAL 16 Oportuno (Timely). Estableciendo el período de tiempo en el que se debe completar cada uno de ellos. 2.2.4. Tipología de Indicadores Existen muchos tipos de clasi�caciones comunes en la teoría sobre indicadores: Medición (Cuantitativos/ Cualitativos). Es una representación numérica. � Cuantitativos. Su característica más importante es que, al encontrarse va- lores diferentes, estos pueden ordenarse de forma ascendente o descendente. � Cualitativos. Su características principal es que su resultado se re�ere a una escala de cualidades. Calidad (E�cacia, E�ciencia, Efectividad). Dan cuenta de la dinámica de actividades especi�cas. � E�cacia. Miden el grado de cumplimiento de los objetivos propuestos o metas programadas. Se concentra en Qué se debe hacer. EficaciaDeObjetivos = ObjetivosAlcanzados ObjetivosP lanteados � E�ciencia. Miden el nivel de ejecución del proceso con un mínimo de recur- sos, se concentran en el Cómo se hicieron las cosas. EficienciaDeObjetivos = ObjetivosLogrados RecursosUtilizados � Efectividad. Este concepto relaciona la e�ciencia y la e�cacia, es decir el logro de los resultados programados en el tiempo y con los costos mas razo- nables posibles. EfictividadDeObjetivos = (PuntajeEficiencia+PuntajeEficacia)/2 MáximoPuntaje Los indicadores se clasi�can según los factores claves de éxito: Figura 2.3: Clasi�cación según los factores claves Jerarquía de objetivos (Gestión/ Estratégicos). � Gestión. Re�eja cuáles fueron las consecuencias de acciones tomadas en el pasado en el marco de una organización. La idea es que estos indicadores CAPÍTULO 2. MARCO CONCEPTUAL 17 sienten bases para acciones o tomar en el presente y en el futuro. Es impor- tante que los indicadores de gestión re�ejen datos veraces y �ables, ya que el análisis de la situación, de otra manera, no será correcto. 2.3. Inteligencia de Negocio (Business Intelligence) En la actualidad la información es uno de los recursos importantes que poseen las organizaciones, sin embargo, su obtención, análisis y manejo no siempre es tan sencillo. La información con�able y acertada es la base para la creación de un estrategia de negocio rentable y productiva. Es por ello, que las distintas organizaciones han enfocado sus esfuerzos no solo en la recopilación de los datos para la generación de información, sino que también, en soluciones que permitan la visualización de reportes e indicadores que ayuden a realizar análisis para la toma de decisiones. 2.3.1. Inteligencia �La inteligencia es información procesada y explotada a un muy alto nivel� [Prior, 2007], es decir, la inteligencia es la capacidad de abstracción para solucionar un problema y de organizar grandes cantidades de información para luego razonar y pensar sobre un aspecto en especí�co. 2.3.2. Negocio Un negocio o una organización es �La acción y el efecto de articular, disponer y hacer operativos un conjunto de medios, factores o elementos para la consecución de un �n concreto� [Andrade, 2005], es decir, es un conjunto de personas que trabajan en conjunto desempeñando diversas actividades para lograr un objetivo en común (satisfacer las necesidades de la sociedad). 2.3.3. De�nición de Inteligencia de Negocio inteligencia de negocio por las siglas en ingles BI (Business Intelligence) por Ho- ward Dresner 1989, cuando era consultor de Gartner, mediante el uso de tecnología y metodologías se quiere convertir datos en información y a partir de la información ser capaces de descubrir conocimientos basados en hechos. También puede intervenir en todos los procesos de una compañía, actuando en las tareas y actividades de los em- pleados, creando nuevas actividades y nuevas habilidades, mejorando la comunicación entre departamentos e incrementando la capacidad de reacción de la compañía. Para de�nir BI partiremos de la de�nición de Gartner 1.[Cano, 2007] 1Glosario de Gartner, www.gartner.com, enero 2006. Gartner es una consultora internacional espe- cializada en Tecnologías de Información y Comunicación. CAPÍTULO 2. MARCO CONCEPTUAL 18 �BI es un proceso interactivo para explorar y analizar información estructurada sobre un área (normalmente almacenada en un datawarehouse), para descubrir tenden- cias o patrones, a partir de los cuales derivar ideas y extraer conclusiones. El proceso de Business Intelligence incluye la comunicación de los descubrimientos y efectuar los cambio.� El origen de la Business Intelligence va ligado a proveer acceso directo a la infor- mación a los usuarios de negocio para ayudarles en la toma de decisiones. [Cano, 2007] Una solución de BI nos proporcionara los siguientes bene�cios a la empresa. 2.3.3.1. Características La Inteligencia de Negocio tiene características como [Cano, 2007]: Proceso interactivo. Hablar de BI estamos suponiendo que se trata de un aná- lisis de información continuado en el tiempo, no sólo en un momento puntual. Aunque evidentemente este último tipo de análisis nos puede aportar valor, es incomparable con lo que nos puede aportar un proceso continuado de análisis de información, en el que por ejemplo podemos ver tendencias, cambios, variabilida- des, etc. Explorar. En todo proyecto de BI hay un momento inicial en el que por primera vez accedemos a información que nos facilita su interpretación. En esta primera fase, lo que hacemos es �explorar� para comprender qué sucede en nuestro nego- cio; es posible incluso que descubramos nuevas relaciones que hasta el momento desconocíamos. Analizar. Pretendemos descubrir relaciones entre variables, tendencias, es decir, cuál puede ser la evolución de la variable, o patrones. Si un cliente tiene una serie de características, cuál es la probabilidad que otro con similares características actué igual que el anterior. Área de análisis. Todo proyecto de BI debe tener un objeto de análisis con- creto. Nos podemos centrar en los clientes, los productos, los resultados de una localización, etc. que pretendemos analizar con detalle y con un objetivo concre- to: por ejemplo, la reducción de costes, el incremento de ventas, el aumento de la participación de mercado, el ajuste de previsiones de venta, el cumplimiento los objetivos de venta presupuestados, etc. Comunicar los resultados y efectuar los cambios. Un objetivo fundamen- tal del BI es que, una vez descubierto algo, sea comunicado a aquellas personas que tengan que realizar los cambios pertinentes en la organización para mejorar nuestra competitividad. CAPÍTULO 2. MARCO CONCEPTUAL 19 2.3.4. Niveles de Soluciones de Inteligencia de Negocio La inteligencia de negocio muestra resultados, de acuerdo a las necesidades de los distintos niveles jerárquicos de la organización 2.4 se presenta una pirámide con los distintos tipos de BI, mostrando de izquierda a derecha el personal y a la derecha las herramientas o instrumentos que utilizan para realizar las tareas de la organización. Figura 2.4: Niveles (Fuente [Inteligencia de Negocios, 2017]) Apoyan a los distintos niveles de la organización [Inteligencia de Negocios, 2017]: Nivel Operativo. Se permite a los empleados de la empresa recibir de forma oportuna, exacta y adecuada la información operativa, basándose en herramientas de trabajos como reportes, hojas de cálculos, manteniendo siempre un formato �jo cuya información se actualiza cada cierto tiempo. Nivel Táctico. Permite a los analistas de datos y a la gerencia media de una empresa, utilizar herramientas de análisis y consultas con el �n de obtener acceso a la información sin intervención de terceros. Nivel Estratégico. Permite que los directivos de la empresa pueda analizar y seguir día a día las tendencias, patrones, metas y objetivos estratégicos de la empresa. Un ejemplo de ello, lo constituye el cuadro de mando integral, entre otros. 2.3.5. Arquitectura de una Solución de Inteligencia de Negocio Una solución de inteligencia de negocio tiende a ser una de las piezas más complejas de software que se puedan llegar a implementar en una organización, debido a que se requiere de la integración de diversos sistemas que usualmente no tienen una conexión directa entre sí. Por esta razón, vale destacar que una solución BI es mucho más que un software que despliega los datos de la empresa al usuario. CAPÍTULO 2. MARCO CONCEPTUAL 20 Una organización que maneja grandes cantidades de datos, necesita para maximizar sus ingresos e incrementar su e�ciencia, monitorear una serie de indicadores claves que informen sobre el funcionamiento de la empresa en tiempo real. Para poder generar conocimientos en una organización a partir de los datos que esta maneje, es necesario involucrar un conjunto de elementos mínimos indispensables, los cuales, permitirán aplicar inteligencia de negocio en las organizaciones que lo requieran. Los diversos componentes que componen a una solución de inteligencia de negocio se ven expresados en la 2.5: Figura 2.5: Componentes de inteligencia de negocio Fuentes de Datos. Es el proceso de donde se parte DWH para alimentar de información el DWH. ETL Proceso de extracción, transformación y carga de los datos en el DWH. Antes de almacenar los datos en un DWH, éstos deben ser transformados, limpiados, �ltrados y rede�nidos. Normalmente, la información que se tiene en los sistemas transaccionales no está preparada para la toma de decisiones. Almacén de Datos (DWH). Metadata o Diccionario de datos. Se busca almacenar los datos de una forma que maximice su �exibilidad, facilidad de acceso y administración. Motor OLAP 2. Provee capacidad de cálculo, consultas, funciones de planea- miento, pronóstico y análisis de escenarios en grandes volúmenes de datos, sin embargo, en la actualidad existen otras alternativas tecnológicas al OLAP. Las herramientas de acceso. Permiten el análisis y la navegación de la infor- mación a través de los mismos. 2OLAP: On-Line Analytical Processing / Procesamiento Analítico en Línea CAPÍTULO 2. MARCO CONCEPTUAL 21 2.3.6. Fuentes de Datos A la hora de desarrollar una un solución de BI, se debe determinar que datos se necesitan para realizar los análisis requeridos, por esta razón, un sistema de este tipo sin una fuente de datos correcta válida, tendría poco valor para la organización. El conjunto de datos que se puede usar 2.6 para una solución de BI es muy amplia, se puede usar datos internos de la empresa, así como también datos externos que sirvan para efectos de los análisis a realizar. Figura 2.6: Fuentes de Datos En esta etapa deberíamos plantearnos una serie de preguntas, como: ¿ Qué in- formación necesita la organización?, ¿Cuándo se requiere dicha información?, ¿En que formato se necesita?, ¿Que información posee la empresa? y ¿Para quién está dirigida?, esto servirá para complementar los análisis para implementar la solución. La mayoría de las implementaciones de BI usan snapshots (imágenes instantáneas de uno o más sistemas de archivos) o copias de seguridad como datos fuentes, debido a que esto garantiza que los datos en el sistema sean precisos y correctos. Si se tomaran los datos de los sistemas transaccionales de la empresa a medida que se van generando, una actualización a un registro en el sistema transaccional generaría una pérdida de exactitud en los datos que se emplearán para los análisis, lo cual conlleva a que los resultados que se obtengan sean incorrectos o pocos precisos y adicionalmente, el rendimiento del sistema operacional bajaría considerablemente. 2.3.7. Procesos de Extracción, Transformación y Carga (ETL) Una vez que ya hayamos seleccionado la data necesaria para el sistema procedemos ETL de los datos a la plataforma de BI. Es la encargada de la integración de los datos desde las multiples fuentes existentes para la construcción del almacén de datos (DWH) y los Data Marts, formando el ciclo de vida de una implementación de BI. Cada proceso de de�ne como: CAPÍTULO 2. MARCO CONCEPTUAL 22 Figura 2.7: Procesos de Extracción, Transformación y Carga (ETL) (Fuente [Cano, 2007]) Extracción. Consiste en la identi�cación y selección de los datos de los sistemas operacionales para satisfacer las necesidades de la organización. Una vez seleccio- nados los datos, se extraen los datos. Se considera la consolidación de los datos desde las diversas fuentes que usan diferentes estructuras y formatos, establecien- do el acceso a las fuentes de datos, extrayendo de manera e�ciente cada una de los datos requeridos. Transformación. Los datos de la transacciones se convierten en datos con un formato consistente y orientado a los negocios, es decir, unos datos correctos, no ambiguos, consistentes y completos. Aplicando una serie de reglas o funciones a los datos extraídos desde la fuente para generar los datos a cargar al destino �nal. Carga. Se toman los datos y registran en el almacén de datos siguiendo las especi�caciones que se de�nieron con anterioridad 2.3.8. Almacén de Datos (Data Warehouse) El almacén de datos (DWH) 3 es una base de datos corporativa que proporcio- na múltiple funciones a un número determinado de usuarios, como el de disponer de Sistemas de Información de apoyo a la toma de decisiones. Figura 2.8: Almacén de Datos La tecnología DWH se ha desarrollado rápidamente, y representa mejor que otros sistemas, las compleja estructura de una organización a la hora de administrar su datos generenciales [Inmon, 2002]. 3Data Warehouse siglas en inglés CAPÍTULO 2. MARCO CONCEPTUAL 23 2.3.8.1. De�nición Un DWH es una colección de información creada para soportar las aplicaciones de toma de decisiones.4 Es decir es una BD corporativa que abarca los procesos, las herramientas y las tecnologías para convertir datos en información, en conocimiento y planes para conducir de forma e�caz las actividades de negocios. [Cano, 2007] El término DWH tiene sus orígenes en dos fuentes, �An Architecture for a Bussinesdd and Information Systems� de Barry Devlin y Paul Morphy56 y �Building the Data Warehouse� de Inmon, William H.7 La primera fuente, �An Architecture for a Bussinesdd and Information Systems�, publicado en el IBM Systems Journal, es considerado como uno de los primeros artículos que describe la arquitectura de un DWH, desarrollado entre 1985 y 1986 para uso interno de IBM Europa en Dublín. En dicho artículo se hizo uso del término �Information Warehouse� para hacer referencia al proyecto. En la actualidad, suele usarse de manera general, para referirse a un DWH, la siguiente expresión que aparecía en el artículo: �El almacén de datos es un único, completo y consistente almacén de datos obtenido de una variedad de fuentes, y puesto a la disposición de los usuarios �nales, de manera que ellos puedan entender y usar en el contexto del negocio� [Cano, 2007]. La segunda fuente, �Building the Data Warehouse�, describe al DWH como �un conjunto de datos orientados hacia una materia, integrados, no transitorios y que varían en el tiempo, los cuáles apoyan el tema de toma de decisiones de una administración� Inmon,1992. Inmon es considerado el padre del DWH y ha escrito una serie de libros, junto con otros autores, donde abordan diversos tópicos relacionados con la arquitectura almacén de datos [Cano, 2007]. 2.3.8.2. Características Las características principales del almacén de datos son las siguientes: Integrado. Los datos almacenados en el DWH deben estar integrados en una estructura que sea capaz de eliminar cualquier tipo de inconsistencias existentes entre los diversos sistemas operacionales que sirven de fuentes de datos. Al mismo tiempo, la información suele estructurarse en distintos niveles de detalle para adecuarse a los requerimientos preestablecidos por todos los usuarios �nales. Temático u Orientado a un área. Sólo los datos necesarios para generar in- formación del negocio se integran desde el entorno operacional. Los datos se orga- nizan por temas, no por aplicación, así se facilita el acceso y entendimiento de los 4La primera aproximación es la del Watson, que de�ne DWH 5Devlin, 1997 6�An Architecture for a Bussinesdd and Information Systems� de Barry Devlin y Paul Morphy 7�Building the Data Warehouse� de William H. Inmon CAPÍTULO 2. MARCO CONCEPTUAL 24 datos contenidos en el DWH. Eventualmente, esta característica permite realizar análisis y minería de datos. Histórico o Indexado en el tiempo (�gura: 2.9). El tiempo es parte implíci- ta de la información contenida en un DWH. , en el DWH se carga con los distintos valores que puede tomar una variable en el tiempo, para poder hacer compara- ciones y análisis, soportando de esta manera el proceso de toma de decisiones. Es decir, el DWH se carga con los distintos valores que toma una variable en el tiempo para permitir comparaciones. Los datos históricos son de poco uso en el procedimiento operacional. La información del depósito por el contrario, de- be incluir los datos históricos para usarse en la identi�cación y evaluación de tendencias. Figura 2.9: Histórico de DWH (Fuente [DWH, 2015]) No volátil. El DWH se construye para ser leído, y no modi�cado. La información que existe en un DWH es permanente, su actualización consiste en la incorporación de los últimos valores que tomaron las distintas variables sin alteración de los datos que ya existían se actualiza de manera periódica ya establecida. Figura 2.10: No Volátil (Fuente [DWH, 2015]) Como se puede observar en la �gura: 2.10 en la BD operacional la actualización (actualizar, borrar y modi�car) se hace regularmente, mientras en el DWH sea CAPÍTULO 2. MARCO CONCEPTUAL 25 una sola actualización esto hace que cuando tengamos que tomar una decisión con esta información tengamos seguridad de esta. Además de las características previamente mencionadas, otras, quizás menos relevantes, pero que igualmente sirven para remarcar la potencialidad de un DWH: Contiene datos diversos. Es un repositorio uni�cado de información. Los da- tos de toda la organización, aunque pertenezcan a aplicaciones diferentes, son integrados en el DWH. Optimizado para la consulta masiva. El diseño físico de un DWH tiene un objetivo diferente al de las bases de datos transaccionales, mejorar los tiempos de respuesta de procesos de consultas de datos masivos de información, tomando en cuenta que deben ser orientados a temas, así como también brindar facilidad de entendimiento al usuario �nal. La interfaz de usuario. Está dirigida a los ejecutivos y diversos analistas, por lo que deben ser intuitivas. Gran volumen. Cuando se habla de almacén de datos, el espacio de almacena- miento suele medirse en Gigabytes y Terabytes debido a la cantidad de informa- ción sumarizada. Cabe destacar que un DWH admite redundancia de datos y un tiempo de vida de información entre 5 y 10 años. 2.3.8.3. Arquitectura Una arquitectura de almacén de datos es una forma de representar la estructura global de los datos, la comunicación, los procesos y la presentación al usuario �nal. La arquitectura está constituida por las siguientes partes interconectadas [DWH, 2010]: Elementos que constituyen la arquitectura de un almacén de datos: Nivel de base de datos externos, base de datos operacional. Las organiza- ciones adquieren datos de Bases de Datos externas a la propia organización, que incluyen datos demográ�cos, económicos, datos sobre la competencia, etc. Mediante el proceso de DWH se extrae la información que está en la bases de datos operacionales y se mezcla con otras fuentes de datos. Enriquecemos la in- formación. Nivel de acceso a la información. Es la capa con la que trata el usuario �nal. La información almacenada se convierte en información fácil y transparente para las herramientas que utilizan los usuarios. Se obtienen informes, grá�cos, diagramas, etc. Nivel de acceso a los datos. Comunica el nivel de acceso a la información con el nivel operacional, es el responsable de la interfaz entre las herramientas de acceso a la información y las bases de datos. CAPÍTULO 2. MARCO CONCEPTUAL 26 Figura 2.11: La Arquitectura (Fuente [DWH, 2010] ) La clave de este nivel está en proveer al usuario de un acceso universal a los datos, es decir, que los usuarios sin tener en cuenta la ubicación de los datos o la herramienta de acceso a la información, deberían ser capaces de acceder a cualquier dato del DWH que les fuera necesario para realizar su trabajo. Nivel de directorio de datos (metadatos). Para proveer de un acceso uni- versal, es absolutamente necesario mantener alguna clase de directorio de datos o repositorio de información de metadato que ayude a mantener un control sobre los datos. El metadato aporta información sobre los datos de la organización, de dónde proviene, qué formato tenía, cuál era su signi�cado y si se trata de un agregado, cómo se ha calculado éste. Para mantener un almacén completamente funcional, es necesario disponer de una amplia variedad de metadatos, información sobre las vistas de datos para los usuarios �nales y sobre las bases de datos operacionales. Nivel de gestión de proceso. Este nivel tiene que ver con la plani�cación de las tareas que se deben realizar, no sólo para construir, sino también para mantener el DWH y la información del directorio de datos. Es o el controlador de alto nivel de los procesos que se han de llevar a cabo para que el almacén de datos permanezca actualizado. Nivel de mensaje de la aplicación. El nivel de mensaje de la aplicación tie- ne que ver con el transporte de información alrededor de la red de la empresa. Puede usarse para aislar aplicaciones operacionales o estratégicas a partir de un formato de datos exacto, recolectar transacciones o los mensajes y entregarlos a una ubicación segura en un tiempo especí�co. CAPÍTULO 2. MARCO CONCEPTUAL 27 Nivel Almacén de Datos (físico). Es el repositorio central, altamente �exible de información, donde residen las copias de datos operacionales usados. En un DWH físico las copias de datos, operaciones y/o externos se almacenan de forma que sea fácil de acceder. En la actualidad un DWH se almacena en plataformas cliente/servidor, pero también existen con�guraciones sobre mainframes, equipos externos para su rápido acceso mediante consulta. Nivel de organización de datos. El componente �nal de la arquitectura es la organización de los datos. Incluye todos los procesos necesarios para seleccionar, editar, resumir, combinar y cargar datos en el y para acceder a la información desde bases de datos operacionales y/o externas. La forma de implementar un está sujeta a la forma en la que se va a estructurar el almacenamiento de los datos dentro del mismo. Independientemente del modelo que se escoja el objetivo principal es escoger uno que satisfaga las necesidades empresariales. 2.3.8.4. Metadata La Metadata es el repositorio central de la información y es un componente crítico del DWH. Nos da el signi�cado de cada uno de los componentes y sus atributos que se encuentran en el DWH. Puede incluir de�niciones de negocio gestión del Almacén de Datos, descripciones detalladas de los tipos de datos, formatos y otras características [Cano, 2007]. Son los datos que describen la información, campos y formatos de BD y del DWH. Para gestionar metadatos es necesario proporcionar una guía del punto de vista técnico y comercial de éstos. Los metadatos pueden ser categorizados en dos tipos: Los metadatos técnicos. Son metadatos que se crean durante el principio de un repositorio de datos , los cuales sirven para apoyar la gestión del repositorio. Éstos incluyen normas de adquisición, la transformación de los datos dentro del formato requerido por el repositorio, horarios para realizar copias de seguridad y la actualización de los datos. Los metadatos de negocio. Permiten al usuario �nal comprender información que se tiene guardada en el DWH y de qué manera se puede acceder a ella. 2.3.8.5. Requerimientos de un DWH Se de�ne los requerimientos que debería cumplir un DWH 8: Fácil acceso. Lograr que la información de la organización sea de fácil acceso. El alcance del Almacén de Datos puede ser bien un departamento o un corpora- tivo. Aportando datos entendibles, manejables, rápidos de acceder y navegables, facilitándole al personal obtener dicha información para poder lograr un objetivo en especí�co. 8(Kimball & Margy, 2002), De�ne los objetivos de un DWH CAPÍTULO 2. MARCO CONCEPTUAL 28 Consistencia. Lograr que la información de la organización sea consistente. Lo- grando que la información que se trabaja en la organización tenga el mismo nom- bre, signi�cado, lógica, coherencia y solidez. Adaptable y elástica. Proporcionar información adaptable y elástica. La infor- mación en el DWH puede ser separada y combinada para analizar cada una de las posibles medidas del negocio. Tanto los datos, como la tecnología existente, no cambian en absoluto. Seguridad. Proporcionar un mecanismo de seguridad que protege los valores de la información. Permite al usuario �nal la manipulación de los datos, según la permisología asignada, logrando brindar seguridad en la información, ya que no todos los usuarios pueden modi�car la información. Fundamentar la toma de decisiones. Almacenando los datos correctos, como el volumen de datos necesarios, para apoyar la toma de decisiones en la organiza- ción. 2.3.9. Bodega de Datos (Data Mart) Los DWH representan una gran cantidad de información, es decir una gran base de datos que puede estar distribuida en distintas bases de datos, sería muy costoso y tiempo que ninguna organización podría aceptar. Es por ello que surge la bodega de datos, que está dirigido a un grupo de usuarios dentro de la organización. Figura 2.12: Bodega de Datos (Fuente [Cano, 2007]) Una bodega de datos es una bases de datos departamental, especializada en el al- macenamiento de los datos de un área de negocio especí�ca. Se caracteriza por disponer la estructura óptima de datos, para analizar la información al detalle desde todas las perspectivas que afecten a los procesos de dicho departamento [sinnexus, 2016]. Los bodega de datos son más pequeños que los DWH y tienen menos información, menos modelos de negocios y son utilizados por un grupo menor de usuarios, pueden CAPÍTULO 2. MARCO CONCEPTUAL 29 ser dependientes e independientes. Un bodega de datos independiente puede originar inconsistencia con otro bodega de datos ver en la �gura: 2.12. 2.3.9.1. Estrategias de Construcción Dos estrategias básicas para la construcción de un DWH, una propuesta por Kimball y la otra por Inmon: W.H Inmon, Propone construir un DWH corporativo y a partir de él ir constru- yendo los modelos de análisis para los distintos niveles y departamentos de la organización; es decir, una estrategia de arriba abajo, desde la estrategia a lo más operativo se conoce como Descendente[Cano, 2007]. R. Kimball, Propone construir distintos bodega de datos que cubran las distintas necesidades de la organización, sin la necesidad de construir un DWH se conoce como Ascendente [Cano, 2007]. Las dos estrategias son válidas. De construir un DWH corporativo es desarrollo en fases es decir se construye un bodega de datos dependiente con una parte de información del DWH y en partes pos- teriores se van desarrollando bodega de datos usando subconjuntos del DWH. Igual que los proyectos complejos, es caro,y necesita mucho tiempo y es propenso al fracaso. Cuando tenemos éxito conseguimos un DWH integrado y escalable [Cano, 2007]. Si optamos por la más común, de construir distintos bodega de datos, el proyecto comienza con un bodega de datos único al que posteriormente se irán añadiendo otros bodega de datos que cubrirán otras áreas de negocio. Normalmente no requiere de grandes inversiones y es fácil de implementar, aunque con lleva algunos riesgos. Si seguimos esta estrategia debemos tener claro el plan de acción, es decir, qué áreas cubriremos y la integración de los distintos modelos. Esta estrategia se utiliza a veces como un paso previo al desarrollo de un DWH corporativo. 2.3.10. Modelo Dimensional del DWH El modelo dimensional se describe en el año 1996 por Ralph Kimball, como propuesta para el diseño del Almacén de Datos, partiendo de la visión multidimensional que los usuarios tienen de los datos empresariales cuando se enfrentan a ellos con propósito de análisis (análisis multidimensional � OLAP � en concreto). Todo DWH comienza con modelo dimensional, ya que se identi�can los hechos, que es la tabla central de dicho modelo y la dimensiones son categorías que describen el contexto en el cual se analizan la tabla de hecho. Existen dos tipos de esquema en el modelo relacional: esquema estrella y copo de nieve. CAPÍTULO 2. MARCO CONCEPTUAL 30 2.3.10.1. De�nición El modelo dimensional es una técnica de diseño para el DWH (a nivel lógico) que pretende representar los hechos del negocio. Este modelo está optimizado para llevar a cabo consultas con un alto rendimiento. El modelo dimensional es una de las técnicas de modelado de un Almacén de Datos. En el proceso de modelado dimensional, un modelo de tablas y relaciones se constituye con el propósito de optimizar el soporte de toma de decisiones a nivel de desempeño del query en bases de datos Relacionales relativo al proceso de negocio que se esté mo- delando. En contraste, los modelos convencionales de Entidad-Relación se constituyen para eliminar la redundancia en el modelo de datos, facilitar la obtención de registros en base a indicadores establecidos y por lo tanto optimizar el nivel de desempeño de los sistemas OLTP. Por tal motivo, es necesario de�nir y tener claros los conceptos básicos al modelo dimensional, los tipos de tablas involucradas, y los esquemas de trabajo que pueden emplearse en una solución. La Dimensión es una entidad independiente en el modelo dimensional que sirve como un punto de entrada o como un mecanismo de reordenamiento y fraccionamiento de las medidas sumarizadas, localizadas en la tabla de hechos del modelo [Kimball, 2002]. 2.3.10.2. Tabla de Dimensión Las tablas de dimensiones contiene descripciones textuales, tablas que integran la tabla de hechos, cada dimensión se de�ne por su clave primaria única, designada por la notación PK como vemos en la �gura: 2.13, que sirve como base para la integridad referencial con cualquier tabla de hechos a la que se une y una columnas de atributos descriptivos que juegan un papel fundamental en el DWH son lo que queremos medir. Figura 2.13: Tablas de Dimensión (Fuente [Kimball, 2002]) 2.3.10.3. Tabla de Hechos Es la representación en el DWH de los procesos de negocio de la organización. La tabla principal del DWH con las mediciones de rendimiento numéricas que son caracterizadas por una clave compuesta, donde cada elemento de la misma es una clave CAPÍTULO 2. MARCO CONCEPTUAL 31 foránea que corresponde a una tabla de dimensiones se encuentra todo lo que queremos medir, y analizar. Una medida se toma en la intersección de todas las dimensiones (fecha, producto y la tienda) como podemos ver en la �gura:2.14. Una �la de una tabla de hechos corresponde a la medida. Todas la medidas de una tabla de hechos deben estar al mismo grano o granularidad [Kimball, 2002]. Figura 2.14: Tabla de Hechos (Fuente [Kimball, 2002] ) 2.3.10.4. Esquema Estrella (Star Scheme) El esquema de estrella es la representación genérica de un modelo dimensional en una base de datos relacional, en la cual una tabla de hechos con una clave compuesta que forma la clave de cada dimensión, es unidad a un número de tablas de dimensiones (Em- pleado, tiempo, centro, etc.), cada una con una clave primaria simple [Kimball, 2002]. El esquema estrella es ideal por su simplicidad y simetría porque son más fáciles de en- tender, navegar y es altamente reconocible por los usuarios de negocios como podemos ver en la �gura 2.15. Las características del esquema estrella [Cano, 2007]: Una tabla de hechos,que contiene los datos sin redundancias. Una sola tabla por dimensión. La tabla de hechos (Fact table) tiene un atributo columna que forma la clave de cada dimensión. Cada tabla de dimensión (Dimension table) es una tabla simple desnormalizada. Cuando unimos distintos esquemas �estrella� que tienen distintas tablas de hechos, pero comparten las de las dimensiones, hablamos de constelaciones de hechos; algunos autores hablan incluso de esquema �galaxia� [Cano, 2007]. CAPÍTULO 2. MARCO CONCEPTUAL 32 Figura 2.15: Esquema Estrella de lo tickets (Fuente [Cano, 2007]) 2.3.10.5. Esquema Copo de Nieve (Snow�ake Scheme) El esquema de copo de nieve es una dimensión normalizada en el cual una tabla de dimensión simple es descompuesta en una estructura de árbol con muchos niveles [Kimball, 2002]. Figura 2.16: Esquema Copo de Nieve o Snow�ake (fuente [Cano, 2007]) CAPÍTULO 2. MARCO CONCEPTUAL 33 El esquema �estrella� no es totalmente normalizado, como podemos ver en la �gura: 2.15 ya que en la tabla de la �Dimensión Centro� tenemos una redundancia que es �Descripción zona�,se repetirá tantas veces la zona como centros existan en la misma. Es por eso que nace el esquema copo de nieve o Snow�ake para solucionar este problema. Como vemos en la �gura: 2.16, en el esquema �copo de nieve� aparecen relaciones entre las tablas de dimensiones, mientras que en el esquema �estrella� sólo hay relaciones entre la tabla de hechos y las de dimensiones [Cano, 2007]. 2.3.10.6. Esquema Constelación (Star�ake Scheme) El esquema constelación está compuesto por una serie de esquema estrellas y tal como se puede apreciar en la siguiente �gura 2.17, está formado por una tabla de hechos principal (�HECHOS_A�) y por una o más tablas de hechos auxiliares (�HECHOS_B�), las cuales pueden ser sumarizaciones de la principal. Dichas tablas yacen en el centro del modelo y están relacionadas con sus respectivas tablas de dimensiones [Bernabeu, 2009]. No es necesario que las diferentes tablas de hechos compartan las mismas tablas de dimensiones, ya que, las tablas de hechos auxiliares pueden vincularse con solo algunas de las tablas de dimensiones asignadas a la tabla de hechos principal, y también pueden hacerlo con nuevas tablas de dimensiones[Bernabeu, 2009]. Figura 2.17: Esquema Constelación [Bernabeu, 2009] Las características del esquema constelación: Su diseño y cualidades son muy similares a las del esquema en estrella, pero posee una serie de diferencias con el mismo, que son precisamente las que lo destacan y caracterizan. Entre ellas se pueden mencionar [Bernabeu, 2009]: Permite tener más de una tabla de hechos, por lo cual se podrán analizar más aspectos claves del negocio con un mínimo esfuerzo adicional de diseño. CAPÍTULO 2. MARCO CONCEPTUAL 34 Contribuye a la reutilización de las tablas de dimensiones, ya que una misma tabla de dimensión puede utilizarse para varias tablas de hechos. No es soportado por todas las herramientas de consulta y análisis. 2.3.10.7. Granularidad Presenta el nivel de detalle al que se desea almacenar la información que posee cada registro de una tabla de hechos en un DWH [Kimball, 2002]. Es decir deberemos decidir cuál es el nivel de granularidad necesario para poder construir un modelo que nos permita responder a aquellas preguntas que nos hemos formulado a determinar un nivel de granularidad podemos responder unas preguntas pero no otras.Por ejemplo, los datos referentes a ventas o compras realizadas por una empresa, pueden registrarse día a día, en cambio, los datos pertinentes a pagos de sueldos o cuotas de socios, podrán almacenarse a nivel de mes. 2.3.10.8. Jerarquía Es una serie de relaciones en cascada de uno a muchos [Kimball, 2002]. Después de que ya se sabe cuál sería la granularidad, se realiza la jerarquía. Esta jerarquía corresponde con las tablas de dimensión que se de�nen como los niveles de asociación que tienen de los datos. Una dimensión debe contener al menos una jerarquía, la cual puede tener varios niveles. Figura 2.18: Jerarquía de lugar (Fuente [Cano, 2007]) Como por ejemplo la dimensión tiempo, una jerarquía del tiempo como podemos ver en la �gura: 2.18. Años se pueden descomponer en trimestres, los trimestres en meses y los meses en días. La existencia de las jerarquías en las dimensiones nos permite pasar del máximo detalle a la agregación en los distintos niveles. En nuestro ejemplo CAPÍTULO 2. MARCO CONCEPTUAL 35 podemos por tanto analizar las ventas de un artículo por días, por meses, por trimestres o por años. 2.3.10.9. Agregación Se trata de una medida, es decir un dato contable. Por ejemplo, si se quiere tener el total del salario de una empresa, lo que se hace es hacerle un proceso de agregación, de�niendo como operación la suma de los sueldos de los empleados, logrando que cada vez que entre más información en el atributo sueldo, se va a ir mostrando sumarizado. 2.4. Herramientas Tecnológicas El proceso de selección de una herramienta tecnológica puede llegar a ser complejo debido a las múltiples alternativas existentes en el mercado (Oracle BI, Pentaho BI, IBM Cognos, MicroStrategy, entre otros) y a la diversa gama de funcionalidades que cada herramienta brinda. Independientemente de la herramienta a seleccionar, ésta debe proveer un repositorio centralizado, visualización de cuadros de mando y la posibilidad de construir consultas a la medida. 2.4.1. Herramientas de Análisis y visualización Con el surgimiento de aplicaciones de inteligencia de negocio, se han creado herra- mientas especializadas que permiten mostrarle a la alta gerencia los datos más relevantes de una empresa de manera resumida, en forma de indicadores y reportes para la toma decisiones. Figura 2.19: Herramienta de Análisis y visualización (Fuente [Cano, 2007]) 2.4.1.1. Reportes Es un informe generado por un sistema, que nos muestra de forma estructurada y resumida, datos relevantes generados por las aplicaciones, de manera que se pueda realizar la toma de decisiones. CAPÍTULO 2. MARCO CONCEPTUAL 36 Figura 2.20: Ejemplos Reportes (Fuente [Planeaux, 2007]) 2.4.1.2. Indicadores Es una medida cuantitativa que permite identi�car cambios en el tiempo, cuyo objetivo es determinar el buen funcionamiento de un sistema o negocio. Logrando así identi�car los problemas y poder tomar medidas para solucionarlos. Figura 2.21: Ejemplos Indicadores (Fuente [Planeaux, 2007]) CAPÍTULO 2. MARCO CONCEPTUAL 37 2.4.2. Herramienta de Extracción, Transformación y Carga (ETL) Las herramientas de Extracción (E), Transformación (T) y Carga (L � de Load en inglés) permiten de manera sencilla recuperar datos de distintas fuentes de información, limpiarlos y realizar las transformaciones necesarias para cargarlos en un repositorio, minimizando fallos comunes como la existencia de campos o valores nulos, tablas de referencia inexistentes, entre otros. Siguiendo la línea de tecnologías de código abierto, se ha seleccionado la herramienta de ETL de Pentaho, llamada Pentaho Data Integration (PDI) o también conocida como Kettel, la cual se explica a continuación. 2.4.2.1. Pentaho Es una plataforma Open Source de BI orientada a soluciones y centrada en procesos fundada en el 2004. Ofreciendo soluciones para la gestión y análisis de la información, incluyendo el análisis multidimensional OLAP, presentación de informes, minería de datos y creación de cuadros de mando para el usuario. La plataforma ha sido desarrollada bajo el lenguaje de programación Java y tiene un ambiente de implementación también basado en Java, haciendo así que Pentaho sea una solución muy �exible al cubrir una alta gama de necesidades empresariales. Arquitectura Los módulos de la arquitectura de Pentaho BI son: Pentaho Data Integration. Permite tomar información de diferentes fuentes y cargarlas en un repositorio analítico. Provee una consistencia, una sola versión de todos los recursos de información mediante ETL 9. Pentaho reporting. Es un potente generador de informe permitiendo la dis- tribución de los resultados del análisis en multiples formatos como PDF, XLS, HTML y textos. Los reportes Pentaho permiten también programación de tareas y ejecución automática de informes con una determinada periodicidad. Pentaho Analysis. Suministra a los usuarios un sistema avanzado de análisis de información es un servidor OLAP10. Es compatible con expresiones multidimen- sionales y el lenguaje de consulta XML para el análisis Pentaho Dashboards. Proporcionar información sobre sus datos, donde se pue- den ver informes, grá�cos interactivos y los cubos creados con las herramientas Pentaho Report Designer. Pentaho Data Minina. Es el proceso de correr datos en algoritmos comple- tamente so�sticados, relevando signi�cantes patrones y correlaciones que pueden estar escondidos median la herramienta Weka. Esto puede ser usado para ayudar a entender lo mejor para el negocio y explotar el rendimiento de este en un futuro prediciendo completamente en el análisis. 9ETL (Extracción, Transformación y Carga) 10OLAP ( Procesamiento analítico en línea) CAPÍTULO 2. MARCO CONCEPTUAL 38 Pentaho para Apache Hadoop. Es una herramientas de desarrollo visual fá- ciles de usar y grandes análisis de datos que permiten a los usuarios preparar, modelar, visualizar y explorar conjuntos de datos estructurados y no estructu- rados en Hadoop. Pentaho simpli�ca el ciclo de vida de los datos de Hadoop de extremo a extremo proporcionando una plataforma completa desde la preparación de datos hasta el análisis predictivo. Pentaho es único al proporcionar ejecución en Hadoop para un rendimiento extremadamente rápido.[?] Figura 2.22: Pentaho Arquitectura (Fuente:[Pentaho, 2016] ) 2.4.2.2. Pentaho Data Integration Pentaho Data Integration (PDI) es una herramienta que permite extraer, transfor- mar y cargar (ETL- Extract, Transform and load) la información disponible en apli- caciones y bases de datos separadas y Hojas de Cálculos para ponerlas en manos del usuario, proyectando consistencia. También es conocido como kettle y posee las siguien- tes aplicaciones: Spoon. Herramienta grá�ca que permite diseñar procesos ETL. Soporta conexión con diversas fuentes de datos y permiten transformar los datos necesarios para cargarlos dentro de la Base Datos destino. Pan. Herramienta que permite ejecutar transformar diseñar con Spoon en XML o en un repositorio de base de datos. Generalmente las transformaciones se pro- graman en modo por lotes para ser ejecutadas en intervalos de tiempo regulares. Chef. Permite ejecutar trabajos complejos que automatizan los procesos de ac- tualización de la base de datos. CAPÍTULO 2. MARCO CONCEPTUAL 39 Kitchen. Herramienta que ayuda a ejecutar el trabajo por lotes, permitiendo iniciar y controlar fácilmente procesos ETL. Carte. Servidor web que permite la supervisión remota de procesos ETL. De las aplicaciones nombrada anteriormente una de las más usadas es Spoon, cuya interfaz se puede ver . Spoon es fácil de usar y resulta muy útil incluso para realizar migraciones pequeña, como pasar datos de una Hoja de Cálculo a una base de datos. Figura 2.23: Interfaz grá�ca de Spoon 2.4.3. Herramienta para crear la bodega de datos (Datamart) Un bodega de datos es una bases de datos departamental, especializada en el alma- cenamiento de los datos de un área de negocio especí�ca. Se caracteriza por disponer la estructura óptima de datos, para analizar la información al detalle desde todas las CAPÍTULO 2. MARCO CONCEPTUAL 40 perspectivas que afecten a los procesos de dicho departamento es decir donde los da- tos están denormalizados basandose en la información que necesite un departamento. Siguiendo la línea de tecnologías de código abierto, se ha seleccionado la herramienta para crear la bodega de datos. 2.4.3.1. PostgreSQL PostgreSQL es un Sistema Manejador de base de datos objeto-relacional, de có- digo abierto, que cuenta con más de 15 años de desarrollo activo y una arquitectura probada que se ha ganado una sólida reputación por su �abilidad, integridad de datos y corrección. Además, permite desarrollar procedimientos en diferentes lenguajes de programación como Java, C++, Ruby y Python, lo que hace a PostgreSQL altamente personalizable[PosrgreSQL, 1996]. Soporta grandes cantidades de datos y una alta concurrencia de usuarios accediendo a la vez al sistema, por lo que se considera una herramienta que favorece a los usuarios con sistemas empresariales de gran tamaño. PostgreSQL se ha enfocado tradicionalmente en la �abilidad, integridad de datos y características integradas enfocadas al desarrollador. Tiene un plani�cador de consultas extremadamente so�sticado, que es capaz de unir cantidades relativamente grandes de tablas e�cientemente [2nsPostgreSQL, 2001]. Se distribuye bajo la Licencia PostgreSQL, que es una licencia similar a la de la Distribución de Software de Berkeley (BSD) y a la del Instituto de Tecnología de Mas- sachusetts (MIT), que permite a los usuarios hacer cualquier cosa que quieran con el código, incluyendo la reventa de los binarios sin el código [2nsPostgreSQL, 2001]. PostgreSQL tiene las siguientes ventajas: Es código abierto. La velocidad de respuesta se mantiene al aumentar el tamaño de la base de datos, cosa que no sucede con otros programas que se suelen poner lentos. Proporciona estabilidad y con�abilidad. Tiene una gran capacidad de almacenamiento. Soporta gran número de peticiones simultáneas a la base de datos de forma co- rrecta. Puede operar sobre distintas plataformas como Linux, Windows, Unix, Solaris y MacOS X. Provee un buen sistema de seguridad mediante la gestión de usuarios, grupos de usuarios y contraseñas. Soporta los tipos de datos, cláusulas, funciones y comandos de tipo estándar SQL92/SQL99 y extendidos propios de PostgreSQL. CAPÍTULO 2. MARCO CONCEPTUAL 41 También presenta las siguientes desventajas: En comparación con otros Sistemas Manejadores de Base de Batos, como por ejemplo MySQL, es más lento en inserciones y actualizaciones, ya que cuenta con cabeceras de intersección. Cuenta con muchos foros o�ciales de ayuda, pero no con una documentación de ayuda obligatoria. La sintaxis de algunos comandos o sentencias no es tan intuitiva. 2.4.4. Herramientas de Visualización Se presenta la siguiente herramienta de visualización, para observar de manera más reducida los grandes volúmenes de datos de forma más �exible y que apoye la toma de decisiones. 2.4.4.1. Tableau Tableau es una herramienta o software de inteligencia de negocio11 que permite visualizar de una manera reducida grandes volúmenes de información, en forma rápida, �exible y gran usabilidad 12. Tableau es en la actualidad la herramienta de BI líder y de mayor velocidad de crecimiento según Gartner, destacando por su facilidad de uso, potencialidad para generar visualizaciones y capacidad de manejo de grandes volúmenes de Datos. A diferencia de las herramientas tradicionales de inteligencia de negocio (BI) desarrolladas pensando en el usuario técnico del área de sistemas, Tableau está orientado a que personas de todos los ámbitos puedan manejar información fácilmente y presentarla en forma atractiva. Así, abogados, periodistas, ingenieros, médicos, entre otros, que trabajen en una organización o en forma independiente, encontrarán en Tableau un poderoso aliado analítico. Tableau Software se fundó sobre la idea de que el análisis de datos y los informes subsiguientes no deben ser actividades aisladas, sino que deben integrarse en un proceso único de análisis visual: uno que les permita a los usuarios ver rápidamente patrones en sus datos y cambiar las vistas al instante para seguir su línea de pensamiento. Tableau combina la exploración de los datos y la visualización de estos en una aplicación fácil de usar que todos pueden aprender rápidamente. Cualquier persona acostumbrada al uso de Excel puede crear análisis interactivos y enriquecidos, e�caces para compartirlos de manera segura en la empresa. Los equipos de TI pueden administrar los datos y metada- tos de manera centralizada, controlar los permisos y escalar hasta implementaciones en toda la empresa. Esta descripción general se diseñó para responder las preguntas comu- nes de los gerentes y administradores de TI y ayudarles a admitir las implementaciones de software de análisis visual de cualquier tamaño. 11Inteligencia de Negocio es poner la información adecuada, en las manos de las personas que toman decisiones 12Usabilidad Cualidad de la página web o del programa informático que son sencillos de usar CAPÍTULO 2. MARCO CONCEPTUAL 42 Arquitectura Tableau Server cuenta con una arquitectura de cliente-servidor de n niveles altamente escalable que presta servicios a clientes móviles, clientes web y softwa- re instalado en equipos de escritorio. Las soluciones de Tableau tienen 2 componentes principales: Tableau Desktop y Tableau Server.[TableauPDF, 2016] Figura 2.24: Tableau Server (Fuente[TableauPDF, 2016]) Tableau Server es una plataforma de análisis de negocios de clase empresarial que puede escalar verticalmente hasta cientos de miles de usuarios. Ofrece poderosos análisis móviles y basados en navegador, y funciona con la arquitectura de datos, la adminis- tración del ciclo de vida y las restricciones de seguridad y gestión existentes en la empresa.[TableauPDF, 2016] Tableau Server cumple con requisitos empresariales, entre los que se incluyen [TableauPDF, 2016]: Escalabilidad Tableau Server puede escalar vertical y horizontalmente para satis- facer las necesidades de su empresa. El servidor puede escalar verticalmente con la incorporación de CPU y RAM adicionales. Todos los componentes de Tableau Server son de multiproceso y pueden con�gurarse en función de sus patrones de uso. Se puede escalar aún más agregando nodos adicionales que pueden con�gu- rarse de manera que cumplan con los requisitos de la organización. Alta disponibilidad con administración de clústeres interna y admite equilibrado- res de carga externos. Seguridad, cifra el trá�co interno, admite integración con Active Directory, SAML y OAuth. Facilidad de administración directa, desde la gestión de usuarios hasta las actua- lizaciones. Extensibilidad ofrece API e�caces. El siguiente diagrama muestra la arquitectura de Tableau Server[TableauPDF, 2016] : CAPÍTULO 2. MARCO CONCEPTUAL 43 Figura 2.25: Arquitectura de Tableau Server (Fuente [TableauPDF, 2016]) Capa de datos. Una de las características fundamentales de Tableau es que admite la arquitectura de datos que usted elija. Tableau no requiere que sus datos se almacenen en un solo sistema, propietario o de otro tipo. La mayoría de las organizaciones tiene un entorno de datos heterogéneo: almacenes de datos conviven con bases de datos, aunque sean locales o se encuentren en la nube. Los cubos y los archivos planos como los de Excel se siguen usando mucho. Tableau puede trabajar con todos ellos de manera simultánea. No es necesario que reúna todos los datos en la memoria, a menos que así lo decida. Si sus plataformas de datos actuales son rápidas y escalables, Tableau le permite bene�ciarse de manera directa de su inversión aprovechando la e�cacia de la base de datos para responder preguntas. Si este no es el caso, Tableau proporciona opciones simples para actualizar sus datos a �n de que sean rápidos y respondan con nuestro motor de datos en memoria. Conectores de datos. Tableau incluye más de 40 conectores de datos optimiza- dos para fuentes de datos como Microsoft Excel, SQL Server, Google BigQuery, Amazon Redshift, Oracle, SAP HANA, Salesforce.com, Teradata, Vertica, Clou- dera y Hadoop, y se agregan conectores de datos nuevos regularmente. También hay un conector ODBC genérico para cualquier sistema sin conector nativo. Ta- bleau proporciona dos modos de interacción con los datos: conexión en vivo o en memoria. Los usuarios pueden cambiar entre la conexión en vivo y en memoria, según lo deseen. Componentes de Tableau Server. El trabajo de Tableau Server se realiza mediante los siguientes cuatro procesos de servidor: � Servidor de aplicaciones. Los procesos del servidor de aplicaciones (wgser- ver.exe) controlan la exploración de contenido, la administración del servidor CAPÍTULO 2. MARCO CONCEPTUAL 44 y los permisos para las interfaces web y móvil de Tableau Server. Cuando un usuario abre una vista en un dispositivo cliente, ese usuario inicia una sesión (workgroup_session_id) en Tableau Server. El administrador puede con�- gurar fácilmente el tiempo de expiración predeterminado de esta sesión. El usuario puede ejecutar dos o más procesos de servidor de aplicaciones para satisfacer sus necesidades de escalabilidad y disponibilidad. VizQL Server: una vez que el usuario recibe la autenti�cación del servidor de aplicacio- nes, puede abrir una vista. El cliente envía una solicitud al proceso VizQL (vizqlserver.exe). A continuación, el proceso VizQL envía las consultas di- rectamente a la fuente de datos y devuelve un conjunto de resultados que se expresa en imágenes y se presenta al usuario. En muchos casos, Tableau Ser- ver aprovecha las representaciones y el almacenamiento en caché del cliente para reducir la carga del servidor. Además, cada VizQL Server tiene su pro- pia memoria caché que pueden compartir varios usuarios de manera segura. El usuario puede ejecutar dos o más procesos de VizQL Server para satisfacer sus necesidades de escalabilidad y disponibilidad. � Data Server. A diferencia de los enfoques tradicionales de administración de metadatos, el Data Server de Tableau es un componente clave que per- mite a los administradores de TI habilitar el monitoreo, la administración de metadatos y el control para los equipos de TI, a la vez que se habilitan los análisis de autoservicio para usuarios profesionales. Permite administrar y almacenar fuentes de datos de Tableau de manera centralizada y propor- ciona a los usuarios �nales acceso seguro a datos con�ables por medio de implementaciones de análisis de autoservicio. Usted puede administrar cen- tralizadamente metadatos, como conexiones, controladores y �ltros de fuen- tes de datos, para acceder a los datos. Puede asignar permisos especí�cos a las fuentes de datos de manera que permita al equipo de TI administrar los permisos a las fuentes de datos en función de grupos de identi�cación especí�ca. En un entorno administrado, los usuarios que conocen mejor sus datos también cuentan con la �exibilidad de de�nir y publicar de�niciones, cálculos y grupos. Estos se pueden compartir para que los usen todos los miembros de la organización o los usuarios de Tableau Desktop para crear y aprovisionar sus propios cálculos, de�niciones y grupos. La fuente de datos publicada se puede basar en: ◦ Una extracción del motor de datos de Tableau; ◦ Una conexión en vivo (los cubos no se admiten como conexiones en vivo). � Componente de segundo plano. El componente de segundo plano actua- liza las extracciones programadas, entrega noti�caciones y administra otras tareas de segundo plano. El componente de segundo plano está diseñado para consumir todos los recursos de CPU disponibles a �n de concluir la actividad de segundo plano tan pronto como sea posible. CAPÍTULO 2. MARCO CONCEPTUAL 45 Puerta de enlace/equilibrador de carga. La puerta de enlace dirige solicitu- des a otros componentes. Las solicitudes de los clientes, primero, se encuentran con un equilibrador de carga externo, si se con�gura uno, o la puerta de enlace y, de allí, se los dirige al proceso adecuado. En caso de que no haya un equilibrador de carga externo, si varios procesos se con�guran para cualquier componente, la puerta de enlace actúa como un equilibrador de carga y distribuye las solicitudes hacia los procesos. En una con�guración de un solo servidor, todos los procesos residen en la puerta de enlace o en el servidor primario. Cuando se trabaja en un entorno distribuido, se designa una máquina física como servidor primario, y las otras se designan como servidores de trabajo y pueden ejecutar cualquier cantidad de procesos adicionales. Tableau Server siempre usa una sola máquina como servidor primario. Clientes: navegadores web y aplicaciones móviles. Tableau Server propor- ciona dashboards interactivos a los usuarios mediante HTML5 que no deja rastro en navegadores web o móviles, o de manera nativa mediante una aplicación móvil. No se necesita ActiveX, Java ni Flash para ejecutar informes o visualizaciones. No se requieren complementos ni aplicaciones auxiliares. Tableau Server admite: � Navegadores web: Internet Explorer, Firefox, Chrome y Safari. ◦ Safari para móviles: las vistas optimizadas para la función táctil se pre- sentan automáticamente en Safari para móviles. ◦ Aplicación para iPad: aplicación nativa para iPad que proporciona vis- tas, contenido, navegación y edición optimizados para la función táctil. ◦ Navegador de Android: vistas optimizadas para la función táctil que se ofrecen automáticamente en el navegador de Android. ◦ Aplicación para Android: aplicación nativa para Android que proporcio- na vistas, contenido, navegación y edición optimizados para la función táctil. Clientes: Tableau Desktop. Tableau Desktop es el entorno de creación rápida de análisis de negocios que se usa para crear y publicar vistas, informes y dash- boards en Tableau Server. Mediante Tableau Desktop, un autor de informes puede conectarse a varias fuentes de datos, explorar relaciones, crear dashboards, modi- �car metadatos y, por último, publicar un libro de trabajo completo o una fuente de datos en Tableau Server. Tableau Desktop también puede abrir cualquier li- bro de trabajo publicado en Tableau Server o conectarse con cualquier fuente de datos publicada, ya sea que se haya publicado como una extracción o como una conexión en vivo. Tableau Desktop es compatible con escritorios de Windows y de Mac. Capítulo 3 Marco Metodológico 3.1. Metodología Descendente (TOP-DOWN) Este enfoque Descendente, se recomienda aplicar cuando se tiene un conocimiento previo de la tecnología y las necesidades de la empresa. Se trata de un método sistémico, que disminuye los problemas de integración pero que resulta ser costoso debido a la gran cantidad de datos que debe manejarse y a la poca �exibilidad en esta metodología. Lo esencial es ir desde lo más general a lo más especí�co. Es decir que primero debe formularse un resumen del sistema sin especi�car detalles para luego rede�nir cada parte del sistema con mayor detalle y así sucesivamente hasta que las especi�caciones sean lo más detalladas para validar el modelo. Uno de los elementos que nos ayuda en el diseño son las llamadas �cajas negras�, aunque las mismas no expliquen en detalle los componentes individuales. Una de las principales ventajas de este enfoque radica en que mediante el mismo almacén de datos resultante se enfoca realmente en las necesidades del cliente y por lo tanto su proceso de apoyo al proceso de toma de decisiones es más preciso. Por otro lado, este enfoque tiene como inconveniente principal que aumenta la com- plejidad en la obtención de información para la carga de datos, sobre todo en los casos en los que las fuentes no se encuentran automatizadas. Este enfoque se basa en la visión de Bill Inmon quien considera que el repositorio de datos debe responder a las necesidades de todos los usuarios en la organización y no solo a un pequeño grupo. 3.1.1. Metodología de Bill Inmon Esta metodología fue de�nida por Bill Inmon en el año 1992 en el libro �Building the Data Warehouse� [Inmon, 2002]. En él se proponen los mecanismos necesarios para llevar a cabo la correcta realización de un almacén de datos. B. Inmon presenta dos camino a seguir para la construcción de un almacén de datos. Una metodología y un plan de migración. La metodología describe actividades especí- �cas, y el orden en el que deben ejecutarse las actividades, sin embargo las dinámicas 46 CAPÍTULO 3. MARCO METODOLÓGICO 47 no describen los procesos. Mientras que el plan de migración describe actividades ge- nerales dinámicamente que deben ejecutarse a lo largo de todo el desarrollo. Juntos forman una imagen completa de lo que se requiere para construir el almacén de datos. [Inmon, 2002]. Sobre la metodología, argumenta que los ambientes del almacén de datos son diri- gidos por los datos, en comparación con los sistemas clásicos los cuales tienen un ciclo de vida de desarrollo dirigido por los requerimientos. Mantiene que los requerimientos son el último elemento a ser considerado en el ciclo de vida del proceso de desarrollo del soporte de decisiones, los mismos son �nalmente entendidos luego que el almacén de datos ha sido poblado con datos y los resultados de las consultas han sido analizados por los usuarios [Inmon, 2002]. Uno de los aspectos sobresalientes de la metodología dirigida por los datos es que la misma construye a partir de esfuerzos previos, es decir construye tanto sobre los códigos como de los procesos que han sido desarrollados anteriormente. La única forma en que el desarrollo sobre esfuerzos previos pueda ser completado es mediante el reconocimiento de aspectos comunes. Esto quiere decir que antes que el desarrollador inicie su trabajo, él o ella necesita entender y conocer lo que realmente existe y como se relaciona con el desarrollo del almacén de datos. Esta fase es esencial en la metodología[Inmon, 2002]. B. Inmon fue el primero en de�nir y defender el concepto de almacén de datos, por lo cual se reconoce como el padre del almacén de datos, ve la necesidad de transferir la información de los diferentes Sistemas Transaccionales (OLTP) de las organizaciones a un lugar centralizado donde los datos puedan ser utilizados para el análisis que sería el Corporate Information Factory (CIF). Insiste además en que ha de tener las siguientes características[Kimball, 2010]: Orientado a temas. Los datos en la base de datos están organizados de manera que todos los elementos de datos relativos al mismo evento u objeto del mundo real queden unidos entre sí. Integrado. La base de datos contiene los datos de todos los sistemas operacionales de la organización, y dichos datos deben ser consistentes. No volátil. La información no se modi�ca ni se elimina, una vez almacenado un dato, éste se convierte en información de sólo lectura, y se mantiene para futuras consultas. Variante en el tiempo. Los cambios producidos en los datos a lo largo del tiempo quedan registrados para que los informes que se puedan generar re�ejen esas variaciones. La información ha de estar a los máximos niveles de detalle. Los DWH departamentales o bodega de datos son tratados como subconjuntos de este DWH corporativo, que son construidos para cubrir las necesidades individuales de análisis de cada departamento, y siempre a partir de este DWH Central donde se pueden construir las estructuras Operational Data Stores (ODS) o similares. CAPÍTULO 3. MARCO METODOLÓGICO 48 Los datos son extraídos de los sistemas operacionales por los procesos ETL y carga- dos en las áreas de stage, donde son validados y consolidados en el DWH corporativo, donde además existen los llamados metadatos que documentan de una forma clara y precisa el contenido del DWH. Una vez realizado este proceso, los procesos de refresco de los bodega de datos departamentales obtienen la información de la organización, y con las consiguientes transformaciones, organizan los datos en las estructuras particulares requeridas por cada uno de ellos, refrescando su contenido. Figura 3.1: Enfoque Inmon (Fuente [Kimball, 2010]) La metodología propuesta por B. Inmon explica los resultados que deben obtenerse y el orden en el que deben estar ejecutados los pasos. La manera en la que los resultados sean logrados es un elemento que se deja enteramente a juicio del desarrollador. La metodología se dividió en tres partes componentes, incluye actividades las actividades clásicas necesarias para que sea una metodología dirigida por los datos [Inmon, 2002]. A continuación se de�nirán de manera general los elementos de cada una de las partes, y componentes de la metodología [Inmon, 2002]. 3.1.2. Parte 1: Desarrollo de Sistemas Operacionales Actividades iniciales del proyecto. Se basa en la recolección de cada uno de los requerimientos a través de entrevistas, recopilación de datos. Uso de código y datos existentes. Como la premisa indica, en este elemento debemos considerar todos los elementos reutilizables posibles. Determinación de tamaño y fases. En este punto se divide el proyecto en fases lo más pequeñas y manejables posibles. CAPÍTULO 3. MARCO METODOLÓGICO 49 Formalización de los requerimientos. Asegurar que los requerimientos sean completos, organizados, legibles, comprensibles y a un nivel de detalle que permita ser efectivos. Sobre el modelado de datos o modelo dimensional Diagrama Entidad Relación. A partir de los requerimientos ya de�nidos se de�nen los elementos constitutivos del sistema y la relación de cardinalidad entre ellos. Conjunto de Elemento de Datos (CED). Los CED contiene los atributos de los datos, agrupamiento de los atributos, claves, tipos de datos, conectores y agrupamiento secundario de los datos. Solo los datos primitivos se manejan aquí. Análisis de Desempeño. Este elemento permite pulir los elementos de ingreso y actualización de data haciendo el proceso más e�ciente. Diseño físico de la base de datos. Se obtienen las tablas y bases de datos diseñadas físicamente, luego de transformar todas las consideraciones lógicas de diseño de datos, desempeño, actualización, ingreso, disponibilidad, etc. Sobre el Especi�caciones de Proceso Descomposición Funcional. Es la descripción de todas las actividades a ser realizadas durante el desarrollo desde el nivel alto hasta un nivel bajo. Nivel de Contexto 0. Corresponde a D1, Diagrama Entidad-Relación, en el modelado de datos. Nivel de Contexto 1-n. Los niveles restantes de la descomposición funcional describen más detalladamente las actividades que ocurren, de manera ordenada, organizada, completa y en concordancia con el �ujo de actividades. Diagramas de Flujo de Datos (DFD). Existe un DFD para cada nivel de contexto n, indica la entrada de un proceso, la salida del proceso, el almacena- miento de datos necesario para establecer el proceso y una breve descripción del proceso. Especi�caciones Algorítmicas. Los procesos de cada DFD se dividen en espe- ci�caciones algorítmicas detalladas, tomando en cuenta los aspectos de desempeño que deben ser resueltos en el diseño de los programas. Pseudocódigo. Los algoritmos y especi�caciones de programas se re�nan en pseudocódigo, el cual debe incluir completitud, orden de ejecución, todos los casos requeridos. Corresponde a D4 en modelado de datos. CAPÍTULO 3. MARCO METODOLÓGICO 50 Codi�cación. Construcción del código fuente. La traducción completa y e�ciente de pseudocódigo en código, incluyendo la documentación en código. Caminata. Explicación verbal del código a los colegas, para encontrar y corregir la mayor cantidad de errores posibles antes de las pruebas. Compilación. El código fuente es compilado y se corrigen todos los errores en- contrados. Pruebas unitarias. pruebas del código a diferentes niveles. Implementación. esta etapa incluye actividades como: descarga inicial de datos, conversión de datos, escritura de la documentación y establecimiento de procesos de respaldo. 3.1.3. Parte 2: Desarrollo del almacén de datos Este es el componente de la metodología que se ocupa del desarrollo de sistemas y procesamiento de soporte a la toma de decisiones. Análisis del Modelo de Datos. Con�rmación que el modelo de datos de la organización es sólido y que contiene la identi�cación de los temas de mayor interés, cada tema tiene separada su propia de�nición de datos: subtipos de datos, atributos, relaciones, identi�cación de claves, entre otros. Análisis Breadbox. Permite la determinación del tamaño �estimación bruta- del entorno de los sistemas de soporte de toma de decisiones. Simplemente proyecta, en términos crudos, qué cantidad de datos mantendrá el almacén de datos. Valoración Técnica. Contiene de�niciones técnicas que tienen la habilidad de manejar grandes cantidades de datos, permitir que los datos sean ingresados �exi- blemente, organizar los datos de acuerdo al modelo de datos y tanto recibir como enviar datos a una amplia variedad de tecnologías. Preparación del entorno técnico. Instalación, ubicación y desarrollo de los componentes técnicos que recibirán los datos. Análisis de los temas del almacén de datos. Determinación del tema que será el primero en implementarse. Diseño del almacén de datos. Este subelemento toma en cuenta las siguiente características; acomodación de los niveles de granularidad, orientación de los datos a los principales temas de organización, la ausencia de datos que no apoya al sistema de soporte de las decisiones, desnormalización donde sea aplicable y �nalmente adaptar los datos del entorno operacional al entorno analítico. CAPÍTULO 3. MARCO METODOLÓGICO 51 Análisis de los sistemas fuentes. Identi�cación del sistema de registro, es decir el mapeo de los datos del ambiente operacional al ambiente analítico. Especi�caciones. Aquí veri�ca qué datos operacionales deben ser obtenidos y cómo guardarlos. Programación. Programas de transformación que permitan la extracción, inte- gración y ubicación en perspectiva de tiempo de los datos. Población. Ejecución de los programas desarrollados en las etapas anteriores. Se deben resolver los aspectos de frecuencia de población, reglas de purga, adminis- tración de múltiples niveles de granularidad y refrescamiento. Con este paso �nal se obtiene un almacén de datos poblado y funcional, accesible y comprensible que sirve las necesidades de las comunidades de los sistemas de soporte a la toma de decisiones. 3.1.4. Parte 3: Uso del Almacén de Datos Este último componente describe el uso del almacén de datos para propósitos de análisis. Repetición del desarrollo estándar. Para la obtención de reportes estándares, el procesamiento analítico repetitivo debe seguir el procesamiento normal descrito en la �Parte 1�, exceptuando el modelado de datos, porque la fuente de datos es el mismo almacén de datos. Una vez comentados los elementos constitutivos de cada una de las partes de la metodología vamos a abordar el segundo elemento de la visión de Inmon, el Migration Path [Inmon, 2002] 3.1.5. Plan de Migración (Migration Path) El punto de arranque del plan de migración es el modelo de datos o modelo dimensio- nal. El modelo suele representar las necesidades de la organización, no necesariamente lo que realmente tiene. El modelo dimensional debe representar lo siguiente [Inmon, 2002]: Atributos Las claves Los grupos repetitivos de atributos y claves Conectores entre las áreas de los temas principales Relaciones de subtipos CAPÍTULO 3. MARCO METODOLÓGICO 52 Una vez que se ha de�nido el modelo de datos es necesario de�nir el sistema de registros, el cual se de�ne en términos de los sistemas existentes que la organización ya tiene. La determinación de la mejor fuente de datos se basa en los siguientes criterios [Inmon, 2002]: Datos más precisos Datos más cercanos a la fuente de entrada Datos más cercanos a la estructura del modelado de datos Datos más complejos El siguiente paso consiste en diseñar el almacén de datos. Si el modelo de datos está elaborado correctamente solo se deben cambiar algunos aspectos para hacerlo más �el a un diseño de almacén de datos. Luego del diseño de datos, el siguiente paso es diseñar y construir las interfaces entre el sistema de registro y el almacén de datos, las cuales poblarán el almacén de datos en periodos de tiempo regulares. Entre las actividades que realizan las interfaces tenemos [Inmon, 2002]: Integración de los datos Alteración de las bases de tiempo de los datos Condensación de los datos La etapa �nal de este plan de migración es iniciar la población del almacén de datos con el primer tema de interés. Es importante que sólo una parte del almacén de datos sea poblada, de esta manera cuando surjan los cambios, a partir de los procesos ite- rativos de análisis y reconocimiento de la data, los mismos sean fáciles de manejar e implementar. Una vez que el usuario �nal tiene acercamiento a los datos y proporciona retroalimentación al arquitecto de datos, entonces puede ser sano poblar cantidades mayores de datos. De esta manera podemos ver la relación que establece Inmon entre los dos com- ponentes de su visión. El componente Migration Path es quien dictamina los pasos a ejecutar para el desarrollo del almacén de datos, mientras que el componente de me- todología describe cuáles son los pasos que debe ejecutarse dentro de cada paso del Migration Path. Finalmente, la naturaleza global del enfoque de Inmon hace que su visión resulte más atractiva a la hora de desarrollar un almacén de datos a gran escala, pero para desarrollos de almacén de datos más pequeños, en los que el factor tiempo también es importante, esta metodología no suele resultar tan atractiva. CAPÍTULO 3. MARCO METODOLÓGICO 53 3.2. Metodología Ascendente (BOTTOM-UP) En este enfoque el objetivo, es entregar valor de negocio mediante la implementación del modelo dimensional lo más rápido posible. Los datos se modela en un diseño de esquema en estrella para optimizar la facilidad de uso y rendimiento de las consultas. Se van construyendo bodega de datos relativamente independientes para ir midiendo las ventajas a medida que se va avanzando. A medida que los bodega de datos resultan exitosos se comienzan a enlazar con otros bodega de datos previamente realizados y así sucesivamente hasta que se tiene la completitud del sistema. Las estrategias en la que funcionan el enfoque Ascendente se basan en el conocimiento de todas las variables que traten del sistema El almacén de datos es un conglomerado de todos los bodega de datos dentro de una empresa, siendo una copia de los datos transaccionales estructurados de una for- ma especial para el análisis, de acuerdo al Modelo Dimensional (no normalizado), que incluye, como ya vimos, las dimensiones de análisis y sus atributos, su organización jerárquica, así como los diferentes hechos de negocio que se quieren analizar. Por un lado tenemos tablas para las representar las dimensiones y por otro lado tablas para los hechos ( facts tables). Los diferentes bodega de datos están conectados entre si por la llamada bus structure, que contiene los elementos anteriormente citados a través de las dimensiones conformadas (que permiten que los usuarios puedan realizar querys conjuntos sobre los diferentes bodega de datos, pues este bus contiene los elementos en común que los comunican). Una dimensión conformada puede ser, por ejemplo, la dimensión cliente, que incluye todos los atributos o elementos de análisis referentes a los clientes y que puede ser compartida por diferentes bodega de datos (ventas, pedidos, gestión de cobros, etc)[Kimball, 2010]. Figura 3.2: Enfoque R. Kimball (Fuentes [Kimball, 2010]) Pues al �nal el almacén de datos Corporativo no es mas que la unión de los diferen- tes bodega de datos, que están estructurados de una forma común a través de la bus CAPÍTULO 3. MARCO METODOLÓGICO 54 structure. Esta característica le hace mas �exible y sencillo de implementar, pues pode- mos construir un Bodega de Dato como primer elemento del sistema de análisis, y luego ir añadiendo otros que comparten las dimensiones ya de�nidas o incluyen otras nuevas. En este sistema, los procesos ETL extraen la información de los sistemas operacionales y los procesan igualmente en el área stage, realizando posteriormente el llenado de cada uno de los Bodega de Dato de una forma individual, aunque siempre respetando la estandarización de las dimensiones (dimensiones conformadas) [Kimball, 2010]. Uno de los bene�cio de este enfoque, es que se centra en la creación de estructuras de datos �exibles, fáciles de usar, utilizando modelos de esquema dimensional, estrella. También ofrece un valor rápidamente por que no ofrece una infraestructura pesada en la delantera. Permite automatizar los procesos de carga de data para así simpli�car procesos de mantenimiento y administración de la información. Un problema con un enfoque, es que se requiere que las organizaciones para ha- cer cumplir el uso de dimensiones y hechos estándar para garantizar la integración y entregar una única versión de la verdad. Cuando los bodega de datos se ordenan lógi- camente dentro de una sola base de datos física, esta integración se realiza fácilmente. Pero en una organización distribuida, descentralizada, puede ser demasiado para pedir a los departamentos y unidades de negocio a que se adhieran y reutilizar las referencias y las reglas para el cálculo de los hechos. No puede haber una tendencia a que las organizaciones crear mercados de datos "independiente" o no integrados. Este enfoque se adapta a la visión de R. Kimball quien considera que el factor tiempo a la hora de explotar las bondades de un almacén de datos es un elemento determinante a la hora de decidirse por esta tecnología. Este enfoque parte de los requerimientos de negocio, mientras que el enfoque Descendente deja la validación de requerimientos para el �nal del proceso. 3.2.1. Metodología de Ralph Kimball La implementación de una solución de BI requiere seguir una metodología con un conjunto de actividades relacionadas entre sí, las cuales han de tener un punto especí�co de inicio y de �n. Se tiene que tomar en cuenta en todo momento que la construcción de una solución de BI debe enfocarse directamente en las necesidades de la organización y que los datos presentados al usuario �nal deben ser consistentes. Esta metodología se basa en la interpretación de la frase �Ciclo de Vida�, que suele usarse en el argot computacional para referirse a todos los pasos del proceso de desarrollo de software pero adaptados a la visión de desarrollo de almacén de datos, en ella se describe paso a paso cómo diseñar, desarrollar y desplegar almacén de datos y bodega de datos. El libro también aborda el proceso de construcción de inicio a �n de forma iterativa y también se muestra la utilización de las técnicas del modelado dimensional. En el mismo, R. Kimball se muestra mucho más técnico que los autores anteriores logrando descripciones más detalladas. CAPÍTULO 3. MARCO METODOLÓGICO 55 Figura 3.3: Ciclo de Vida de la Metodología de Ralph Kimball (Fuente [Kimball, 2002]) El diagrama no re�eja una línea temporal absoluta. Mientras que las cajas son igualmente amplia, hay una gran diferencia en el tiempo y esfuerzo que se requiere para cada actividad principal. Sin embargo a partir de la �gura: 3.3 anterior se puede entonces dividir la metodología en [Kimball, 1998]: 3.2.2. Plani�cación del Proyecto En su metodología R. Kimball plantea que los pasos iniciales para el desarrollo de un almacén de datos son la planeación del proyecto y la obtención de requerimientos. Cada elemento cumple funciones determinadas [Kimball, 2002]. Planeación y Gestión del Proyecto. Este es el primer paso que debe llevarse a cabo para poder iniciar el desarrollo del almacén de datos. En este paso se establece la situación actual de la empresa y se elabora un plan para el proyecto, de�niendo el alcance del mismo. Obtención de Requerimientos. Este paso se re�ere a la implementación de los mecanismos necesarios para poder obtener datos de la información que la empresa desea que se manejen en el almacén de datos. Dichos datos son los que le darán sentido al almacén de datos. Los mecanismos a emplear para obtener dicha información van desde entrevistas hasta sesiones con un facilitador. 3.2.3. De�nición de los Requerimientos del Negocio Consiste en plasmar y expresar los requerimientos de los usuarios basándose en las necesidades de la organización. Este levantamiento de información se puede llevar a cabo realizando reuniones, encuestas, entrevistas, o cualquier otro método que permita expresar de una forma clara y no ambigua los requerimientos del cliente. Los requerimientos obtenidos han de documentarse, dado a que no sólo servirá para certi�car que se contempló todo lo que el cliente necesita, sino que también servirá para el grupo de desarrollo conozca las funcionalidades que ha de tener el sistema, lo que se CAPÍTULO 3. MARCO METODOLÓGICO 56 necesita para cumplir con los requerimientos especi�cados, los usuarios involucrados en el proyecto, el léxico que se emplea, entre otras cosas. Como podemos observar 3.3, después de de�nir los requerimientos, se realiza tres actividades de forma concurrente, las cuales se enfocan en la tecnología, los datos y las aplicaciones analíticas. 3.2.4. Diseño de la Arquitectura El diseño técnico sirve como un marco organizativo que soporta la integración de los elementos tecnológicos necesarios para el desarrollo de la solución de inteligencia de negocio. Este diseño permite identi�car los componentes más importantes y minimizar im- previstos al momento de desarrollar e implementar la solución especi�cada, por medio del análisis de las problemáticas que podrían afectar el proceso de desarrollo. Adicional- mente la realización del diseño permite coordinar la ejecución de diversos procesos en paralelo, acelerando de esta forma el desarrollo mediante la utilización de componentes modulares. Con los requerimientos documentados se procede a realizar una estructura básica que soporte las necesidades de la implementación de la arquitectura para así llevar a cabo el desarrollo de la solución de inteligencia de negocio. Una vez especi�cada la estructura elemental para la solución se procede a realizar el diseño especí�co de cada uno de los subsistemas que se encuentran implicados con nuestra solución, es decir, se de�nen los requisitos por cada uno de los componentes con el mayor nivel de detalle posible. También se deben de considerar los requerimien- tos de seguridad, de la infraestructura física y de las necesidades con respecto a la con�guración. Además de considerar los requerimientos funcionales de la solución, se necesita to- mar en cuenta aspectos como la capacidad que debe tener el almacén de datos, la escalabilidad, la �exibilidad y el desempeño de la solución. Es importante establecer las fases del plan de implementación, darle prioridad a los aspectos técnicos de la arquitectura debido a que usualmente no se pueden implementar todos los elementos deseados desde el inicio del proyecto, por esta razón, se deben de�nir cuáles son los aspectos necesarios para la implementación del mismo y cuáles pueden obtenerse luego para aportar un valor agregado a la solución. Para concluir, es necesario documentar el diseño técnico de la arquitectura inclu- yendo las fases del plan de implementación. Este documento debe incluir información pertinente para que los profesionales cali�cados procedan con la construcción de la solución. En la siguiente tabla se resume el modelo de arquitectura que propone R. Kimball. La misma recibe el nombre de marco de trabajo de la arquitectura como vemos en la 3.1 donde las columnas muestran las principales área de la arquitectura: datos, téc- nica e infraestructura y las �las representan los niveles de detalle en orden creciente: requerimientos del negocio, modelo de arquitectura, modelo detallado, implementación. CAPÍTULO 3. MARCO METODOLÓGICO 57 Cuadro 3.1: Marco de trabajo de la Arquitectura Arquitectura de Datos Este nivel abarca tanto el diseño físico y lógico de los modelos de datos. Todo lo relacionado a dicho diseño ya fue explicado en puntos anteriores. Arquitectura Técnica El área de la arquitectura técnica cubre los procesos y herramientas que se aplican a los datos. Esta área está dividida a su vez en dos elementos con sus requeri- mientos y mecanismos propios [Kimball, 1998]: � Back Room: responsable de la obtención y preparación de los datos. �Es el cuarto de máquinas del almacén de datos� . La función principal de este elemento es resolver los problemas de migración y transformación de datos desde las fuentes de datos hasta el entorno almacén de datos. En la arquitectura del back room, se debe analizar los aspectos relativos a: los sitios donde se almacenan los datos (sistemas fuente), los servicios que proporcionará (extracción, transformación, carga) y la administración de los activos del back room (respaldo y recuperación, entre otros). � Front Room: responsable de entregar los datos a los usuarios determinados. La función principal de este elemento es de servir de intermediario entre los usuarios y la información, de manera tal de poder ofrecerle a dichos usuarios lo que necesiten pero sin que los mismos vean las complejidades latentes en dichos procesos. En la arquitectura del front room se deben analizar los aspectos relativos a: los sitios donde se almacenan los datos (herramientas de acceso a los almacenes, entre otros) y los servicios que proporcionarán para el acceso de datos (navegación, acceso y seguridad, administración de consultas, entre otros). Arquitectura de Infraestructura y Metadatos Este apartado se re�ere a las plataformas sobre las cuales se va a cimentar el CAPÍTULO 3. MARCO METODOLÓGICO 58 almacén de datos. La infraestructura incluye el hardware, la red y elementos de bajo nivel que no suelen ser competencia de las otras áreas. Los elementos a tomar en consideración para esta área son: � Los requerimientos del negocio: los cuales son los que determinan la dirección a tomar por parte del almacén de datos. � Los factores de la infraestructura del back room: tamaño de datos, volatilidad de la data, hardware, sistema operativo, entre otros. � Los factores de infraestructura del front room: servidores de aplica- ción, entre otros. � Factores de redes y conectividad: ancho de banda, acceso remoto, co- nectividad a la base de datos, entre otros. 3.2.5. Selección de productos e instalación El producto a seleccionar debe acoplarse al marco de�nido en el diseño de la arqui- tectura, adaptándose a los procesos de la organización. Para seleccionar el producto más apropiado para la solución se debe desarrollar una matriz de evaluación, la cual debe contener los diversos criterios que se deseen analizar. Mientras más especí�cos y detallados los criterios mejor se adapta a los requerimientos necesarios para el desarrollo de la solución. Además de la matriz, es necesario conocer la mayor cantidad de productos posibles que se encuentren en el mercado, para así poder tener más fundamentos al momento de seleccionar un producto en especí�co. Después de realizar dicha evaluación se selecciona el producto que (según los análisis realizados) se adapte mejor para el cumplimiento de los requerimientos funcionales, así como también, de las especi�caciones del diseño técnico de la arquitectura. 3.2.6. Diseño de Datos o modelado dimensional El modelado dimensional, según su creador R. Kimball, es el diseño tanto físico como lógico que se va a encargar de transformar las fuentes de datos, previamente de�nidas en el paso anterior, en estructuras aptas para el almacén de datos. Cada modelo dimensional está compuesto de una tabla que tiene una clave compuesta llamada tabla de hechos y un conjunto de tablas más pequeñas llamadas dimensiones. Cada tabla dimensión tiene una clave primaria simple, que a su vez forma parte de la clave compuesta de la tabla de hechos. Esta descripción se re�ere al esquema estrella explicado en el Capítulo 2. Los pasos necesarios para convertir un Diagrama Entidad-Relación (ERD) a un conjunto de diagramas que se basan en el modelado dimensional son [Kimball, 2002]: Separar el Diagrama Entidad-Relación en procesos �nitos y discretos e ir los modelando por separado. CAPÍTULO 3. MARCO METODOLÓGICO 59 Determinar cuáles serán las tablas de hechos mediante la selección de las relaciones muchos a muchos del modelo que no tengan claves primarias simples. Determinar cuáles serán las tablas de hechos mediante la selección de las relaciones muchos a muchos del modelo que no tengan claves primarias simples. Crear las tablas dimensionales desnormalizando todas las tablas y añadiéndoles claves primarias simples. De�nir también las tablas dimensionales conformadas que son aquellas que sirven de dimensión a más de una tablas de hechos. Se fundamenta en las siguientes ventajas para proponer el modelado dimensional [Kimball, 2002]: Soporta cambios inesperados en el comportamiento del usuario. Es capaz de crecer y extenderse para aceptar nuevos elementos de datos y de diseño. Otros elementos que se toman en cuenta dentro del aspecto del modelado dimensional son [Kimball, 2002]: Arquitectura de Bus del almacén de datos La arquitectura del bus de almacén de datos se basa en la idea que un almacén de datos está compuesto por muchos bodega de datos. Cada Bodega de Dato a su vez debe estar representado dentro de un modelo dimensional y compuesto por tablas de hechos y tablas dimensionales [Kimball, 2002]. Por lo tanto el autor plantea que es necesario al principio del proyecto de�nir una arquitectura estricta y �nita de datos sobre la cual se desarrollará el almacén de datos. Posteriormente, y basándose en la arquitectura previamente de�nida, deben irse construyendo los bodega de datos. R. Kimball explica que �cada Bo- dega de Dato para que sea práctico debe ser basado en los datos más granulares (atómicos) que sea posible colectar y almacenar� [Kimball, 2002]. La correcta adherencia entre un Bodega de Dato y otro se consigue a través de las tablas dimensionales conformadas, ya que a través de ellas se logra [Kimball, 2002]: � Una tabla dimensional solo puede ser usada contra múltiples tablas de hechos en el mismo espacio de base de datos. � Las interfaces de usuario y los datos que contienen son consistentes en cual- quier instante en que se utilice la dimensión. � Existe una interpretación consistente de los atributos en cada Bodega de Dato. � A partir de lo anteriormente expuesto podemos entender que las dimensiones conformadas son las que hacen de bus en el almacén de datos. Por lo tanto, al de�nir una interfase estándar de bus (mediante dimensiones conformadas) un nuevo Bodega de Dato puede añadirse al almacén de datos y coexistir con los otros sin ningún inconveniente. CAPÍTULO 3. MARCO METODOLÓGICO 60 A partir de lo anteriormente expuesto podemos entender que las dimensiones conformadas son las que hacen de bus en el almacén de datos. Por lo tanto, al de�nir una interfase estándar de bus (mediante dimensiones conformadas) un nuevo Bodega de Dato puede añadirse al almacén de datos y coexistir con los otros sin ningún inconveniente. Elementos del Modelado Dimensional Los siguientes son elementos esenciales para el Modelado Dimensional: � Hechos: un hecho es una observación del mercado de trabajo. � Atributos: usualmente son campos de texto que describen las características de algo tangible, como las descripciones del producto. � Dimensiones: se re�ere a los atributos que describen al objeto y que a su vez se correlacionan entre ellos. Método de Diseño de cuatro pasos para diseñar una tabla de hechos Los siguientes son pasos necesarios para un diseño lógico de un esquema dimen- sional: � Escoger el bodega de datos. Como se desea en primera instancia mantener un nivel de simplicidad adecuado entonces es recomendable en lo posible escoger una única fuente de datos para el bodega de datos. � Declarar la granularidad de la tabla de Hechos. Consiste en de�nir qué se considera una tabla de hechos para el diseño dimensional que se propone. � Escoger las dimensiones. escoger, en lo posible, aquellas dimensiones que sean capaces de tomar un valor único en el contexto de un conjunto dado de medidas del negocio. � Escoger los hechos. Los hechos deben ser siempre especí�cos a la granula- ridad de la tabla de hechos. No se deben hacer manipulaciones convenientes a otros cálculos porque eso podría afectar la naturaleza del hecho. Construcción de Modelos Dimensionales R. Kimball concibe cada bodega de datos como un modelo dimensional separado y el conjunto de modelos dimensionales constituye el diseño lógico del almacén de datos. Para la construcción de los bodega de datos R. Kimball propone emplear un enfoque Ascendente al que llama Matriz de Arquitectura del almacén de datos, en el cual se identi�can todos los bodega de datos que se puedan construir y a su vez todas las dimensiones que implican a cada bodega de datos, posteriormente se deben relacionar ambos elementos para así de�nir cuáles dimensiones podrán ser utilizadas por más de un bodega de datos. Dichas dimensiones pasarán a formar el denominado Bus de almacén de datos. En la siguiente etapa, una vez que se han identi�cado los bodega de datos a cons- truir junto con sus respectivas dimensiones, se procede a realizar los diseños físicos CAPÍTULO 3. MARCO METODOLÓGICO 61 y lógicos de las tablas individuales usando el método de cuatro pasos explicado anteriormente. Con todos estos elementos se podrá elaborar entonces un borrador inicial del sistema el cual permitirá identi�car los hechos base y los hechos derivados que deberán ser incluidos y así pulir el modelo para adaptarlo mejor a las característi- cas y exigencias del negocio. En este proceso se podrán realizar todos los cambios necesarios, los cuales deben estar debidamente documentados, junto a todas las decisiones que se realicen, desde elegir las fuentes de datos hasta determinar las fórmulas de cálculo de los hechos derivados y demás. 3.2.7. Especi�cación y desarrollo de aplicaciones analíticas Como se puede apreciar en la 3.3, la especi�cación y el desarrollo de las aplicaciones analíticas se realiza después de obtener los requerimientos del negocio. Para realizar las especi�caciones de las aplicaciones analíticas debemos llevar a ca- bo un análisis de los diversos productos existentes en el mercado, buscando siempre aquel que se adapte mejor a lo que se requiere para satisfacer las necesidades de la organización. En la fase de desarrollo de las aplicaciones analíticas es necesario establecer con- venciones con respecto a los nombres, cálculos, librerías y codi�caciones para evitar rehacer trabajo a futuro. Esta actividad puede iniciarse una vez que el diseño de la base de datos esté completo, las herramientas de acceso a los datos y metadatos estén instaladas y los datos históricos hayan sido cargados al almacén. 3.2.8. Implementación En esta fase de la metodología es necesario contemplar todos aquellos factores que durante fases iniciales y de diseño no fueron contempladas. A nivel del diseño lógico se debe realizar una última revisión sobre el diseño lógico para determinar cuáles hechos deben ser agregados con respecto a qué dimensiones para mejorar así el rendimiento del almacén de datos. A nivel del diseño físico el mismo debe culminarse. La secuencia básica es iniciar con elementos de planeación, que se re�eren a establecer estándares de nomenclatura, de bases de datos, estrategias de seguridad, entre otros. Luego, a partir del estado del diseño físico, realizar un corte preliminar en el tamaño de la base de datos y su respectiva tasa de crecimiento. Al mismo tiempo, cuando se tienen ya de�nidas todas las tablas, se debe hacer un corte para la estrategia de establecimiento de índices. A partir de este momento se puede dar por concluido el diseño físico y se puede iniciar realmente el proceso de implementación pues se cuenta con su�ciente información acerca de lo que ocurre en la base de datos en sus mínimos detalles. Posteriormente quedarían pendientes dos elementos dentro de esta fase de la meto- dología: la consolidación de datos y construir aplicaciones al usuario �nal. CAPÍTULO 3. MARCO METODOLÓGICO 62 Sobre la consolidación de datos R. Kimball propone dividir este proceso en un plan de 10 pasos para conseguir con éxito el proceso de consolidación de los Datos en el almacén de datos [Kimball, 1998]: Plan � Crear un esquema de alto nivel, muy consolidado, del �ujo de fuente a des- tino. � Probar, escoger e implementar la herramienta de consolidación de datos. � Bosquejar grá�camente cualquier reestructuración o transformación de datos compleja. Carga de Dimensiones � Construir y probar la carga de una tabla de dimensión estática. � Construir y probar el proceso de cambio lento para una dimensión. � Construir y probar la carga de las dimensiones faltantes. Tablas de hechos y automatización � Construir y probar la carga de las tablas de hechos históricas. � Construir y probar el proceso de carga incremental. � Construir y probar la carga de las tablas de agregaciones. � Diseñar, construir y probar las aplicaciones de automatización del proceso de conciliación. Debido a que en esta etapa deben cuidarse todos los detalles de data y los inherentes a la implementación entonces suele considerarse que la etapa de conciliación de datos es una de las más complicadas en el proceso de desarrollo de un almacén de datos. Sobre la construcción de aplicaciones de usuario �nal, este proceso está relacionado a la herramienta que se vaya a emplear para el acceso a los datos y por lo tanto deberá brindar soporte a los usuarios con requerimientos de análisis tanto de�nidos como improvisados. 3.2.9. Despliegue y Crecimiento Un despliegue exitoso de un almacén de datos requiere: Planeación del despliegue �Despliegue es la convergencia de tecnología, datos y aplicaciones en los escritorios de los usuarios de negocios, junto con la necesaria educación y estructura de soporte al usuario� [Kimball, 1998]. CAPÍTULO 3. MARCO METODOLÓGICO 63 La planeación del despliegue se puede dividir en varias partes. En una de ellas se determina la disponibilidad de los escritorios de los usuarios para su instalación, en otra parte se desarrolla una estrategia para educar al usuario �nal sobre la mejor manera de explotar las bondades del almacén de datos. El desarrollo de un plan para brindar soporte al usuario �nal sobre el uso de la herramienta es fundamental para cimentar el proceso de aprendizaje y así garantizar el éxito del proyecto. Un último elemento a ser tomado en consideración es el desarrollo de un marco de trabajo para la emisión del despliegue. Cada emisión estará de�nida dentro de nuevos requerimientos que vayan añadiéndose al almacén de datos o nuevos grupos de usuarios que vayan a hacer uso del mismo. Es importante que cada emisión de despliegue esté debidamente documentada. Mantenimiento y Crecimiento del almacén de datos Este el último componente dentro de la metodología propuesta por R. Kimball. Este apartado se basa en la constante retroalimentación que deberá existir entre los usuarios �nales y el equipo técnico de forma de poder medir y proyectar el éxito del proyecto y también gestionar adecuadamente las operaciones del almacén de datos. 3.3. Metodología a seguir Desde un estudio de las dos metodología, se puede establecer una serie de compa- raciones, descritas en la tabla 3.2 Cuadro 3.2: Comparación de las metodologías Bill Inmon plantea que el desarrollo de la solución tiene de ser descendente es decir que se debe realizar primero el almacén de datos que abarque toda la estructura de CAPÍTULO 3. MARCO METODOLÓGICO 64 la organización, pasando por un proceso de integración y puri�cación de los datos. Posteriormente se generan la bodega de datos que serán subconjuntos del almacén de datos que se crean a partir de agrupaciones lógicas existentes, como por ejemplo agrupar los elementos que tienen que ver con el área de ventas y generar una bodega de datos. Ralph Kimball plantea que el desarrollo de la solución se tiene que realizar de manera inversa a la ofrecida por Inmon, puesto que se basa en la construcción de las bodegas de datos departamentales, para luego hacer su integración en un almacén de datos que abarque toda la organización, este tipo de diseño se denomina �Ascendnete�. Ralph establece que la complejidad de las organizaciones di�culta la realización de una solución inicial que abarque toda la organización. Por lo que la realización de bodega de datos que apoyen los procesos organizacionales especí�cos, es un mejor comienzo para el desarrollo de una solución. Eventualmente, a medida que se van construyendo más bodega de datos, estos pueden conectarse por elementos en común (atributos, dimensiones, etc) por lo que se va generando una solución que va abarcando íntegramente la organización. La metodología Kimball es idónea cuando se está empezando a desarrollar una infraestructura de inteligencia de negocio, porque se puede desarrollar mercado de datos los cuales tienen una complejidad menor e instaurar una solución de negocios completa sobre un área determinada. Esto ayuda a que el proyecto pueda ser puesto en producción de forma rápida que si se compara con Inmon, lo cual ayuda a la organización a recuperar su inversión más rápido. La metodología a seguir en una adaptación a la metodología de Kimball que se muestra en la �gura 3.4 en cuando a una solución de inteligencia de negocio, ya que la metodología busca es el desarrollo de un almacén de datos, cuando se realiza su adaptación es incorporarle un componente de manipulación de la información. Figura 3.4: Ciclo de vida dimensional adaptado a inteligencia de negocio Capítulo 4 Marco Aplicativo Para cumplir con los objetivos plateados, la solución de BI para la Coodrinación de Investigación se realizó empleando una adaptación a la metodología de Ralph Kimball. La descripción de las actividades realizadas a lo largo del proceso de desarrollo de la solución de inteligencia de negocio, usando la metodología seleccionada, se exhiben a continuación. 4.1. Plani�cación del Proyecto Como en todo proyecto software, es necesario realizar una plani�cación del mismo parar tratar de garantizar que el desarrollo, se realizara según las siguientes actividades previstas: Levantamiento de la información. De�nición de indicadores de gestión. Diseño de modelo dimensional. Implementación del almacén de datos. Implementación de las consultas analíticas y reportes. Elaboración de la implementación Pruebas a la aplicación. El mayor tiempo del proyecto se destina al modelo dimensional, fase que agrupa cuatro subtareas que son: De�nir el modelo de negocio, De�nir el grano, Elegir las dimensiones, Identi�car los hechos. En la tabla 4.1 se de�ne con detalle cada una de las fases del proyecto que se desarrolla. 65 CAPÍTULO 4. MARCO APLICATIVO 66 Cuadro 4.1: Plani�cación del proyecto Se realizó un análisis de la base de datos de los proyectos de investigación de la Facultad de Ciencias para poder determinar los elemento de los proyectos, productos, eventos, área de conocimiento, la formación de los investigadores, entre otros. Es decir lo que se desea conocer. Con la investigación realizada se logró establecer un modelo de constelación del proceso estudiado, así como también, se logró de�nir una serie reportes y de indicadores, facilitar la toma de decisiones en la Coordinación de Investigación de la Facultad de Ciencias. 4.2. De�nición de los Requerimientos Bajo la perspectiva de seguimiento de proyectos de investigación, abstrayéndonos de las variantes que pudieran implementarse en el mismo, para poder generar bene�cios a la organización necesitan poder monitorear los proyectos, productos, eventos y el nivel académico en términos generales, entre otros. Para facilitar a la Coordinación de Investigación la obtención de información rápida, precisa y de calidad para saber de ellos. Por esta razón basándonos en lo que se desea saber, se contempló una serie de reportes y indicadores de la coordinación para apoyar en la toma de decisiones. Se muestran a continuación: 1. Conteo de productos de los investigadores, por área de conocimiento, área de aplicación, institución, y la fecha de publicación de dicho producto. 2. Conteo de proyectos de los investigadores, por área de conocimiento, área de aplicación, institución, y la fecha que inicia y �naliza un proyecto. 3. Conteo de eventos de los investigadores, por área de conocimiento, institución, y la fecha en que inicia y �naliza el evento. 4. Saber el Nivel académico de los investigadores, por institución, y fecha de titula- ción. CAPÍTULO 4. MARCO APLICATIVO 67 Para poder desarrollar los indicadores y reportes referentes a los requerimientos contem- plados para la solución de inteligencia de negocio propuesta para un modelo de gestión de los proyectos de la Coordinación de Investigación, es necesario especi�car cómo se puede obtener lo deseado. Se realiza un análisis de los indicadores, especi�cando las fórmulas utilizadas para calcularlos. 4.3. Diseño de la Arquitectura Técnica El diseño de la arquitectura implementado para la solución de inteligencia de negocio se expone en la �gura 4.1. Figura 4.1: Arquitectura de Diseño La arquitectura implementada está conformada por cuatro (4) componentes y di- versos procesos y elementos que permiten llevar a cabo el �ujo de trabajo de la misma: 1. Se presentan las fuentes de datos que es la base de datos de la coordinación, que se considera para la solución de inteligencia de negocio. Estos datos pueden provenir de fuentes internas y/o externas, usualmente se emplean aquellos almacenados en los sistemas transaccionales y en archivos utilizados por la organización. 2. Es el proceso de extracción, transformación y carga que se ejecutará periódica- mente, se procede a almacenar los datos de las fuentes de datos en el almacén de datos. 3. La estructura del almacén de dato que permite llevar a cabo la obtención de los datos requeridos por el usuario con un alto rendimiento. 4. El ultimo componente se re�ere a la capa de presentación, es decir, a las herra- mientas de acceso a los datos que hacen uso del almacén de datos para permitir a los usuarios visualizar y analizar los distintos indicadores y reportes contemplados para la solución de inteligencia de negocio CAPÍTULO 4. MARCO APLICATIVO 68 4.4. Selección de Productos e Instalación El proceso de selección de una herramienta tecnológica puede llegar a ser complejo debido a las múltiples alternativas existentes en el mercado (Oracle BI, Pentaho BI, IBM Cognos, MicroStrategy, entre otros) y a la diversa gama de funcionalidades que cada herramienta brinda. Después de realizar un análisis de las distintas herramientas existentes en el mercado, se decidió utilizar para el desarrollo de la solución de inteligencia de negocio planteada para el modelo, la herramienta a utilizar para realizar la extracción , transformación y carga de los dato (ETL) es Data Integration (kettle), PostgreSQL para la construcción del almacén de datos y la herramienta de acceso y visualización de los datos Tableau como podemos ver en la �gura 4.2. Figura 4.2: Arquitectura de Diseño con sus herramientas Entre las razones por las que se utilizó Tableau para el desarrollo de la solución de inteligencia de negocio se enumeran a continuación: Usabilidad de la herramienta enfocada a los usuarios �nales e inexpertos. No es necesario tener conocimientos técnicos ni de programación como para poder usar la herramienta. La instalación y con�guración de la herramienta es sencilla y no requiere de co- nocimientos técnicos. Se cuenta con expertos en el área técnica dispuestos a dar asesoramiento y soporte. Existe una amplia documentación sobre tableau. CAPÍTULO 4. MARCO APLICATIVO 69 4.5. Modelo Dimensional El diseño del modelo dimensional se realizó basándose en los requerimientos de�- nidos, se de�nió en un modelo tipo estrella para los proyectos de investigación, éstos fueron analizados para determinar qué elementos podrían considerarse como hechos o dimensiones que pudieran formar parte de la solución de inteligencia de negocio. Para poder saber que hechos y dimensiones son necesarios para poder realizar la solución planteada, se desglosó uno a uno los requerimientos haciendo hincapié en de- terminar lo que se quería medir y bajo qué perspectivas se deseaba ver. Los hechos medibles que se tomaron en cuenta para la solución planteada son los elementos o indicadores que se quieren saber en la Coordinación de Investigación, éstos son: Conteo de proyectos. Conteo de productos. Conteo de Eventos. El Nivel Académico de los investigadores Así como se contemplaron los hechos, el análisis indico las diversas perspectivas con los cuales se desearía o se pudiera agrupar los datos. Indicó como se identi�caron las distintas dimensiones que se contemplan en la solución y se mencionan a continuación: Tiempo. Investigador. Área de Conocimiento. Área de Aplicación. Institución. Proyectos. Producto. Evento. Nivel Académico. Con los elementos expuestos anteriormente se construyo el modelo dimensional tipo estrella como se muestra en la �gura 4.3. CAPÍTULO 4. MARCO APLICATIVO 70 Figura 4.3: Modelo Dimensiona tipo estrella Una vez de�nidas las perspectivas a utilizar y los hechos a medir en la solución propuesta, se procedió a identi�car por cada dimensión los atributos y las jerarquías que se consideraron para poder cumplir con los objetivos planteados. Una vez establecida las dimensiones, puede establecerse las distintas jerarquías aso- ciadas a ella. Entendiendo que las jerarquías van a permitir navegar sobre los distintos niveles lógicos existentes. En la �gura 4.4 se observan las jerarquías establecidas para cada una de las dimensiones. Figura 4.4: Jerarquía de las dimensiones La jerarquía en cada dimensión se de�ne dependiendo de lógica del negocio. Una vez de�nidos los niveles jerárquicos para cada dimensión contemplada para la solución de inteligencia de negocio propuesta, se de�nen los atributos necesarios para cumplir con los requerimientos planteados. CAPÍTULO 4. MARCO APLICATIVO 71 A continuación se describen todas las dimensiones y la tabla de hecho contempladas para la solución de inteligencia de negocio para un modelo tipo estrella de los proyectos de investigación: Dimensión Tiempo. Permite ver los proyectos de investigación en función del momento en que se crea, termina un proyecto. Por esto, dicha dimensión tomara distintos roles como la fecha de inicio y fecha �n en el modelo dimensional. Una característica particular de la dimensión tiempo es que son generadas todas las fechas acorde a un período de tiempo en el proceso de ETL, para luego asociar las fechas especí�cas a las ocurrencias en las instancias. Esta forma de trabajo permite generar en los cuadros de mandos calendarios porque se poseen todas las fechas, para posteriormente solo obtener los proyectos a partir de un rango de fechas establecido. La tabla 4.2 muestra los atributos de la dimensión tiempo. Cuadro 4.2: Dimensión Tiempo Dimensión Investigador. Permite ver el investigador con sus atributos que lo de�nen como se muestra en la �gura 4.5. CAPÍTULO 4. MARCO APLICATIVO 72 Cuadro 4.3: Detalle de la Dimensión Investigador Dimensión Institución. Permite ver la institución con sus atributos que los de�nen como se muestra en la �gura 4.5. Cuadro 4.4: Dimensión de Institución CAPÍTULO 4. MARCO APLICATIVO 73 Dimensión de Área de Conocimiento. Permite ver el área de conocimiento con sus atributos que lo de�nen como se muestra en la �gura 4.5 . Cuadro 4.5: Dimensión de Área de Conocimiento Dimensión de Área de aplicación. Permite ver el área de aplicación con sus atributos que lo de�nen como se muestra en la �gura 4.5 . Figura 4.5: Dimensión de Área de aplicación Dimensión Proyecto. Permite ver el proyecto con sus atributos que lo de�nen como se muestra en la �gura 4.6 . Cuadro 4.6: Dimensión de Proyecto CAPÍTULO 4. MARCO APLICATIVO 74 Dimensión Producto. Permite ver el producto con sus atributos que lo de�nen como se muestra en la �gura 4.7 . Cuadro 4.7: Dimensión de Producto Dimensión Evento. Permite ver el evento con sus atributos que lo de�nen como se muestra en la �gura 4.8 . Cuadro 4.8: Dimensión de Evento Dimensión Nivel Académico. Permite ver el nivel de académico con sus atri- butos que lo de�nen como se muestra en la �gura 4.9 . CAPÍTULO 4. MARCO APLICATIVO 75 Cuadro 4.9: Dimensión Nivel Académico Tabla de Hecho investigación. El modelo dimensional tipo estrella busca la representación de los proyectos de investigación. Por tanto la medida en el modelo dimensional descrito anteriormente es la incidencia de un hecho (tabla de hechos sin hechos) es llamado FACTLESS y no medidas especí�cas. Por tanto la tabla de hechos, como se observa en la tabla 4.10 está conformada por un conjunto de claves foráneas que enlazan al hecho con las dimensiones, una clave que identi�ca unívocamente ese hecho y un atributo medida con valor por defecto 1, que ayuda a comprender que cada instancia tiene el mismo valor. Cuadro 4.10: Tabla de Hecho Gestión de los proyectos Ya con la de�nición del modelo dimensional tipo estrella, contempla la solución de inte- ligencia de negocio y con los hechos necesarios para cumplir con los objetivos trazados, CAPÍTULO 4. MARCO APLICATIVO 76 se realizó la elaboración del modelo dimensional de�nitivo que puede apreciarse. Figura 4.6: Modelo de�nitivo tipo estrella 4.6. Diseño físico Una vez que se de�nió la arquitectura, las herramientas y el modelo dimensional a utilizar en la solución de inteligencia de negocio se continuó con la realización del diseño físico. El almacén de datos se desarrolló físicamente usando PostgreSQL y basándose en el modelo dimensional realizado y descrito con anterioridad. En la primera instancia, usando PostgreSQL, se de�nieron cada una de las dimen- siones contempladas en el modelo dimensional, estableciendo inicialmente el nombre de la dimensión, luego sus atributos y por último sus niveles jerárquicos. Para crear la dimensión tiempo se utilizó Data Integration de Pentaho que permite generar está dimensión. En este caso se especi�có el nombre que se deseaba para dicha dimensión y los atributos a considerar (ano, mes y día) a partir del año 2000, de esta forma la herramienta se generó las fechas con su respectiva jerarquía como vemos en la �gura 4.7. CAPÍTULO 4. MARCO APLICATIVO 77 Figura 4.7: Dimensión Tiempo Una vez completado dicho diseño se realizó el despliegue del mismo usando Post- greSQL herramienta seleccionada, de esta forma se crearon todas tablas y elementos que componen el almacén de datos propuesto para la solución de inteligencia de negocio. Figura 4.8: Diseño lógico de las dimensiones CAPÍTULO 4. MARCO APLICATIVO 78 Cabe destacar que al crear las tablas para el almacén de datos, se agregaron una serie de campos o columnas necesarias para el correcto funcionamiento de las distintas aplicaciones. Estos campos adicionales no inter�eren de ninguna manera con el modelo dimensio- nal propuesto para la solución de inteligencia de negocio, tanto los requerimientos como los objetivos establecidos pueden cumplirse aún con las modi�caciones de las dimen- siones, que son los atributo que tienen por nombre (versión, fecha inicio, fecha_�n). Como vemos en �gura 4.9 Figura 4.9: ETL de la Dimension Investigador El resultado del despliegue del modelo dimensional realizado puede apreciarse en la �gura 4.10 CAPÍTULO 4. MARCO APLICATIVO 79 Figura 4.10: Modelo dimensional 4.7. Diseño y Construcción de procesos ETL Dado a la arquitectura propuesta se contempla (la base de datos, y el almacén de datos), fue necesario elaborar procesos ETL para las extraer los datos de la base de datos de la coordinación. Un proceso capaz de permitir el llenado del almacén de datos usando como fuente de datos la base de datos. Dichos procesos se muestra a continuación. 4.7.1. Diseño de Procesos de ETL y Desarrollo (almacén de datos) El diseño de los procesos de extracción, transformación y carga para el almacén de datos se realizó utilizando la herramienta Data Integration de Pentaho (kettle). El proceso de ETL para cada una de la dimensiones, es similar al mostrado en la �gura 4.11. Figura 4.11: ETL de Dimensión Investigador El proceso de construcción de los ETL, para el llenado de la única tabla de hecho llamada hechos investigación, conllevan a un conjunto de elementos adicionales que CAPÍTULO 4. MARCO APLICATIVO 80 serán descritos a continuación. Es requerido usar las dimensiones del almacén de datos, y extraer los hechos que se quieren analizar de la fuentes de datos, en nuestro caso la fuente es solo una base de datos. Figura 4.12: ETL de los Hechos del nivel académico a la Tabla de Hecho de investigación Como vemos en la �gura 4.12, a partir del uso de la tabla relacional BD_TABLA _USUARIO_ESTUDIO, se van realizando una serie de uniones para asociar el con- junto de dimensiones. Esto porque una instancia de la tabla BD_TABLA_USUARIO _ESTUDIO, representa el nivel de granularidad asociado al modelo dimensional tipo estrella, lo que implica que se requiere ir agregando las claves asociadas a las dimensiones que caracterizan esa acción correctiva en particular. Una vez realizado todas las transformaciones o ETL, se creara el �ujo del proceso es decir el job que ejecutara todos los procesos según el �ujo se crea como vemos en la �gura 4.13 CAPÍTULO 4. MARCO APLICATIVO 81 Figura 4.13: El llenado del almacén de datos 4.7.2. Veri�car la calidad de los datos Una vez se ha realizado la inserción de los datos en el almacén de datos, es necesario comprobar que la carga ha sido correcta y que el almacén de datos representa de forma acertada los datos del modelo dimensional, para esto se realiza la veri�cación consistente en la aplicación de un conjunto de consultas en ambos ambientes y que estén cargados de forma adecuados los datos del modelo relacional de la base de datos fuente. Se muestra la comparación de cada elemento del modelo dimensional que se encuentre relacionado con la base de datos. Dimensión investigador. Se extraer los datos del usuario que solo tienen el roll investigador, se muestra en la �gura 4.14 los primeros 19 registros de ambas tablas y la consulta de la cantidad de valores existentes en cada una de las tablas como vemos en la �gura4.15. Figura 4.14: Veri�cación de la dimensión investigador CAPÍTULO 4. MARCO APLICATIVO 82 Figura 4.15: Veri�cación de la cantidad de los datos de la dimensión investigador Dimensión área de conocimiento. Esta compuesta por tres tablas en la base de datos, que es la tabla disciplina, subárea de conocimiento y área de conocimiento. Donde podemos ver las primeras nueve �las de ambas tablas y la cantidad de valores existentes en cada una de las tablas. Figura 4.16: Veri�cación de la dimensión área de conocimiento Figura 4.17: Veri�cación de la cantidad de datos de la dimensión área de conocimiento Dimensión área de aplicación. Dicha dimensión esta compuesta de dos tablas de las base de datos, que es la tabla de subárea de aplicación, y área de aplicación. CAPÍTULO 4. MARCO APLICATIVO 83 Figura 4.18: Veri�cación de la dimensión área de aplicación Figura 4.19: Veri�cación de la cantidad de datos de área de aplicación Dimensión institución. Esta compuesta de tres tabla a partir de la dependencia, facultad, y institución. Figura 4.20: Veri�cación de la dimensión institución CAPÍTULO 4. MARCO APLICATIVO 84 Figura 4.21: Veri�cación de la cantidad de datos de la dimensión institución Dimensión proyecto. La validación de los datos se ha realizado observando la tabla de proyecto. Figura 4.22: Veri�cación de la dimensión proyecto Figura 4.23: Veri�cación de la cantidad de datos de la dimensión proyecto Dimensión producto. La validación de los datos se ha realizado observando los productos y su tipo. CAPÍTULO 4. MARCO APLICATIVO 85 Figura 4.24: Veri�cación de la dimensión producto Figura 4.25: Veri�cación de la cantidad de datos de la dimensión producto Dimensión evento. La validación de datos se ha realizado observando los eventos en función de su nombre y tipo de evento. Figura 4.26: Veri�cación de la dimensión evento CAPÍTULO 4. MARCO APLICATIVO 86 Figura 4.27: Veri�cación de la cantidad de datos de la dimensión evento Dimensión nivel académico. La validación de los datos se ha realizado obser- vando la tabla de grado académico, y nivel académico Figura 4.28: Veri�cación de la cantidad de datos de la dimensión nivel académico Figura 4.29: Veri�cación de la cantidad de datos de la dimensión nivel académico Dimensión tiempo. La dimensión no requiere una veri�cación de datos con respecto a la base de datos, sin embargo puede con�rmarse que los datos son consistentes en función de una fecha. CAPÍTULO 4. MARCO APLICATIVO 87 Figura 4.30: Veri�cación de datos de la dimensión tiempo 4.7.3. Veri�cación de la calidad de los datos de los componentes del modelo implementado Adicionalmente a la veri�cación de los datos por tabla, se ha realizado una veri- �cación para comprobar que efectivamente los datos del modelo relacional han sido transformados y cargados en el modelo dimensional tipo estrella, ya que existe una única tabla de hechos. Para esto hay que comprender que la realización del modelo de estrella, la tabla de hecho y dimensiones, generan nueva clave primaria llamada clave subrogada para el registro de cualquier elemento. Por lo que, la inserción de dicho elemento en la tabla de hechos conlleva a que se haga una relación a partir de estas claves generadas en el proceso ETL. La veri�cación del modelo estrella implica comprobar que las distintas claves subrogadas en la tabla de hecho, corresponden efectivamente a los datos que se quiere enlazar en las distintas dimensiones. Se realiza del modo que la tabla de hecho se relaciona con una dimensión, y está se encuentra relacionada con ella en la base de datos. 4.7.3.1. Veri�cación de la tabla de hecho investigación con sus dimensiones Como es un modelo dimensional tipo estrella, todas las dimensiones se relacionan con la tabla de hechos. Así que se realiza la veri�cación de esas tablas con la tabla de hecho investigación. Dimensión tiempo. Para la comprobación de que efectivamente se están repre- sentando los datos del modelo relacional con respecto a la dimensión tiempo. Se muestra un registro de la tabla de proyecto de la base de datos de la fecha de inicio y de �n del proyecto y la tabla de hecho producto con eso mismo valor CAPÍTULO 4. MARCO APLICATIVO 88 asociado una clave subrogada de la dimensión tiempo. Figura 4.31: Comparación de los dato del modelo con la dimensión tiempo Dimensión proyecto. Para la comprobación de dicha dimensión se realiza dado unos registros como en la �gura 4.33, sus valores en la dimensión y su veracidad como en la �gura 4.32 en la base de datos. Figura 4.32: Proyecto en la base de datos CAPÍTULO 4. MARCO APLICATIVO 89 Figura 4.33: Dimensión proyecto con la tabla de hecho investigación Dimensión área de conocimiento. Para la comprobación de dicha dimensión se realiza unos registros como en la �gura 4.34, sus valores en la dimensión y su veracidad como en la �gura 4.35 en la base de datos. Figura 4.34: Dimensión área de conocimiento con la tabla de hecho investigación Figura 4.35: Área de conocimiento en el almacén de datos CAPÍTULO 4. MARCO APLICATIVO 90 Dimensión área de aplicación. Para la comprobación de dicha dimensión se realiza unos registros como en la �gura 4.37, sus valores en la dimensión y su veracidad como en la �gura 4.36 en la base de datos. Figura 4.36: Subárea de aplicación en la base de datos Figura 4.37: Dimensión área de aplicación con la tabla de hecho investigación Dimensión institución. Para la comprobación de dicha dimensión se realiza unos registros como en la �gura 4.39 , sus valores en la dimensión y su veracidad como en la �gura 4.38 en la base de datos. CAPÍTULO 4. MARCO APLICATIVO 91 Figura 4.38: Dependencia en la base de datos Figura 4.39: Dimensión institución con la tabla de hecho investigación Dimensión investigador. Para la comprobación de dicha dimensión se realiza dado unos registros como en la �gura 4.41, sus valores en la dimensión y su veracidad como en la �gura 4.40 en la base de datos. Figura 4.40: Usuario en la base de datos CAPÍTULO 4. MARCO APLICATIVO 92 Figura 4.41: Dimensión investigador con la tabla de hecho investigador 4.7.3.2. Detallar los requerimientos según el modelo Desde el estudio del modelo dimensional, que plasma los datos relevantes de la base de datos, especí�camente los proyectos, productos, eventos, y el nivel académico, y utilizando los grá�cos que se estaban generando en la base de datos para buscar satisfacer las necesidades analíticas, se han propuesto un conjunto de requerimientos analíticos presentados a continuación: 1. Indicadores a) Conteo de proyectos por investigador. b) Conteo de proyectos por área de conocimiento. c) Conteo de proyectos por área de aplicación. d) Conteo de proyectos por institución. e) Conteo de producto por investigador. f ) Conteo de producto por área de conocimiento. g) Conteo de producto por área de aplicación. h) Conteo de producto por institución. i) Conteo de evento por investigador. 2. Reportes a) Los proyectos del investigador. b) Los proyectos por área de conocimiento. c) Los proyectos de la institución. d) Los productos del investigador e) Los productos del área de aplicación f ) Los eventos de los investigadores g) Nivel académico del investigador. CAPÍTULO 4. MARCO APLICATIVO 93 4.8. Desarrollo de los requerimientos de información Esta fase consiste en la creación de los indicadores de gestión usando la herra- mienta de inteligencia de negocio (Tableau), de forma tal que puedan satisfacerse los requerimientos analíticos planteados previamente. Para esto se debe con�gurar desde la herramienta a utilizar la conexión a la base de datos en este caso es la conexión a PostgreSQL, realizar las consultas que satisfacen los requerimientos analíticos para luego de forma sencilla poder visualizar los distintos indicadores dispuesto de una forma ordenada. Por último se realiza una veri�cación de los datos para con�rmar la exactitud de los indicadores. 4.8.1. Con�guración de la conexión Implica integrar la implementación del modelo dimensional ubicado en el almacén de datos PostgraSQL en Tableau, de forma que se puedan manipular los datos dentro de la herramienta de inteligencia de negocio. Figura 4.42: Creación de la conexión con la fuentes de dato desde Tableau Tableau enlaza las distintas tablas a partir de atributos clave, un atributo clave es aquel que su nombre que se repite en dos tablas, Tableau realiza una unión entre dichas tablas por lo que se puede navegar entre los atributos de dichas tablas. CAPÍTULO 4. MARCO APLICATIVO 94 Figura 4.43: La tabla de hecho investigación con sus dimensiones A continuación se detallara los elementos que conforman la fuente de datos. Figura 4.44: Elemento de almacén de datos 4.8.2. Generador de los indicadores de gestión Disponibles los datos en la herramienta de inteligencia de negocio se procede a desarrollar los indicadores de gestión son indicadores e�ciente, es decir miden los resul- tados en �n que se cumplan con la propuesta de los requerimientos analíticos señalados CAPÍTULO 4. MARCO APLICATIVO 95 previamente. Y mostrar los reportes que fueron solicitados La construcción de los indicadores de gestión implico la evaluación de las distintas formas como pueden observarse los mismos y la forma de distribuir los indicadores de gestión dentro de la fuente de datos de forma que se tuviera una lógica al ser observado. 4.8.3. Desarrollo y distribución de consultas Para la realización de las consultas, se ha optado por seleccionar la tabla de hecho investigación con sus dimensiones asociadas, para luego observar las dimensiones con sus hechos. Una de las ventajas que ofrece Tableau es que permite las agrupaciones de las dimensiones a las tabla de hecho siempre que esta tenga una relación con esas tablas. Se muestran a continuación. 4.8.3.1. Tabla de hecho de investigación Se presentan todas las tablas con que se relaciona la tabla de hecho investigación, que se desea analizar para responder los indicadores y mostrar los reportes nombrado anteriormente. 1. Indicadores a) Proyectos por investigador. Se puede observar desde la fuente de datos la �gura 4.44, permite seleccionar la unión que se desea tener. lo que se quiere analizar y observar. Figura 4.45: Conteo de proyectos del investigador b) Proyectos por área de conocimiento. Se provee las área de conocimiento para la clasi�cación de los proyectos según las áreas. CAPÍTULO 4. MARCO APLICATIVO 96 Figura 4.46: Conteo de proyectos por área de conocimiento Figura 4.47: Grá�ca de conteo de proyectos del investigador c) Proyectos por área de aplicación. Provee las áreas de aplicación para saber las distintas áreas que siguen los proyectos. CAPÍTULO 4. MARCO APLICATIVO 97 Figura 4.48: Conteo de proyectos por área de aplicación Figura 4.49: Grá�ca de conteo de proyectos por área de aplicación d) Proyectos por área de institución. Provee las instituciones a la que un proyecto puede pertenecer. CAPÍTULO 4. MARCO APLICATIVO 98 Figura 4.50: Conteo de proyectos por institución Figura 4.51: Grá�ca de conteo de proyectos por institución e) Producto por investigador. Se puede observar desde la fuente de datos la �gura 4.44, permite seleccionar la unión que se desea tener. lo que se quiere analizar y observar. CAPÍTULO 4. MARCO APLICATIVO 99 Figura 4.53: Cantidad de productos por institución Figura 4.52: Conteo de producto del investigador f ) Producto por área de institución. Provee las instituciones a la que un producto puede pertenecer. g) Producto por área de conocimiento. Se provee las área de conocimiento para la clasi�cación de los productos según las áreas. CAPÍTULO 4. MARCO APLICATIVO 100 Figura 4.54: Conteo de productos por área de conocimiento Figura 4.55: Grá�ca de conteo de productos por área de conocimiento h) Producto por área de aplicación. Provee las área de aplicación para saber las distintas áreas que siguen los productos. CAPÍTULO 4. MARCO APLICATIVO 101 Figura 4.56: Conteo de productos por área de aplicación Figura 4.57: Grá�ca de conteo de productos por área de aplicación i) Eventos por investigador. Se puede observar los eventos de los investiga- dores y el conteo de los eventos. CAPÍTULO 4. MARCO APLICATIVO 102 Figura 4.58: Conteo de eventos por investigador 2. Reportes a) Proyectos por investigador. Se puede observar en la �gura 4.59, los pro- yectos del investigador Figura 4.59: Los proyectos del investigador b) Proyectos por área de conocimiento. Se puede observar los proyectos que hay por área de conocimiento. CAPÍTULO 4. MARCO APLICATIVO 103 Figura 4.60: Los proyectos del área de conocimiento c) Proyectos de la institución. Se puede observar los proyectos de las insti- tuciones. Figura 4.61: Los proyectos de las instituciones d) Productos del investigador. Se puede observar los proyectos del investi- gador. CAPÍTULO 4. MARCO APLICATIVO 104 Figura 4.62: Los productos del investigador e) Productos del área de aplicación. Se puede observar los proyectos del área de aplicación. Figura 4.63: Los productos del área de aplicación f ) Evento de los investigadores. Se puede observar los eventos de los investiga- dores CAPÍTULO 4. MARCO APLICATIVO 105 Figura 4.64: Evento de los investigador g) Nivel académico por investigador. Se puede observar desde la fuente de datos la �gura 4.44, permite seleccionar la unión que se desea tener. lo que se quiere analizar y observar. Figura 4.65: El nivel académico de los investigador 4.8.4. Veri�car la calidad de los datos en la herramienta de manipulación y visualización de datos Una vez generado la visualización de los datos, se realiza la veri�cación de los datos. En este caso fueron analizadas las distintas dimensiones lo cual implica la realización de consultas sobre la base de datos relacional ajustando los indicadores de gestión a partir de los �ltros planteados las fuentes de datos para comprobar su igualdad. Cantidad de proyecto. Como en la �gura 4.66, la consulta al sistema de la base de datos muestra el mismo resultado que en la consulta en Tableau. CAPÍTULO 4. MARCO APLICATIVO 106 Figura 4.66: Veri�cación de la tabla de hecho investigación con base de datos Figura 4.67: Veri�cación de la tabla de hecho investigación con base de datos Cantidad de producto. Como en la �gura 4.67, la consulta al sistema de la base de datos muestra el mismo resultado que en la consulta en Tableau. Cantidad de eventos. Como en la �gura 4.68, la consulta al sistema de la base de datos muestra el mismo resultado que en la consulta en Tableau. Nivel Académico de los investigadores. Como se observa en la �gura 4.69, la consulta al sistema de la base de dato muestra el mismo resultado que la consulta en Tableau. CAPÍTULO 4. MARCO APLICATIVO 107 Figura 4.68: Veri�cación de la tabla de hecho investigación con base de datos Figura 4.69: Veri�cación de la tabla de hecho de nivel académico con base de datos CAPÍTULO 4. MARCO APLICATIVO 108 4.9. Implementación Debido a que el trabajo presentado forma parte de una solución de inteligencia de negocio para un trabajo especial de grado, su implementación dentro de la coordinación no trabajo con datos reales, por tanto las pruebas de aceptación no fue realizada. Esto genera que dicha fase de desarrollo de la solución no sea ejecutada de forma total. Con estas herramientas, tal y como se explicó en el capítulo anterior, se integró la capa física con el modelo del negocio, y éste a su vez con la capa de presentación que es la que se exhibe a los usuarios. 4.9.1. Ajuste de las consultas Para el ajuste de consultas se realizaron pruebas de visualización de los indicadores para comprobar la vialidad en la forma como se estaban desplegando los indicadores de gestión. De estas reuniones con el tutor se plateo los indicadores y reportes, para así diseñar el modelo dimensional. Conclusiones y recomendaciones Los fundamentos teóricos aprendidos en la carrera y los estudios realizados para el desarrollo del seminario y la tesis fueron importantes para el cumplimiento de los objetivos planteados, dado a que de esta forma, se obtuvieron las bases sobre los co- nocimientos y experiencia necesarios para el desarrollo de la solución de inteligencia de negocio. Este desarrolló es un prototipo de una solución de inteligencia de negocio para la Coordinación de Investigación, ya que no se logro trabajar con los datos reales. En la construcción de la solución de negocio se desarrolló un modelo dimensional que permite observar los proyectos, productos, eventos, y nivel académico a partir de distintas perspectivas. La utilización de la metodología propuesta por Ralph Kimball para el desarrollo de soluciones de inteligencia de negocio facilitó el cumplimiento de los objetivos planteados. Se logró desarrollar una solución adaptada a las necesidades y requerimientos de la Coordinación de Investigación. Sin embargo, debido a que el trabajo de investigación se efectuó en un ambiente de pruebas y no en un ambiente de producción, algunas tareas se realizaron parcialmente. La �exibilidad a la hora de realizar informes o visualizar indicadores usando grá�- cos permite el análisis de datos de forma e�ciente. La realización de nuevas consultas y grá�cos a partir de necesidades presentadas pueden ser atendidas rápidamente. La facilidad de uso se traduce en que el sistema es capaz de resolver necesidades analíticas sin necesidad de que el usuario �nal recurra a programadores que tengan que generar un nuevo elemento para la obtención de información. Como recomendaciones generales tenemos: Se plantea realizar un proceso de adiestramiento a los usuarios en el uso de las herramientas. Ajustar las consultas en función a necesidades adicionales de los usuarios e im- plementar efectivamente la solución en la organización. Se plantea establecer la conexión con la base de datos real para la implementación de los indicadores y que sea de gran utilidad para la toma de decisiones. Hacer uso extensivo de la herramienta Tableau, ya que es una herramienta de fácil manejo por el usuario, y entrenar a los usuarios en su uso para que puedan generar mucha más información que la mostrada en este proyecto. 109 Bibliografía [Andrade, 2005] Andrade, S. (2005). Diccionario de Economía (3era ed.). Andrade. [CoorInv, 2011] Coordinación de Investigación. (2011). ¿Quiénes So- mos?. Caracas, Venezuela: Facultad de Ciencias de la Universidad Central de Venezuela. Recuperado en julio 2016 de: http://www.coordinv.ciens.ucv.ve/ investigacion/quienes.php [Pérez, 2016] Pérez V. (2016). GENCI�2 Sistema de Gestión de In- formación Cientí�ca para la Coordinación de Investi- gación de la Facultad de Ciencias de la UCV . Cara- cas, Facultad de Ciencias de la Universidad Central de Venezuela (UCV). [Borges, 2006] Borges C. & Rivero A. (2006). Generador de Sitios Web de Centros de Investigación. Centro de Ingeniería de Software y Sistemas, Facultad de Ciencias, Univer- sidad Central de Venezuela, Caracas, Venezuela. Re- cuperado en julio 2015, de: http://www.coordinv. ciens.ucv.ve/investigacion/genci/index.php [Prior, 2007] Prior V. (2007). Glossary of Terms used in Competitive Intelligence and Knowledge Management. Knowledge- Board. [Thomas, 2005] Thomas M. & Carolyn E. (2005). �Sistemas de bases de datos�. Pearson Education. [Michael, 2007] Michael, V. (2007). Administración de bases de da- tos Diseño y desarrollo de aplicaciones. México: McGRAW-HILL/INTERAMERICANA EDITORES, S.A. DE C.V. [Date, 2001] Date, C. (2001). Introducción a los sistemas de Base de datos. México: Pearson Educación 110 http://www.coordinv.ciens.ucv.ve/investigacion/quienes.php http://www.coordinv.ciens.ucv.ve/investigacion/quienes.php http://www.coordinv.ciens.ucv.ve/investigacion/genci/index.php http://www.coordinv.ciens.ucv.ve/investigacion/genci/index.php BIBLIOGRAFÍA 111 [Ramaskrishnan, 1999] Ramakrishnan, R. & Gehrke, J. (1999). Database Ma- nagement Systems. US: McGRAW-HILL Higher Edu- cation [CCM, 2016] CCM. (2016). Administración de bases de datos (DBMS). Recuperado en Julio 2016 de: http://es.ccm.net/contents/ 66-introduccion-bases-de-datos [Peña, 2006] Peña A. (2006). inteligencia de negocio: Una Propues- ta para su Desarrollo en las organizaciones. Primera Edición. Instituto Politécnico Nacional. México: INS- TITUTO POLITÉCNICO NACIONAL [Cano, 2007] Cano, J. (2007). Business Intelligence: competir con información. Madrid: Fundación Cultural Banesto . [1] Planeaux, D., & Alvin, D. (2007). Oracle Business Intelligence Standard Edition One. California: Oracle Parkway. [sinnexus, 2016] Sinnexus. (2016). Data Warehouse. Recuperado en Julio 2016 de: http://www.sinnexus.com/business_ intelligence/datamart.aspx [DWH, 2010] Buigues, A. (2010). Arquitectura de un Da- ta Warehouse. Recuperado en Julio 2016 de: http://anabuigues.com/2010/03/05/ arquitectura-de-un-data-warehouse/ [DWH, 2015] Pacheco, O. (2015). Características de un Data Warehouse. Recuperado en Julio 2016 de: http://dwhucv.blogspot.com/p/ caracteristicas-de-un-datawarehouse.html [Inmon, 2002] Inmon, W. (2002). Building the Data Warehouse. Ca- nada: Technical Publishing Group. [Inteligencia de Negocios, 2017] Inteligencia de Negocios. (2017). Inteligencia de Nego- cios. Recuperado en Enero de 2017, de: http://www. idensa.com/ [Kimball, 2010] Espinosa, R. (2010). 15.2. Kimball vs In- mon. Ampliación de conceptos del Modelado Dimensional. Recuperado en Julio 2016 de: https://churriwifi.wordpress.com/2010/04/19/ 15-2-ampliacion-conceptos-del-modelado-dimensional http://es.ccm.net/contents/66-introduccion-bases-de-datos http://es.ccm.net/contents/66-introduccion-bases-de-datos http://www.sinnexus.com/business_intelligence/datamart.aspx http://www.sinnexus.com/business_intelligence/datamart.aspx http://anabuigues.com/2010/03/05/arquitectura-de-un-data-warehouse/ http://anabuigues.com/2010/03/05/arquitectura-de-un-data-warehouse/ http://dwhucv.blogspot.com/p/caracteristicas-de-un-datawarehouse.html http://dwhucv.blogspot.com/p/caracteristicas-de-un-datawarehouse.html http://www.idensa.com/ http://www.idensa.com/ https://churriwifi.wordpress.com/2010/04/19/15-2-ampliacion-conceptos-del-modelado-dimensional https://churriwifi.wordpress.com/2010/04/19/15-2-ampliacion-conceptos-del-modelado-dimensional BIBLIOGRAFÍA 112 [Eckerson, 2012] Eckerson, W. (2012). For Payés to Build a Data Wa- rehouse. Recuperado en Julio 2016 de:http://www. bi-bestpractices.com/view-articles/4770 [Kimball, 2002] Kimball R. & Ross M. (2002). The Data Warehouse Toolkit. Canada: Wiley Computer Publishing. [Kimball, 1998] Kimball R. (1998). The Data Warehouse Life Cycle Toolkit. Canada: Wiley Computer Publishing. [Bernabeu, 2009] Bernabeu, R..(2009).Datawarehouse manager. Recu- perado en Julio 2016 de: http://www.dataprix.com/ datawarehouse-manager#x1-520003.4.5.3 [PosrgreSQL, 1996] The PostgreSQL Global Development Group. (1996- 2015). PostgreSQL. Recuperado en julio 2015, de: http://www.postgresql.org/about/ [2nsPostgreSQL, 2001] 2ndQuadrant Ltd. (2001-2015). 2ndQuadrant Profes- sional PostgreSQL. Recuperado en julio 2015, de: http://2ndquadrant.com/es/postgresql/ [Rouda, 2014] Rouda, N. & Anlyst, S. (2014). Getting Real About Big Data : Build Versus Buy. Re- cuperado en Julio 2016 de: http://www. oracle.com/us/corporate/analystreports/ esg-getting-real-bigdata-2228170.pdf [Tableau, 2016] © 2003-2016 Tableau Software. Todos los derechos re- servados. Recuperado en Octubre de: http://www. tableau.com/es-es/about/leadership#aselipsky [TableauPDF, 2016] Kamkolkar, N. & Fields, E. & Rueter, M.(2016). Ta- bleau para la empresa: descripción general de TI. ta- bleau software. [Pentaho, 2016] bligoo. (2016). Pentaho Open BI. Recuperado en Noviembre de:http://cognus2.bligoo.cl/content/ view/1020771/Pentaho-Open-BI.html [OracleBI,2016] GoLive. (2016). Oracle Business Intelligence. Recupe- rado en Noviembre de:http://onegolive.com/es/ portfolio-golive-soluciones-consultoriaerp-crm-bi/ oracle-bi http://www.bi-bestpractices.com/view-articles/4770 http://www.bi-bestpractices.com/view-articles/4770 http://www.dataprix.com/datawarehouse-manager#x1-520003.4.5.3 http://www.dataprix.com/datawarehouse-manager#x1-520003.4.5.3 http://www.oracle.com/us/corporate/analystreports/esg-getting-real-bigdata-2228170.pdf http://www.oracle.com/us/corporate/analystreports/esg-getting-real-bigdata-2228170.pdf http://www.oracle.com/us/corporate/analystreports/esg-getting-real-bigdata-2228170.pdf http://www.tableau.com/es-es/about/leadership#aselipsky http://www.tableau.com/es-es/about/leadership#aselipsky http://cognus2.bligoo.cl/content/view/1020771/Pentaho-Open-BI.html http://cognus2.bligoo.cl/content/view/1020771/Pentaho-Open-BI.html http://onegolive.com/es/portfolio-golive-soluciones-consultoriaerp-crm-bi/oracle-bi http://onegolive.com/es/portfolio-golive-soluciones-consultoriaerp-crm-bi/oracle-bi http://onegolive.com/es/portfolio-golive-soluciones-consultoriaerp-crm-bi/oracle-bi BIBLIOGRAFÍA 113 [Gartner, 2014] Gartnet Magic Quadrant. Recuperado en Noviembre de 2016 de: http://www.gartner.com/technology/ research/methodologies/research_mq.jsp. [Indicador,2014] ALTAG. (2014). 85% de las empresas no anali- za correctamente los recursos. Recuperado en Mar- zo de 2017 de: http://www.altag.net/wp-content/ uploads/2014/03/indicadores1.jpg [Planeaux, 2007] Planeaux, D. & Alvin, D. (2007). Oracle Business Intelligence Standard Edition One. California: Oracle Parkway. http://www.gartner.com/technology/research/methodologies/research_mq.jsp. http://www.gartner.com/technology/research/methodologies/research_mq.jsp. http://www.altag.net/wp-content/uploads/2014/03/indicadores1.jpg http://www.altag.net/wp-content/uploads/2014/03/indicadores1.jpg Problema de Investigación Situación Actual Planteamiento del Problema Solución Propuesta Objetivo General Objetivo Específicos Justificación Alcance Marco Conceptual Facultad de Ciencias Estructura Organizativa Coordinación de Investigación Indicadores Criterios de los Indicadores Objetivo de un indicador Características Tipología de Indicadores Inteligencia de Negocio (Business Intelligence) Inteligencia Negocio Definición de Inteligencia de Negocio Características Niveles de Soluciones de Inteligencia de Negocio Arquitectura de una Solución de Inteligencia de Negocio Fuentes de Datos Procesos de Extracción, Transformación y Carga (ETL) Almacén de Datos (Data Warehouse) Definición Características Arquitectura Metadata Requerimientos de un DWH Bodega de Datos (Data Mart) Estrategias de Construcción Modelo Dimensional del DWH Definición Tabla de Dimensión Tabla de Hechos Esquema Estrella (Star Scheme) Esquema Copo de Nieve (Snowflake Scheme) Esquema Constelación (Starflake Scheme) Granularidad Jerarquía Agregación Herramientas Tecnológicas Herramientas de Análisis y visualización Reportes Indicadores Herramienta de Extracción, Transformación y Carga (ETL) Pentaho Pentaho Data Integration Herramienta para crear la bodega de datos (Datamart) PostgreSQL Herramientas de Visualización Tableau Marco Metodológico Metodología Descendente (TOP-DOWN) Metodología de Bill Inmon Parte 1: Desarrollo de Sistemas Operacionales Parte 2: Desarrollo del almacén de datos Parte 3: Uso del Almacén de Datos Plan de Migración (Migration Path) Metodología Ascendente (BOTTOM-UP) Metodología de Ralph Kimball Planificación del Proyecto Definición de los Requerimientos del Negocio Diseño de la Arquitectura Selección de productos e instalación Diseño de Datos o modelado dimensional Especificación y desarrollo de aplicaciones analíticas Implementación Despliegue y Crecimiento Metodología a seguir Marco Aplicativo Planificación del Proyecto Definición de los Requerimientos Diseño de la Arquitectura Técnica Selección de Productos e Instalación Modelo Dimensional Diseño físico Diseño y Construcción de procesos ETL Diseño de Procesos de ETL y Desarrollo (almacén de datos) Verificar la calidad de los datos Verificación de la calidad de los datos de los componentes del modelo implementado Verificación de la tabla de hecho investigación con sus dimensiones Detallar los requerimientos según el modelo Desarrollo de los requerimientos de información Configuración de la conexión Generador de los indicadores de gestión Desarrollo y distribución de consultas Tabla de hecho de investigación Verificar la calidad de los datos en la herramienta de manipulación y visualización de datos Implementación Ajuste de las consultas